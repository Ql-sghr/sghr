IPC主分类,发明名称,摘要
G01M13/028  ,一种减速机的智能故障检测方法 [发明],本发明公开了一种减速机的智能故障检测方法，本发明设计的技术方案步骤包括：S10：采集减速机易损部件的振动信号和声音信号；S20：对所述振动信号和声音信号进行过滤；S30：将过滤后的振动信号和声音信号依次输入卷积神经网络和长短期记忆网络进行训练，获取振动信号特征和声音信号特征；S40：将所述振动信号特征与声音信号特征与减速机历史的工作特征进行比较，获取故障信息；本申请通过对信号进行过滤并依次输入卷积神经网络和长短期记忆网络，减少计算量并补全信号特征，提高检测结果。
G10L19/00  ,音频处理方法、装置、计算机设备和存储介质 [发明],本申请涉及一种音频处理方法、装置、计算机设备、存储介质和计算机程序产品。本申请实施例可应用于云技术、人工智能、智慧交通、辅助驾驶等各种场景。所述方法包括：获取音频缓冲区的当前累积数据量和当前网络抖动值；基于当前网络抖动值确定各个候选缓冲等级对应的累积数据量条件，基于当前累积数据量和累积数据量条件，从各个候选缓冲等级中确定音频缓冲区对应的目标缓冲等级；基于目标缓冲等级确定目标数据包类型和目标数据包类型对应的目标压缩参数；基于目标压缩参数，压缩音频缓冲区中属于目标数据包类型的音频数据包；音频缓冲区中的音频数据包用于解码播放。采用本方法能够提高音频播放质量。
G10L15/07  ,一种音频信息内容识别方法 [发明],本发明公开了一种音频信息内容识别方法，涉及音频识别技术领域，本发明提供的方法能够精准对音频信息进行分析，在针对少量用户使用时，能够适应性建立对应用户的习惯数据库，能够识别出系统在识别个人因为习惯发音错误的内容，并针对错误内容进行正确文本的匹配再识别；之后建立一个纠偏的语音信号来调整，后续涉及到声纹识别出来后自动替换纠偏的语音信号来进行识别，使得本申请提供的音频识别更加个性化；本发明简单有效，且易于使用。
G06F16/34  ,基于多模态大语言模型的电话录音摘要提取方法、装置 [发明],本发明提出一种多模态大语言模型的电话录音摘要提取方法，本发明提出一种基于多模态大语言模型的电话录音摘要提取方法，该方法应用于用户侧和服务侧，当用户侧向服务侧发送电话录音摘要提取请求后，服务侧中经过预先训练过的多模态大语言模型进行请求解析、特征提取后生成符合要求的电话录音摘要，在准确生成电话录音摘要的过程中对录音数据准确识别、高效处理，增强了用户体验，同时提升了用户办事效率。
G10L21/0208  ,基于模型融合的语音降噪方法、装置及存储介质 [发明],本申请公开了一种基于模型融合的语音降噪方法、装置及存储介质，涉及语音处理技术领域，其中，上述方法包括：将与待降噪语音信号对应的待降噪语音特征输入到目标判别模型，得到判别降噪结果和参考噪声信息，判别降噪结果包括第一降噪语音特征，参考噪声信息为估计出的待降噪语音特征中的噪声信息；将待降噪语音特征和参考噪声信息输入到目标生成模型，得到第二降噪语音特征，第二降噪语音特征为目标生成模型基于述参考噪声信息对待降噪语音特征进行降噪处理得到的语音特征；对第一降噪语音特征和第二降噪语音特征进行融合，得到融合降噪语音特征，并将融合降噪语音特征转换为与融合降噪语音特征对应的已降噪语音信号。
G10H1/00  ,基于大模型的多媒体资源的生成方法、装置及存储介质 [发明],本申请公开了一种基于大模型的多媒体资源的生成方法、装置及存储介质，涉及语音处理技术领域，该方法包括：对目标对象的输入数据进行解析，得到至少包括文本提示信息和多媒体提示信息的提示信息；将基于文本提示信息生成的文本提示模板输入至大模型，得到大模型输出的多媒体描述信息，对多媒体提示信息进行编码，得到多媒体提示信息的编码信号，将编码信号量化为多媒体特征向量；将多媒体描述信息对应的信息特征向量和多媒体特征向量发送至特征融合模型，得到特征融合模型输出的融合向量；对融合向量进行解码，以生成融合向量对应的多媒体资源，解决了如何使用大模型生成更符合用户需求的多媒体资源的技术问题，生成更符合用户需求的多媒体资源。
H04H20/59  ,一种应急广播音量自动调节方法、装置、电子设备及介质 [发明],本申请涉及数据处理技术领域，尤其是涉及一种应急广播音量自动调节方法、装置、电子设备及介质，方法包括识别每个现场音频数据对应的声音响度，并基于每个现场音频数据的声音响度与预设标准响度，判断待监测区域内是否存在异常子区域；当异常子区域对应的风力不超过预设风力时，根据异常子区域对应的角度调整量和音量调整量确定第一调整指令，并按照第一调整指令进行调整；当异常子区域对应的风力超过预设风力时，根据目标传播响度影响率、异常子区域的声音响度以及预设标准响度，确定第二调整指令，按照第二调整指令对待调整广播设备进行调整。本申请能够在不同风力下，提高调节应急广播音量时的准确性。
G10L21/02  ,音频数据处理方法、装置、介质、设备及程序产品 [发明],本申请公开了音频数据处理方法、装置、介质、设备及程序产品，涉及计算机技术领域，方法包括：获取待处理音频数据；分别获取当前音频算法集与多个候选算法集间的听感差异信息和开销差异信息；听感差异信息用于指示待处理音频数据分别经当前音频算法集和候选算法集对应的音频处理后在听觉感知维度的质量差异，开销差异信息用于指示分别运行音频算法集和候选算法集的算法所需运算资源消耗的差异；根据听感差异信息和开销差异信息确定多个候选算法集中的目标算法集；基于目标算法集对待处理音频数据进行音频处理，得到目标音频数据。本申请能够避免设备额外音频开销，避免设备卡顿和死机。
G10L15/22  ,一种基于语义依存分析的语句多意图识别方法及装置 [发明],本申请公开了一种基于语义依存分析的语句多意图识别方法及装置，可应用于语音识别技术领域。获取文本交互语句，识别文本交互语句的领域分类结果，并基于语义依存分析获得文本交互语句中的每两个实体之间的语义依存关系。当领域分类结果为生活技能领域时，通过生活技能实体识别模型获取文本交互语句中的各个实体和每个实体的实体类型。基于实体之间的语义依存关系对文本交互语句中的技能名称类实体进行意图构建，获取包括技能名称类实体的单意图结构化表示。组合各个技能名称类实体分别对应的单意图结构化表示，获得多意图结构化表示。在确定领域分类结果为生活技能领域后，执行该领域对应的多意图解析过程即可，可提高语句多意图解析效率。
G16H50/30  ,基于声响的睡眠呼吸评价及辅助调节方法、系统和装置 [发明],本发明提供基于声响的睡眠呼吸评价及辅助调节方法、系统和装置，通过从用户睡眠过程各种声响信号中识别睡眠呼吸声响信号并得到睡眠呼吸声响动力学信号，提取睡眠呼吸声响事件信息，并通过睡眠姿势体位信息、睡眠时相分期和脑状态变化特征进一步校正事件强度，生成睡眠呼吸评价报告；对所述睡眠呼吸动力学信号进行时间序列预测分析，结合用户当前睡眠呼吸状况，生成睡眠呼吸辅助调节策略并通过信号接口发送睡眠呼吸调节设备，以实现用户睡眠呼吸的动态辅助调节；通过睡眠呼吸声音的创新评估和睡眠呼吸辅助调节的一体化架构，辅助用户睡眠和提高睡眠质量。本发明能够实现睡眠呼吸行为的科学检测评估和高效动态辅助调节。
G06F30/31  ,一种基于语音交互的电子设计自动化软件架构 [发明],本发明属于电子设计自动化技术领域，具体公开了一种基于语音交互的电子设计自动化软件架构，基于MVC模式设计，包括：硬件绘制层，负责电子元件的绘制和隔离的工作；UI界面层，负责界面显示和人机交互的工作；核心逻辑层，用于响应UI界面层的服务请求，对接调用硬件绘制层，并将产生的显示请求反馈至UI界面层；硬件绘制层包括硬件绘制模块和封装模块，UI界面层包括语音输入模块、绘制显示模块、控件库、对话框模块、消息循环模块和设置模块，核心逻辑层包括通用模块和功能模块。本发明提升了EDA软件的运行效率和代码的维护效率，提升了PCB板的设计效率，降低了研发和维护的工作量。本发明适用于板级EDA的绘制。
G06T19/00  ,3D数字人唇形实时驱动方法、装置、终端和存储介质 [发明],本公开提供3D数字人唇形实时驱动方法及装置、终端和存储介质。3D数字人唇形实时驱动方法包括：获取训练音频和训练BS数据，得到训练音频‑BS数据对；利用训练音频‑BS数据对训练卷积神经网络模型，得到经训练的卷积神经网络模型；将音频输入经训练的卷积神经网络模型以输出BS数据；基于音频和BS数据进行3D数字人唇形的驱动和音频的同步播放。本公开的方法提高了训练模型的泛化能力，且通用性更强，能够保证3D数字人唇形驱动的实时性。
G10L13/10  ,基于大模型的语音生成方法及装置、存储介质、电子装置 [发明],本申请公开了一种基于大模型的语音生成方法及装置、存储介质、电子装置，涉及语音处理领域，上述方法包括：对目标对象输入的用户指令进行解析，以确定用户指令对应的语言风格信息，并生成语言风格信息对应的第一语音；确定第一语音的第一梅尔频谱和第二语音的第二梅尔频谱；根据第一梅尔频谱提取第一语音的第一音色向量；以及根据第二梅尔频谱提取第二语音的第二音色向量；删除第一语音对应的第一语音向量中的第一音色向量，得到第二语音向量，并在第二语音向量中添加第二语音对应的第二音色向量，以生成第三语音，将第三语音确定为语音助手输出的语音，基于上述方案，解决了现有技术中语音助手语料库单调，缺乏语言风格上的变化等问题。
G10L17/26  ,一种基于云端检测鸟类鸣声的方法及系统 [发明],本发明公开了一种基于云端检测鸟类鸣声的方法及系统，所述方法包括：接收智能终端获取的原始声音数据；对所述原始声音数据进行处理，分离得到鸟类鸣声数据；以及根据所述鸟类鸣声数据，确定与所述鸟类鸣声数据对应的鸟类信息，并将所述鸟类信息发送给所述智能终端。本发明通过用户随身携带的智能终端采集环境声音，再在云端通过两组不同的神经网络模型对环境声音中的鸟类鸣声分别进行分离与识别，从而确定相应的鸟类信息，可以精准识别鸟类声纹特征，无需额外的硬件设备即可实时处理、分析和反馈环境中的鸟类信息，方便随身使用、应用范围广，易于推广及科普鸟类信息。
G10L21/0216  ,远程会议通信智能降噪方法及系统 [发明],本发明涉及电通信技术领域，提供远程会议通信智能降噪方法及系统，包括：通过麦克风阵列采集音频信号获取环境信号和音频预处理信号，同时获取参会人员语音信息并进行语音识别。基于语音信号，使用语音增强模块对音频预处理信号进行增强处理得到音频初级处理信号；结合环境信号和音频初级处理信号进行多源噪声消除，获取音频处理信号并播放，解决在远程会议多端连接状态，抑制噪声的参数调整相对复杂，无法满足实时通信要求技术问题，实现有效地降低会议室内外各种噪声的干扰，提高语音质量，在远程会议多端连接状态，实时处理多源带噪语音，使得会议参与者可以更加清晰地听到处于不同连接端的各方声音，从而提高会议的效率和质量技术效果。
G06F16/635  ,基于语音迁移学习的新闻播报个性化音频生成系统及方法 [发明],本发明提供一种基于语音迁移学习的新闻播报个性化音频生成系统及方法，属于语音合成技术领域。所述系统包括：数据采集模块，用于获取用户偏好新闻播报音频合集及播报新闻音频文本；特征提取模块，用于对获取的数据进行特征提取，得到音频声音特征信息及文本特征信息；第一确定模块，用于计算出个性化播报语音选择系数；第二确定模块，用于计算出个性化新闻文本内容选择系数；音频合成播报模块，用于根据个性化播报语音选择系数与个性化新闻文本内容选择系数确定用户个性化音频调控指数，为用户定制个性化新闻音频播报；用户界面，用于为用户提供偏好更改功能，满足用户个性化新闻播报需求。采用本发明，能够精准推荐用户个性化新闻播报音频。
G10L15/26  ,多语种语音转换文本方法、系统、存储介质及电子设备 [发明],本发明提供一种多语种语音转换文本方法、系统、存储介质及电子设备，所述方法包括以下步骤：获取多个语种的语音音频信息和对应的语音转换文本请求和语音转换文本；基于所述语音音频信息、所述语音转换文本请求和所述语音转换文本训练多语种语音文本转换模型；基于训练好的多语种语音文本转换模型将待识别语音音频信息转换为对应的文本信息。本发明的多语种语音转换文本方法、系统、存储介质及电子设备能够将不同语种的语音转换为同一语种的文本信息，快速高效。
G10L15/02  ,语音特征提取加速方法、装置、设备和存储介质 [发明],本发明属于语音识别技术领域，公开了语音特征提取加速方法、装置、设备和存储介质，方法包括：获取原始语音信号；对原始语音信号进行语音特征提取，获得语音特征；在语音特征提取过程中，通过如下步骤计算目标定点值的开方值；将目标定点值移动到固定的q0，得到第二目标定点值x2；预先构建第一查找表，第一查找表存储的是第一预设区间的数值的开方值；若x2在第一预设区间内，则基于第一查找表获取目标定点值的开方值，若x2在第二预设区间内，对x2进行移位，移动到第一预设区间，并结合查表和截断计算目标定点值的开方值；若x2大于第二预设区间的最大值，则采用牛顿迭代法计算目标定点值的开方值。本申请可以加速语音特征提取的速度以及保证精度。
G10L13/08  ,语音合成方法、系统、电子设备及介质 [发明],本申请提供一种语音合成方法、系统、电子设备及介质，所述方法包括：输入文本内容以获取文本词元；获取参考语音以对所述参考语音进行编码获取语音嵌入数据；对所述语音嵌入数据进行特征转换以获取语音特征矩阵；基于所述文本词元和所述语音特征矩阵获取声学词元序列；基于所述文本词元、所述语音特征矩阵和所述声学词元序列获取声学特征以进行语音合成。本申请能够同时接受文本内容和参考语音，进行语音合成，合成后的语音说话内容为文本内容，风格为参考语音风格，包括说话风格、声音和环境。本申请有效降低了语音合成的难度，并且提高了合成语言的人化程度，情感真实且自然。
G10L15/28  ,语音识别加速方法、装置和设备 [发明],本发明属于语音识别技术领域，公开了一种语音识别加速方法、装置和设备，所述方法包括获取原始语音信号；对原始语音信号进行语音识别，获得语音识别结果；其中，在语音识别过程中，采用如下步骤计算目标定点值的对数值；获取目标定点值，将目标定点值移动到固定的q1，获得第二目标定点值；预先构建第一查找表、第二查找表，基于第二目标定点值，利用第一查找表以及插值公式进行插值计算，获得目标定点值的对数值，或者基于第二目标定点值，利用第二查找表获取目标定点值的对数值，无需像现有技术采用泰勒公式需要实时计算很多个数，即无需花费很多时间去计算，本发明能够快速计算出定点的对数，大大加速定点的推理速度，从而加速语音识别的速度。
G10L17/26  ,基于TDNN结构的鸟鸣物种自动识别方法 [发明],本发明涉及语音处理技术领域，提出了基于TDNN结构的鸟鸣物种自动识别方法，包括：采集生态区内的混合鸟鸣数据；基于每一帧信号能量的周期性以及鸟鸣音高的稳定性确定每一帧的鸟鸣音节覆盖率；根据每一帧的单帧能量向量所在聚类簇中每一帧的鸟鸣音节覆盖率、信息逼近系数确定时频掩蔽概率；基于每一帧的鸟鸣音节覆盖率、时频掩蔽概率确定频谱掩蔽值；基于所有帧的频谱掩蔽值构建每个频谱子图的时频掩蔽图；将频谱子图与其时频掩蔽图相乘的结果作为频谱子图的增强鸟鸣特征图；采用TDNN识别模型基于增强鸟鸣特征图确定物种识别结果。本发明通过对频谱图中频谱子图的掩蔽处理，提高了识别模型训练样本的质量，以及鸟鸣物种识别的准确率。
G10L17/26  ,基于特征融合的鸟类声音智能识别方法 [发明],本申请涉及语音处理技术领域，提出了基于特征融合的鸟类声音智能识别方法，包括：采集生态区内不同鸟类的鸟鸣数据；基于每个鸟鸣数据的频谱图采样均匀分块的方式确定每个鸟鸣数据的频谱向量；基于每个鸟鸣数据的频谱向量在自编码器潜在空间每个维度上的投影长度确定音频信息相关系数；基于频谱向量与相同潜在空间维度之间的音频信息相关系数确定维度区分系数；根据频谱向量以及维度区分系数确定鸟鸣特征向量；基于鸟鸣特征向量以及图像识别模型所提取特征向量的特征融合结果确定鸟鸣数据的鸟类识别结果。本申请能够利用不同维度作为坐标系维度，并通过维度递增的方式对相似度较高的鸟鸣数据准确区分，提高鸟类声音的识别准确率。
G10L25/51  ,基于语音分析的森林枪声定位方法 [发明],本申请涉及语音处理技术领域，提出了基于语音分析的森林枪声定位方法，包括：获取森林中的声音信号数据，将每个声音信号采集点的声音信号数据转换为语谱图，根据语谱图中每个数据点的局部能量特征构建局部声音能量密度，根据局部声音能量密度构建声音高能量聚集度，根据语谱图中每个数据点对应的声音高能量聚集度获取语谱图中每帧声音信号的高能频带集中覆盖率，根据高能频带集中覆盖率获取枪声马赫波疑似度，根据枪声马赫波疑似度获取枪声马赫波数据序列，基于枪声马赫波数据序列利用多重信号分类算法获取森林中枪声的方向角度，根据枪声的方向角度完成森林枪声定位。本申请通过马赫波数据序列获取枪声的方向角度，提高森林枪声定位的准确性。
G10L25/51  ,基于音频分解的生物多样性预测方法 [发明],本发明涉及音频信号处理技术领域，具体涉及基于音频分解的生物多样性预测方法，该方法包括：采集一天中不同时刻的各生态音频信号；提取生态音频加窗信号；根据生态音频加窗信号的频域幅值信息结合聚类算法获取生态音频汉宁窗的各聚类类别的类宽度；构建生态音频汉宁窗的时域鸟鸣指数及频域鸟鸣指数；基于此计算生态音频汉宁窗的鸟鸣复杂指数及音频区间的鸟鸣回应指数；获取VMD算法分解时各音频区间的分解层数，结合不同音频区间分解后各分解层数下的模态分量之间的巴氏系数以及各音频区间的声学多样性指数构建生物丰度指数。本发明可实现对生物多样性的准确评估。
G10L21/0208  ,用于野外鸟类声音数据的智能降噪方法 [发明],本申请涉及语音处理技术领域，提出了用于野外鸟类声音数据的智能降噪方法，包括：获取鸟类音频信号数据；根据鸟类音频信号数据获取时序区间，根据时序区间获取音频混叠突出指数；根据音频混叠突出指数获取低混叠效应簇及高混叠效应簇；根据时序区间中波峰点的特征获取鸟鸣存在置信度；根据鸟鸣存在置信度并结合低混叠效应簇及高混叠效应簇获取模态分量惩罚调节系数；根据模态分量惩罚调节系数获取惩罚系数；利用VMD变分模态分解算法基于惩罚系数获取去噪后的鸟类音频信号数据。本申请通过自适应VMD变分模态分解算法中的惩罚因子，提高了对鸟类音频信号数据的去噪效果。
G10L25/51  ,基于机器学习的森林盗猎监测方法及系统 [发明],本申请涉及语音处理技术领域，提出了基于机器学习的森林盗猎监测方法及系统，包括：获取森林盗猎监测的音频信号，对采集的音频信号进行分帧处理，获取每个短时段帧的模态分量，根据每个短时段帧的模态分量的峰值形状和分布特征构建音频峭度关联契合度，根据不同短时段帧之间的音频峭度关联契合度构建音频关联契合矩阵，根据音频关联契合矩阵和音频特征的分析结果计算音频峭度特征系数，根据音频峭度特征系数构建音频信号的森林盗猎监测特征向量，基于森林盗猎监测特征向量利用卷积神经网络模型获取森林盗猎的监测结果。本申请通过音频峭度特征系数反映盗猎活动音频特征，提高对森林盗猎监测的准确性。
G10L21/0208  ,用于生态音频信息的滤波增强方法 [发明],本申请涉及语音处理技术领域，提出了用于生态音频信息的滤波增强方法，包括：获取鸟类音频信号数据；根据鸟类音频信号数据获取频谱能量差异指数；根据频谱能量差异指数获取音频受噪因子；根据音频受噪因子获取噪声受扰指数；根据鸟类音频信号数据获取风声干扰程度指数；根据风声干扰程度指数获取风声干扰调整系数；根据噪声受扰指数及风声干扰调整系数获取维纳滤波平滑调整系数；根据维纳滤波平滑调整系数获取维纳滤波平滑系数；利用维纳滤波算法基于维纳滤波平滑系数获取滤波增强后的鸟类音频信号数据。本申请通过自适应维纳滤波平滑系数，提高了对鸟类音频信号数据的滤波增强效果。
G10L25/51  ,基于语谱特征分析的生态种群评估方法 [发明],本申请涉及语谱特征分析技术领域，提出了基于语谱特征分析的生态种群评估方法，包括：获取生态音频信号的语谱图，以语谱图中每个数据点的中心构建谱特征窗口，根据语谱图中每个数据点的谱特征窗口中数据点的连通域特征、能量梯度幅值和能量值特征构建自然鸣叫指数；以语谱图中每个数据点为中心构建掩蔽监测窗口，根据掩蔽监测窗口中数据点的分布特征计算鸟鸣增强因子，根据自然鸣叫指数和鸟鸣增强因子计算自然鸣叫增强指数，根据自然鸣叫增强指数构建权重系数，基于权重系数利用谱聚类算法获取生态种群评价结果。本申请通过构建自然鸣叫增强指数获取谱聚类算法中的权重系数，提高基于谱聚类算法对生态种群评价的准确性。
G10L17/26  ,基于深度迁移学习的混合鸟鸣识别方法 [发明],本发明涉及语音处理技术领域，提出了基于深度迁移学习的混合鸟鸣识别方法，包括：采集生态区内的混合鸟鸣信号；基于每个频谱子图上每一帧处谐波成分的相关性和衰减特征确定每一帧的鸟鸣帧识别概率；基于每个频谱子图上所有帧的鸟鸣帧识别概率的分布特征确定每个频谱子图上每一帧的帧扩展尺度；基于每个频谱子图上每一帧的帧扩展尺度确定每一帧的鸟鸣特征图；将预训练的识别模型中的权重参数迁移到混合鸟鸣识别模型，基于混合鸟鸣识别模型确定鸟鸣特征图的识别结果。本发明考虑每一帧上谐波成分在频率、时间上的变化特征构建每一帧的鸟鸣特征图训练识别模型，降低源领域与目标领域数据的特征分布差异对迁移效果的影响，提高识别准确率。
G10L25/51  ,基于时频持续性分析的人类活动影响评估方法及系统 [发明],本发明涉及语音分析处理技术领域，具体涉及基于时频持续性分析的人类活动影响评估方法及系统，该方法包括：采集音频信号并进行分帧处理得到各信号帧，构建信号周期的振幅特征组；计算各信号帧的活跃显著因子；根据各信号帧的活跃显著因子、对应振幅的信息熵以及各信号周期的振幅特征组得到各信号帧的有效稳态因子；构建各信号帧的有效置信权重，并结合频域中各频率分量的信号衰减率计算信号帧的高能有效因子；将短时能量及高能有效因子组成有效二维向量；计算各信号帧的高能效持续系数以提取各活动帧，基于活动帧对人类活动影响进行评估。从而实现对人类活动影像进行准确评估，避免传统VAD端点检测算法难以准确判定活动帧的弊端。
G10L13/08  ,一种语音合成方法、装置、设备及可读存储介质 [发明],本发明提供了一种语音合成方法、装置、设备及可读存储介质，通过获取目标文本，通过预训练的文本模型BERT对目标文本进行编码，以生成文本情感编码，获取参考语音，通过预训练的语音模型BERT对参考语音进行编码，以生成语音情感编码；将解析音素与文本情感编码和语音情感编码输入到基于Transformer的先验编码器生成潜在表示编码；调用MAS算法获得对齐矩阵，对齐矩阵的元素为每个音素的发音时长，通过对齐矩阵训练时长预测器，对潜在表示信息的文本特征和语音帧进行对齐和优化，推理时对潜在表示信息进行扩展处理生成目标文本的梅尔频谱，使用基于hifigan的解码器对目标文本的梅尔频谱进行解码处理，生成目标文本的音频波形。解决现有的TTS产品的情感表达有限的问题。
G10L25/51  ,基于声学识别的生物多样性监测方法及系统 [发明],本发明涉及生物多样性分析技术领域，具体涉及基于声学识别的生物多样性监测方法及系统，该方法包括：获取保护区声音语谱图，构建各保护区声音语谱图的无向图，进而获取节点路径序列以及可达中间节点；获取代表路径差异系数，进而获取各节点之间的节点邻近相似指数；根据节点邻近相似指数获取第一聚类簇，获取第一聚类簇的中心频率，获取各第一聚类簇的最外围时频单元，进而获取轮廓不规则系数；获取最外围时频单元的曲率偏差值，进而获取轮廓曲率离散系数，计算轮廓形态复杂指数；获取各第一聚类簇的形态特征向量，进而获取各第二聚类簇，对生物物种进行识别。本发明旨在解决解决生物鸣叫声音和人类活动声音无法进行准确区分的问题。
G10L15/06  ,基于深度学习的手提电脑语音识别方法及系统 [发明],本申请实施例提供一种基于深度学习的手提电脑语音识别方法及系统，通过对待识别语音数据包含的各语音区块进行声学属性向量解析，可以有效地从复杂的待识别语音数据中获取关键信息，提高了语音识别的准确性和效率。其次，使用时空优化模型进行属性向量优化，能够充分利用语音信号中的时空信息，进一步增强语音识别的精确性。此外，通过确定各语音区块关联的干扰特征参数，能够有效地处理并削减语音信号中的干扰，使得在噪声环境下的语音识别更加准确。最后，根据目标语义意图数据对手提电脑进行功能控制，实现了智能交互，极大地提升了用户体验。
G10L15/22  ,一种音视频的生成方法、装置、设备及存储介质 [发明],本申请实施例公开了一种音视频的生成方法、装置、设备及存储介质，该方法包括：通过图像传感器获取包含交互对象的图像，以及通过语音传感器获取语音数据；对图像进行特征分析，得到交互对象的姿态信息；根据交互对象的姿态信息，获取数字人的姿态信息；获取语音数据对应的回复语音数据；根据回复语音数据和数字人的姿态信息，生成数字人视频，数字人视频中数字人的口型与回复语音数据匹配，数字人视频中数字人的姿态与数字人的姿态信息匹配；基于数字人视频和回复语音数据构建音视频，并输出音视频。采用本发明实施例，能够有效提高数字人与交互对象的互动性，从而确保播放的音视频中的数字人更加拟人化。
G10L13/047  ,一种语音合成方法、装置、设备及存储介质 [发明],本申请实施例公开了一种语音合成方法、装置、设备及存储介质，该方法包括：获取文本信息，以及说话人嵌入信息和语言嵌入信息，说话人嵌入信息用于指示基于说话人的语音特征将文本信息进行语音合成，语言嵌入信息指示对文本信息进行语音合成的语言类型；对说话人嵌入信息进行特征提取，得到说话人的语音特征；对文本信息进行编码，得到文本信息的离散编码向量；在优化后的嵌入空间中查找与语言嵌入信息指示的语言类型匹配，且与离散编码向量的距离最近的嵌入向量；基于说话人的语音特征对嵌入向量进行解码，得到文本信息的音频数据。采用本申请实施例，能够确保语音合成得到的音频数据更加拟人化，更加贴近说话人的语音和发音方式。
G10L25/51  ,一种用于智慧监管的多目标监测方法 [发明],本发明公开了一种用于智慧监管的多目标监测方法，属于语音处理技术领域，本发明将原始声音信号进行分段，得到多个子段声音信号，对每个子段声音信号进行小波分解，得到各个子段声音信号的小波分解系数向量，小波分解系数体现的是信号的成分，从而更容易体现声音信号的组成结构，一方面能减少数据量，另一方面能凸显信号的结构，再进行说话人数预测，在数据量大大减少后，人数预测模型结构更简单，计算量更小。找到预测说话人数为1对应的小波分解系数向量，再重构，得到个人的时域声音信号，根据个人的时域声音信号的信号特征，从原始声音信号中找出各个个体的说话声音时段，实现各个说话目标的说话监测。
G10L15/22  ,一种交互式AI智能机器人控制方法与智能机器人 [发明],本发明涉及语音交互、人工智能等技术领域，提供的交互式AI智能机器人控制方法与智能机器人，通过根据语音机器人的历史呼出内容和对话方的历史回应内容，生成历史语音交互场景内容，根据历史语音交互场景内容进行对话意图特征和对话情绪特征提取，模型训练，得到能够识别对话意图和对话情绪的AI对话辅助机器人，当前语音呼出后，获取对话方的当前回应内容，传输给AI对话辅助机器人进行辅助分析，以得到对话方的当前对话意图和当前对话情绪，获取当前对话意图和当前对话情绪，并根据当前对话意图和当前对话情绪，控制语音机器人呼出适配当前对话意图和当前对话情绪的呼出内容，从而实现识别当前对话方的情绪、意图，减少无效的交互和骚扰发生。
G10L15/02  ,音频识别方法、装置、系统和电子设备 [发明],本公开涉及一种音频识别方法、装置、系统、电子设备和存储介质，该方法包括：接收音频识别目标信息，并输入编码器模块得到目标特征向量，其中音频识别目标信息对应的类别数量为至少一个；将目标特征向量和类别数量输入参数推理模块得到模型配置参数；将模型配置参数发送到部署于终端设备的音频识别分类模型，使得音频识别分类模型基于模型配置参数进行配置，并使得终端设备接收到与音频识别目标信息相关联的音频信息后，通过音频识别分类模型得到音频识别结果。本公开实现了终端设备利用一个模型实现声音事件检测和关键词识别的两种功能，有助于终端设备功耗的降低和运行速度的提升，减少了终端设备为得到模型配置参数而进行的模型训练的消耗。
G10L21/0272  ,联合听觉场景分析与深度学习的混合水声信号分离方法 [发明],本申请的实施例涉及声信号分离技术领域，公开了一种联合听觉场景分析与深度学习的混合水声信号分离方法，该方法包括：通过预训练的听觉分割模型对获取到的混合水声信号进行听觉分割，将所述混合水声信号分解成若干个听觉片段；其中，每一个所述听觉片段均用于表征对应的声学事件在听觉场景中的局部描述；通过预训练的深度聚类网络对所述若干个听觉片段进行听觉重组，将来自于同一个声源的听觉片段重组在一起，得到各所述声源对应的水声信号。本申请的实施例提供的联合听觉场景分析与深度学习的混合水声信号分离方法，可实现对水下复杂环境中的混合水声信号的精准分离与重构，分离时抗干扰能力强，稳定性高，为水声目标识别提供了便利。
B60W30/18  ,一种农用拖拉机驱动桥智能控制系统及方法 [发明],本发明提供一种农用拖拉机驱动桥智能控制系统及方法，其中，系统包括：语音信息采集子系统，用于采集目标农户的语音信息；驱动桥控制指令确定子系统，用于根据语音信息，确定目标农用拖拉机的驱动桥控制指令；驱动模式确定子系统，用于基于驱动桥控制指令，确定驱动模式；分配控制方案确定子系统，用于根据驱动模式，确定驱动扭矩分配控制方案；智能控制子系统，用于根据驱动扭矩分配控制方案进行智能控制。本发明的一种农用拖拉机驱动桥智能控制系统及方法，根据农户的语音信息，确定驱动桥控制指令触发的驱动模式。基于驱动模式，确定驱动扭矩分配控制方案进行智能控制，控制更适宜，农机驱动效率更高，降低了车轮磨损和四驱损耗。
G10L25/51  ,一种基于多传感器融合的远场声音分类方法和装置 [发明],本申请涉及一种基于多传感器融合的远场声音分类方法和装置。该方法包括：构建具有多个音频传感器的传感器阵列，所述音频传感器具有置信度，所述置信度用于表征所述音频传感器的可靠性；响应于接收的音频信号，由多个音频传感器对音频信号进行预处理，提取音频特征；将所述音频特征输入至预先训练的声音分类模型，获得初步声音分类结果；将多个传感器的初步声音分类结果输入至融合处理模型，获得最终声音分类结果；依据所述最终声音分类结果，调整所述音频传感器的置信度。本申请融合多个传感器的初步分类结果，获得最终分类结果，同时使用最终分类结果反向计算调整传感器置信度，使传感器置信度判断依据更加丰富和客观，增加远场声音分类准确度。
G10L21/0208  ,一种基于频域自注意力网络的语音质量增强方法及系统 [发明],本发明公开了一种基于频域自注意力网络的语音质量增强方法及系统，首先输入原始语音并进行预处理；然后将处理后频率响应输入频域自注意力网络；最终输出信号并对输出的信号进行后处理得到语音增强信号；频域自注意力网络，包括位置编码模块、N个相同的基本单元模块；位置编码模块包括位置编码层；基本单元模块包括多注意力头层、残差连接和层归一化层、前馈层；N个相同的基本单元模块，其中N由所需网络深度决定。本发明能够实现对语音信号中噪声的去除，在语音通信方具有重要意义。
G06F16/75  ,一种视频处理方法、装置及相关产品 [发明],本申请公开了一种视频处理方法、装置及相关产品。利用视频处理模型对语音模态特征集和图像模态特征集进行特征融合，获得多模态融合特征，其中视频处理模型用于生成多模态融合特征；根据多模态融合特征对待处理视频进行处理，获得待处理视频的处理结果，其中处理结果包括对于待处理视频的分类结果、对于待处理视频的主题生成结果和对于待处理视频的标签提取结果。可见，在本申请中提出对待处理视频中的语音模态特征集和图像模态特征集进行特征融合，以获得多模态融合特征，此时便可以根据该多模态融合特征确定视频的分类、标签提取等结果。如此，在本申请中采用对多种模态特征进行融合的方式来确定视频的处理结果，提高了视频处理效果。
G10L25/63  ,一种基于口才表达的互动方法、装置、设备及存储介质 [发明],本申请提出一种基于口才表达的互动方法、装置、设备及存储介质，基于口才表达的互动方法通过获取口才表达的语音数据，对语音数据进行情感分析，得到原始情感分析结果以及原始情感分析结果的情感高潮点，以及对语音数据进行口才维度分析，得到口才维度分析结果，根据情感高潮点以及原始情感分析结果，对原始情感分析结果进行情感调整，得到调整后的目标情感分析结果，有利于提升情感的传达能力；根据目标情感分析结果以及口才维度分析结果，确定目标互动元素，根据目标情感分析结果以及目标互动元素，生成互动内容，有利于提升口才表达的吸引力以及提高互动内容的参与性，增强参与感以及互动效果。
G10L21/0232  ,用于数据中台的数据智能清洗方法 [发明],本发明涉及数据处理技术领域，具体涉及用于数据中台的数据智能清洗方法，包括：采集语音信号数据；将原始语音数据分成多个数据区间；将任意一个数据区间记为参考数据区间，根据数据区间中数据的变化与对应时间段内的原始语音数据的变化，获得参考数据区间的纯噪声程度；通过比较预设阈值与参考数据区间的纯噪声程度的数值大小获得噪声数据区间和非噪声数据区间；根据噪声数据区间之间的相似性与非噪声数据区间之间的差异性获得每个噪声数据区间的权重；根据每个噪声数据区间的权重对始语音信号数据进行去噪。本发明通过分析语音信号在不同数据区间上的变化，自适应噪声数据区间与非噪声数据区间的权重，使得对语音信号的去噪更彻底。
G06F18/20  ,一种基于大模型的多模态细粒度倾向分析方法及系统 [发明],本发明涉及语音文本分析技术领域，并提供一种基于大模型的多模态细粒度倾向分析方法及系统，所述方法的步骤包括：获取语音数据，将所述语音数据划分为多个语音子数据，将每个所述语音子数据编码为语音子向量；获取每个语音子数据对应的文本子数据，基于预设的编码器将每个所述文本子数据编码为文本子向量；将所述语音子向量输入到预训练的第一模型中，所述第一模型输出第一情绪倾向向量；将所述文本子向量输入到预训练的第二模型中，所述第二模型输出第二情绪倾向向量；所述第一情绪倾向向量和第二情绪倾向向量均包括鸽派情绪值和鹰派情绪值，基于所述第一情绪倾向向量和第二情绪倾向向量确定相互对应的语音子数据和文本子数据的情绪倾向。
G10L15/22  ,用于窗帘控制的智能语音识别电开关 [发明],本发明具体涉及一种用于窗帘控制的智能语音识别电开关，包括电连接的本地MCU、本地存储电路和网络通信电路，在初始的配置阶段，本地MCU还用于网络通信电路与在线服务器交互，在线服务器根据用户音频数据识别用户的控制指令；本申请仅仅需要初始的配置阶段依据在线服务器神经网络模型识别用户的控制指令，然后建立用户的音频电信号特征与用户的控制指令之间的映射表，这种映射表是基于精准的识别建立的，映射表存储在本地存储电路；在非初始的配置阶段也即使用阶段，在本地存储电路查找“用户的音频电信号特征与用户的控制指令之间的映射表”，即可确定待识别音频电信号特征对应的用户的控制指令，不需要再与服务器交互。
G06T13/40  ,基于数字人的视频生成与交互方法、设备、存储介质与程序产品 [发明],本申请实施例提供一种基于数字人的视频生成与交互方法、设备、存储介质与程序产品，在本申请实施例中，基于用户的声音特征和情感标签进行文本转语音处理，以及基于用户的声音特征和表情系数之间的映射关系进行语音转表情处理，并基于语音信号和表情系数渲染数字人模型，以得到数字人模型的视频数据。由此，精准地模拟用户的声音特征，确保了数字人的语音输出不仅听起来自然，而且具有高度的个性化，实现数字人的个性化驱动，提高数字人在声音和动态形象方面的逼真度，进而提高用户体验，提升了数字人的互动性、真实感和沉浸感。
G10L25/51  ,智能识音门铃及其控制方法、存储介质 [发明],本申请应用于门铃技术领域，公开了一种智能识音门铃及其控制方法、存储介质，智能识音门铃包括：状态检测模块，用于获取待检测门的运动状态信号并发送；控制模块，控制模块和状态检测模块连接，用于接收运动状态信号，并在检测到运动状态信号为关门状态时，发送拾音信号；拾音模块，拾音模块和控制模块连接，用于接收拾音信号，获取音频信号并发送；声音识别模块，声音识别模块分别与拾音模块和控制模块连接，用于接收音频信号，并检测音频信号中是否包括预设的标识音，将检测结果发送至控制模块；通信模块，通信模块与控制模块连接，用于向预设的服务器发送控制模块基于检测结果生成的关门情况界面。从而，解决确认关门状态的操作复杂的问题。
G10L15/22  ,多命令词的语音解码识别方法、装置、设备及存储介质 [发明],本申请涉及语音解码技术领域，特别是涉及到一种多命令词的语音解码识别方法、装置、设备及存储介质，其中方法包括：基于转换为token序列的所述命令词列表生成前缀树；基于用户指令的语音识别模型输出，结合前缀树在模型输出中计算当前时间步对应的指定数量的候选序列；识别所述候选序列的前缀序列在所述前缀树中确认当前时间步对应的节点，并基于所述节点的子节点，确定下一个时间步的token搜索范围；对所述token搜索范围进行目标搜索，并根据搜索结果更新扩展所述前缀序列；直到最后一个时间步搜索完毕后，对获得的预选数量的所述候选序列进行二次打分，得到识别结果。本申请解码时长受命令词数量变化影响小，确保了系统处理大量命令词时保持高效性。
G08G1/048  ,一种基于交通数据采集的噪声预警系统、装置及预警方法 [发明],本发明属于交通数据采集技术领域，本发明公开了一种基于交通数据采集的噪声预警系统、装置及预警方法；包括：收集路线实时交通量、实时车辆类型与实时车速；收集噪声分贝数据与噪声信号数据；基于路线实时交通量、实时车辆类型、实时车速与噪声分贝数据训练预测未来k时刻噪声分贝的第一机器学习模型；基于路线实时交通量、实时车辆类型、实时车速与噪声信号数据训练预测未来k时刻频谱的第二机器学习模型；基于噪声信号数据训练实时判别噪声类型的第三机器学习模型；基于预测噪声分贝数据绘制噪声辐射图，将噪声辐射图与预设色深程度比对分析，生成预警指令；基于第三机器学习模型输出与预设比例值比对分析，生成第一调节指令和第二调节指令。
G10L13/10  ,一种基于人工智能的声音克隆方法及系统 [发明],本发明提供了一种基于人工智能的声音克隆方法及系统，该方法通过将原始文本正则化处理，并依次转换为若干待转换句和若干待转换词，获取待转换词的拼音，并将其中各字的拼音进行标注，得到第一标注，将字的拼音中的声母和韵母拆分，并将字的拼音的第一标注赋给韵母，再对字的拼音中的声母进行标注，根据预设规则，确定音素信息，音素信息包括第一标注中的目标标注，然后重新组合词组，并根据用户说话语速，确定重新组合后的各词组之间的停顿时间，最后根据字和对应的音素信息，转换为声学特征，并将声学特征转换为目标波形，根据目标波形，完成声音克隆，可以有效解决仅依靠专业的语义学知识和经验进行人工设计，往往耗时耗力，且效果不好的问题。
G10L15/10  ,一种物联网设备的控制方法、设备及系统 [发明],本申请提供了一种物联网设备的控制方法、设备及系统，属于物联网的技术领域，用于解决相关技术中模糊语音控制技术应用于物联网控制准确性较差的问题，该方法、设备及系统能够基于对语音交互信息和语音交互记录大数据的分析，确定语音交互信息对每一预期控制指令的置信度，能够以模糊语音控制的方式实现物联网设备的控制，确定的预期控制指令的置信度也较为合理，从而有利于提高物联网设备模糊语音控制的控制准确性。
G10L13/08  ,一种人工智能交互方法及人工智能交互系统 [发明],本发明适用于语音交互技术领域，提供了一种人工智能交互方法及人工智能交互系统，所述方法包括以下步骤：接收目标用户语音输入信息，采集目标用户人脸图像；对目标用户语音输入信息进行分析，得到文字信息、方言信息和语速信息；对目标用户人脸图像进行分析，得到目标性别和目标年龄；根据目标性别和目标年龄确定虚拟人像；根据文字信息、方言信息和语速信息确定交互语音信息，使得虚拟人像发出所述交互语音信息。本发明中，虚拟人像的外形和声音特点更能符合用户的倾听喜好；另外，交互语音信息的方言和说话速度能够与用户的方言和说话速度匹配，使得用户感到亲切，体验感更好。
G01H17/00  ,一种设备运行状态监控方法、装置、设备及系统 [发明],本发明提供了一种设备运行状态监控方法、装置、设备及系统，获取位于目标监控区域中的待监测设备的设备运行数据，根据环境数据对应的声纹采集影响因子，确定环境数据对应的声纹处理方式，以按照声纹处理方式，处理初始声纹数据，得到目标声纹数据，消除采集的声纹数据中的环境噪音，使得得到的目标声纹数据为待监测设备的声纹数据，则在基于目标声纹数据确定设备运行状态时，能够提高设备运行状态确定的准确性。另外，检测初始声纹数据的声音采集板采用非接触式安装方式安装在待监测设备的预设距离范围内，相比于直接贴附安装方式，避免待监测设备运行对声音采集板采集声纹数据的影响，提高数据采集准确性，提高后续设备运行状态确定的准确性。
G06T13/40  ,一种基于超参数神经辐射场的人脸语音驱动方法及装置 [发明],一种基于超参数神经辐射场的人脸语音驱动方法及装置，涉及人脸图像处理技术领域，包括以下步骤：S1、将采集到的人像说话视频数据逐帧进行分割并提取出头部特征、音频特征及躯干特征；S2、将所述头部特征和音频特征输入至基于动态神经辐射场相互构建的超参数网络中计算出头部采样点颜色和密度；S3、将所述头部特征和所述躯干特征输入到基于网格的神经辐射场网络提取出躯干采样点颜色和透明度；S4、采用体渲染合成说话数字头像和躯干图像并合成整体动画；本发明解决了音频与面部合成动画显得生硬不自然的问题，通过头部特征和音频特征之间的相互引导优化，使得面部表情更贴合说话者的实际情感变化，能高度逼真地反映说话者的表情变化。
G10L15/16  ,降噪识别联合网络的语音识别方法、装置、设备及介质 [发明],本申请涉及语音识别技术领域，特别是涉及到一种降噪识别联合网络的语音识别方法、装置、设备及介质，其中方法包括：对输入的带噪音频进行傅里叶变换，得到实部和虚部的频域特征；对所述频域特征进行变换，得到FBank特征；将FBank特征经过线性映射后输入到降噪网络中，获取降噪输出结果，其中，所述降噪输出结果为包含实部和虚部的复数掩码；基于目标函数对所述降噪输出结果进行训练，输出降噪后的复数掩码；通过所述降噪后的复数掩码和所述频域特征计算出降噪后的频域特征及降噪后FBank特征；将所述FBank特征和所述降噪后FBank特征输入到语音识别网络，计算音素序列。本申请实现对噪声降噪和语音识别的同时优化，提高整体的识别性能和轻量化性能。
G10L13/08  ,音频描述信息生成方法、装置、电子设备及存储介质 [发明],本发明提供一种音频描述信息生成方法、装置、电子设备及存储介质，属于信息处理技术领域，所述方法包括：获取文本信息转化的音频数据以及所述音频数据的元数据；基于所述音频数据、所述元数据和第一提示信息，生成所述音频数据的描述信息；所述第一提示信息是基于所述元数据确定的。本发明可以在生成描述信息时更全面、准确地捕捉音频与文本之间的关联，使得生成的描述信息更具表现力和音频元素的表达能力，大大提升了生成音频描述信息的质量，比人工标注效率更高，可以很好地适用于大规模数据集的应用场景。
G06F9/451  ,基于智能手环的智能语音助手方法及系统 [发明],本申请涉及智能语音处理技术领域，公开了一种基于智能手环的智能语音助手方法及系统。所述方法包括：创建空中手写识别任务并识别得到目标手写轨迹数据集；通过时空图卷积神经网络进行轨迹特征点提取，得到E个第一手写轨迹特征点；得到轨迹特征点聚类结果和轨迹特征点连续性指标；特征点筛选和优化得到M个第二手写轨迹特征点；数据集分割和字符识别得到多个目标手写字符，并进行字符编码和手环执行控制策略匹配，得到目标手环执行控制策略；进行任务执行语音播报并进行执行控制策略校验，通过智能手环响应目标手环执行控制策略，本申请实现了智能手环的智能语音控制并提高了智能手环的语音控制准确率。
G06F16/732  ,一种智能化安防服务方法及装置 [发明],本申请提供了一种智能化安防服务方法及装置，属于视频数据处理技术领域。所述方法包括步骤S1、获取用户输入的安防需求；步骤S2、在所述安防需求中提取事件要素，形成安防指令，所述事件要素包括事件主体、事件发生时间以及事件内容；步骤S3、在所述事件发生时间范围内，识别所有包含事件主体及事件内容的各摄像头采集的视频片段，形成视频片段集；步骤S4、基于与事件内容关联的时限特征对所述视频片段集内的各视频片段进行整合归类，形成一个或多个组合视频；步骤S5、基于给定的简报类型，对各组合视频或者多个需要联合的组合视频进行简报生成并输出。本申请强化了安防软件服务体系的自主能力，提高了用户体验。
G10L13/08  ,一种视听一致个性化语音合成系统、合成方法及训练方法 [发明],本发明涉及个性化语音合成领域，尤其涉及一种视听一致个性化语音合成系统、合成方法及训练方法。本发明通过加入说话人的人脸图像进行语音合成，并将参考音频与人脸图像进行结合，使得合成的语音能兼具视觉模态信息和听觉模态信息，有效提高语音合成系统的个性化建模能力；同时采用两个阶段对语音合成系统进行训练，可以充分挖掘语音和人脸图像的特征，并提高模型的准确性和自然度。
G10L15/22  ,大语言模型驱动的显微镜控制方法、装置及电子设备 [发明],本发明涉及计算机技术领域，公开了一种大语言模型驱动的显微镜控制方法、装置及电子设备，所述方法包括：获取第一语音数据，并基于调整后的语音大模型结合上下文进行意图分析，确定与显微镜控制相关的第一指示信息；基于第一指示信息和硬件库，确定对显微镜的控制方案；按照控制方案对显微镜进行控制，并获取图像数据，以对图像数据进行分析；本申请的方法可以更好的对显微镜进行控制。
H04N7/15  ,一种基于AR的多人复杂交互会议方法和装置 [发明],本发明涉及数字化技术领域，提供了一种基于AR的多人复杂交互会议方法和装置。方法包括：当各参会人员单独发言时，建立正在发言的参会人员与声纹特征之间的关联关系；当多位参会人员同时发言时，使用各正在发言的第一参会人员的第一声纹特征对实时语音数据进行特征匹配，分离提取各第一参会人员的语义信息；对实时影像识别得到各操作物，将各第一参会人员的语义信息与各操作物进行匹配，使用与参会人员相同的颜色对匹配操作物进行标记。本发明通过对多人语音进行分离，对分离得到个人音频进行识别，根据识别结果对操作物进行标记，以便于远程操作人员在多人同时发言时，能够迅速识别各人的表述消息，提升多人会议的效率，确保多人会议的正常有序进行。
G06T11/00  ,一种基于语言提示的影像风格成像系统 [发明],本发明适用于影像风格成像技术领域，提供了一种基于语言提示的影像风格成像系统，所述系统包括：语音采集模块、语音解码模块、数据库模块、图像增强神经网络训练模块、图像处理模块。该系统可应用于手机以及单反设备拍照通路中，根据用户说的语音，进行拍照参数的下发，得到相应的raw图，再将得到的raw图通过风格神经网络进行增强，最终得到符合用户需要的定制增强后的图像，相比于之前拍照通路只能让用户进行手调拍照参数以及进行后处理方案，使方案更加方便用户使用，并且能够达到不光清晰度去噪效果好的图像，还能根据用户所需要的亮度、颜色、对比度、锐度直接输出最终的图像。
G10L21/0232  ,一种实时音频滤除窄带噪声的方法及系统 [发明],本申请涉及音频处理技术领域，尤其涉及一种实时音频滤除窄带噪声的方法及系统，本发明基于快速傅里叶变换算法提取实时噪声音频信号中高斯窄带噪声信号的角频率；根据角频率重构高斯窄带噪声信号；利用自适应线性神经网络对重构信号进行模拟；将实时噪声音频信号减去模拟获得的重现噪声信号，获得原始实时音频信号。本发明可有效去除噪声信号中的高斯窄带噪声；且只需一次FFT变换，即可实现实时音频信号滤除高斯窄带噪声信号的目的，极大地降低了处理时延，有效提高算法的实时性；且滤波流程简单，无需复杂的网络模型，使得在低功耗设备中也能轻松实现；解决了现有技术中实时音频滤除窄带噪声算法实时性差及滤波流程复杂的技术问题。
G10L15/26  ,一种基于营销场景的语音识别语意理解方法及系统 [发明],本发明涉及语音识别技术领域，具体公开一种基于营销场景的语音识别语意理解方法及系统，该方法包括：语音识别和文本分类，本发明利用人工智能对非结构化录音数据的语音波形图进行分析，实现通话录音的文本转化，以自动化代替现有人工的质检工作，同时对转化后的文本进行关键字提取并进行关键字多样化处理，利用数据分类方法，实现对通话录音文本的情景分类，有效提高质检效率和覆盖率，并提供一种语音识别和文本分类的评估方法，分别处理得到语音识别字错率和分类准确率，用以评估语音识别结果和文本分类结果，并分析最终的质检覆盖率，为语音识别语意理解方法的优化提供数据支持。
G10L25/51  ,一种往复压缩机关键部位摩擦磨损状态识别方法及装置 [发明],本申请公开了一种往复压缩机关键部位摩擦磨损状态识别方法及装置，涉及往复压缩机领域，该方法包括：采集声信号并进行提取及预处理，建立样本数据库；建立神经网络模型，通过样本数据库中的训练数据对神经网络模型进行训练，得到参数预测模型；通过样本数据库中的测试数据对所述参数预测模型进行测试；使用参数预测模型对往复压缩机关键部位摩擦磨损状态类型进行预测。本申请能够对往复压缩机关键部位摩擦磨损状态实现快速准确的识别，能够声信号判断摩擦磨损部位及状态，从而对确立后续故障的修复方案及压缩机寿命预测上提供了便利，防止在源头就可解决的问题流入后续步骤。减少生产成本，对于产品的大面积生产有着重大的意义。
G01N29/14  ,一种声发射信号分类方法、计算机设备及介质 [发明],本发明公开一种声发射信号分类方法、计算机设备及介质，涉及无损检测和声发射信号处理领域，该方法通过多个传感器获取的同一振动实验装置的目标声发射信号，对各目标声发射信号的MFCC特征、LPC特征、GTCC特征进行拼接融合，得到MFCC融合特征、LPC融合特征、GTCC融合特征和M‑GTCC‑LPC特征，通过融合拼接后的上述特征进行声发射信号分类，提高了声发射信号分类的精度。
G06T13/40  ,基于虚拟数字人技术的名片制作方法、系统、介质及设备 [发明],本发明提供了一种基于虚拟数字人技术的名片制作方法、系统、介质及设备，涉及人工智能领域，方法包括：将人脸图像上传至虚拟数字人制作平台；基于虚拟数字人技术，根据所述人脸图像生成虚拟数字人；基于动态生成人像技术，根据所述人脸图像生成动态人像；结合所述虚拟数字人以及动态人像，生成虚拟数字人名片；利用语音合成技术，将用户的文字信息转换为语音信息，添加至所述虚拟数字人名片中，制作具有语音功能的虚拟数字人名片。本发明能够降低虚拟数字人名片制作及更新成本，满足用户的个性化需求。
G10L15/06  ,语音识别模型生成方法、语音识别方法、设备和介质 [发明],本公开的实施例公开了语音识别模型生成方法、语音识别方法、设备和介质。该方法的一具体实施方式包括：通过初始音频编码子模型对样本音频信息进行编码处理，得到音频编码信息；通过初始关键文本子模型对各个关键文本信息进行特征提取处理，得到至少一个关键文本特征信息；通过初始融合解码子模型对音频编码信息和至少一个关键文本特征信息进行融合解码处理，得到文本信息；根据样本文本信息和文本信息，确定初始模型是否训练完成；响应于确定初始模型训练完成，将初始模型确定为语音识别模型。通过本公开的一些实施例的语音识别模型生成方法得到的语音识别模型可以提高特定词汇的识别准确率，进而提高语音识别的准确率和召回率，提高识别效果。
G10L25/18  ,一种基于集成学习的神经网络噪声源分类的方法及装置 [发明],本申请涉及环境噪声识别技术领域，解决了现有技术中因噪声类别过多而导致的神经网络模型难以训练以及准确率难以得到提升的问题，公开了一种基于集成学习的神经网络噪声源分类的方法及装置，该方法先通过初级噪声分类模型对噪声进行分大类，根据所述第一推理结果和预设的次级噪声分类模型选择策略匹配出次级噪声分类模型，再利用大类对应的次级噪声分类模型对噪声进行分小类，最后结合两次分类结果得出最终的分类结果，通过设置多个模型有效的降低了每一个模型中的类别，进而有效的降低了模型训练的难度，同时大大的提高了模型预测的准确率。
G06F3/12  ,一种TTS语音播报方法、装置以及打印机 [发明],本发明实施例提供一种TTS语音播报方法、装置以及打印机，属于打印机技术领域。该方法包括：利用文本纠错模型对文本内容进行识别，获得异常位置的位置宽度和中心位置；根据位置宽度和中心位置确定文本异常信息；从文本内容中获得图表内容的关联文本并根据关联文本确定图表内容的目标位置；根据目标位置和图表内容确定关联文本的关联内容；根据关联文本对关联内容进行虚假检测，获得关联文本和关联内容之间的差异性并根据差异性确定图表异常信息；根据文本异常信息确定文本异常描述以及根据图表异常信息确定图表异常描述；将文本异常描述转换成第一语音数据，以及将图表异常描述转换成第二语音数据，并将第一语音数据和第二语音数据进行语音播报。
G06F21/62  ,用于人工智能语音陪练的隐私保护方法 [发明],本发明涉及人工智能语音陪练隐私保护技术领域，具体为用于人工智能语音陪练的隐私保护方法，方法包括，用户在与人工智能语音陪练交流时，对用户语音特征去标识化；构建隐私信息筛选器，对含有隐私内容的语音信息进行模糊化处理；用户在完成与人工智能语音陪练后，自行选择是否将陪练数据进行存储；构建加密模型，对选择存储的语音陪练数据进行加密，并构建对应的用户访问权限，本发明提供的隐私保护方法，解决了在与人工智能进行语音交流时会出现的语音特征泄露的问题，并且通过构建隐私内容过滤器，可以过滤在交流时不经意间说出的自身隐私问题。
G10L13/027  ,一种基于低秩适应的个性化语音合成方法 [发明],本发明涉及语音合成技术领域，公开了一种基于低秩适应的个性化语音合成方法，包括以下步骤：获取具有多个音频文件的音频数据集；构建基础合成模型并进行训练；构建低秩适应网络并进行训练；进行推理；本发明通过低秩适应快速地训练个性化解码器，实现定制化需求，同时加入F0预测器来提取丰富的音频特征，并应用于解码器的训练以及后验概率分布的采样点生成中，以此来生成更加贴合原声的音频。
H04M9/08  ,回声消除方法、装置、电子设备及存储介质 [发明],本申请公开了一种回声消除方法、装置、电子设备及存储介质。本发明实施例可应用于各种场景，包括但不限于云技术、人工智能、智慧交通、辅助驾驶等。该方法包括：分别对近端语音信号以及近端语音信号对应的远端语音信号进行移频处理以及下采样处理，得到远端语音信号对应的目标远端复信号以及近端语音信号对应的目标近端复信号；根据目标远端复信号以及目标近端复信号，确定近端语音信号与远端语音信号之间的互相关函数；根据互相关函数，确定回声信号的回声延迟；基于回声信号的回声延迟，对近端语音信号进行回声消除。通过本申请的方法，实现了近端语音信号的回声消除。
G06F16/33  ,一种体育赛事数据统计方法及系统 [发明],本发明涉及数据统计技术领域，具体公开了一种体育赛事数据统计方法及系统，包括以下步骤：S1：确定当前赛事项目的统计人员；S2：实时获取采集周期内的输入语音；S3：将输入语音转换为文本格式，获取文本中所有的句子；筛选待定句子，并确定待定位置；获取待定位置后的文本，并根据待定位置后的文本生成统计格式；获取所有待定句子的统计格式；S4：生成统计表格，并发送至统计人员。本发明可以在通过语音统计体育赛事数据的过程中，降低由于周围噪音过多导致的语音输入错误的情况，提高统计体育赛事数据的效率。
G10L25/51  ,一种数据处理方法、装置、设备以及计算机可读存储介质 [发明],本申请公开了一种数据处理方法、装置、设备以及计算机可读存储介质，该方法包括：获取包括A个音频帧的第一帧统计滤波；根据A个音频帧分别对应的异常预测概率，对第一帧统计滤波进行状态检测，得到第一帧统计滤波的激活状态，将携带激活状态的第一帧统计滤波添加至第一滑动窗口；获取第一滑动窗口中的B个帧统计滤波分别对应的激活状态；B个帧统计滤波包括第一帧统计滤波；根据B个激活状态，对第一滑动窗口进行属性检测，得到第一滑动窗口的窗口属性，根据第一滑动窗口的窗口属性，确定B个帧统计滤波的滤波状态。采用本申请，可以提高音频帧的帧状态的检测准确度。本申请实施例可应用于云技术、人工智能、智慧交通、辅助驾驶等各种场景。
G10L25/51  ,数字化矿山生产管控系统 [发明],本申请公开了一种数字化矿山生产管控系统，涉及智能管控领域，其通过实时监测采集黄金提炼设备的噪声信号，并在后端引入信号处理和分析算法来进行该噪声信号的分析，以此基于黄金提炼设备的噪声信号来判断该设备的工作状态是否存在异常。通过这样的方式，不需要依赖多组传感器，降低了传感器的安装和维护成本，同时，避免了传统的阈值监测法造成的低精度问题，从而提高了黄金提炼设备的状态监测准确性和实时性，为金矿生产过程的安全和高效运行提供支持。
G10L15/20  ,一种智能家具控制器及控制方法 [发明],本发明公开了一种智能家具控制器及控制方法，该方法包括：检测到智能家具从待机状态切换至使用状态时，将预设的初始范围作为响应音区；当麦克风阵列采集到响应音区的第一笔语音信号时，将当前的用户坐姿标记为初始坐姿并计算第一笔语音信号的声源坐标；基于第一音区修正算法计算第一笔语音信号的声源坐标对应的空间范围，将所述空间范围更新为初始坐姿对应的响应音区；检测到用户坐姿发生第一类改变时，基于第二音区修正算法计算最新用户坐姿对应的响应音区。该方法能够根据用户的坐姿动态调整智能家具的响应音区的范围与用户的嘴部位置相匹配，得到以声源为中心的范围更小的响应音区，降低非用户声源进入响应音区的几率，提升语音识别准确性。
H04L1/00  ,一种语音编码、解码方法、装置、电子设备及存储介质 [发明],本申请涉及数据处理技术领域，尤其涉及一种语音编码、解码方法、装置、电子设备及存储介质，并在语音编码过程中，提出了采用语音编码器，获得各原始语音帧各自的编码数据包；分别基于所述各原始语音帧的语音特征，获得表征各编码数据包的重要性评估值；再将所述各编码数据包，按时序划分为多组候选数据包，其中，每获得一组候选数据包，基于确定的关键数据包，生成N个冗余数据包，并将各候选数据包、编码的N个冗余数据包，以及关键数据包的指示信息，发送至音频接收端，这样，在原始语音帧的编码过程中，降低了生成冗余数据包时消耗的计算资源，并能够降低数据传输过程中消耗的传输资源，极大的提高了计算资源和传输资源的利用效率。
G10L15/30  ,基于智能音箱的问答控制方法、装置、计算机设备和介质 [发明],本实施例提供了一种基于智能音箱的问答控制方法、装置、计算机设备和介质，第一智能音箱将第一语音数据发送第一路由器，第一路由器包含第一意图识别模型；第一路由器通过第一意图识别模型将第一语音数据转化为第一文本数据，将第一文本数据转化为第一意图特征，根据第一意图特征输出第一意图结果；第一路由器将第一文本数据及第一意图结果发送至总路由器；总路由器包含第三意图识别模型；总路由器通过第三意图识别模型将第一文本数据转化为第三意图特征，根据第三意图特征输出第三意图结果，实现了分布式的人工智能模型，不需要很高的硬件成本，降低硬件成本，减少训练时间，提高运行效率，提高智能音箱的语音识别率。
G10L25/51  ,基于广义互相关的音频数据处理方法、装置及存储介质 [发明],本发明提供一种基于广义互相关的音频数据处理方法、装置及存储介质，其中方法包括通过计算窗口取出两路音频流的当前处理数据，并分别放入到两路音频片段缓冲区；采用短时平均能量特征对所述两路音频片段缓冲区的数据进行静音段处理；采用广义互相关延迟算法对经过静音段处理的数据进行延迟估计处理，获取两路音频数据之间的延迟估计值；根据所述两路音频数据之间的延迟估计值，采用皮尔森相关系数对所述两路音频片段缓冲区的数据进行门限判决；通过状态机对延迟估计处理以及门限判决进行控制调控，实现两路音频数据对齐。利用本发明，能够解决各路音频传输延迟不确定、音频延迟实时变化的问题，从而实现各路音频数据实时精确对齐。
B65G43/02  ,一种斗轮机运行AI监护方法和服务器 [发明],一种斗轮机运行AI监护方法和服务器，应用于自动化监护领域，该方法包括获取由摄像机拍摄的轨道图像；对轨道图像进行图像识别，确定轨道是否处于异常状态；通过测距仪监测斗轮机前方预设范围内是否存在障碍物；获取斗轮机的行走驱动机构的声音数据；对声音数据的频率、音量和声音密度进行分析，得到测试曲线；将测试曲线与预设的基准曲线进行对比，确定行走驱动机构是否运行异常；在轨道处于异常状态、在斗轮机前方预设范围内存在障碍物或行走驱动机构运行异常的情况下，控制斗轮机停止工作。本申请具有使斗轮机运行的监护操作自动化，提高斗轮机运行的可靠性的效果。
G10L15/30  ,一种基于语音指令的智能系统操作方法及系统 [发明],本发明提供了一种基于语音指令的智能系统操作方法及系统，其方法，包括：基于语音服务前端子系统对用户语音指令进行实时录制并转换为语音数据流准实时推送给语音服务后端子系统；语音服务后端子系统对语音数据流进行语音识别，并将识别结果准实时返回至语音服务前端子系统；在用户语音指令输入结束后结合当前应用场景，进行语音纠错以及语音解析；语音服务前端子系统按照语音解析结果生成系统操作指令，控制前端页面作出操作响应。本发明在现有Web业务应用系统的基础上，构建智能系统操作系统，通过语音服务前端子系统和语音服务后端子系统的结合对在不改版PC或复杂大屏导航操作逻辑的基础上有效理解用户的复杂的语音指令对应的是操作意图。
G06T13/40  ,一种护工数字人生成方法及系统 [发明],本发明提供一种护工数字人生成方法及系统，涉及数据处理技术领域，方法包括：获取护工专业知识和老年人兴趣知识，构建知识库；构建应答模型，利用知识库训练应答模型；收集训练后的应答模型的输出结果，结合图神经网络和句法树对输出结果进行情绪分类，得到多个情绪类型；录制视频样本，从视频样本中提取视频帧和音频流；接收护理对象的语音请求，将语音请求提取为文字请求，并将文字请求输入至应答模型，通过应答模型得到目标输出结果；解析目标情绪类型；构建双模编解码网络，将相应视频帧和音频流进行融合，得到具有音频特征和视频特征的护工数字人；通过护工数字人对目标输出结果进行播报。提升护工数字人的逼真程度和护理对象的对话体验。
H04N19/172  ,视频图像的编码方法、物品检索方法、电子设备、介质 [发明],本发明公开一种视频图像的编码方法，其中，所述编码方法包括：获取视频源文件；利用设定编码模型对所述视频源文件的每帧图像进行编码，得到图像编码；其中，所述设定编码模型为基于ViT的编码模型，在所述设定编码模型中，自注意力层的输出由以下公式：；将每帧图像的时间信息添加至所述图像编码中，得到所述视频源文件的时序图像表征。本发明还提供一种物品检索方法、一种电子设备和一种计算机可读介质。
H04N5/76  ,一种智能化双录系统及方法 [发明],本发明涉及一种智能化双录系统及方法，业务流程定义模块通过可视化界面对业务流程进行定义：业务服务模块为主录制模块提供业务数据支持；主录制模块实现双录音视频文件的录制和播报，将双录音视频文件结构化；预加工加密模块对主录制模块录制的双录音视频文件进行编码、打包、切片及加密；解密合成及上传模块将加密切片文件进行解密、缓存、合成及上传给外部影像服务平台；RTC通信模块实现主录制模块与远程RTC系统之间的音视频数据交互；质检模块进行实时质量检查。本发明的优点在于：避免了实时网络损伤导致的录制内容质量下降，也同时能够确保在录制任务结束时快速完成提交，从而实现即时在解密合成及上传模块落盘视频文件。
H04N21/258  ,基于参与人数进行直播及互动动态切换方法、系统及终端 [发明],本申请属于教学领域，公开了一种基于参与人数进行直播及互动动态切换方法、系统及终端，确定方法具体包括：获取当前在线视频互动的终端数量、终端身份标识以及当前各个终端录入的用户表情、用户动作以及用户语音。分析所述用户表情、用户动作和用户语音，确定语义。对所述语义打标签，确定多个维度的语义标签。将所述语义标签输入到神经网络模型，确定出当前的互动模式。本申请通过该方法帮助教师在直播过程中不需要花费多余的精力去关注学生的状态，可根据提供的互动模式对课堂模式进行适时调整，调动学生的课堂积极性。
G10L13/10  ,基于韵律情感迁移的语音合成系统及方法 [发明],本发明公开了一种基于韵律情感迁移的语音合成系统及方法，该系统包括：文本编码器模块、序列对齐模块、多级风格适配器、内容适配器模块、解码器模块，其中，文本编码器模块用于TTS系统中输入的文本进行向量化编码，此种编码会混合一些风格属性；序列对齐模块用于语音‑文本的对齐，对齐后通过内容适配器模块，消除这种风格属性；多级风格适配器对参考音频进行多尺度特征的提取，并将这些多尺度特征进行融合，再和内容适配后的输出一起输入语音帧解码器进行梅尔声谱的输出；最后接入声码器即可将梅尔声谱转为语音波形。本申请不仅能够对韵律进行细粒度建模，而且解决了长句依赖中局部和全局信息的获取问题，提高了语言合成系统的泛化能力。
G10L13/027  ,一种基于深度学习的海豚声音生成方法 [发明],本发明公开了一种基于深度学习的海豚声音生成方法，属于声音合成技术领域，本发明中采用EMD分解算法对海豚原始声音进行分解，得到多个EMD原始信号，每个EMD原始信号包含部分声音特征，再提取奇异值和时频特征，实现获取每个EMD原始信号的声音特征，采用深度学习模型处理奇异值特征矩阵和时频特征矩阵，生成EMD估计信号，将多个EMD估计信号进行叠加组合，得到海豚声音。本发明中将海豚原始声音进行了分解，使得每个EMD原始信号仅包含海豚原始声音的部分特征，数据量更少，复杂度更低，能提高生成海豚声音的精度。
H04N21/433  ,一种用于钢琴全录播系统的移动数据终端 [发明],本发明公开了一种用于钢琴全录播系统的移动数据终端，包括：第一获取模块，用于获取用户弹奏钢琴时的声音信号；第一处理模块，用于对所述声音信号进行预处理，得到目标声音信号；第二获取模块，用于获取用户弹奏钢琴时的视频信号；第二处理模块，用于对所述视频信号进行预处理，得到目标视频信号；同步模块，用于判断所述目标声音信号与所述目标视频信号是否同步，在确定不同步时，对目标声音信号和目标视频信号进行同步处理，并将同步处理后的目标声音信号和目标视频信号进行融合处理，得到用户的弹奏数据。可将每位学生弹奏声音与弹奏画面进行声画同步采集，便于教师根据学生弹奏数据进行针对性的讲解，提高教学效果。
G10L25/63  ,基于多尺度注意力的轻量级语音情感识别方法及系统 [发明],本发明属于语音情感识别技术领域，具体公开了一种基于多尺度注意力的轻量级语音情感识别方法及系统，该方法包括步骤：读取待识别的音频数据，将待识别的音频数据转换表示为时间，频率，通道的三维张量；对三维张量进行浅层特征提取，获取四个浅层特征，所述浅层特征包括时间特征、频率特征、小尺度时频特征和大尺度时频特征；对四个浅层特征进行特征融合；对融合后的特征进行深层特征提取；将深层特征输入Softmax层，进行情感分类，得到情感识别结果。采用本技术方案，充分提取和利用多尺度特征信息，提高语音情感识别的效果，并保证模型的轻量性。
G10L15/02  ,基于对比学习预训练模型的语音识别方法 [发明],本发明公开一种基于对比学习预训练模型的语音识别方法，CTAP使用对比学习技术联合训练语音编码器、音素编码器、提示编码器和解码器，以学习语音和音素之间的帧级别相似性。语音识别模型训练利用预训练好的CTAP语音表征模型，用于训练的语音数据的梅尔谱通过预训练的语音编码器提取语音编码，后接一个音素解码器用于预测音素序列，此过程的语音编码器权重是冻结的，只需要训练音素解码器，同时利用预训练好的CTAP模型的音素信息编码能力。
G09B27/00  ,一种用于天象仪运行演示天象的控制方法、设备及介质 [发明],本申请涉及设备管理的技术领域，尤其涉及一种用于天象仪运行演示天象的控制方法、设备及介质，该方法包括：获取预设区域内的观看人数以及观看时间段；确定观看人数是否大于预设人数且当前时间处于观看时间段，若观看人数大于预设观看人数且当前时间处于观看时间段，则获取预设区域内的声音信息以及与声音信息中不同声音源相对应的方位信息，并对声音信息以及方位信息进行分析，确定位于不同位置的用户是否存在对天象仪的观看需求信息，若存在，则基于观看需求信息生成控制指令，控制天象仪演示与观看需求信息相适配的天象。本申请提高了观看天象仪用户的观看质量。
G10L25/51  ,基于自适应编码的摩托车蓝牙音响数据管理系统 [发明],本发明涉及数据处理技术领域，提出了基于自适应编码的摩托车蓝牙音响数据管理系统，包括：采集摩托车蓝牙音响的音频数据；获取每个数据点的异常分数，得到若干目标数据点及普通数据点；根据目标数据点的决策树及音频数据的语谱图，得到每个目标数据点的若干参考树及关联数据点与非关联数据点；根据目标数据点的参考树及关联数据点，获取任意两个目标数据点的噪声相似性；根据噪声相似性及异常分数获取每个目标数据点的最终噪声程度；根据目标数据点的最终噪声程度及普通数据点的异常分数，对蓝牙音响的音频数据进行比特率编码得到编码数据。本发明旨在解决对音频数通过孤立森林进行噪声检测时会发生异常分数相近而影响检测结果的问题。
G06F30/27  ,一种基于生成对抗网络的主动声浪生成方法 [发明],本发明公开了一种基于生成对抗网络的主动声浪生成方法，通过对抗训练的方式生成与真实声浪数据分布尽可能接近的声浪数据，本发明使用GANsynth来进行音频数据预处理，并结合了ProGAN和DCGAN的架构和训练策略，使其能够稳定的生成高质量声浪音频文件。
G10L15/06  ,语音服务改进方法及系统 [发明],"本申请涉及人工智能领域，公开了一种语音服务改进方法及系统，可以自动分析语音服务对话，有效地提升语音服务的效率和成功率。方法包括：捕获语音服务录音，将捕获到的语音服务录音识别分割为服务人员文字和服务对象文字。基于大语言模型，为识别到的服务对象文字匹配相应的服务语言模板，将识别到的服务人员文字与服务语言模板进行比较得到第一相似度S＆lt;subgt;1＆lt;/subgt;。设定关键词集合K={k＆lt;subgt;1＆lt;/subgt;,k＆lt;subgt;2＆lt;/subgt;,…,k＆lt;subgt;i＆lt;/subgt;,…k＆lt;subgt;n＆lt;/subgt;}，检测关键词集合中的各关键词在识别到的文字中出现的情况，得到第二相似度S＆lt;subgt;2＆lt;/subgt;，第二相似度S＆lt;subgt;2＆lt;/subgt;为：；第一相似度S＆lt;subgt;1＆lt;/subgt;和第二相似度S＆lt;subgt;2＆lt;/subgt;进行加权获得总相似度S，若总相似度S低于第一门限，且可统计指标高于第二门限，则将识别到的文字添加至服务语言模板形成新的服务语言模板。"
G10L21/0272  ,基于深度学习的音频话者分离方法 [发明],本发明涉及音频处理技术领域，具体涉及一种基于深度学习的音频话者分离方法；采集音频，并进行多通道音频处理；根据音频滤波进行语音活动检测；进行声纹特征提取；将声纹特征向量聚类成不同的类别；将混合在同一音频信号中的多个说话者的声音进行分离，使每个说话者的声音成为独立的音频流；读取音频信息，进行可视化界面试听，通过上述方式，实现了提高在复杂的环境中音频话者分离效果。
G06F11/30  ,一种基于服务器声音判定服务器工作状态的方法 [发明],本发明涉及服务器状态检测技术领域，特别涉及一种基于服务器声音判定服务器工作状态的方法。包括如下步骤：步骤1：通过麦克风采集服务器工作时产生的声音信号；步骤2：利用小波变换的方法对声音信号进行降噪处理；步骤3：利用运动单元动作电位序列的解码方法，对服务器声音信号进行解码分类；步骤4：根据分类的声音信号匹配不同的服务器工作状态。本发明为运维人员的日常工作提供有力的支撑，缩短了故障发现、问题定位处理的时间，保障了机房内服务器安全稳定的运行。而且本发明极大减轻了运维人员的工作量，节省系统运维成本，具有广阔的市场推广价值。
A61H9/00  ,一种基于语音交互的空气波自适应控制系统及方法 [发明],本发明提供了一种基于语音交互的空气波自适应控制系统及方法，应用于空气波理疗仪，包括：语音交互模块：用于进行语音识别，确定语音控制指令；中央处理器模块：用于识别语音控制指令，并生成对应的功能指令；功能指令包括：电磁阀控制指令、气泵控制指令、温度控制指令和振动控制指令；热敷控制单元：用于根据温度控制指令调节台式空气波理疗仪内热敷器的实时温度；振动控制单元：用于根据振动控制指令调节台式空气波理疗仪内振动仪的实时振动频率气泵管理模块：通过气泵控制指令，控制气泵开启和输出流量，电磁阀管理模块对气路进行充气；电磁阀管理模块：通过中央处理器的电磁阀控制指令，对气路进行独立控制，实现气路的充放气管理。
G06F3/0484  ,一种应用于线上虚拟展馆的导览交互方法、装置及设备 [发明],本申请提供一种应用于线上虚拟展馆的导览交互方法、装置及设备，涉及数字多媒体技术领域，用于解决虚拟展馆的观展效果与用户体验感差的问题。所述方法应用于终端，所述终端用于提供图形用户界面，且，所述终端与服务器通信，包括：响应于登录操作，通过图形用户界面显示目标场景的初始化页面，初始化页面至少包括第一区域；接收服务器发送的第一询问请求；响应于第一询问请求，若用户选择预设路径游览方式，则在第一区域内按照预设路径进行移动，以使图形用户界面对第一区域进行展示；若用户选择用户自行规划游览方式，则基于用户进行的方向控制操作，以使图形用户界面对第一区域进行展示，进一步提高虚拟展馆内对展品的展出效果与用户体验感。
G06F18/27  ,基于多模态融合的大五人格特征预测方法 [发明],本发明公开了一种基于多模态融合的大五人格特征预测方法，涉及情感计算技术领域，包括：从目标对话视频中截取包含被试者人脸的待处理图像序列，从目标对话视频中提取出包含被试者对话信息的音频文件；利用训练好的人脸表情预测网络与训练好的头部姿态估计网络，从待处理图像序列中分别提取出人脸表情特征序列和头部姿态特征序列；提取音频文件的音频特征序列和音频转录的文本特征；对人脸表情特征序列、头部姿态特征序列、音频特征序列和文本特征进行多模态融合，得到目标融合特征，使用基于标签分布的损失函数训练整个网络；基于训练好的多层感知机对目标融合特征进行加权回归，得到被试者的大五人格各维度的量化预测结果。
H04N21/43  ,一种基于时间轴微调的国际中文教学视听课件编辑系统 [发明],本发明涉及教育技术领域，具体涉及一种基于时间轴微调的国际中文教学视听课件编辑系统，包括视频解析模块、字幕识别处理模块、时间轴分析模块、视频剪辑模块、分层交互集成模块、个性化内容生成模块以及课件整合生成模块；其中，视频解析模块：用于解析输入的教学视频文件；字幕识别处理模块：识别并提取视频中的字幕文本数据，生成标准化的文本数据流；时间轴分析模块：用于指导视频剪辑模块的操作；视频剪辑模块：使用时间轴分析模块提供的时间标记数据。本发明，通过自动化和智能化的视频编辑流程提高教学视频的制作效率和质量，同时强化了视频的个性化和互动性，保证了其在多种平台的兼容性和广泛可接入性。
G05B15/02  ,一种智慧园区能源数据管控系统 [发明],本发明涉及能源数据管控领域，公开了一种智慧园区能源数据管控系统，包括数据采集终端；图像采集设备，用于采集空间图像并进行人数检测，当检测到人数小于预设人数阈值时，播放提问语音，若接收到回应语音，将回应语音发送至智慧后台；智慧后台，用于对回应语音进行语音识别，得到识别文本并进行文本情感分析；当分析结果表征允许调整能耗设备运行模式时，调节能耗设备的运行模式；若未接收到回应语音，生成表征无人的提示信息并发送至智慧后台，智慧后台在接收到提示信息后，控制能耗设备进入夜间运行模式或第一耗能模式；可视化显示设备，用于对能源数据和环境数据进行展示。由此，实现了有效降低园区能耗。
G06F3/01  ,一种多场景VR互动方法、系统及存储介质 [发明],本发明提出一种多场景VR互动方法、系统及存储介质，本发明通过接收用户的VR互动设置，确定VR互动角色和VR互动场景；对用户进行VR互动展示；记录VR互动角色在VR互动场景中的互动特征信息；确定用户的兴趣标签信息；匹配并互动展示VR推荐场景。能够在VR互动场景中，记录用户的VR互动角色在VR互动场景中的互动特征信息，匹配生成对应的兴趣标签信息，进而按照兴趣标签信息，匹配并互动展示VR推荐场景，实现在用户的VR互动的过程中，识别用户的体验需求，根据用户在VR互动中的表现，进行更加满足其兴趣的VR场景的推荐并生成定制化的VR互动程序，能够丰富VR互动的体验，增强用户的体验感。
G10L15/22  ,一种基于语音的虚拟人物模型控制方法及系统 [发明],本发明提供了一种基于语音的虚拟人物模型控制方法及系统，该方法包括：当检测到虚拟人物模型工作时，实时接收用户输入的语音指令，并实时生成与语音指令对应的原始字符串；对原始字符串进行实时解析处理，以检测出与用户对应的控制结果，并根据控制结果判断是否对原始字符串进行修改；若根据控制结果判断到不对原始字符串进行修改，则将原始字符串转换成对应的控制代码，并基于控制代码生成对应的控制指令，以使虚拟人物模型根据控制指令执行对应的动作。本发明能够使虚拟人物模型执行准确的动作，对应提升了用户的使用体验。
G10L21/0232  ,一种基于SIFT的RNN语音降噪与去混响方法及系统 [发明],本发明公开了一种基于SIFT的RNN语音降噪与去混响方法及系统，所述方法包括：提取原始语音的SIFT特征；将所述SIFT特征输入至预设的RNN模型，根据RNN模型的输出数据进行信号重构，生成目标语音。本发明通过将SIFT特征与RNN网络模型结合，能够提高语音处理的速度，增强语音降噪和去混响的处理效果，同时能够在保证实时性的同时对于设备内存的需求较低，节约了运算成本。
G06F16/9535  ,基于输入数据生成虚拟情景剧的方法、系统及存储介质 [发明],本发明涉及数据处理领域，具体涉及一种基于输入数据生成虚拟情景剧的方法、系统及存储介质，旨在提高吸引力。本发明的方法包括：获取用户输入数据和用户状态信息；对用户输入数据进行处理，分析用户的发言内容、行动和心理；对世界设定、历史世界状态以及用户的发言内容、行动和心理进行数据处理，推演世界状态的变化并生成多个剧情分支；根据用户输入数据、用户状态信息、历史剧情和世界状态的变化，从多个剧情分支中选择一个分支进而生成虚拟角色的发言内容、行动和心理；对世界状态的变化、虚拟角色的发言内容、行动和心理，以及用户的发言内容、行动和心理进行数据合成，得到虚拟情景剧片段。采用本发明的方法可以对用户产生持续的吸引力。
G10L17/26  ,结合大语言模型的深度合成音频检测方法、系统和产品 [发明],本申请提供了一种结合大语言模型的深度合成音频检测方法、系统和产品，涉及音频检测技术领域，该方法包括：通过音频编码器对待检测音频进行编码，得到音频编码结果；通过预先训练的Q‑former模块从所述音频编码结果中提取音频鉴别特征，并将所述音频鉴别特征对齐至文本模态，得到文本模态的音频鉴别特征；通过预先训练的线性对齐模块将所述文本模态的音频鉴别特征的维度对齐至大语言模型的输入维度；通过文本编码器对提示文本进行编码，得到文本编码结果；将所述文本编码结果与经过维度对齐的文本模态的音频鉴别特征输入预先训练的大语言模型，得到音频检测结果。
G10L17/04  ,连续学习语音鉴别模型的训练方法、装置、设备及介质 [发明],本发明提供了一种连续学习语音鉴别模型的训练方法、装置、设备及介质，具体涉及语音识别技术领域，在利用流式传输的训练数据集对待训练语音鉴别模型进行训练的过程中，当损失函数值发生突变的情况下，确定训练数据集处于旧语音数据集与新语音数据集之间的数据集边界；采用旧语音数据集，生成权重重要性矩阵；采用新语音数据集并结合第二损失函数继续训练待训练语音鉴别模型；重复上述训练过程，直至待训练语音鉴别模型完成对训练数据集中的多个语音数据集的学习，结束训练，得到语音鉴别模型。上述方法优化了连续学习中的权重更新算法，提高了模型在新数据集上的鉴别准确率。
G10L21/007  ,用于语音转换的可控说话者音频表示的方法及装置 [发明],本公开涉及一种用于语音转换的可控说话者音频表示的方法及装置，上述方法包括：基于机器学习模型，对目标说话对象的音频进行特征提取，得到作为目标说话对象音色参考基准的说话者表示向量；获取编码空间中用于编码说话者音色的基础编码向量；基于上述基础编码向量，对上述说话者表示向量进行跨模态特征表示和计算残差，并对逐轮累积的残差进行跨模态特征表示，将各轮次的跨模态特征表示的累加结果确定为说话者音色表示向量。由于脱离了不同音色特征采用基础编码向量进行各类音色的表示，具有广泛的适用性，有助于提升语音转换方法或语音转换模型面对训练未出现过的说话者的鲁棒性。
G10L19/038  ,基于扩散模型的音频编解码方法及装置、存储介质及设备 [发明],本公开涉及一种基于扩散模型的音频编解码方法及装置、存储介质及设备，所述方法包括：接收目标音频的原始波形，并对原始波形进行编码，得到编码后音频向量；对编码后音频向量进行矢量量化，得到压缩后音频信息；接收压缩后音频信息，对压缩后音频信息进行恢复，得到恢复后音频向量，并将恢复后音频向量输入预先训练的扩散模型，将恢复后音频向量恢复为目标音频的原始波形，在目标音频的原始波形通过编码和矢量量化后传输，再经过解码还原原始音频的过程中，利用扩散模型对音频进行编码和解码，使得音频编码量化传输后，能够在接收端高质量还原原始音频。
G10L17/04  ,正交化低秩适应矩阵的语音检测模型的训练方法及装置 [发明],本发明提供了一种正交化低秩适应矩阵的语音检测模型的训练方法及装置，具体涉及语音识别技术领域，通过获取新训练数据集；加载预训练语音大模型并冻结其参数，引入第一低秩适应矩阵和第二低秩适应矩阵，得到待训练语音检测模型；将新训练数据集输入至待训练语音检测模型中，通过正交优化第一低秩适应矩阵和第二低秩适应矩阵的参数，结束训练，得到语音检测模型。针对实际获取的新数据集，使用上述训练方法对语音检测模型进行训练，引入低秩适应矩阵，对模型进行微调，不仅可以显著降低训练成本，还可以极大的提高模型对新数据集下生成音频的检测能力，同时几乎不影响模型对先前已学习的语音算法的检测能力。
G10L17/26  ,融合大语言模型的伪造语音检测方法、系统、设备及介质 [发明],本发明提供了一种融合大语言模型的伪造语音检测方法、系统、设备及介质，涉及语音检测技术领域，通过获取待检测语音；通过预先训练的声学编码模块从待检测语音中提取声学特征序列，并对所述声学特征序列进行处理，得到声学编码序列和音素序列；通过预先训练的大语言模型模块对所述音素序列进行编码，得到音素编码序列；将声学编码序列和音素编码序列输入至预先训练的多模态融合分类模块中，得到语音检测结果。上述方法不仅将声学信息和音素信息进行融合，同时结合大语言模型强大的泛化性与模式识别能力，以使检测方法同时具有强鲁棒性和对于伪造语音类型的强泛化性。
G06F3/01  ,一种3D虚拟数字人的交互系统及方法 [发明],本发明涉及数据处理领域，具体涉及一种3D虚拟数字人的交互系统及方法，解决了现有的3D虚拟数字人的交互系统无法对控制3D虚拟数字人的指令进行调节，导致接收到的指令不够准确，导致人机交互效果不佳，而且无法对3D虚拟数字人投影过程中的稳定性进行监控，由于各种原因，可能会出现不稳定的情况，影响用户体验的问题；本发明提供的3D虚拟数字人的交互系统及方法，具有真实感和沉浸感强、交互方式多样，指令接收准确且高效的优点，能够广泛应用于游戏、影视、教育等领域，具有广泛的应用前景和市场前景，而且可以实时反馈3D虚拟数字人的状态和调整情况，使用户能够及时了解并进行调整，确保其稳定性，提高用户体验。
G06T13/00  ,基于LLM和ANN的数字人生成方法及其在云视频的应用 [发明],本发明涉及人工智能技术领域，具体为基于LLM和ANN的数字人生成方法及其在云视频的应用，包括以下步骤：基于捕获的视频数据，采用渐进式关键帧优化技术，通过卷积神经网络的边缘检测算法分析视频帧的特征，自动识别出关键帧，并筛除非关键帧，进行视频数据处理和关键帧的优化处理，生成关键帧数据集。本发明中，通过渐进式关键帧优化技术和基于子空间学习的特征分离算法能够更加高效和准确地从大规模或多源异构数据中提取关键信息，通过自动化特征提取与优化算法的应用，本发明在处理复杂环境下的人体姿态估计方面显著提高了准确性和运算效率，此外，还包括针对数据预处理的优化措施，更有效地处理各种噪声和异常值，提高生成数字人的质量。
G06F16/26  ,一种基于5G通信技术的音视频监控方法及系统 [发明],本发明公开了一种基于5G通信技术的音视频监控方法及系统，涉及5G通信技术领域，包括控制中心，所述控制中心连接有数据采集模块、音频处理模块、视频处理模块以及监控跟踪模块；通过数据采集模块采集音频数据和视频数据；所述音频处理模块对获得的音频数据进行处理，获得质优信号频谱图；所述视频处理模块对获得的视频数据进行处理，获得特征点图；所述监控跟踪模块根据所获得的质优信号频谱图和特征点图对目标对象进行路径追踪，获得目标行动轨迹；增强音视频清晰度，提高音视频监控的实时性和可靠性，便于对视频人物进行识别并追踪人物踪迹，提高监控追踪的工作效率和音视频监控的安全性。
G10L25/66  ,面向脑瘫儿童的语音和面部表情数据处理方法及系统 [发明],本申请公开了一种面向脑瘫儿童的语音和面部表情数据处理方法及系统。本方法首先通过摄像头和麦克风来采集目标用户的视频和语音数据；然后对视频和语音数据进行预处理操作；包括识别视频中的人脸，并将检测出的人脸进行追踪及对齐进行切片；对于语音数据进行切片，并转换为对应Mel语谱图；最后将经过预处理的视频输入到3D的CNN中、音频数据对应的Mel频率谱输入到2D的CNN中使用双向注意力机制来处理视频内部和音频内部不同时间点的相关性得到目标用户的状态评分结果。本申请基于语音和面部表情数据对目标用户进行评分，从而辅助医生对目标用户的心理状态进行判断。
G06F18/213  ,一种基于多元高斯函数空间变换的卷积神经网络计算方法 [发明],本发明公开了一种基于多元高斯函数空间变换的卷积神经网络计算方法，所述方法包括下列步骤：获取原始输入数据；将所述原始输入数据转换为M维数值矩阵；构建卷积神经网络，并在所述卷积神经网络的卷积层中构造M维的多元高斯核函数，通过数值矩阵作为多元高斯核函数的基底，完成输入数据的特征图构建；将特征图输入卷积神经网络的池化层以及全连接层中计算，获得卷积神经网络的计算结果。
G10L15/26  ,一种智慧型无纸化会议系统 [发明],本发明属于智能会议设备技术领域。本发明提供了一种智慧型无纸化会议系统，包括摄取模块、提取模块及记录模块；摄取模块，用于获取会议区域内的音频数据及视频数据；提取模块，用于对音频数据进行音频解析以获得对话数据，对视频数据进行人脸识别以获得发言人员数据，将对话数据和发言人员数据进行关联得到有效对话数据；以及，按照时间顺序将有效对话数据进行整理得到数字化会议记录档案；记录模块，存储和/或输出数字化会议记录档案。本发明的方案可通过对会议现场的音频数据进行解析而自动生成数字化的会议记录，不再需要会议记录人员手动实施会议记录，提升了会议记录的效率和准确性。
G10L25/60  ,一种基于电话通信的智能语音质检系统及其质检方法 [发明],本发明公开了一种基于电话通信的智能语音质检系统及其质检方法，涉及语音质检系统技术领域，包括语音质量评估模块，所述语音质量评估模块用于对通话质量进行动态评估；所述语音质量评估模块包括：客观质量评估单元、主观质量评估单元和动态调整单元。本发明通过设计有语音质量评估模块，实现了对通话中的语音质量进行客观和主观评估的功能，为质检员提供可量化的质量评估数据，帮助系统优化和问题排查，解决了缺少用户主观反馈导致通话质量评估不够全面的问题。
G10L25/51  ,切刀健康评估方法、装置、设备及存储介质 [发明],本申请适用于电池制造技术领域，提供一种切刀健康评估方法、装置、设备及存储介质，其中方法包括：获取声音特征数据，所述声音特征数据为基于切刀对来料进行分切的声音数据提取得到；基于所述声音特征数据对所述切刀进行健康评估，得到所述切刀的健康状态数据。
G10L15/06  ,一种卫星宽带短报文通信的语音通信方法及系统 [发明],本发明公开了一种卫星宽带短报文通信的语音通信方法及系统，涉及语音通信的技术领域，通过大数据的采集和方言模型的建立，该系统能够有效地适应各个地区的不同口音和方言，这意味着用户可以在多语言环境下更轻松地进行语音通信以及将语音转换成文字，并借助自然语言处理技术和反复训练语音识别，能够进一步提高语音转文字的准确性，用户终端可以根据标记选择所需的方言输入方式，进一步提高了系统的可定制性，减少误解和信息失真的风险；同时通过语音综合分析模块，利用信号强度Xhqd、环境因子Hjyz以及麦克风的灵敏度Lbd等多维因数，实时评估通信质量，有助于提前识别通信问题并采取措施来优化通信质量，从而进一步提供更可靠的语音通信体验。
G10L15/06  ,方言流式语音识别方法、装置、电子设备及存储介质 [发明],本发明提供一种方言流式语音识别方法、装置、电子设备及存储介质，其中方法包括：分别调整预训练语音识别模型的注意力机制和卷积感受野，以将其进行流式化处理；在流式化的预训练语音识别模型中引入蒸馏损失，以实现非流式模型至流式模型的知识迁移；对目标方言语音对应的方言语音样本进行预处理并分段，并利用分段的方言语音样本对经知识迁移的预训练语音识别模型进行微调训练，获取目标方言语音识别模型；将目标方言语音进行预处理并分段后，将分段的目标方言语音输入所述目标方言语音识别模型，以获取对目标方言语音的识别结果。本发明通过对预训练语音识别模型进行流式化处理，并利用知识迁移进行辅助，能够显著提升流式模型的识别精度。
G10L15/06  ,一种基于自知识蒸馏的方言语音识别训练方法及系统 [发明],本发明涉及语音识别领域，更具体地，涉及一种基于自知识蒸馏的方言语音识别训练方法及系统，包括以下步骤：S1：获取方言语音信号I；S2：提取方言语音信号I的MFCC特征，记为X；S3：将X输入到Transformer模型中进行方言语音识别训练；其中，在步骤S3中，还包括了通过获取Transformer模型的中间层表征R＆lt;subgt;M＆lt;/subgt;来进行后验概率自蒸馏和表征自蒸馏的特征学习。通过在训练过程中进行后验概率层次自蒸馏与表征层次自蒸馏，从而减少了减少模型训练的过拟合程度，提升了方言小语种语音识别的精确度与鲁棒性。
H04L51/02  ,基于模拟角色的信息交互方法、装置和存储介质 [发明],本申请公开了一种基于模拟角色的信息交互方法、装置和存储介质。其中，该方法包括：获取至少一个角色数据，和视频数据；利用至少一个角色数据中的原始文本数据，模拟指定角色在使用文本交互时的文本风格特性，以提供模拟角色服务中的交互内容；利用至少一个角色数据中的原始音频数据，模拟指定角色的指定声音，以提供信息交互服务中的交互音频，其中，交互音频是指定声音对交互内容进行听觉呈现的结果；利用至少一个角色数据中的原始视频数据，模拟指定角色的表现交互习惯，以提供信息交互服务中的交互视频，可应用在人工智能场景，涉及语音识别等技术。本申请解决了基于模拟角色的信息交互准确性较低的技术问题。
G10L19/008  ,一种多路多标准的音频解码系统 [发明],本发明涉及一种多路多标准的音频解码系统。本发明的架构包括处理器CPU、音频帧解码单元、任务队列模块。处理器CPU用于对任务队列模块进行配置音频帧的解码任务，通过寄存器配置的方法配置解码任务和与解码任务关联的输入控制信息。音频帧解码单元用于将一帧音频压缩码流数据解码成一帧脉冲编码调制数据，为单任务执行单元，支持现有的多个标准音频解码。任务队列模块用于管理和实现多路音频解码的运转，任务队列模块采用先进先出的结构。本发明通过任务队列模块增加了多路多标准音频解码的灵活性，解决了多路灵活变化的应用问题。本发明灵活且易扩展，且CPU的参与大大降低，最大可能地释放CPU。
G10L21/0216  ,基于知识蒸馏的音频降噪模型的训练方法、装置及设备 [发明],本申请公开了一种基于知识蒸馏的音频降噪模型的训练方法、装置及设备，涉及人工智能技术领域。该方法的一具体实施方式包括：将具有噪声的音频信号从时域转换至时频域，得到具有噪声的音频特征；分别将具有噪声的音频特征输入到教师网络和学生网络中，得到教师网络预测输出的第一降噪特征，以及学生网络预测输出的第二降噪特征；将第二降噪特征从时频域转换至时域，得到第二降噪信号；根据第二降噪信号与干净的音频信号，第二降噪特征与干净的音频特征，以及第二降噪特征和第一降噪特征，确定学生网络对应的损失函数；利用学生网络对应的损失函数对学生网络进行知识蒸馏训练，得到训练后的音频降噪模型。
G16H40/63  ,一种用于肝脏MRI的成像优化方法及系统 [发明],本发明公开了一种用于肝脏MRI的成像优化方法及系统，属于肝脏MRI的成像优化技术领域，包括数据归纳模块、监测模块和成像模块。数据归纳模块用于对历史患者数据进行归纳，形成若干个代表分类以及各代表分类对应的代表呼吸曲线；归纳出不同代表分类及代表呼吸曲线对应的最佳扫描方案；监测模块用于对检查患者进行实时呼吸监测，获取患者信息，根据患者信息确定对应的代表分类和代表呼吸曲线；识别代表呼吸曲线的最佳扫描方案，根据最佳扫描方案确定对应的最佳呼吸数据；当达到成像要求时，生成对应的成像指令；成像模块用于肝脏MRI的成像管理，当获取成像指令时，按照最佳扫描方案进行患者的成像采集，获得对应的成像图像。
G10L15/06  ,模型训练方法、装置、设备及计算机可读存储介质 [发明],本申请提供了一种模型训练方法、装置、设备及计算机可读存储介质；方法包括：从外部存储器中读取初始训练语音样本，并将初始训练语音样本加载到内部存储器中；在内部存储器中基于房间冲击响应仿真参数和混响噪声模拟参数进行实时仿真和卷积处理，得到样本混响结果和噪声混响结果；利用样本混响结果和噪声混响结果生成扩充训练语音样本，利用初始训练语音样本和扩充训练语音样本对语音识别模型进行训练，得到训练好的语音识别模型。通过本申请，能够降低数据扩充的时间成本，提高模型训练效率，并提高训练好的语音识别模型的鲁棒性。
G10L25/51  ,目标音频识别模型的确定方法、装置及计算设备 [发明],本申请公开了一种目标音频识别模型的确定方法和装置。在该方法中，首先获取初始音频识别模型。初始音频识别模型利用初始训练样本集对初始深度学习模型进行训练得到，初始训练样本集包括多个训练样本，每个训练样本包括一个音频样本和对应的第一标签，一个音频样本对应的第一标签被设置为表明所述一个音频样本是目标类型的音频。然后，以初始音频识别模型为当前分类模型，对当前分类模型执行调整步骤组以确定目标音频识别模型。调整步骤组用于对当前分类模型进行调整。通过本申请的实施例，可以实现快速、准确且低成本地建立目标音频识别模型，进而用于目标类型的音频的识别。
G10L25/51  ,一种基于SLAM和SONAH融合的声纹监测方法及设备 [发明],本申请涉及一种基于SLAM和SONAH融合的声纹监测方法及设备，利用统计最优近场声全息SONAH技术，获取所述监测区域内各设备运行时所产生声音的实时声场分布云图；并传输至所述中央处理模块；利用即时定位与地图构建SLAM技术，构建所述监测区域的三维地图以及所述监测区域内各设备的三维模型，将接收到的实时声场分布云图与所述监测区域内各设备正常运行状态下的声场分布云图进行对比，若实时声场分布云图与所述监测区域内各设备正常运行状态下的声场分布云图存在差异，则判定所述监测区域内存在出现运行异常的目标设备，实现对所述监测区域内各设备运行状态的实时监测。进而，基于构建的三维地图以及三维模型，精确定位异常设备及异常点。
G10L25/51  ,一种基于神经网络的小语种口语智能训练方法、系统及设备 [发明],本发明公开了一种基于神经网络的小语种口语智能训练方法、系统及设备，属于语音识别技术领域。该方法包括：收集小语种词语口语表达数据，对小语种词语口语表达数据进行预处理，作为样本数据集；构建生成对抗网络模型，并将样本数据集送入生成对抗网络模型进行样本数据扩充，得到训练样本数据集；构建口语评估模型，并根据训练样本数据集训练口语评估模型，得到优化后的口语评估模型；获取用户的口语信息并输入优化后的口语评估模型，输出评估结果。对于提高小语种学习者的口语水平和语言能力具有重要的意义。
G06V40/16  ,云环境下基于声纹信息和人脸信息的身份识别方法及系统 [发明],一种云环境下基于声纹信息和人脸信息的身份识别方法及系统，方法包括采集声纹信号与人脸图像信息；从声纹信号与人脸图像信息中提取声纹信号特征以及人脸图像特征；将声纹信号特征以及人脸图像特征按顺序拼接在一起，组成拼接特征向量；对拼接特征向量进行加密，将加密向量发送给云端服务器；云端服务器对接收到的加密向量进行比对验证，根据比对验证的结果进行决策。本发明将声纹信号特征与人脸图像特征按顺序拼接在一起，组成拼接特征向量，作为身份识别标准，提供更多的生物特征互为补充，从而提高了身份认证的稳定性和鲁棒性。本发明将声纹信号与人脸图像信息进行特征级别的融合，步骤简单，在进行身份识别的同时实现对用户数据的隐私保护。
G06T13/40  ,数字人肢体动画生成方法、装置、存储介质及计算机设备 [发明],本申请提供的数字人肢体动画生成方法、装置、存储介质及计算机设备，当获取到制作数字人肢体动画的原始文本后，可以将该原始文本转换为语音信息，并获取与语音信息对应的字幕信息后，本申请可以获取存储有与原始文本相关的多个动作关键字的预设语料库，该预设语料库中的每一动作关键词对应多个动作动画，而本申请的字幕信息中既包含有文本内容，又包含有时间码，因此，本申请使用字幕信息与预设语料库中的动作关键字进行匹配后，可以同时确定动作动画及对应的触发时段，这样既能够较好的匹配动画资源，生成符合语义且效果自然的数字人肢体动画，又可以显著提升数字人肢体动画的生成效率。
G10L15/16  ,声音识别方法、装置、介质和电子设备 [发明],本申请涉及声音识别技术领域，特别是涉及一种声音识别方法、装置、介质和电子设备。该方法包括：获取预处理后的待识别声音；对上述待识别声音进行特征提取，得到待识别声音对应的待识别特征向量；将上述待识别特征向量输入目标卷积神经网络模型，得到对应的声音类别；根据上述声音类别遍历预设映射表，得到目标声音识别模型；将上述待识别声音输入至上述目标声音识别模型，输出待识别声音对应的文字。本申请对不同声音类别的待识别声音进行分类处理，每一声音类别均有对应的声音识别模型，由此，利用不同声音识别模型针对性处理不同口音的待识别声音，识别的结果的准确度更高。
G10L15/16  ,语音识别方法、装置、关键词检测模型的训练方法和装置 [发明],本申请涉及一种语音识别方法、装置、计算机设备、存储介质和计算机程序产品。方法包括：获取待识别语音，并对待识别语音进行编码，得到编码特征；获取与识别业务相关的关键词，对关键词进行特征提取得到偏置特征；基于注意力机制融合编码特征和偏置特征得到目标特征，目标特征中包含与关键词相适配的信息；基于目标特征进行分类，得到建模单元的概率分布；根据建模单元的概率分布进行关键词识别，得到识别结果。采用本方法能够提高语音识别过程中关键词的检出率，从而提高语音识别的准确性。
G10L15/06  ,语音识别方法、装置、设备及可读存储介质 [发明],本申请公开了一种语音识别方法、装置、设备及可读存储介质。本方案中，预先对端到端语音识别模型进行领域自适应训练得到多领域语音识别模型以及各领域的提示向量参数，每个领域的提示向量参数用于指示该领域专有的语音识别信息，在获取待识别语音数据、确定待识别语音数据的声学特征序列之后，获取待识别语音数据所属领域的提示向量参数，将该提示向量参数和声学特征序列，输入该领域的多领域语音识别模型，多领域语音识别模型对提示向量参数和声学特征序列进行编解码处理，得到语音数据的识别结果。本方案可有效保证端到端语音识别模型在各领域识别效果。
G06F16/33  ,一种基于人工智能的智能数据查询系统及方法 [发明],本发明公开了一种基于人工智能的智能数据查询系统及方法，属于数据处理技术领域。一种基于人工智能的智能数据查询系统，包括语言处理模块、知识图谱构建模块、查询处理和优化模块、用户界面模块、安全和隐私模块和系统管理和监控模块。本发明中，设置的语音处理模块不仅包括语音识别，还有语音质量优化。语音识别利用音频信号处理和机器学习算法，而语音质量优化通过降噪算法提高语音输入的准确性，且系统还提供实时反馈，帮助用户调整发音或语速，提升用户体验。
G10L19/00  ,用于PCM编码的数字语音失步噪音处理方法和系统 [发明],本发明提供了一种用于PCM编码的数字语音失步噪音处理方法和系统，方法包括：将语音信号转换为线性PCM数据；在语音信号的每个检测周期内监测每个采样点的音频幅度，将音频幅度超过第一设定阈值的采样点定义为高音频幅度点；根据检测周期内高音频幅度点的数量，判断该检测周期内是否存在语音失步噪音，并利用静音标志对检测周期是否存在语音失步噪音进行标记；对完成标记的语音信号进行延时处理，并根据静音标志对延时处理后的语音信号进行话音切换。系统包括PCM编解码芯片、失步噪音检测模块、时延模块和话音切换模块。本发明可快速完成失步噪音检测，并及时消除失步噪音，具备准确的失步噪音反馈机制，可应用于多种类型的数字语音通信系统中。
G10L21/0216  ,一种用于智能客服机器人的语音信号智能处理方法及系统 [发明],本发明涉及数据处理技术领域，具体涉及一种用于智能客服机器人的语音信号智能处理方法及系统，包括：采集智能客服机器人的语音数据序列；根据不同语音数据之间的语音幅值的变化差异，从语音数据序列中划分出客服未回复语音段；根据对照语音数据与客服未回复语音段之间所含信息内容量的差异，得到对照语音数据的信息丢失率；根据客服未回复语音段与对照语音数据之间能量信息的分布情况以及信息丢失率，得到对照语音数据的最佳步长；根据最佳步长对每个对照语音数据进行滤波。本发明提高了滤波器对语音信号的去噪效果，提高了智能客服机器人处理语音信号的效率。
H04N21/85  ,一种高帧率回放式快速虚拟制片系统 [发明],本发明公开了一种高帧率回放式快速虚拟制片系统，涉及虚拟制片领域。其首先获取由摄像头捕捉的用户动作视频和由录音设备捕捉的用户录制语音，提取所述用户录制语音的语义特征以得到用户语音文本识别结果词粒度语义特征向量的序列，分析所述用户动作视频的动作语义特征以得到用户动作语义编码特征向量的序列，对所述用户语音文本识别结果词粒度语义特征向量的序列和所述用户动作语义编码特征向量的序列进行跨模态融合以得到动作‑语音交互融合特征向量的序列，基于所述动作‑语音交互融合特征向量的序列来生成动画角色虚拟视频。这样，可以实现快速的虚拟制片过程，并提供实时预览能力，从而为影视创作者提供更多的创意空间和表达方式。
G10L13/02  ,一种融合位置和音频通用表征的双耳音频生成方法及系统 [发明],本发明公开了一种融合位置和音频通用表征的双耳音频生成方法及系统，其特征在于，包括，S1，制作视频帧数据集和音频数据集；S2，对音频数据集进行短时傅里叶变换和计算，得到对应的复数谱图、幅度谱图和相位谱图；S3，将视频帧数据集、音频数据集及其对应的谱图输入包含相对位置信息提取器、音频通用表征提取器、掩膜生成模块的双耳音频还原模型中进行训练和优化；S4，基于训练好的所述双耳音频还原模型进行双耳音频还原。本发明提出的网络模型能够有效提取视频帧中声音源的相对位置信息，获得更有效的音频通用表征，用于引导双耳音频的生成，从而提升系统性能。
G06F3/01  ,一种智能化野外观鸟监测系统及方法 [发明],本发明公开了一种智能化野外观鸟监测系统及方法，属于人工智能技术领域。本发明能够智能对野外的鸟类进行实时、全面的监测与分析。包括鸟名识别模块、行为分析模块、鸣叫识别模块、环境分析模块、VR交互模块；鸟名识别模块使用卷积神经网络，通过多层卷积和池化操作，显示出鸟的名称；行为分析模块使用循环神经网络处理时序数据，分析鸟的运动轨迹和飞行模式，发现鸟的异常行为时及时报警；鸣叫识别模块获取多个角度和频谱的鸣叫声数据，识别和分类不同种类的鸣叫声；环境分析模块利用图表和图形实时展示气象和环境数据的变化趋势，与鸟类异常行为结合展示；VR交互模块利用真实地理数据创建虚拟野外环境，用户进行交互。
G10L15/00  ,中英混合语音识别系统训练方法、装置、设备及介质 [发明],本申请公开了中英混合语音识别系统训练方法、装置、设备及介质，包括：获取中英文混合的训练集语料；利用预设文本翻译词典的中文词汇与翻译得到的英文词汇之间的对应关系对文本训练集进行编码处理，以得到编码后文本训练集；利用编码后文本训练集以及基于文本训练集中的文本句子类型对应的句子级别提示学习模板对初始中英混合语音识别模型进行迭代训练，得到目标中英混合语音识别模型；将与语音训练集中各语音训练数据的语音特征输入至目标中英文混合语音识别模型，以便进行解码推理，以获取中英混合语音识别系统。结合语音语境上下文信息以及文本翻译信息，在训练过程中进行模型效果优化，使得模型对于中英混杂句子中对英文句子的预测更加准确。
G10L15/22  ,语音数据处理方法、装置、设备及介质 [发明],本申请实施例提供了一种语音数据处理方法、装置、设备及介质，该方法包括：从针对第一对象的语音数据流中获取目标帧长的语音唤醒数据；通过一级唤醒模型，对语音唤醒数据进行唤醒词检测处理；在唤醒词检测处理的结果指示语音唤醒数据唤醒第一对象的第一概率高于第一预设阈值的情况下，通过二级唤醒模型对目标数据进行识别处理，目标数据为语音数据流中包含语音唤醒数据的部分；在识别处理的结果指示语音唤醒数据唤醒第一对象的第二概率高于第二预设阈值的情况下，确定唤醒成功，以控制第一对象进入工作状态。本申请基于一级唤醒模型实现唤醒词检测处理，并基于二级唤醒模型实现二次校验处理，能够提高唤醒识别的准确性。
G10L21/10  ,3D数字人的语音驱动方法、装置、存储介质及相关设备 [发明],本申请提供的3D数字人的语音驱动方法、装置、存储介质及相关设备，当获取到目标用户输入的语音信号时，可以获取目标表情预测模型，然后将语音信号输入至目标表情预测模型中，这样便可以得到目标表情预测模型输出的、与语音信号同步的、3D数字人的人脸不同区域的表情参数；利用该表情参数以及语音信号驱动3D数字人说话时，既可以通过人脸不同区域的表情参数来生成嘴形丰富度较高的3D数字人，又可以控制3D数字人说话时语音与嘴形的同步性，为用户提供接近于实时与真人自然交流的体验，从而在极大程度上提升用户的互动感与沉浸感，满足元宇宙3D场景数字人音频驱动唇形的需求。
G16H40/20  ,一种基于大数据分析的妇科护理管理系统及方法 [发明],本发明公开了一种基于大数据分析的妇科护理管理系统及方法，属于护理数据管理技术领域；通过对第一对象实施的妇科护理的询问状态进行评估，对第一对象实施妇科护理询问的全过程语音数据进行处理以及数据分析，可以获取到第一对象实施妇科护理询问时的工作是否到位；对第一对象实施的妇科护理的收获状态进行评估，对第二对象实施妇科护理回答的全过程语音数据进行处理以及数据分析，可以获取到第二对象的身体状态是否正常；本发明用于解决现有方案中不能对不同护理人员每次的护理行为实施自动的数据监测统计以及处理分析和共享，导致每次实施的妇科护理询问过程透明性不佳以及状态分析的效果不佳的技术问题。
A61C17/34  ,口腔护理设备的控制方法、装置、设备及存储介质 [发明],本申请公开了一种口腔护理设备的控制方法、装置、设备及存储介质。其中，该方法应用于口腔护理设备，包括：接收携带目标口腔护理模式的目标口腔护理指令；若目标口腔护理模式为第一模式，则响应于目标口腔护理指令，控制口腔护理设备的电机通过振动输出第一目标声音，第一模式用于表征口腔护理过程中有表征语音或音乐的目标声音输出的口腔护理模式；若目标口腔护理模式为第二模式，则响应于目标口腔护理指令，控制电机通过振动进行口腔护理，第二模式用于表征口腔护理过程中无目标声音输出的口腔护理模式，使用户可以根据实际护理环境需求选择有目标声音输出或无目标声音输出的口腔护理模式进行口腔护理，提升口腔护理设备适用场景的多样性。
G10L25/51  ,一种两阶段的音频复制粘贴检测方法 [发明],本发明公开了一种两阶段的音频复制粘贴检测方法，涉及音频复制粘贴检测技术领域，本方法分为三个部分：对音频分帧下采样、第一阶段寻找疑似区域、第二阶段寻找进行篡改定位；首先通过计算每两帧之间的皮尔逊相关系数，得到疑似帧的索引。然后基于疑似帧的索引结果进行细寻找，最终确定真正的复制帧和粘贴帧的位置。现有方法的检测流程中通常会提取音频特征或进行特征融合；本发明不用提取音频特征，直接对音频原始数据进行检测，并且可以提高检测的准确性，缩短检测时间。
H04M3/51  ,客服通话质检方法、装置、计算机设备及存储介质 [发明],本申请实施例属于人工智能和金融科技领域，涉及一种客服通话质检方法、装置、计算机设备及存储介质，方法包括：对于通话信息中的每句客服通话，通过预训练模型编码为通话向量；根据类型识别模型对各客服通话的通话向量进行质检类型识别，得到涉及的质检类型；通过情感识别模型和语气识别模型分别获取客服通话的情感特征和语气特征；根据客服通话的通话向量、情感特征和语气特征，生成客服通话的初始复合向量；给各初始复合向量添加注意力权重，得到各客服通话的复合向量；将各复合向量输入质检类型下的各质检点检测模型，得到各质检点检测模型输出的点检测结果，并生成客服的通话质检结果。本申请提高了客服通话质检的效率和准确性。
G10L25/51  ,一种风机叶片异常声音监测方法、系统、设备及介质 [发明],本发明公开了一种风机叶片异常声音监测方法、系统、设备及介质，通过采集风机叶片声音信号数据，对风机叶片声音信号进行降噪处理，得到降噪后的叶片声音信号Z(t)，可视化处理降噪后的叶片声音信号Z(t)，得到时序图，对风机叶片的状态进行监测分析；系统、设备及介质用于实现一种风机叶片异常声音监测方法；本发明能够及时快速的检测到风机叶片异常声音信号，具有操作简单，检测效率高，时间成本和人力成本低的特点，同时，不破坏风机结构，不影响风机叶片的正常运行。
G10L25/51  ,基于货车称重的信息提示方法及相关装置 [发明],本申请提供了一种基于货车称重的信息提示方法及相关装置，首先，确定目标货车的音频采集起始时刻和音频采集结束时刻；然后，通过音频采集模块获取所述音频采集起始时刻至所述音频采集结束时刻的目标音频数据；接着，根据所述目标音频数据确定所述目标货车的行驶行为数据；最后，若所述行驶行为数据符合预设异常行驶行为数据，则生成提示信息并通过所述提示模块进行展示，所述提示信息用于提示所述目标货车重新进行称重。可以基于货车在称重过程中的音频确定货车是否存在作弊行为，硬件成本较低，同时可以尽可能防止货车在称重过程中作弊所造成的道路安全隐患。
G10L15/02  ,语音识别方法、装置及车辆 [发明],本申请涉及一种语音识别方法、装置及车辆。该方法包括：接收车辆座舱内用户发出的语音请求；当检测到语音请求中静音的持续时长大于第一时长且小于第二时长时，将第一音素概率矩阵输入语音识别系统的语音解码图中进行解码，获得对应的第一语音识别文本；若第一语音识别文本的语义不完整，则保留第一语音识别文本；将第二音素概率矩阵输入语音解码图中进行解码，获得对应的第二语音识别文本；将第一语音识别文本与第二语音识别文本共同输出并在车载系统的图形用户界面显示。本申请提供的方案，能够确保语音识别结果的准确性，以及缩短句中静音时长，提高语音识别效率，改善用户体验。
G10L25/30  ,针对网络音频丢包的低延迟修复和隐藏方法及其设备 [发明],本发明涉及音频修复技术领域，具体涉及一种针对网络音频丢包的低延迟修复和隐藏方法及其设备；使用短时傅里叶变换将音频信号分成多个时间段，并在每个时间段内计算其频谱表示；使用自回归模型以及循环神经网络模型对其进行建模和预测；使用卷积神经网络对其进行建模和预测；将时域和频域的预测结果进行合并，得到完整的音频信号预测结果；在针对网络音频丢包的低延迟修复和隐藏设备中，包括模型训练模块、数据加密模块和音频修复模块；通过上述方式，实现实时隐藏错误的能力有助于减轻丢包造成的音频损伤，从而提高现实场景中音频播放的质量。
G10L25/51  ,基于神经网络的噪声等级监测装置、监测方法及电子设备 [发明],本申请涉及一种噪声等级监测装置、方法及电子设备，该装置包括：模拟信号处理模块、噪声获取模块、噪声等级识别模块及噪声等级确定模块。模拟信号处理模块用于基于模拟电路来提取环境中的模拟的音频信号的音频特征。噪声获取模块用于基于第一级神经网络模型过滤所述音频特征中的人声的音频特征，以得到噪声的音频特征。噪声等级识别模块用于基于第二级神经网络模型对所述噪声的音频特征分级，以得到所述环境中的音频信号的N个初始噪声等级。噪声等级确定模块用于判断所述N个初始噪声等级中为同一个噪声等级的数量是否达到M个，若是，则将该同一个噪声等级对应的初始噪声等级确定为噪声等级。其噪声等级监测的准确度高且功耗极低。
G06F30/20  ,基于物理发动机模型的实时声浪模拟方法及系统 [发明],本发明涉及一种基于物理发动机模型的实时声浪模拟方法及系统，属于声浪模拟技术领域，本发明基于所述两次点火时持续时间之间的间隔以及燃烧音频之前的等待时间计算出燃烧音频之后的等待时间，并获取燃烧音频之前的等待时间的音频数据以及燃烧音频之后的等待时间的音频数据，从而将所述燃烧音频之前的等待时间的音频数据以及燃烧音频之后的等待时间的音频数据补充到所述声音缓存区中，生成单缸发动机完整声浪。本发明通过模拟传统燃油发动机的声音特性，并将其应用于电动汽车的主动声浪生成。通过建立精确的燃油发动机物理模型，并分析其在不同工况下的声音特性，算法能够实时生成与电动汽车状态相匹配的主动声浪。
H04S3/00  ,一种立体环绕音效实现方法及装置、电子设备、存储介质 [发明],本申请公开了一种立体环绕音效实现方法及装置、电子设备、存储介质，所述方法包括：对待处理立体音频进行解码，得到待处理立体音频的PCM数据；对待处理立体音频的PCM数据进行滤波处理，得到超低频信号；对待处理立体音频的PCM数据进行音源分离，得到多个目标音源数据；将待处理立体音频的各个目标音源数据分别放置至目标环绕声道的各个目标立体声道上，并结合待处理立体音频的超低频信号，形成虚拟目标环绕声道；分别通过自相位算法控制各个目标立体声道的旋转速度以及方向；采用目标音效数据库的数据集对虚拟目标声道进行下混渲染，得到当前还原立体音频；对当前还原立体音频进行动态响度平衡处理以及响度限制处理后输出。
G10L17/02  ,一种基于嵌入特征融合的防伪说话人识别方法及系统 [发明],公开了一种基于嵌入特征融合的防伪说话人识别方法及系统，包括，获取注册语音数据集和测试语音数据集；搭建说话人识别模型，提取注册语音数据集中的说话人嵌入特征和测试语音数据集中的说话人嵌入特征；搭建语音防伪检测模型，提取测试语音数据集中的鉴伪嵌入特征；搭建多嵌入特征双分支多维注意力融合模型，将注册语音数据集中的说话人嵌入特征和测试语音数据集中的说话人嵌入特征进行拼接操作，得到整体说话人嵌入特征，将整体说话人嵌入特征和鉴伪嵌入特征输入多嵌入特征双分支多维注意力融合模型进行训练和模型优化，得到融合后的嵌入特征；将融合后的嵌入特征输入下游分类网络模型中，获得具备伪造感知能力的说话人识别得分。
G10L15/22  ,掘进设备的语音控制方法、装置、系统及掘进设备 [发明],本发明涉及掘进设备控制领域，提供一种掘进设备的语音控制方法、装置、系统及掘进设备，其中的方法包括：接收用户终端发送的语音信息；基于预先训练的声纹识别模型对语音信息进行声纹识别，得到声纹识别结果；在声纹识别结果符合预设条件的情况下，基于预先训练的语音识别模型对语音信息进行文本识别，得到语音识别结果；根据语音识别结果确定对掘进设备的控制指令，并按照控制指令控制掘进设备。该方法通过在掘进设备的边缘计算单元中部署训练好的声纹识别模型和语音识别模型，能够快速、准确地对用户终端的身份信息及其发送的语音信息内容进行推理预测，使掘进设备能够快速响应动作，实现了语音上的人机交互，有效提高了掘进设备的工作效率。
H04N21/845  ,基于声音分析的影片片段定位方法、装置、终端及介质 [发明],"本发明公开了基于声音分析的影片片段定位方法、装置、终端及介质，包括：对影片介质的音轨进行人声和背景声分离,提取到分离的背景声分片数据；对分离的背景声分片数据，进行音量的声音响度分析，找出预定峰值的声音分片；对影片介质按场景切换镜头进行镜头分片处理，得到多个镜头片段；基于得到的多个镜头片段，结合找出的预定峰值的声音分片，进行对应片段合并，得到针对影片介质的多个高能片段合集。本发明提供了一种基于声音分析的影片高能片段自动定位方法，可以很快为所用的影片定位齐高能片段的位置，提高了影片定位齐高能片段效率，降低了成本。"
G10L13/027  ,一种多情感多说话人语音合成方法和系统 [发明],针对现有的开源情感语音库一般规模较小进而限制情感语音合成质量的缺点，本发明提供了一种多情感多说话人语音合成方法和系统。方法包括：首先使用现有开源情感语音库训练一个语音情感分类器，去除该分类器的分类层可得到一个语音情感编码器。然后利用该语音情感编码器提取语音中的情感特征训练一个情感转换器，利用情感转换器构建出一个新的多说话人多种情感的情感语音库，最后利用构建的情感语音库和开源情感语音库训练一个情感语音生成器实现多情感多说话人语音合成。本发明依据情感转换器构建新情感语音库，再利用新情感语音库训练情感语音生成器，扩展了情感语音数据集、提升了情感语音合成质量。
G06Q30/0204  ,基于人工智能的客户偏好分析方法、装置、设备及介质 [发明],本申请属于人工智能领域与金融科技领域，涉及一种基于人工智能的客户偏好分析方法、装置、计算机设备及存储介质，包括：获取目标客户的业务语音数据并生成业务文本数据；从业务文本数据确定与产品服务偏好相关的服务关键词；从业务语音数据筛选与服务关键词关联的目标语音数据并生成目标文本数据；基于语音情感识别模型得到目标语音数据的第一情感值；基于文本情感识别模型得到目标文本数据的第二情感值；基于第一情感值与第二情感值生成情感综合值；从情感综合值筛选第二情感综合值；获取第二情感综合值的目标服务关键词，基于目标服务关键词生成产品服务偏好标签。本申请通过结合语音与文本的情感分析技术实现了对客户产品服务偏好的精准生成。
G08B25/00  ,一种应急广播图文报警方法、报警系统及存储介质 [发明],本申请公开了一种应急广播图文报警方法、报警系统及存储介质，该应急广播图文报警方法包括以下步骤：将险情图片或险情视频上传至险情数据库；判断拍摄到的图片或视频与所述险情数据库中险情图片或险情视频的相似度是否到达预设值；当拍摄到的图片或视频与所述险情数据库中险情图片或险情视频的相似度到达预设值时，自动通过应急广播进行图文报警。该报警系统包括：险情数据上传装置、相似度判断装置和应急广播报警装置。该存储介质包括存储器和处理器。本申请具有可以对于出现险情的情况或具有安全隐患的情况进行图文报警，便于相关工作人员快速进行有效的决策和应急处理等优点。
G10L15/22  ,一种提升人机对话交互体验感的方法、装置、设备及介质 [发明],本申请提供一种提升人机对话交互体验感的方法、装置、设备及介质，涉及智能语音对话技术领域，用于解决人机语音交互过程中，针对复杂问题的处理在智能度、交互自然流畅度上存在一定缺陷，用户体验感差的问题。该方法包括：建立全双工模式下异步通信的第一通信任务和第二通信任务；在通过所述第二通信任务对第一语音数据对应的第一语音识别结果进行处理的过程中，通过所述第一通信任务接收到第二语音数据的情况下，获取所述第二语音数据对应的第二识别文本；判断第一识别文本与所述第二识别文本的语义意图是否相关；若所述第一识别文本与所述第二识别文本的语义意图不相关，则停止所述第一语音数据的处理，并执行所述第二语音数据的处理。
G10L21/0208  ,一种车内外声音交流方法、系统及车辆 [发明],本申请公开了一种车内外声音交流方法、系统及车辆，所述方法包括：获取多个外部声音信号，对外部声音信号进行预处理和声音特征提取，得到多个声音特征；将多个声音特征输入到声音分类模型中进行分析，得到多个声源的类别；获取多个声源的类别中的目标类别音源，计算目标类别音源相对于车辆的目标位置；控制离所述目标位置最近的车外麦克风获取目标类别音源发出的第一外部目标声音信号；对第一外部目标声音信号进行声音增强处理和噪音消除处理，得到第二外部目标声音信号，将第二外部目标声音信号在车内进行播放。本申请解决了车内和车外人员在车窗关闭时，声音交互受限，车内的人员难以听清车外传来的声音的问题，为汽车行业发展带来积极影响。
H04B1/7163  ,基于UWB的音频传输方法、装置、终端及存储介质 [发明],本发明实施例公开了一种基于UWB的音频传输方法、装置、终端及存储介质。该方案可以获取音频的数字信号，基于线性预测编码对数字信号进行压缩，将压缩后的数字信号转化为脉冲信号，并控制发送端在UWB信道中发送脉冲信号，接收端在接收到脉冲信号后，解调为数字信号并进行解压缩，对解压缩后的数字信号进行丢包检测处理，并将检测到的丢包数据进行补偿，以得到完整的音频数字信号。本申请实施例所提供的方案通过UWB信道传输音频信号，将传输和处理引起的延迟降至最低水平，并且通过无损压缩、解压缩和丢包补偿等手段，实现了数据完整性以及效率都更高的音频传输。
G10L15/22  ,基于改进的seq2seq模型的多意图识别方法、装置、设备及介质 [发明],本申请公开了一种基于改进的seq2seq模型的多意图识别方法、装置、设备及介质，应用于车辆中控设备，所述方法包括：获得待识别语音信息，并根据所述待识别语音信息中的各个词，构建对应所述词的特征向量；其中，所述特征向量包括字符向量和分词向量；将所述特征向量输入至多意图识别模型中，采用所述多意图识别模型对所述特征向量进行处理，得到处理结果；其中，所述处理结果包括所述待识别语音信息对应的由多个单意图语句组成的意图识别结果，所述多意图识别模型是基于seq2seq模型进行改进的；所述处理结果至少依据所述字符向量对应的局部上下文特征向量和所述分词向量对应的全局上下文特征向量得到的。
B60L58/10  ,一种无线电力传输的车载电源系统 [发明],本发明提供一种无线电力传输的车载电源系统，涉及电力控制领域，系统包括如下模块：无线电力传输模块包括双模式（Qi和PMA）兼容性算法和距离感应充电算法；自适应电源管理模块内置数据冗余处理算法和电力分配算法；语音控制模块内置AI算法；手势控制模块包括CCD相机和红外相机；安全模块内置面部识别算法和指纹扫描算法；支持无线和有线（USB‑C和Ethernet）连接；用户模块：具有触摸屏和物理按钮双重操作界面，高效能和节能：通过使用高频电力转换器和自适应功率分配模块，系统能够实现高达98%的电力转换效率。同时，太阳能辅助充电模块和节能模式的温度传感器进一步提高了系统的能效，有助于减少能源消耗和碳排放。
G06F3/01  ,一种基于多模态特征的智能人机交互系统及方法 [发明],一种基于多模态特征的智能人机交互系统及方法，首先采集用户所处环境的图片/视频并通过图文转化模块或者视频转文本模块将其转换为文字描述，同时通过语音识别模块采集并转译用户的语音指令。随后，环境说明文本和文本指令均提交至自然语言理解模块进行进一步解读。所述系统及方法可保证数据安全、降低部署成本。无需上传用户的语音或视频资料，保障用户隐私权益；同时，由于自然语言理解模块仅处理文本信息，模型参数较之多模态AI大模型减少，相应地工程部署成本可大幅度降低。通过应用这种智能人机交互系统及方法，可以为用户提供更高智能水平、更准确性能的服务。
G10H1/00  ,一种智能音乐创作方法及系统 [发明],本发明涉及一种智能音视频创作方法及系统。具体应用于K歌系统或者打碟系统，包括采集音乐数据及从K歌系统及用户历史数据，对其进行预处理，将音乐数据和用户历史数据进行融合，对深度学习模型进行训练以得到目标模型，调用目标模型对目标歌曲进行混音处理以制作生成符合用户意图的混音歌曲并传送至打碟系统，调用目标模型对目标歌词进行歌曲创作以制作生成符合用户意图的歌曲并传送至K歌系统。本发明将K歌系统和打碟系统结合在一起，K歌系统的数据和打碟系统的数据能够互为使用，从而为音乐混音及歌曲创作提供丰富及用户个性化的素材，且能够根据指令自主实现音乐混音及歌曲创作的过程，大大降低了用户的音乐创作门槛和学习成本。
G10L21/0272  ,一种车载多音区交互方法、装置、电子设备和存储介质 [发明],本发明涉及一种车载多音区交互方法、装置、电子设备和存储介质，该方法包括：获取麦克风接收信号以及参考信号；将麦克风接收信号以及参考信号转换至短时时频域；将转换至短时时频域的信号进行回声消除；判断回声消除后的信号属于哪个音区；分离回声消除后的信号得到每个音区的分离信号；对每个音区的分离信号转换得到每个音区最终的时域输出；根据每个音区最终的时域输出确定音区信号的实际唤醒位置；将实际唤醒位置的信号输入识别引擎完成语音交互。本发明对每个音区的信号进行分离，通过分离后的信号送入对应的唤醒引擎确定实际唤醒位置，将实际唤醒位置的信号输入识别引擎，由此完成车载多音区交互，从而实现各个音区的单独交互。
G10L21/0272  ,一种车载语音分离方法、装置、电子设备和存储介质 [发明],本发明涉及一种车载语音分离方法、装置、电子设备和存储介质，该方法包括：获取麦克风接收信号以及参考信号；将麦克风接收信号以及参考信号转换至短时时频域；将转换至短时时频域的信号进行回声消除；判断回声消除后的信号属于哪个音区；分离回声消除后的信号得到每个音区的分离信号；对每个音区的分离信号进行后处理得到每个音区的输出信号；对每个音区的输出信号转换得到每个音区最终的时域输出。本发明将信号转换至时频域，通过回声消除去除信号中喇叭噪声；判断当前回声消除后的信号中包含哪些音区的信号；完成各音区信号的初步提取，对各音区中其他音区的声音残留通过后处理进一步抑制，各音区信号转回时域信号输出，完成多音区语音分离。
G10L15/02  ,一种基于语音增强技术的蛙人语音处理方法 [发明],本发明公开了一种基于语音增强技术的蛙人语音处理方法，本发明涉及蛙人语音处理方法技术领域。该基于语音增强技术的蛙人语音处理方法通过建立具有呼救关键语句包的呼救语音模型集，使得蛙人入水后进行语音交流时，除了能够有效的对蛙人交流语音进行除杂，还能够实时捕捉到蛙人交流语音内容中的呼救关键语句，进而针对性的循环的播出除杂增强后的呼救关键词，保证目标接收人能够准确的接收到呼救内容，无须事故目标人重复呼叫，故而在水下作业发生事故时，有效的节省事故目标人的氧气和体力，提高其水下作业的安全性。
H04H20/62  ,一种基于语音识别的人工智能列车广播系统 [发明],本发明公开一种基于语音识别的人工智能列车广播系统，包括：司机室子系统和客室子系统，司机室子系统与客室子系统通过列车通信网络进行通信；司机室子系统包括列车广播控制器、广播控制面板、司机室扬声器和目的地显示器，列车广播控制器用于将广播指令、待广播的语音发送到每个客室；客室子系统包括客室广播控制器、客室扬声器、乘客紧急报警器、客室噪声检测器以及客室图像与文字信息显示设备；人工智能列车广播系统还包括：广播前语音识别模块，用于对待发送到客室扬声器的语音进行识别判断；广播后语音识别模块，用于对客室扬声器的广播语音进行识别判断。本发明通过语音识别技术，实现系统内对广播声音进行自动检测和识别的闭环处理。
G10L21/10  ,一种语音驱动数字人方法、装置、设备及存储介质 [发明],本申请实施例提供了一种语音驱动数字人方法、装置、设备及存储介质，涉及人工智能技术领域，该方法为：提取语音音频的语音内容特征和语音情绪特征；将语音情绪特征作为条件，通过自注意力机制的深度学习模型对语音内容特征进行融合处理，得到语音融合特征；通过解码器将语音融合特征转换为人脸表情系数；基于人脸表情系数和数字人的表情基信息，生成与语音音频契合的数字人表情图。本申请实施例中，通过将语音内容特征和语音情绪特征融合，得到语音融合特征不止包含语音内容，还包含了语音情绪特征；通过将语音融合特征映射为人脸表情系数，根据人脸表情系数生成数字人表情图，使得数字人表情图带有与语音音频相同的情绪，提升了数字人的自然性。
F21V33/00  ,一种多功能可调节式助眠星空灯 [发明],本发明提供一种多功能可调节式助眠星空灯，属于助眠星空灯技术领域；包括星空灯本体，所述星空灯本体的内腔设置有灯体旋转结构，所述灯体旋转结构包括电机支撑套、伺服电机、电机轴、第一传动齿轮、第一内旋转彩灯、第二传动齿轮、旋转轴、第二固定套筒、第二内旋转彩灯、内圈齿轮、限位圆槽、外旋转彩灯和支撑板。本发明通过设置的内容播放和定时计划，海浪，下雨等白噪音释放压力，并且用户可以通过设定定时计划用以规律自己的作息时间，且用户可以通过APP蓝牙连接功能远程操控星空灯，通过APP中的组合功能，视频监控对婴儿哭泣时发出提醒并进行视频通话，并通过各种计划区域来创建计划，实现了星空灯的多功能使用，使星空灯可以适用于各种场景。
H04W4/12  ,一种基于5G消息的信息管理方法 [发明],本发明属于5G消息技术领域，具体为一种基于5G消息的信息管理方法，S1：个人将文字、图片以及语音信息，由5G消息传输需要架构企业信息管理平台；S2：企业信息管理平台需要搭建AI平台、存储数据库、链接模块、语音模块、互联网模块、小程序模块、群发信息模块和红包自动发放模块；S3：文字类的5G消息上传至企业信息管理平台后，通过AI平台完成对文字内容识别工作，并将是内容上传至存储数据库内。本发明有利于快速将大数量的集群信息进行同步发送，有利于具有大基数的用户群的企业进行消息的群发，有利于完成企业信息管理平台和个人之间互动，大大提高信息交换的效率，有利于快速反馈个人所需内容。
G10L15/02  ,朗读进度跟踪方法、装置、设备及存储介质 [发明],本申请实施例公开了一种朗读进度跟踪方法、装置、设备及存储介质，对朗读者朗读目标文本时的语音数据进行语音识别，得到语音识别结果及其对应的发音时长序列后，除了基于发音时长序列在目标文本中对语音识别结果进行标记外，还至少根据语音识别结果在目标文本中确定朗读者的后续朗读内容及其对应的预测发音时长序列，基于预测发音时长序列在目标文本中对后续朗读内容进行标记，从而避免仅根据语音识别结果及其对应的发音时长序列进行朗读跟踪时的标记滞后问题，实现实时的朗读进度跟踪。
G10L21/02  ,一种音频数据优化系统、方法以及存储介质 [发明],本发明提供一种音频数据优化系统、方法以及存储介质，属于音频优化领域，包括客户端和服务端，服务端用于接收原始音频数据，对原始音频数据进行预处理得到待优化音频数据；客户端用于对待优化音频数据和原始音频数据进行优化分析得到音频数据的优化结果。本发明保证了拾音的下限，且能满足了会议终端的设计指标，解决了拾音质量进一步恶化，且输出音频音质未达到拾音质量上限的问题。
G10L15/22  ,一种音频识别方法、音频识别装置、车辆和计算机设备 [发明],本申请公开一种音频识别方法、音频识别装置、车辆和计算机设备。方法包括对待识别音频进行编码，以生成音素概率矩阵；根据预设的句式纠错模型，对音素概率矩阵进行处理，以生成第一发音概率矩阵，发音概率矩阵包括文本特征和槽位特征；在槽位特征的权重不是发音概率矩阵的最大权重的情况下，对第一发音概率矩阵进行解码，以生成第一识别结果；在槽位特征的权重为发音概率矩阵的最大权重的情况下，根据预设的槽位纠错模型对音素概率矩阵进行处理，以生成第二发音概率矩阵；对第二发音概率矩阵解码，以生成第二识别结果，提高车载的语音识别系统的响应速度、效率和维护效率，降低训练时长和存储的空间占用量。
H04L1/20  ,一种基于用户特征的音频数据传输分析方法及系统 [发明],本发明涉及一种基于用户特征的音频数据传输分析方法及系统，属于音频传输分析技术领域，引入隐马尔可夫模型以及Viterbi算法计算用户的初始音频特征与实际音频特征之间的序列差异，得到状态序列差异分数，基于所述状态序列差异分数分析未执行拥塞避免控制机制情况下是否存在序列误差，得到第一传输异常分析结果，分析已执行拥塞避免控制机制时是否出现冗余丢包，得到第二传输异常分析结果，基于所述第一传输异常分析结果和所述第二传输异常分析结果对用户的初始音频特征误差进行计算修正，生成用户音频特征的修正方案。本发明能够分析在传输拥塞情况下用户音频特征数据的传输误差，并修正传输误差，确保音频特征完整性和可靠性。
G06V40/16  ,一种基于多模态的肌肤作业控制方法 [发明],本申请涉及图像处理领域，尤其涉及一种基于多模态的肌肤作业控制方法，方法包括步骤：统计带有标签的激光波长数据及采集的历史面部图像、历史语音信息生成肌肤作业数据集；提取历史语音信息的语音特征；构建深度学习模型并根据深度学习模型将历史面部图像划分为多个区域，提取区域中历史面部图像的图像特征，将图像特征与语音特征融合生成融合特征；根据肌肤作业数据集训练深度学习模型获得最优模型；响应于实时面部图像及实时语音信息被获取，根据最优模型控制每个区域的激光波长。本申请结合语音和图像数据，根据人体肌肤的区域设置最佳激光波长，提高肌肤作业的效果及智能化。
G10L15/00  ,一种变声程序的形成方法、存储介质和使用终端 [发明],本发明公开了一种变声程序的形成方法、存储介质和使用终端，属于声音处理技术领域，具体包括变声程序的形成方法、用于执行实现变声程序的可读写存储介质和变声程序使用终端。本发明采集使用者的声音数据，在深度学习神经网络的协同下，可以有效的做到对使用者声音特征的识别，从而在需要变声的情况下，可以有效的对使用者输入的声音和其他输入声音进行分离，从而将使用者输入的声音数据进行变声处理，将输入的其他声音数据不做处理，原声输出，有效的确保了变声器的输出效果，让他人不容易轻易察觉到使用者在使用变声器，同时，在本方案中通过将使用终端分为收音部和扬声部，可以减小使用终端的整体体积，实现将使用终端融入衣帽、首饰的可能。
G10L15/22  ,音频处理方法和装置 [发明],本申请提供了一种音频处理方法和装置，该方法包括：获得待识别的目标音频信号；基于唤醒词识别模型，确定目标音频信号的唤醒词识别结果，唤醒词识别结果包括：多个唤醒概率，多个唤醒概率用于表征目标音频信号中多个不同音频段各自存在唤醒词的唤醒概率，其中，不同唤醒概率对应不同的音频段，音频段属于目标音频信号的至少部分；如果多个唤醒概率表明目标音频信号的至少一个音频段中存在唤醒词，确定进入唤醒状态。
A63F13/52  ,音频特效渲染方法、装置、电子设备和存储介质 [发明],本申请提供了一种音频特效渲染方法、装置、电子设备和存储介质，其中，该方法包括：获取目标音频文件的时频贴图，时频贴图用于指示目标音频文件的各音频帧在频域上的能量分布，对时频贴图进行采样，得到各音频帧中多个频率的能量，根据各音频帧中多个频率的能量，确定各音频帧中多个频率的振幅值，根据各音频帧中多个频率的振幅值，对目标音频文件对应的预设渲染模型进行特效渲染。本方案通过时频图对目标音频文件对应的预设渲染模型进行特效渲染，不需要实时解析音频，降低了处理消耗，提高了音频可视化特效的性能，并且仅获取目标音频文件的时频图，避免其它音效的干扰，提高了特效渲染精度。
G10L15/22  ,语音交互方法及其装置、模型训练方法、车辆和存储介质 [发明],本发明公开了一种语音交互方法及其装置、模型训练方法、车辆和存储介质。语音交互方法包括接收语音请求，将语音请求转化为文本语音指令；利用指令理解模型对文本语音指令进行多层理解处理，得到与文本语音指令对应的业务功能信息；根据业务功能信息执行文本语音指令。本发明的语音交互方法可以利用指令理解模型对文本语音指令进行多层理解处理，得到与文本语音指令对应的业务功能信息，从而根据业务功能信息执行文本语音指令，从而实现高效精准地理解用户发出的语音请求，可以满足用户对于车辆零部件的定制场景对应的定制化语音的执行需求。
G06Q10/083  ,一种智能语音发货系统 [发明],本发明公开了一种智能语音发货系统，该系统包括：语音采集模块、文本识别模块、文本解析模块、货物信息确认模块、订单生成模块；语音采集模块，用于响应于货主进入发货界面，采集输入的语音信号；文本识别模块，用于对语音信号进行识别，获得语音信号对应的文本信息；文本解析模块，用于对文本信息进行解析和理解，获得货主的对应目标需求；货物信息确认模块，用于根据货主的目标需求，从预存储的数据库内确定与目标需求对应且规范的货物信息；订单生成模块，用于根据目标需求和货物信息，生成相对应的发货订单，并进行发货。本发明将语音识别和发货流程相结合，降低货主操作成本和提高发货效率。
G06F3/01  ,一种基于听觉的双向脑机接口系统 [发明],本发明公开了一种基于听觉的双向脑机接口系统，包括：采集用户经运动想象发出声音后产生的脑电信号，对脑电信号进行预处理并构建脑电信号数据集；构建匹配长短期记忆网络模型，对匹配长短期记忆网络模型进行训练，获取训练好的匹配长短期记忆网络模型，并将脑电信号数据集转换为对应的文本数据；构建声码器模型，将文本数据输入声码器中生成对应的语音信号；将语音信号和脑电信号进行预处理，并构建脑电‑语音数据集；对脑电‑语音数据集进行分类识别，构建语音数据集、脑电‑语音数据集和脑电数据集；构建双边对偶生成网络模型，对双边对偶生成网络模型进行训练，获取训练好的双边对偶生成网络模型；将语音信号进行转换，获取对应的脑电信号。
G10L15/16  ,智能对话方法、装置、计算设备及计算机可读存储介质 [发明],本发明公开了一种智能对话方法、装置、计算设备及计算机可读存储介质，属于人工智能技术领域。该智能对话方法包括：对当前对话文本进行意图识别和实体识别，确定当前对话文本的当前意图信息和当前实体信息；获取历史对话文本的历史意图信息、历史实体信息和历史决策；基于当前意图信息、当前实体信息、历史意图信息、历史实体信息和历史决策，通过决策模型确定当前对话文本的当前决策，该决策模型是使用多轮样本语料对深度学习模型训练得到的。上述方法将意图识别、实体识别和决策确定结合，结合多轮对话挖掘用户的需求，准确理解用户的意图，并通过决策模型生成符合用户需求的决策，提高了智能对话的准确性和灵活性，使得对话更加流畅。
G10L25/63  ,一种基于Transformer的调制融合在语音情感识别的方法 [发明],本发明属于自然语言处理情感分析技术领域，具体涉及一种基于句法结构迁移和领域融合的跨领域情感分类方法，基于句法结构迁移和领域融合的跨领域情感分类总体框架。依存句法递归神经网络模型。跨领域模型参数迁移策略。源领域网络到目标领域网络的参数预训练和微调。跨领域融合策略。领域联合学习和优化过程。本发明提出了一种基于句法结构迁移和领域融合的跨领域情感分类方法，具体设计一种新的可迁移的依存句法递归神经网络模型，通过句法结构迁移有效地迁移跨领域结构信息。在递归神经网络层和Softmax层之间加入了领域融合层，通过约束源领域和目标领域的分布，以领域融合的方式实现最大化源领域和目标领域情感信息之间的共享。
G10L15/26  ,语音识别方法、模型训练方法、装置、设备及存储介质 [发明],本申请实施例公开了一种语音识别方法、模型训练方法、装置、设备及存储介质，对语音识别模型的训练过程包括两轮自监督预训练和一轮有监督的微调，在第二轮自监督预训练过程中，利用对应不同语义粒度的第一类伪标签计算语音识别模型的不同层的自监督损失，使得预训练的语音识别模型可以学习到不同粒度的语音内容信息，从而提高语音识别模型的识别准确率。
G10L15/22  ,多语音设备的响应方法、装置和设备 [发明],本申请提供一种多语音设备的响应方法、装置和设备，涉及语音技术领域。该方法包括：在多语音设备场景中，针对语音信号源输出的语音唤醒信号，第一语音设备在第一相对方位下执行语音唤醒信号的接收操作，得到第一语音唤醒信号；从第一语音唤醒信号中提取第一语音信号特征，并向第二语音设备发送第一语音信号特征，以使第二语音设备基于第二语音唤醒信号和第一语音信号特征，确定是否向第一语音设备发送第二语音信号特征；并基于是否接收到第二语音信号特征，控制第一语音设备执行对应的操作，操作包括响应语音唤醒信号，或者，不响应语音唤醒信号，避免了出现“一呼百应”的情况，从而提高了语音唤醒的准确度。
G10L17/26  ,一种鸟鸣识别方法、装置、计算机设备及存储介质 [发明],本申请适用于声音识别技术领域，提供了一种鸟鸣识别方法、装置、计算机设备及存储介质，所述方法包括：获取鸟鸣声音数据；根据声源定位算法，确定鸟鸣声音的方向来源；根据人工智能，分析鸟鸣声音的种类；根据鸟鸣声音的种类，得到鸟类物种信息。通过将所述方法嵌入到便携式装置中，设备小巧轻便，易于携带，适合户外活动和野外观察。用户可以随时随地使用它来识别周围的鸟类，而无需额外的设备或复杂的设置。
G10L15/02  ,语音识别方法、装置及车辆 [发明],本申请涉及一种语音识别方法、装置及车辆。该方法包括：接收车辆座舱内用户发出的语音请求；对待识别的语音请求进行特征提取，生成特征向量；根据输入的特征向量，通过端到端的预设语音识别模型输出对应的语音识别文本，并以子词的形式在车载系统的图形用户界面逐一显示；其中，语音识别模型的建模单元包括子词单元，语音识别文本中的单个单词拆分的子词数量与对应的IPA音节数量相同且强制对齐，以根据IPA音节逐一输出对应的子词。本申请提供的方案，能够将端到端输出的语音识别文本实现与发音的强关联，识别效率高，且用数据量少。
G06F3/16  ,一种控制方法及电子设备 [发明],本申请实施例公开了一种控制方法及电子设备，该控制方法包括：获得电子设备的音频输出模组的使用参考数据，所述使用参考数据至少包括所述音频输出模组输出的音频数据和/或所述音频输出模组的使用对象；基于所述使用参考数据控制所述音频输出模组进入对应的音频输出模式，其中，在不同的音频输出模式下，所述音频输出模组中的至少一发声模组的工作参数不同。
G10L15/26  ,语音识别方法、模型训练方法、装置、设备及存储介质 [发明],本申请实施例公开了一种语音识别方法、模型训练方法、装置、设备及存储介质，对语音数据进行编码，得到语音数据的编码特征，对编码特征进行解码，得到解码特征；该解码特征用于确定语音数据的语音识别结果和语法分类结果，对解码特征进行处理，得到语音识别结果。本申请对解码特征进行解码得到的解码特征既可以用于语音识别，也可以用于语法分类，也就是说，本申请对语音数据进行编码的过程，以及对解码特征进解码的过程考虑了语法知识，从而提高了语音识别结果的准确性。
A61N1/36  ,一种基于语音识别的OSA电刺激装置 [发明],本发明提出了一种基于语音识别的OSA电刺激装置，包括体外机和体内机，其中，体外机采用红外辐射的方式为体内机供能，并由体内机产生刺激信号，体外机包括：音频采集模块，用于对用户的鼾声进行音频采集，获得音频数据；数据处理模块，用于通过预设的语音识别系统判断用户是否出现OSA病症以及病症等级，并根据病症等级生成控制信号；红外发射模块，用于根据控制信号生成对应强度和频率的红外辐射。本发明通过鼾声检测实现了将OSA检测的外移，使其在体外机中实现，减少了植入手术的风险；同时，无线供能的方式也避免了体内机电池需要手术更换的问题，保证了产品工作的稳定性并进一步降低了手术风险，且红外辐射对人体无害，保证了用户的使用安全。
G10L15/06  ,数据处理方法、装置、设备及存储介质 [发明],本公开提供一种数据处理方法、装置、设备及存储介质，涉及语音识别技术领域。该方法包括：获取待处理视频的音频数据及对对应的待处理视频帧进行字幕文本识别得到的图像识别文本，对待处理视频的音频数据及进行语音识别并进行强制对齐处理，获得对齐后的文本，然后对对齐后的文本进行纠错处理，获得纠错后文本，并参考对应的图像识别文本对纠错后文本进行筛选，以获得用于训练语音识别模型的训练数据。该方法扩充了语音识别模型的训练数据集。
A61B5/16  ,一种精神状态分析系统、电子设备及存储介质 [发明],本发明提供一种精神状态分析系统、电子设备及存储介质，其中，系统包括：多模态特征提取模块、跨模态注意力模块和精神状态检测模块；所述多模态特征提取模块将长音视频转换为图像序列和语音片段，并且提取面部特征和音频特征；将所述面部特征和音频特征输入所述跨模态注意力模块，探索图像和音频模态之间的关系，提取受试者的情绪特征值；将所述情绪特征值输入精神状态检测模块，以获取受试者当前的精神状态。本发明提出的方案能够使用单个跨模态注意力模块对音视频的特征进行精神状态特征值的提取，以该特征进行抑郁、焦虑和疲劳状态的检测分析，有更高的识别精确度，并且可以提供更多的分析信息。
G10L15/26  ,基于语音指令的设备控制方法、装置以及电子设备 [发明],本申请公开了一种基于语音指令的设备控制方法、装置以及电子设备。涉及智能设备领域或其他相关领域，该方法包括：接收目标语音指令，将目标语音指令输入语音识别模型，输出目标文本数据，其中，语音识别模型用于将目标语音指令转化为数据类型为文本格式的目标文本数据；根据预设语法规则以及词汇库对目标文本数据进行解析，得到目标语音标签树，并将目标语音标签树与多个预设控制规则进行匹配，根据匹配结果确定目标控制规则，其中，目标语音标签树用于指示目标语音指令的语音内容信息；依据目标控制规则对目标设备进行控制处理。通过本申请，解决了相关技术中基于语音信息控制设备时，智能设备识别语音信息的准确率低的问题。
G06F16/904  ,智慧园区的信息呈现方法、装置、设备及存储介质 [发明],本申请实施例涉及智慧园区的技术领域，具体涉及一种智慧园区的信息呈现方法，包括：获取智慧园区的监控数据以及基于用户交互设备采集的提示词；通过预设的大模型对所述监控数据进行特征分析，以输出对应于所述提示词的目标信息；将所述目标信息呈现于所述用户交互设备的显示界面。相比于现有技术，本方法在采集了智慧园区的监控数据之后，根据用户通过用户交互设备输入的提示词来输出不同维度的目标信息，从而使得园区管理人员能够更加有针对性地了解园区内不同场景下的特定信息，能够减少园区管理者对大量无效信息的判别时间，从而节省了大量的人力物力，且能够降低对园区管理者的注意力需求，避免由于人工懈怠影响监控效果。
G10L17/02  ,一种基于局部和全局跨通道融合的声纹识别方法 [发明],本发明公开了一种基于局部和全局跨通道融合的声纹识别方法，属于数字信号处理和语音识别技术领域，该方法引入了局部和全局跨通道融合的设计，通过将一个整理的信息划分为两个部分，分别对其进行局部和全局特征提取，接着将局部和全局特征进行融合，让信息更加丰富增加模型识别的泛化能力。该方法在声纹识别中具有较高的准确率和实时性，并行的设计在没有加宽模型的宽度前提下，进一步加快了运算速度，弥补了传统的声纹识别技术在准确性和运算速度方面存在的不足，在语音助手唤醒、身份证和信用卡识别等相关应用场景具有较大的应用潜力。
G10L21/0272  ,一种音频转译方法及音频转译服务器、设备及存储介质 [发明],本申请提供了一种音频转译方法及音频转译服务器、设备及存储介质，其中，对目标用户端请求转译的待转译音频流进行声纹分割得到多个子音频流和各子音频流所对应的发言人信息；调用SDK服务器对各子音频流进行语音识别得到各子音频流所对应的文字内容；将各子音频流、各子音频流所对应的发言人信息以及各子音频流所对应的文字内容发送至所述目标用户端进行展示。采用上述方法，以减少在进行音频转译时所需耗费的人力成本，同时提高音频转译结果的准确性。
G10L15/22  ,基于语音识别的场景创建方法、装置及车辆 [发明],本发明公开一种基于语音识别的场景创建方法、装置及车辆，通过获取用户发出的目标语音；然后根据所述目标语音，提取创建场景的条件信息以及动作信息；之后根据竞合策略，对所述条件信息以及所述动作信息进行合理性检查；最后根据检查后的条件信息、动作信息，创建场景。如此，通过语音识别控制的方式，智能化的创建场景，无需用户自己手动去编辑，方便快捷。
G10L21/013  ,语音转换方法及装置、存储介质、电子装置 [发明],本申请实施例提供了一种语音转换方法及装置、存储介质、电子装置，所述方法包括：获取待转换的原始语音与目标说话人的目标语音样本；通过音频特征编码模块识别所述目标语音样本的风格类别，并根据所述目标语音样本的风格类别提取所述目标语音样本的目标音频特征；通过风格特征编码模块获取所述目标语音样本的风格特征；将所述原始语音的原始音频特征、所述目标语音样本的目标音频特征和所述目标语音样本的风格特征进行融合映射得到联合编码特征；对所述联合编码特征进行标准流化操作后解码，得到与所述目标说话人的说话风格对应的目标语音特征，并基于所述目标语音特征对所述原始语音进行转换，得到目标语音。
G10L13/10  ,语音生成方法、装置、计算机设备和存储介质 [发明],本申请涉及一种语音生成方法、装置、计算机设备和存储介质，涉及计算机技术领域。可用于金融科技领域或其他相关领域。所述方法包括：从预设的语音数据库中查找语音文本对应的音节标记数据；根据语音文本，确定语音文本的韵律参数信息；根据韵律参数信息和音节标记数据，对语音文本的语音波形数据进行修改，得到音节标记数据对应的待合成波形数据；根据待合成波形数据，生成语音文本对应的目标语音。采用本方法能够通过分析语音文本的上下文语义，确定语音文本的韵律参数，结合语音文本在语音数据库中的音节标记数据，修改语音文本各语音段对应的语音波形，得到具有与语音文本的上下文语义相匹配的韵律特征的目标语音，提高合成的语音的自然度。
G10L13/08  ,文本音素标注信息生成方法、装置和计算机设备 [发明],本申请涉及一种文本音素标注信息生成方法、装置和计算机设备，涉及计算机领域。可用于金融科技领域或其他相关领域。所述方法包括：对语音文本进行分词，得到语音文本对应的分词结果；按照预设的韵律分析规则，根据分词结果对应的语法信息，确定语音文本对应的韵律边界信息；获取语音文本对应的注音信息，根据韵律边界信息和注音信息，确定语音文本对应的音素标注信息。采用本方法能够通过分析语音文本的韵律特征，结合语音文本的上下文韵律，对语音文本中的各音素进行准确的标注，得到用于生成对应的语音的音素标注信息，从而基于音素标注信息，生成能够体现语音文本上下文韵律特征的语音，进而提高语音合成的自然度。
G06F40/205  ,音频播放方法、装置、设备及可读存储介质 [发明],本申请实施例提供一种音频播放方法、装置、设备及可读存储介质。该方法包括：获取第一文本，第一文本是多媒体文件的相关文本；通过第一大型语言模型，对第一文本进行摘要提取，得到第二文本；通过第二大型语言模型，对第二文本进行口语化生成，得到第三文本；将第三文本转换为音频文件，得到多媒体文件的介绍音频；播放多媒体文件以及多媒体文件的介绍音频。为多媒体文件生成对应的介绍内容，辅助用户对多媒体文件作进一步了解，提高用户收听多媒体文件的趣味性；以及将多媒体文件和对应的介绍音频进行关联，进一步提高对多媒体文件信息的获取效率。
G10L25/30  ,一种基于残差计算的卷积神经网络的城市音频分类方法 [发明],本申请实施例是关于一种基于残差计算的卷积神经网络的城市音频分类方法。该方法包括：构建城市音频分类模型；对城市音频数据进行数据增强，并将数据增强后的城市音频数据划分为训练集和测试集；分别对训练集和测试集进行处理，以得到训练集音频特征和测试集音频特征；将训练集音频特征送入城市音频分类模型中进行训练，得到训练后的城市音频分类模型；将测试集音频特征送入训练后的城市音频分类模型中进行训练，以对测试集音频特征进行分类，并根据测试集音频特征的分类结果对测试集进行分类。本申请实施例能够有效解决传统深度学习神经网络对城市音频分类精度不高的问题，在提升计算效率的同时，提升了城市音频的分类精度。
G10L15/06  ,训练数据的确定方法、服务器及计算机可读存储介质 [发明],本申请公开一种训练数据的确定方法，所述方法包括：获取原始训练数据，获取增强训练数据，融合原始训练数据与增强训练数据，从而得到目标训练数据。如此，在本申请实施方式中，服务器可获取由第二类型的结构化数据所构成的增强训练数据，进而将增强训练数据与原始训练数据融合，从而实现原始训练数据的增强以得到目标训练数据，进而通过目标训练数据进行大语言模型的训练，在一定程度使得大语言模型的结构化数据处理能力得以保障。
G10L17/14  ,一种基于语音信号的催收对象识别方法与系统 [发明],本发明提供一种基于语音信号的催收对象识别方法与系统，属于语音识别技术领域，具体包括：基于语音机器人进行催收对象的催收得到历史催收记录，基于历史催收记录进行催收对象的催收接通率的确定，并结合催收对象的催收次数以及不同的未接通次数的问题类型进行催收对象的催收接通概率的确定，并当催收对象的催收接通概率满足要求时，至少基于催收对象的不同的可信催收次数之间的语音相似度以及问题评估量、语音不一致催收次数、问题催收次数以及催收接通概率进行问题催收对象以及催收处理顺序的确定，提升了语音机器人的催收对象的催收触达率和催收效率。
G06F3/01  ,一种基于多模态大语言模型的人机交互系统及方法 [发明],本发明属于人工智能相关技术领域，并公开了一种基于多模态大语言模型的人机交互系统及方法。该系统包括智能视觉交互模块和智能语音助手模块，智能视觉交互模块包括图像采集单元、图像处理单元和图像显示单元，图像采集单元用于采集图像和预处理，图像处理单元将采集的图像进行特征提取，显示单元用于提取的特征以文本的形式显示在显示屏上；智能语音助手模块包括声音采集单元、语音处理单元和语音输出单元，声音采集单元用于采集声音和预处理，语音处理单元用于接受来自语音并进行处理获得相应的输出答案，语音输出单元用于进行语音输出，实现与用户的实时沟通。通过本发明，解决智能系统不能进行语音和视觉等多模态的智能人机交互的问题。
G10L13/10  ,基于语音韵律的语音合成模型训练方法及语音合成系统 [发明],本申请提供一种基于语音韵律的语音合成模型训练方法及语音合成系统，通过将训练文本输入先验编码器，得到文本特征编码，再将文本特征编码和训练语音输入韵律编码器，得到韵律编码，然后将训练语音对应的线性谱输入后验编码器中，得到音频隐变量，并通过时序对齐模块对齐训练文本、韵律编码和音频隐变量的时序序列，得到合成语音编码，通过解码器解码合成语音编码，得到训练合成语音，再计算训练合成语音的训练损失，以判断语音合成模型的收敛程度。本申请通过训练文本和训练语音获得韵律编码，并通过时序对齐将韵律编码融入合成语音编码中，使生成的合成语音能贴合人物语音的韵律特征，在语音样本不足的情况下，提高合成语音的韵律相似度。
G10L25/57  ,说话人定位方法、装置、电子设备及存储介质 [发明],本申请提供了一种说话人定位方法、装置、电子设备及存储介质。本申请通过，获取影视作品中的多句待匹配台词；针对每句待匹配台词，获取所述待匹配台词对应的音频序列及至少一条人脸序列，其中，每条人脸序列中仅包含一个人物的人脸；在至少一条人脸序列中确定所述音频序列对应的目标人脸序列，其中，所述目标人脸序列包含的人物为所述待匹配台词对应的说话人；基于对应的目标人脸序列从多句所述待匹配台词中确定至少一句目标台词；基于每句目标台词对应的音频序列和目标人脸序列，对所有目标台词进行分组，得到至少一个台词分组，其中，每个台词分组中包含的目标台词对应同一个说话人。由此提高说话人定位的效率。
G10L13/08  ,语音合成方法、装置、计算机设备和存储介质 [发明],本申请涉及一种语音合成方法、装置、计算机设备、存储介质和计算机程序产品，涉及人工智能技术领域。所述方法包括：获取第一语音数据库和第二语音数据库；根据第一语音数据库和第二语音数据库构建基元模型，并在问题集的指导下对基元模型进行训练，得到初始模型库；对初始模型库中的基元模型进行自适应训练，得到至少两个说话对象对应的均音模型；采用第二语音数据库中的目标说话对象的情感语料信息，对均音模型中的说话对象进行自适应变换，得到目标语音合成模型。采用本方法能够提升合成语音自然度。
G10L21/0208  ,回声消除方法、装置、电子设备及存储介质 [发明],本申请提供一种回声消除方法、装置、电子设备及存储介质，其中，所述方法包括：对接收的音频信号进行变换，得到频域信号；将所述频域信号输入预设的神经网络模型，获取所述神经网络模型输出的卡尔曼滤波参数；使用所述卡尔曼滤波参数及预设的卡尔曼滤波模型对所述频域信号进行处理，得到处理信号；将所述处理信号转换为处理音频信号，通过神经网络模型对卡尔曼滤波模型的参数进行预测，利用预测的参数和卡尔曼滤波模型对语音数据进行回声消除，有效提升了回声消除效果，对于回声路径有变化的环境的响应更为及时并且具有更强的鲁棒性。此外，本申请的方法计算复杂度低，实时性高。
G10L25/51  ,重叠人声检测模型的训练方法、重叠人声检测方法及装置 [发明],本申请实施例提供了一种重叠人声检测模型的训练方法、重叠人声检测方法及装置，涉及音频检测和音频处理技术领域。所述重叠人声检测模型的训练方法包括：获取重叠人声检测模型的训练样本集，训练样本集中包括至少一个训练样本，每个训练样本包括一段歌曲音频以及歌曲音频对应的重叠人声标注结果；通过重叠人声检测模型输出歌曲音频对应的重叠人声检测结果，重叠人声检测结果用于指示歌曲音频中的各个帧分别对应的重叠人声概率值；根据重叠人声检测结果和重叠人声标注结果之间的差异，对重叠人声检测模型的参数进行调整，得到训练后的重叠人声检测模型。采用本申请实施例提供的技术方案，能够提高对歌曲音频中的重叠人声的检测准确率。
G10L15/06  ,基于LORA微调辅助的语音唤醒快速自适应方法 [发明],本发明公开了基于LORA微调辅助的语音唤醒快速自适应方法，通过训练得到一个通用的音素识别模型，对输入音频进行初步的音素序列分类；并在唤醒词通用训练集上对音素识别模型进行微调，快速提高识别模型的唤醒词识别能力；进一步地，基于客户提供的目标唤醒词语料，使用LORA训练的方法进行模型的部分参数微调，使得模型快速提高目标关键词唤醒的自适应能力。本发明在现有唤醒水平的基础上依照客户的具体唤醒词与唤醒环境的需求，利用少量的目标域数据进行快速高效的模型微调训练，使得模型可以在短时间内适应目标域的实际应用场景，在短时间低成本内实现唤醒模型的实际应用效果的提升。
G06F18/25  ,一种AI情绪可视化识别方法 [发明],本发明涉及智能交互技术领域，且公开了一种AI情绪可视化识别方法，包括以下步骤：1)首先，进行图像和语音数据采集，生成图像数据模型和语音数据模型；2)图像信息处理，对图像数据模型进行特征提取处理，获取其中的表情特征和动作特征；3)图像情绪识别，基于表情特征确立所述图像数据中映射的情绪类型，并基于所述动作特征确定所述图像数据中对应的情绪强度。该AI情绪可视化识别方法，可对图像和音频进行分析处理，得出情绪分析结果，并将图像情绪识别的结果和语音情绪识别的结果进行加权融合处理，达到相互印证的目的，以确定处最终的情绪识别结果，得出精确的情绪分析报告，此种方式能够有效排除干扰项，识别出准确度高的真实情绪。
G10L13/02  ,注音方法、装置、语音合成系统、存储介质及电子设备 [发明],一种注音方法、装置、语音合成系统、存储介质及电子设备。所述方法包括：当待注音词条为普通话非多音词词条时，查询目标方言引擎发音词典，得到与所述待注音词条匹配的第一词面；所述目标方言引擎发音词典包括：普通话词条及方言词条，至少部分普通话词条中包括对应方言词条的索引信息；确定所述第一词面所在的普通话词条是否存在对应的方言词条；当存在对应的方言词条时，获取所述对应的方言词条中音素序列信息，作为所述待注音词条指派的音素序列信息并输出。采用上述方案，可以提高文本分析阶段所输出音素序列的准确性。
G06V10/25  ,难例挖掘方法、装置、电子设备及存储介质 [发明],本申请提供了一种难例挖掘方法、装置、电子设备及存储介质。包括：获取基础定位模型及所述基础定位模型对应的测试数据集；利用所述基础定位模型对多个所述测试数据进行分组，得到多个第一数据分组；针对每个第一数据分组，基于所述第一数据分组中的音频数据从所述第一数据分组中的多个测试数据中确定好例数据和难例数据；利用所述好例数据优化所述基础定位模型，得到更新定位模型；利用所述更新定位模型对多个所述难例数据进行分组，得到多个第二数据分组；针对每个第二数据分组，基于所述第二数据分组中的音频数据和视频数据，从所述第二数据分组中的多个难例数据中确定目标难例数据。由此实现对难例数据的智能挖掘。
G10L21/007  ,一种基于音高的语音转换模型训练方法及语音转换系统 [发明],本申请提供一种基于音高的语音转换模型训练方法及语音转换系统，通过先验编码器输出音频特征编码，并通过音高提取模块提取音高特征。然后将参考语音对应的线性谱输入至所述后验编码器中，得到音频隐变量。并将音频特征编码和音高特征拼接得到的语音拼接特征和音频隐变量输入至时序对齐模块，得到转换语音编码，并通过解码器解码转换语音编码，得到转换后的语音。再计算转换后的语音的训练损失，以判断语音转换模型的收敛程度。本申请通过音高提取模块提取参考语音的音高特征，并与音频特征编码进行拼接对齐，使转换后的语音的音高特征更加接近真实人物的语音，提高转换后的语音的音高相似度。
G10L25/57  ,说话人定位方法、装置、电子设备及存储介质 [发明],本申请提供了一种说话人定位方法、装置、电子设备及存储介质。本申请通过，获取影视作品中的多句待匹配台词；针对每句待匹配台词，获取所述待匹配台词对应的音频序列及视频序列，其中，所述视频序列中包含至少一条人脸序列，每条人脸序列中仅包含一个人物的人脸；基于所述音频序列和所述视频序列，提取所述待匹配台词对应的序列融合特征；基于所述序列融合特征，在所述视频序列包含的至少一个人物中确定目标人物，其中，所述目标人物为所述待匹配台词对应的说话人。通过本方案，可以基于待匹配台词对应的音频序列及视频序列，确定该待匹配台词对应的说话人，由此实现智能对影视作品中台词和说话人的匹配，从而提高说话人定位效率。
G10L21/0224  ,一种噪声源自动解析与追踪方法 [发明],本发明公开了一种噪声源自动解析与追踪方法，所述自动解析与追踪方法包括以下几个步骤：第一步，进行噪声信号的获取，通过音频采集设备将噪声的信号进行获取，对噪声信号进行多次采集；第二步，将信号进行过滤筛选，通过对比和筛选将噪声信号进行分组保留；第三步，构建数据库，将噪声信号的时域波形与噪声类型进行整合。本发明一种噪声源自动解析与追踪方法，在使用时先通过采集设备将噪声信号多次进行采集，并将多次采集的噪声信号中所采集的声波信息进行筛选，将多次采集后同时拥有的声波信息按照不同的声波频率进行分组保存，将采集到只存在某一次的声波信息进行去除，从而避免出现因重叠信息导致得到的结果出现错误。
G10L15/20  ,一种计算机语音识别设备 [发明],本发明涉及语音识别技术领域，尤其为一种计算机语音识别设备，包括主体、数据线、音频解码器和语音信号处理芯片，所述主体包括壳体，所述壳体的内侧开设有安装口，所述壳体的内侧开设有槽位，所述槽位的外侧开设有轨槽，所述安装口的内侧安装有收音模块，所述收音模块包括连接管，所述连接管的内侧固定连接有固定架，所述固定架的内侧安装有麦克风收音头，所述连接管的外侧固定连接有集音管，所述集音管的内侧开设有出液口，所述集音管的内侧固定连接有挡条，本发明中，通过设置的收音模块、降温模块、集液箱等结构实现了语音识别设备在保证语音接收不受外部环境音影响的前提下，可以对语音时呼出的水蒸气进行提前处理的能力。
G01L5/24  ,基于特征掩蔽网络的螺栓松动检测方法、装置、介质 [发明],本申请涉及铁塔检测领域，公开了一种基于特征掩蔽网络的螺栓松动检测方法、装置、介质，包括：获取声音检测信号，并对声音检测信号进行特征编码操作，以获取初始特征信息；利用特征掩蔽网络对初始特征信息进行掩蔽处理，以获取目标特征信息；利用事件分类器对目标特征信息进行分类处理，以根据分类结果判断是否存在螺栓松动事件。本申请采用声信号检测法，无需设置大量传感器，降低了检测系统成本。并通过特征掩蔽网络对特征信息进行掩蔽处理，以消除声音检测信号中的干扰信号，获取目标特征信息，从而更准确的判断螺栓是否松动。采用Sigmoid函数作为特征掩蔽网络的激活函数，提高不同特征的区分度，进一步提高检测结果的准确性和可靠性。
G16H50/30  ,一种基于语音识别和动作分析的呼吸行为习惯监测系统 [发明],本发明涉及呼吸行为习惯监测技术领域，具体公开一种基于语音识别和动作分析的呼吸行为习惯监测系统，该系统包括设置呼吸行为习惯数据采集模块、呼吸行为习惯数据分析模块、面部特征数据采集分析模块、数据整合处理云端和呼吸习惯数据库，本发明通过对人员的呼吸行为习惯进行分析，有助于实时监测和评估个体的呼吸行为习惯问题，有助于为人员提供个性化的改善建议，通过对人员的呼吸行为习惯进行分析并生成人员的呼吸习惯调节管理标签进行智能提醒，有助于人员及时发现潜在的呼吸行为习惯问题，从而采取相应的维护措施，避免潜在呼吸行为习惯问题的进一步恶化。
G10L15/22  ,基于生成对抗网络的语音唤醒方法、装置及存储介质 [发明],本申请公开了一种基于生成对抗网络的语音唤醒方法、装置、存储介质、电子设备及计算机程序产品，该方法包括：获取待识别的目标语音数据；对目标语音数据进行声学特征提取，得到目标声学特征；将目标声学特征输入语音识别模型中进行处理，语音识别模型包括解码器和已训练的生成对抗网络，生成对抗网络包括生成器和第一判别器，生成器用于根据目标声学特征生成目标编码特征；第一判别器用于根据目标编码特征输出第一判别结果；解码器用于根据预设唤醒词对目标编码特征进行解码，并输出解码分数；根据第一判别结果和解码分数，进行车载语音系统的唤醒操作，从而无需用户手动操作即可唤醒车载语音系统，简化了唤醒流程，用户体验感好。
H04L9/40  ,基于人工智能的网络安全等级保护测评方法、系统及装置 [发明],本发明涉及一种基于人工智能的网络安全等级保护测评方法、系统及装置，包括构建基于深度学习和知识图谱的网络安全等级保护模型、设计基于智能语音交互的安全管理和设备配置扫描方法、构建人工智能驱动的网络安全等级保护评级与决策系统、设置网络安全情报系统，通过将人工智能技术应用在网络安全等级保护测评领域，实现网络安全等级保护测评流程的智能化和自动化，有效减少人工干预和操作，降低测评成本，提高测评效率和准确率。
G10L25/30  ,一种环境噪声识别方法、系统、设备和介质 [发明],"本发明涉及声音识别技术领域，公开了一种环境噪声识别方法、系统、设备和介质。本发明将原始音频数据划分为有标签的源域原始音频数据和无标签的目标域原始音频数据；构建包括对比学习网络、对抗训练学习网络和分类识别网络的音频识别网络模型；将每个音频数据转换为对应的声谱图组并进行特征提取，得到特征向量组；根据特征向量组在源域和目标域对对比学习网络和对抗训练学习网络进行训练，并根据源域特征向量组对所述分类识别网络进行标签的分类识别训练，得到训练好的音频识别网络模型；通过训练好的音频识别网络模型对环境噪声进行识别分类。本发明降低了数据标记的成本,提高了环境噪声分类的准确性，提高了模型的泛化能力。"
G10L17/02  ,一种基于语音单元的声纹识别方法及装置 [发明],本发明主要涉及声纹识别技术领域。为了解决现有的语音识别技术由于文本信息的变化是使得同一说话人的不同语音识别率不一致的问题，本发明提供一种基于语音单元的声纹识别方法及装置，所述方法包括：提取输入语音的帧级别特征；预测语音的帧级别特征对应的语音单元的个数以及每个语音单元包含的帧级别特征；将每个语音单元包含的帧级别特征进行融合，得到语音单元特征；将语音单元特征进行融合，得到说话人声特征；根据说话人声特征计算说话人声语音向量的相似度，判断输入的语音是否属于已注册的说话人的语音。
G10L21/0316  ,音频信号处理方法、装置、车辆及存储介质 [发明],本公开涉及一种音频信号处理方法、装置、车辆及存储介质，涉及车辆技术领域，该方法包括：获取车辆内的模拟声浪对应的声浪音频信号，模拟声浪是车辆播放目标音频信号产生的声浪。根据声浪音频信号和目标音频信号，确定修正频响关系。根据修正频响关系调整目标音频信号。本公开根据从环境中获取的模拟声浪对应的声浪音频信号，对车辆播放目标音频信号进行修正，使得目标音频信号能够灵活地适应于各种不同的环境，能够保证车辆在不同的环境中都能稳定输出较为理想的模拟声浪，提高了生成模拟声浪的灵活性和稳定性。
G10L17/22  ,人机交互的方法、装置和设备 [发明],本申请提供一种人机交互的方法、装置和设备，所述方法用于机器人与用户之间的互动，包括：检测所述用户是否朝向所述机器人；在所述用户朝向所述机器人的情况下，获取所述用户的语音信息；根据所述语音信息确定所述用户的语音是否针对所述机器人；在所述用户的语音是针对所述机器人的情况下，确定所述用户有与所述机器人进行语言交互的意愿。相比于通过用户说出唤醒词来表达其语言意图的方式，提升了语音交互的连贯性，并且由于在理解用户的语意之前，先检测用户是否朝向机器人，并在用户朝向机器人的情况下才对用户的语音信息进行收集分析，在一定程度上避免了对用户语音的过度解析。
G10L15/20  ,车辆座舱的语音唤醒方法、装置及车辆 [发明],本申请涉及一种车辆座舱的语音唤醒方法、装置及车辆，该方法包括：获取车辆座舱内的用户语音信号，对用户语音信号进行滤波，获得残差语音信号和中间语音信号，根据残差语音信号和中间语音信号生成目标语音信号，采用目标语音信号对车辆座舱进行唤醒。本申请提供的方案，能够降低语音识别和语音唤醒的难度，提高语音唤醒的准确度和用户体验感。
H04N21/854  ,多媒体处理方法及装置 [发明],本申请实施例提供一种多媒体处理方法，所述方法包括：获取目标对象对应的个性化素材库，其中，所述个性化素材库根据目标对象的历史使用素材和/或实时使用素材得到，所述历史使用素材或所述实时使用素材从通用素材库中得到；在接收到目标多媒体输入的情况下，对所述目标多媒体进行分析，确定与所述目标多媒体对应的目标标签；根据所述目标标签在所述个性化素材库中确定并返回目标素材，以根据所述目标素材和所述目标多媒体生成目标视频。本申请实施例提供的多媒体处理方法，可以使视频剪辑创作者从个性化素材中快速选择想要的素材，提高视频创作的效率。
G10L17/06  ,说话人的语音识别方法、系统、电子设备及存储介质 [发明],本发明公开了一种说话人的语音识别方法、系统、电子设备及存储介质。该语音识别方法包括：获取目标音频，并对所述目标音频进行语音识别处理，得到目标文本；根据语义对所述目标文本进行断句处理，得到至少两个子句文本；对所述子句文本对应的子句音频进行声纹识别，得到所述子句音频的声纹信息；根据所述子句音频的声纹信息以及所述子句文本与当前场景的关联度确定所述子句音频对应的说话人是否为主说话人。通过对音频进行声纹信息识别和场景主题相关度的识别，判断音频对应的说话人是否为主说话人，解决了旁边人说话的干扰问题，提高了语音对话中的交互舒适度。
G10L15/06  ,语音识别方法、系统、设备及存储介质 [发明],本发明提供了语音识别方法、系统、设备及存储介质，该语音识别方法包括：将音频数据输入声学模型，输出语音识别结果，语音识别结果包含由单字组成的兴趣点词及其声学得分；在语音识别结果中的至少一个目标单字具有同音字的情况下，对目标单字的识别结果进行同音字声学得分增强，以缩小目标单字与同音字之间的声学得分分差；利用增强后的目标单字的识别结果更新语音识别结果，使用语言模型对更新后的语音识别结果进行打分，输出兴趣点识别结果。本方法能够通过拉近语音识别后单字及其同音字的声学得分，从而在最终与语言模型结合时给出更精确答案。
G10L25/60  ,一种音频测试分析方法 [发明],本发明涉及音频测试技术领域，具体为一种音频测试分析方法，包括步骤如下：S1.音频基础参数采集；S2.音频基础参数质量分析；S3.信噪比分析；S4.音频失真数据采集；S5.音频失真数据分析；S6.音频标准性分析；S7.音频设备质量分析，本发明通过对音频的音频基础参数分析得到音频的质量系数，通过音频的平均功率、噪声音频的平均功率分析得到音频的信噪比，根据削波失真的时长占比、音频频率段的平均幅度偏差、主频率的谐波总和得到音频的失真程度，同时结合音频识别的标准程度综合分析得到音频综合质量指数，可以量化地反映音频质量的优劣，便于有效改善音频的质量，提高声音的清晰度和音质，获得更为一致和高质量的音频输出。
G10L25/51  ,一种音频采集设备的测试方法、装置及相关设备 [发明],本申请涉及车载配件测试技术领域，尤其涉及一种音频采集设备的测试方法、装置及相关设备。方法包括：获取由音频采集设备对预置语音进行采集后得到的采集语音；针对所述采集语音进行语音识别，得到识别语句；确定所述识别语句与对应的预置语句之间的语句长度差值以及差异文字数量；所述预置语句为所述预置语音对应的文本内容；根据所述语句长度差值、所述差异文字数量以及预设标准，确定所述音频采集设备是否通过测试。本申请能够解决现有的MDVR音频采集设备的测试由于依赖人工测听，导致测试结果误差大以及无法反映音频采集设备的采集性能的技术问题。
G10L17/04  ,声纹识别方法、装置、电子设备及存储介质 [发明],本申请提供一种声纹识别方法、装置、电子设备及存储介质，涉及计算机的技术领域。声纹识别方法，包括：获取待检测音频信号；提取所述待检测音频信号的STFT特征；将所述STFT特征输入预先训练好的VAD模型中，得到表征所述待检测音频信号为人声的概率值；当所述概率值大于预设阈值的情况下，基于所述概率值、所述概率值对应的STFT特征以及预先训练好的声纹识别模型，得到表征声音对象的输出结果。本方案仅需要对待检测音频信号提取一次特征，声纹识别模型的输入数据由VAD模型输出的概率值和STFT特征融合得到。相较于现有技术中需要分别提取两次特征的方式，本方案能减少提取特征的次数。
G06V20/50  ,场景识别方法、模型训练方法、装置以及电子设备 [发明],本申请实施例公开了一种场景识别方法、模型训练方法、装置以及电子设备，方法包括：通过第一网络模型获取待识别数据的第一特征向量，待识别数据为图像模态或者语音模态的数据；获取多个候选场景各自的第二特征向量；将多个候选场景各自的第二特征向量中，与第一特征向量的相似度满足目标相似条件的第二特征向量作为目标特征向量；将目标特征向量所对应的候选场景，作为待识别数据对应的场景。从而通过上述方式使得在需要增加新的候选场景时，可以仅需要增加该新的候选场景对应的场景描述数据，并通过第二网络模型进行转换以得到对应的第二特征向量即可使得该新的候选场景能够进行识别，从而实现了更加简便的扩展可进行识别的场景。
G10L19/00  ,一种无线抗干扰传输音频的方法 [发明],本发明公开了一种无线抗干扰传输音频的方法，通过音频发送端采集音频设备Soundbar的待传输音频数据，并对从音频设备Soundbar获取的待传输音频信号进行编码获取音频数据包；通过对待传输音频信号进行编码加密处理后，来无线收发音频数据，提高了传输数据的稳定性且防止丢包率的出现；根据通信机制通过音频接收端对音频数据包进行解码播放，将音频数据通过打包后整体发送，接收设备接收到数据包后直接解码，减少了数据重组的时间，有效降低了时延，同时也提升了数据的安全性，减小了外界无线的干扰，提高了音频数据传输连接的稳定性。
G10L13/027  ,一种基于推理整合到训练过程中的音频生成的加速方法 [发明],本发明提出了一种基于推理整合到训练过程中的音频生成的加速方法，包括步骤1：训练去噪扩散概率模型(DDPM)，在正向过程中，通过马尔可夫链和高斯噪声，按预设噪声调度向数据样本注入噪声，获得带噪声的数据分布；步骤2：推理过程为逆向，逐步从高斯分布的噪声中恢复数据，利用参数化的逆向转换步骤和神经网络估计的噪声训练模型，目的是最大化似然函数的变分下界；步骤3：优化DDPM，通过比较生成样本与真实样本的距离，使用多分辨率短时傅里叶变换(STFT)损失函数和其他度量，以接近人类的感知质量；步骤4：增强模型对不同噪声级别的鲁棒性，在训练中考虑不同噪声水平变化，同时针对声码器任务优化推理过程中的噪声级别选择。
G10L19/008  ,语音宽动态范围压缩方法、装置、设备及存储介质 [发明],本申请涉及一种语音宽动态范围压缩方法、装置、设备及存储介质，应用在语音信号处理技术领域，包括获取待处理的语音信息，所述待处理的语音信息包括从所述助听器中获取的一段正常听力动态范围内的声音信息；将所述待处理的语音信息转换成频域的语音信号，并分解成预设数量的通道信号；对每个所述通道信号进行宽动态范围压缩处理后得到通道压缩信号；将每个所述通道压缩信号合成全通道频域信号，并转换成时域语音信号后输出。本申请具有的技术效果是：经过宽动态范围压缩处理实现听力补偿后减小背景噪声的影响。
G10L21/0216  ,一种噪声环境下耳机通话语音增强方法及系统 [发明],本发明公开了一种噪声环境下耳机通话语音增强方法及系统，包括通过获取耳机佩戴用户的反馈信息提取预选使用场景，将历史通话语音序列根据使用场景进行聚类，提取用户语音特征，根据所述语音特征及预设声学特征构建语音识别增强模型；在当前使用场景中获取含有环境噪声的通话语音序列，分离通话语音序列中佩戴用户的语音子序列；获取语音子序列中的噪声分布，调用当前使用场景对应的噪声衰减及滤波，利用线性编码对滤波后的语音子序列进行线性预测，获取连续的通话语音序列。本发明对不同场景下的声场环境进行语音增益，大大提高了耳机通话质量，并且考虑耳机佩戴用户的用户语音特征，提供个性化降噪效果，提高了耳机佩戴用户的通话舒适度。
G10L25/27  ,基于惩罚机制的声源检测方法、装置及存储介质 [发明],本发明实施例提供了一种基于惩罚机制的声源检测方法、装置及存储介质，涉及声源检测技术的技术领域。其方法包括：获取初始波束输出矩阵，并对初始波束输出矩阵进行搜索处理，以得到所述初始波束输出矩阵中满足预设条件的第一矩阵元素；基于所述第一矩阵元素对所述初始波束输出矩阵进行归一化处理，以得到第一惩罚矩阵；对第一惩罚矩阵以及预设的加权向量进行第一积值计算，以得到更新后的目标加权向量；基于所述目标加权向量，对预设的波束形成函数进行目标次数的迭代计算，以得到第一输出结果；基于所述第一输出结果确定目标区域的声源检测结果。通过本发明，解决了声源检测效率低的问题，进而达到了提高声源检测精度及效率的效果。
G10L19/26  ,语音处理的方法及装置、电子设备、存储介质 [发明],本申请涉及语音处理技术领域，公开一种语音处理的方法及装置、电子设备、存储介质。该方法包括：获取上一帧的输出语音数据和当前帧的混合语音数据；根据上一帧的输出语音数据、当前帧的混合语音数据利用预设的神经网络模型获取步长；根据步长更新预设的自适应滤波器中与上一帧的输出语音数据对应的状态估计矩阵；根据更新后的状态估计矩阵、上一帧的输出语音数据和当前帧的混合语音数据确定当前帧的输出语音数据。这样，由于神经网络模型是预先通过大量的语音数据训练获得，能够使得通过神经网络模型确定的步长，更容易使自适应滤波器达到收敛。从而加快自适应滤波器的收敛速度，以更快的抑制声反馈，进而提高用户的体验感。
G10L21/0232  ,一种频谱修复方法、系统及设备 [发明],本申请公开了一种频谱修复方法、系统及设备，通过获取初步增强后的预备掩膜值和预备语音频谱；基于第一预设阈值对各个时间频率单元的预备掩膜值进行二元化，得到用于表征时间频率单元为噪声主导单元或语音主导单元的第一掩膜值，基于预备语音频谱和第一掩膜值，计算得到预备输出；基于滑动窗覆盖区域是否包含语音主导单元，对所述第一掩膜值进行更新，得到第二掩膜值；基于滑动窗覆盖区域中语音主导单元的个数，对所述第二掩膜值进行更新，得到第三掩膜值；计算所述第三掩膜值和所述预备输出的乘积，得到频谱输出结果。由此，实现了对语音占主导的部分进行针对性修复，该修复能够使得模糊的谐波更加清晰，进而提升低信噪比下的语音增强效果。
G06V20/40  ,熵和傅里叶变换增强BAN模型的教态自主识别方法 [发明],本发明公开了熵和傅里叶变换增强BAN模型的教态自主识别方法，包括以下步骤：S1、针对智慧教室智能终端采集的教态视频，联合建立教态自主识别模型；S2、利用Hadamard积增强双线性注意力网络，捕获教师授课时表情与语调变化的交互过程；S3、利用条件域对抗网络CDAN，通过域自适应缓解域偏移和类别边缘化问题。本发明采用上述的熵和傅里叶变换增强BAN模型的教态自主识别方法，采用信息熵和傅里叶变换分别提取教师授课时肢体语言及语调的变化特征，联合建立教态自主识别模型，而后利用Hadamard积增强双线性注意力网络，提高多模态融合特征的稳定性，最终达到了在不同场景下稳定提升教态自主识别准确率的目的。
G10L15/30  ,一种流式语音识别方法、装置、介质及设备 [发明],本申请的实施例公开了一种流式语音识别方法、装置、介质及设备，涉及智能语音对话技术领域，本申请通过启动监听任务来监听流式语音识别，实时获取后端与语音识别模块的连接状态，在其处于断开状态时，通过断开时对应的时间戳与启动监听任务对应的时间戳之间的差值大小，确认引起中断的原因并进而确定中断事件类别，确认后根据不同情况的中断对应发起重连请求，并与语音识别模块重新连接继续进行流式语音识别，既能确保对话交互的流畅，又能保证有效信息不丢失，提升语音识别的质量。
G10L15/26  ,智能家居设备的控制权限配置方法、装置、存储介质及服务器 [发明],本申请实施例公开了一种智能家居设备的控制权限配置方法、装置、存储介质及服务器，涉及智能控制领域。本申请中管理员通过任意一个智能家居设备发出权限配置指令，然后服务器通过该智能家居设备提示临时用户输入生物识别数据，以及将输入的生物识别数据配置默认控制权限信息，这样可以实现临时用户不借助终端设备，就能实现智能家居网络的控制权限和操作，降低临时用户对硬件的依赖性，提升控制权限配置的便捷性和通用性。
G10L15/01  ,大语言模型提示信息确定方法、服务器及存储介质 [发明],本申请公开了一种大语言模型提示信息确定方法，包括：根据多个预设提示信息模板以及语音请求样本，通过预设的大语言模型，分别获取与每个预设提示信息模板对应的语义标签识别结果；根据语义标签识别结果，在多个预设提示信息模板中确定目标提示信息。本申请能够针对同一个语音请求样本确定出语音请求样本对应的多个语义标签识别结果，并对上述的语义标签识别结果进行评估，并将满足条件的提示信息模板确定为能够针对实际应用时的语音请求进行应用的目标提示信息，以在实际应用过程中对语音请求样本进行语义标签识别，从而通过确定提示信息的方式筛选出最能够保证语义标注准确率的语义标签识别结果，提高效率的同时克服了语义标注难度过高的问题。
G10L15/22  ,语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种语音交互方法，所述方法包括：获取当前语音请求，识别当前语音请求对应的目标应用场景类别，基于预先确定的应用场景类别与提示信息模板的对应关系，及结合预先配置的多种提示信息模板，确定与目标应用场景类别相对应的目标提示信息，根据目标提示信息和大语言模型，确定当前语音请求所对应的目标车辆控制指令，完成语音交互。如此，本申请的服务器根据当前语音请求对应的目标应用场景类别，及预先配置的提示信息模板确定目标提示信息，大语言模型根据目标提示信息，确定目标车辆控制指令，使得大语言模型可根据语音请求对应的提示信息确定车辆控制指令，改善固定提示难以可靠地引导模型推理的情况，推理精度得以保障。
G10L15/06  ,生成水声目标识别模型的方法和水声目标识别方法 [发明],本公开提供了一种生成水声目标识别模型的方法。该方法包括：基于源域训练数据对第一深度学习模型进行训练，源域训练数据包括声音数据，并且该第一深度学习模型包括第一二值化深度卷积神经网络和第一分类器，第一分类器包括全连接层和分类层；将经训练的第一深度学习模型的第一二值化深度卷积神经网络的模型参数迁移到第二深度学习模型的第二二值化深度卷积神经网络，第一二值化深度卷积神经网络和第二二值化深度卷积神经网络的结构相同，该第二深度学习模型包括第二分类器，并且第二分类器包括全连接层、循环神经网络和分类层；以及基于目标域训练数据对第二深度学习模型进行训练，得到训练后的第二深度学习模型作为水声目标识别模型，目标域训练数据包括水下目标声音数据，在对第二深度学习模型进行训练的过程中，固定第二二值化深度卷积神经网络的模型参数并且更新第二分类器的模型参数。本公开的实施例还提供了一种水声目标识别方法。
H04N21/439  ,基于Prompt提示信息的视频剪辑方法及装置 [发明],本发明实施例涉及一种基于Prompt提示信息的视频剪辑方法及装置，包括：对目标待剪辑视频进行解析，提取得到视频流和音频；将音频转换为文本信息，同时，文本信息中包含目标待剪辑视频中出现对应的音频的时间信息；获取用户端发送的Prompt提示信息；基于大语言模型对文本信息进行语义解析，识别得到与Prompt提示信息对应的目标文本信息；基于目标文本信息中包含的时间信息对所述视频流进行剪辑，得到目标视频。由此，利用大语言模型制定各种Prompt提示信息来解析视频语音中对应的文本，对文本进行语义拆分完成视频剪辑，简化了视频剪辑的结构，提高视频剪辑的效率，提高了视频剪辑的多样性。
G10L15/22  ,一种语音识别增益方法、设备、存储介质及麦克风 [发明],本申请涉及一种语音识别增益方法、设备、存储介质及麦克风，涉及语音识别技术领域，其包括预设语音信号转化的电压阈值；接收语音采集设备采集的语音信号；将语音信号转化为电信号输出，获取电信号的电压实际值；将电压实际值与电压阈值进行比较，根据比较结果调整语音信号增益，使电压实际值等于电压阈值。本申请具有有效提升语音识别功能可靠性的效果。
G10L25/51  ,一种基于多通路声学谐振腔的说话人定位装置与方法 [发明],本发明公开了一种基于多通路声学谐振腔的说话人定位装置，包括麦克风和多通路声学谐振腔结构，所述麦克风通过信号采集设备连接计算机，所述多通路声学谐振腔结构包括矩形主体、四个通路和长方体空气腔，所述四个通路呈十字型相交设置，其交点位于矩形主体的中心处，并且在该中心处设置有所述麦克风，同时在每条通路上从外向内依次设有两个长方体空气腔，其中靠近入口处的长方体空气腔尺寸大于靠近中心处的长方体空气腔。本发明利用不同方向上的谐振腔结构对语音信号进行频率上的调制，使得各个方向的入射声具有不同的声纹特征，再结合基于深度学习的声纹识别算法，完成对声音方向的判别，实现说话人定位。
H04W4/40  ,基于5G的车联网智能终端及方法 [发明],公开了一种基于5G的车联网智能终端及方法。该车联网智能终端，包括：Modem模组，用于连接5G网络以提供网络连接和通信功能；本地控制程序编写模块，用于编写本地控制程序以实现对网络连接和通信功能的控制；网络管理器，用于管理网络连接和网络配置；网络连接服务器，用于处理网络连接的服务；以及，5G‑Tbox网络控制终端，用于提供网络请求和Modem电话语音服务。通过这样的方式，可以提供更智能化和便捷的车辆网络服务，推动车联网技术的进一步发展。
H04N21/266  ,一种基于智能过程自动化技术的内容审核方法及系统 [发明],本发明公开了一种基于智能过程自动化技术的内容审核方法及系统，系统包括自动化内容接收与分类模块、文本内容预处理与审核模块、图像内容审核模块、音频内容审核模块、审核决策和处理模块、智能学习和优化模块、安全性与隐私保护模块。本发明通过自动化的内容接收、分类和预处理，利用批量处理和并行计算能力，大规模地处理上传内容，满足大数据环境下的需求，集成的深度学习和自然语言处理技术能够准确理解文本的语义和情感，减少误判，集成一个统一的审核系统同时处理文本、图像、视频和音频内容，保证了审核的全面性和一致性，通过机器学习模型的不断训练和优化，提升了系统的适应能力，反馈学习机制确保了审核标准的持续更新。
G10L15/02  ,语音识别方法、装置、电子设备和存储介质 [发明],本发明提供一种语音识别方法、装置、电子设备和存储介质，其中方法包括：获取待识别语音；确定所述待识别语音中各语音帧所属音素的预测难易程度，基于与所述预测难易程度对应的特征提取方式，提取所述各语音帧的语音特征；基于所述各语音帧的语音特征，确定所述待识别语音的识别结果。本发明提供的方法、装置、电子设备和存储介质，通过确定待识别语音中各语音帧所属音素的预测难易程度，基于与预测难易程度对应的特征提取方式，提取各语音帧的语音特征，以得到待识别语音的识别结果，实现了难易渐进式语音识别，提升了针对较困难语音片段的语音识别效果。
G06F16/332  ,数字对象渲染方法、装置、电子设备及非易失性存储介质 [发明],本申请公开了一种数字对象渲染方法、装置、电子设备及非易失性存储介质。其中，该方法包括：接收前端客户端发送的用户需求信息，并确定用户需求信息对应的回复文本，生成与回复文本对应的播报语音数据；依据前端客户端对应的引擎类型信息和引擎负载信息，确定前端客户端对应的目标渲染引擎；采用目标渲染引擎，依据播报语音数据进行渲染，得到目标数字对象的渲染数据，并将目标数字对象的渲染数据发送至前端客户端进行展示，其中，目标数字对象用于通过语音应答的方式对用户需求信息进行回复。本申请解决了由于相关技术在进行数字对象渲染时，大多采用实时云侧渲染的方式，造成的云侧渲染资源耗费高的技术问题。
G06Q10/0639  ,模拟培训对话的评分方法 [发明],本发明公开了一种模拟培训对话的评分方法，包括以下步骤：通过语音转文本技术，将学员录制的语音，转成文字；对语音进行语速检测，得出语速评分；对语音进行分析，得到波形图，检查是否有停顿，进行缺陷评分；对转出的文字进行规范词和敏感词检测，得出关键字评分；对转出的文字，使用大语言模型进行语义分析，得出语义评分；对转出的文字，进行分词处理后，进行重复检测，得出缺陷评分；结果汇总，得出最终得分和得分明细。本发明实现对语音的多维度综合评分，保证对学员模拟培训对话的评分质量。
G06V20/40  ,视频分类模型的训练、机器生成视频的识别方法及系统 [发明],本公开提供了一种视频分类模型的训练、机器生成视频的识别方法及系统。该训练方法包括：获取视频训练数据；其中，所述视频训练数据包括表征该所述视频训练数据是否为机器生成的预设标签；提取所述视频训练数据中的内容特征，所述内容特征包括图像特征和音频特征；基于所述内容特征生成对应的融合向量，将所述融合向量作为输入，所述预设标签作为输出，训练预设分类模型得到目标视频分类模型。通过对视频训练数据多维度识别处理，从视频训练数据中提取表征机器生成特征的多模态特征，基于多模态融合向量训练预设分类模型，得到能够对机器生成视频进行分类识别的目标视频分类模型，具备高准确性和鲁棒性。
G06F11/36  ,人机对话流程测试方法及系统 [发明],本发明公开了一种人机对话流程测试系统，包括器人管理装置、测试装置、记录装置；机器人管理装置创建语音机器人，对语音机器人进行配置；机器人管理装置将语音机器人信息发送至测试装置；测试装置测试语音机器人的人机对话流程并生成对应的测试结果，将测试结果反馈发送至对话机器人管理装置，对话机器人管理装置根据测试结果优化对话机器人的配置，从而形成测试闭环；记录装置记录测试结果及数据。此外，本发明还公开了一种人机对话流程测试方法。本发明使得语音机器人的测试过程变得清晰可见，并且复用性高，能够及时发现并定位机器人在搭建、意图理解过程中出现的问题，极大地提升了语音机器人的测试效率。
G10L15/02  ,语音识别系统的词序纠错方法 [发明],本发明属于语音识别技术领域，尤其为语音识别系统的词序纠错方法，所述词序纠错方法包括如下步骤：语音信号预处理；特征提取；使用语音识别模型进行语音识别，将语音转化为原始文本；上下文建模及错误检测和纠错；建立文本对照库；建立规则逻辑库。本发明中，通过原纠错系统中抽取的实体词建库，通过原始语音信号的录入场景、时间戳和人物的语言习惯建立文本对照库，确定一般常规词序，与实体词库进行对照，将该规定场景、时间戳和人物下的实体词库，在原始文本的上下文中的词序，确定在该规定场景、时间戳和人物下该实体词的原始意图，从而调整每一个实体词在原始文本中上下文的具体位置，生成符合一般人阅读习惯的文本。
G10L21/0208  ,基于神经网络的电力调度录音系统的语音降噪方法 [发明],本发明涉及电力系统技术领域，是一种基于神经网络的电力调度录音系统的语音降噪方法，其将带噪语音通过特定的函数编码成RGB图片，再利用计算机视觉方面的深度学习神经网络技术对生成的语音图片进行处理，产生滤除噪声的语音图片，最后将得到的去噪语音图片还原成语音，从而达到语音降噪的目的，实现对调度录音系统的降噪处理。本发明针对于录音系统的语音降噪处理不仅可以降低背景噪声干扰、改善语音质量、提升听者的舒适感、提高语音信息传达的可懂度，而且还可以在一定程度上减轻劳动力，提升录音的准确性，从而保障电力系统的安全运行。
G10L15/18  ,车辆语音交互方法、服务器及存储介质 [发明],本申请公开了一种车辆语音交互方法，包括：接收车辆转发的当前语音请求；根据当前语音请求以及当前语音请求对应的属性参数，确定当前语音请求的分类参数；在根据分类参数以及预设的语音分类模型，确定当前语音请求为第一类型语音请求的情况下，根据当前语音请求执行语音交互。本申请能够充分利用语音请求自身的各个属性参数通过预设的逻辑加以处理，实现语音请求有效性的分辨，大幅提高了分辨效率的同时还能够避开ASR识别误差或者受话人识别误差对分辨过程造成的不利影响。
H04S3/00  ,一种音频数据播放方法及电子设备 [发明],本申请公开了一种音频数据播放方法及电子设备，该方法包括：响应于在第一应用的播放界面对第一音频数据的播放操作，播放该第一音频数据；在播放该第一音频数据的情况下，响应于该第一音频数据为媒体流，且电子设备支持空间音频功能，基于该第一音频数据的属性特征对该第一音频数据进行空间音频音效处理，得到第一空间音频数据；播放该第一空间音频数据。通过本申请，能够与第三方应用相联合，生成效果更佳的空间音频数据，有效地为用户播放空间音频数据，提高音乐播放质量，给用户带来沉浸式的空间音频体验。
G10L25/66  ,一种双通道CNN-LSTM的肺音分类模型训练方法及系统 [发明],本发明公开了一种双通道CNN‑LSTM的肺音分类模型训练方法及系统，包括：将原始肺音数据样本随机划分成训练集和测试集，利用librosa库提取训练集重音频，得到MFCC特征；将MFCC特征输入基础模型中的LSTM层和CNN层中进行特征学习，分别利用CNN和LSTM提取肺音数据空间特征信息和时序信息特征；肺音数据空间特征信息和时序信息特征输入至特征融合层进行拼接融合，得到一个包含有非周期性空间特征与周期性时序特征的特征向量，作为融合特征向量；将融合特征向量输入全连接层，以进行分类任务，训练得到初始双通道CNN‑LSTM的肺音分类模型。得到的分类模型训练准确度更高，分类更准确。
G10L13/02  ,一种文本转语音方法及模型训练方法、装置和电子设备 [发明],本公开涉及一种文本转语音方法及模型训练方法、装置和电子设备，所述方法包括：将样本文本输入情感语音合成模型，得到初始音色的第一语音，所述第一语音具备目标语音情感；利用语音转换模型对第一语音进行语音转换，得到目标音色的第二语音；基于所述样本文本和所述第二语音构成的训练数据，对情感语音合成模型进行训练，使得训练后的情感语音合成模型能够根据文本生成目标音色的第三语音，所述第三语音具备目标语音情感。本公开实施例有效减少了情感语音合成时的线上计算负载，减少了对计算资源的消耗，计算延时低。
G10L25/51  ,一种水电机组放电和轴承故障风险声音的分类方法及系统 [发明],本发明公开了一种水电机组放电和轴承故障风险声音的分类方法及系统，涉及水电设备风险识别技术领域。包括：构建待分类时频图数据集，并将待分类时频图数据集输入至训练好的分类模型中；分类模型利用VGG16、Inception10以及Resnet18神经网络分别提取待分类时频图数据集的音频特征，音频特征通过加权的特征融合得到融合后的音频特征，对融合后的音频特征采用逻辑回归分类器进行分类；将分类结果进行输出。本发明以模拟设备出现风险而产生的音频信号来尽可能地实时识别，混合内部或外界噪声的情况以构建训练数据集并对网络的特征提取进行融合以确保精准分析。
G16H40/20  ,一种语音智能识别的耗材柜管理系统和方法 [发明],本发明提供一种语音智能识别的耗材柜管理系统和方法，耗材柜，其包括有控制模块、语音识别模块和灯光显示模块；医护人员只需要发出语音指令，耗材柜的语音识别模块通过获取语音指令并配合控制模块的解析和匹配工作，确定耗材所在的位置并生成灯光指令，灯光显示模块根据灯光指令对耗材所在的存货单元进行第一灯光工作，对其余的存货单元进行第二灯光工作，那么医护人员就能在不需要查询存放列表的情况下清楚知道耗材放置的位置，方便取出耗材。
G10L25/27  ,基于智能语义分析的角色目标表情动画生成方法及系统 [发明],一种基于智能语义分析的角色目标表情动画生成方法及系统，涉及人工智能技术领域。在该方法中，获取第一音频流和第二音频流；确定第一音频流和第二音频流之间的间隔时长；当间隔时长处于预设间隔时长范围内时，从第一音频流中提取得到第一子音频流，并从第二音频流中提取得到第二子音频流；基于第一音频流，得到角色表情关键动画；基于第一子音频流和第二子音频流，得到角色表情过渡动画；将角色表情关键动画和角色表情过渡动画进行合成，得到角色目标表情动画，并将角色目标表情动画下发至用户端。实施本申请的技术方案，可以提高生成的虚拟角色表情与声音的匹配程度，从而使得生成的虚拟角色整体表情更加真实。
G10L21/02  ,一种语音增强方法、装置、设备及存储介质 [发明],本发明涉及语音处理技术领域，公开了一种语音增强方法、装置、设备及存储介质，该方法包括：将待处理音频段输入至预设分类模型，获得待处理音频段属于语音的概率和目标音频段，预设分类模型包括短时傅里叶变换模块、深度可分离卷积模块、长短期记忆神经网络模块和二分类模块；在概率大于预设第一阈值时，使用均方根方法确定目标音频段的音频能量；在音频能量大于预设第二阈值时，将目标音频段存入结果处理队列。由于本发明通过将待处理音频段输入至预设分类模型，然后使用均方根方法确定概率大于预设第一阈值对应的目标音频段的音频能量，并将音频能量大于预设第二阈值的目标音频段存入结果队列，相比于现有技术，有效提高了语音增强的质量。
G10L15/22  ,电子设备控制方法及控制装置 [发明],本申请提供一种电子设备控制方法及控制装置，通过对用户输入进行语义分析，以确定所述用户输入包含的至少两个控制意图，以对至少一个目标电子设备执行至少两个控制指令。实现了通过一语多意图对电子设备的控制，提高了用户指令输入来控制的灵活性。
G10L15/22  ,多屏车辆的语音控制方法、设备及存储介质 [发明],本申请公开了一种多屏车辆的语音控制方法、设备及存储介质，涉及车辆技术领域，多屏车辆的主驾驶区域和副驾驶区域均设置有头部朝向检测装置，多屏车辆的语音控制方法包括在检测到多屏车辆所接收的车内语音信号携带了意图信息的情形下，确定车内语音信号的声源位置；若声源位置在目标区域内，则通过目标区域对应的头部朝向检测装置采集目标用户的头部朝向信息，目标区域为主驾驶区域或副驾驶区域，目标用户是指处在目标区域的用户；在多屏车辆的中控屏和副驾屏中，将头部朝向信息所指向的屏幕确定为目标屏幕；控制目标屏幕执行车内语音信号的指令内容。本申请解决了如何提高多屏车辆的语音控制的准确性，以提高用户的使用体验的问题。
G10L15/01  ,车载语音功能的测试系统、测试方法、电子设备及介质 [发明],本申请提供了一种车载语音功能的测试系统、测试方法、电子设备及介质，所述测试系统包括工控机、机械臂、IVI主机以及音频分析仪；所述工控机，用于获取当前待测试的功能，基于所述当前待测试的功能生成控制指令，将所述控制指令发送给所述机械臂；所述机械臂，用于接收所述工控机发送的控制指令，基于所述控制指令控制所述机械臂触控所述IVI主机的显示屏的对应功能；所述IVI主机，用于响应于所述机械臂的触控，播放对应功能的测试音频，将所述测试音频发送给所述音频分析仪；所述音频分析仪，用于基于所述测试音频确定所述IVI主机的响应速度与声音质量。采用本申请提供的技术方案能够实现车载语音功能的自动化测试，提高测试效率。
G10L21/007  ,一种多路音频数据混音的方法、系统、装置及存储介质 [发明],本发明实施例公开了一种多路音频数据混音的方法、系统、装置及存储介质，属于音频处理技术领域，该方法可以包括：接收各终端上传的多路待叠加的音频数据，其中，所述多路待叠加的音频数据至少包括两路音频数据；将接收到的所述多路待叠加的音频数据通过音频数据交替复制算法叠加到目标音频数据以获得叠加后的音频数据；将所述叠加后的音频数据进行音频重采样以获得单路的输出音频数据；将所述输出音频数据发送至各终端进行播放以实现多路通话。通过该技术方案，能够不限制混音路数，可以提高整体音频质量并避免过饱和及爆破音失真现象。
G10L15/02  ,一种无障碍蓝牙控制器数据智能分析方法 [发明],本发明涉及声音信号增强技术领域，具体涉及一种无障碍蓝牙控制器数据智能分析方法。该方法从原始语音信号分解的分量信号中选取最优分析信号，从最优分析信号中信号点拟合得到的模拟语音信号中筛选出主信号；将除主信号外的分量信号作为待分析信号，获取每个待分析信号的噪声干扰度与环境噪声叠加度，结合分析得到待分析信号的去噪参数；将去噪参数作为对待分析信号进行滤波的信号比，进而获取去噪语音信号，对无障碍蓝牙控制器的输入语音进行分析。本发明结合噪声干扰度与环境噪声叠加度对分量信号进行自适应去噪，使对原始语音信号的增强效果更佳明显。
H04N5/265  ,数字人视频生成方法、电子设备及存储介质 [发明],本公开提供了一种数字人视频生成方法、电子设备及可读存储介质。本公开的数字人视频生成方法包括：获取目标图像数据和目标音频数据；根据目标图像数据和注意力网络对预训练参数中的关键参数进行调整，获取调整参数；根据调整参数执行人像重建，获取目标唇读脸模；以及根据目标唇读脸模和目标音频数据执行音视频合成，获取数字人视频；其中，注意力网络用于提高图像数据的人脸关键点权重。
G10L13/08  ,语音资源确定方法、装置、电子设备及非易失性存储介质 [发明],本申请公开了一种语音资源确定方法、装置、电子设备及非易失性存储介质。其中，该方法包括：获取目标输入文本，并依据目标变分自编码器对目标输入文本进行编码，得到目标输入文本对应的隐变量；采用目标变分自编码器，依据隐变量，确定目标输入文本对应的候选正则化表达式；在目标输入文本符合候选正则化表达式对应的文本规则情况下，确定候选正则化表达式为目标正则化表达式；获取资源数据库中目标正则化表达式对应的语音资源数据，其中，语音资源数据用于对目标输入文本进行语音回复。本申请解决了由于客服场景的语音合成任务中输入的文本较短，造成相关技术在确定与输入文本对应的语音资源时准确率较差的技术问题。
G06F40/174  ,简历及其文本内容生成方法、装置、设备及存储介质 [发明],本发明涉及一种简历及其文本内容生成方法、装置、设备及存储介质，用以解决用户撰写简历难度大的问题。简历文本内容生成方法包括：响应于用户在内容单元的引导触发操作提供引导交互界面；基于所述内容单元的类别确定对应的提示信息内容；基于所述提示信息内容生成信息描述文本；将所述信息描述文本封装为对话发送到所述引导交互界面；接收用户输入的响应内容，参照提示信息内容中的目标信息及要求对所述响应内容进行语义分析；响应于用户提供的响应内容包含了目标信息内容并符合其要求，基于用户提供的响应内容生成所述内容单元的内容描述文本。本发明实施例能够识别到用户的撰写困难并为用户提供优质的内容描述文本。
G10L15/01  ,应用于语音机器人的智能质检方法、系统、设备及介质 [发明],本发明涉及一种应用于语音机器人的智能质检方法、系统、设备及介质，所述方法包括：对目标装置的质检要求做预处理，包括获取质检录音、业务类型、节点类型并预设语音机器人各节点的机器人预期行为；识别质检录音中机器人实际行为和客户行为，并将机器人实际行为与机器人预期行为进行比对确定对应的节点类型，并按照节点类型将客户行为和机器人实际行为分类存储；根据分类存储的识别结果，采用业务领域分析模型对客户行为进行分析，得出语音机器人不同节点类型下客户行为分析结果；按节点类型归类存储领域分析模块的分析结果。与现有技术相比，本发明可实现全范围、各业务节点的高效率语音质检。
G10L15/22  ,音频识别方法、音频识别装置、车辆、计算机设备和介质 [发明],本申请公开一种音频识别方法、音频识别装置、车辆、计算机设备和介质。方法包括：对待识别音频进行编码，以生成发音概率矩阵；通过预设的延迟纠错模型，对发音概率矩阵进行纠错，以得到对应的字结果和输出概率矩阵；对字结果和输出概率矩阵进行发音映射，以得到映射概率矩阵，并根据映射概率矩阵和发音概率矩阵，生成目标概率矩阵；对目标概率矩阵输入到语音解码图进行解码，以得到识别结果。通过延迟纠错模型具备的纠错能力，对发音概率矩阵进行纠错，从而获取到准确的字结果，提高音频识别的准确性，且延迟纠错模型可以有效地节省算力，节省存储空间等。
G10L15/22  ,一种基于语音识别的麦克风系统 [发明],本发明涉及语音识别技术领域，尤其涉及一种基于语音识别的麦克风系统，本发明通过设置转换模组、特征表征模组、条件数据库、信号处理模组以及动作执行模组，通过显性计算单元计算声源年龄评估系数，判定是否需要对语音进行文本转换，通过条件数据库存储各控制对象关联的指令文本，并预先构建各指令文本关联的触发条件，通过信号处理模组判定语音文本是否可以触发指令文本，通过动作执行模组根据语音文本对应的声源年龄评估系数与指令文本所关联的触发条件的匹配结果判定是否执行指令文本，进而，实现了直接根据声源的特定特征数据化直观地表征声源年龄，并对不同声源发出的指令进行选择性的执行，提升了智能家居语音交互的安全性以及高效性。
G10L15/22  ,可穿戴电子设备及其语音检测方法 [发明],公开了一种可穿戴电子设备及其语音检测方法。电子设备包括第一处理器和第二处理器，第二处理器的语音处理能效高于第一处理器。语音检测方法包括：获取语音信号；确定第二处理器在语音信号中检测到唤醒词，对唤醒发生后第一时段内的语音信号进行人声检测；以及确定在第一时段内检测到人声，使得经由第一处理器实现对唤醒发生后的时长不长于第二时段的语音信号进行语音识别。通过将唤醒检测、连说检测放在语音处理能效更高的第二处理器上实现，并在检测到连说时经由第一处理器进行后续命令词的识别，本公开能够在高效进行音频处理并降低主处理器开销的同时，快速检测出唤醒和连说，降低延迟，并防止唤醒连说时的漏识别和误识别。
G10L19/02  ,音频处理方法、装置、电子设备及存储介质 [发明],本公开提供了一种音频处理方法、装置、电子设备及存储介质。本公开提供的音频处理方法，包括：将待处理音频进行转换，得到第一频谱图；将第一频谱图输入预先训练的VQGAN模型，得到第一编码；将第一编码进行处理，得到第一音频token。
G10L15/22  ,一种基于5G网络的语言交互学习方法及系统 [发明],本发明提供了一种基于5G网络的语言交互学习方法及系统，该方法包括：交互终端获取用户在时间M内的第一语音信息，所述第一语音数据包括多条用户的语音，该语音为用户的英语学习语音；将所述第一语音数据发送给云端服务器；所述云端服务器分析第一语音数据，根据第一语音数据确定用户说一句语音的时长L；交互终端获取当前用户的第二语音信息，比较第二语音信息的时长是否大于时长L；如果是，交互终端根据第二语音信息与用户交互；如果不是，等待预设时间，交互终端根据第二语音信息与用户交互。本发明提高了语言学习交互的速度，减少了用户等待的时间，提高了交互体验。
G10L15/06  ,一种方言连续语音的识别方法、装置、设备及存储介质 [发明],本申请涉及一种方言连续语音的识别方法、装置、设备及存储介质。所述方法包括：构建方言语音识别模型。方言语音识别模型包括编译器模块与解码器模块。获取方言语音表征数据作为训练样本数据集。将其输入至方言语音识别模型中提取语音表征因子，得到话语者因子向量与口音因子向量。通过编译器模块将预先获取的JS指令数据表征成文本内容向量，并将文本内容向量、话语者因子向量以及口音因子向量进行随机组合，得到批量的待训练方言表征向量。利用待训练方言表征向量更新解码器模块，将该模块与待训练方言表征向量对方言语音识别模型进行训练，得到训练好的方言语音识别模型。采用本方法能够高效的生成领域数据，准确识别出方言连续语音。
G06F18/241  ,一种基于扩散模型数据增强的情感识别方法和系统 [发明],本发明提出一种基于扩散模型数据增强的情感识别方法和系统。其中，方法包括：从视频中提取音频数据的语谱图，将语谱图输入基于深度学习的音频情感特征生成模型，生成音频情感特征；再将视频帧输入基于深度学习的视频情感特征生成模型，提取图像特征；然后对图像特征进行归一化，得到视频情感特征；应用音频情感特征和视频情感特征作为输入，训练基于深度学习的扩散模型；应用训练好的扩散模型进行数据增强，生成扩展数据集；应用扩展数据集训练基于深度学习的情感识别模型；将训练好的情感识别模型应用于音视频情感识别应用中进行情感识别，并输出情感识别结果。本发明提出的方案能够提升模型的泛化性能，从而提高实际情感识别的效果。
G10L25/51  ,一种音频识别方法及识别系统 [发明],本发明涉及音频识别与设备监测技术领域，具体涉及一种音频识别方法及识别系统，用于解决现有的基于声音信号的工业设备通用故障检测方法无法对设备各个零件进行实时监控，并不能消除正常声音的干扰，更未做进一步的监测分析，导致音频识别对设备故障的判断不够精确，易于出现误报的情况的问题；通过本发明的一种音频识别方法及识别系统，能够对设备运行过程中的音频数据进行处理和分析，实现了对设备故障的实时、准确识别，并在后续进行进一步监测，提高了故障监测的准确性，避免设备故障造成重大损失，本发明具有较低的误报率和较高的实时性等优点，能够适应不同的设备和应用场景。
G10L25/51  ,基于声学信号的水轮机初生空化预警方法 [发明],本发明公开了基于声学信号的水轮机初生空化预警方法，采集各工况运行参数下不同空化状态水轮机运行时的声学信号，对声学信号去噪处理，计算低频空化声学信号熵率和高频空化声学信号的信号瞬时能量值；构建水轮机工况运行参数与初生空化声学信号预警特征值之间关系的预测模型，通过水轮机工况运行参数空化声学信号熵率和高频声学信号的信号能量值对预测模型训练；采集工况运行参数已知、空化状态未知状态的实况声学信号，计算实况声学信号的熵率和能量值，将实况声学信号工况运行参数输入训练后的预测模型中获得熵率预警阈值与能量值的预警阈值；当计算信号的熵率或能量值指标超过相应预警阈值时，发出预警，精确实现水轮机初生空化预警。
G10L17/02  ,用于3D打印手办的配音决策方法及配音决策系统 [发明],本发明提供了用于3D打印手办的配音决策方法及配音决策系统，涉及数据处理技术领域，方法包括：当语音录入装置接收语音录入请求时基于语音数据库通过语音输出装置输出验证语句内容，提示用户录入比对语音信息，加载声纹比对频谱特征属性集生成一级频谱特征属性组、二级频谱特征属性组直到N级频谱特征属性组，激活声纹校验模块，生成声纹校验结果，校验通过则提示用户开始录音，激活语音录入装置，录入用户输入语音信息发送至用户端操作界面配置3D手办响应姿态标签，存储至语音数据库，解决现有技术中录音手办无法对用户进行差异化区分，导致隐私数据存在被恶意修改的风险的技术问题，实现对用户进行精准的差异化管控，降低恶意修改的风险。
G06F16/33  ,信息处理方法、模型训练方法及相关装置、设备 [发明],本申请公开了一种信息处理方法、模型训练方法及相关装置、设备，属于数据处理技术领域。该信息处理方法包括：接收用户终端发送的呼叫请求，获取用户的语音信息；将语音信息转为语音文本，根据语音文本确定查询关键文本；基于数据匹配模型，根据查询关键文本，得到查询关键文本的匹配结果和结果匹配度，其中，数据匹配模型用于根据查询关键文本确定数据类别，并从与数据类别对应的数据库中获取匹配结果和结果匹配度；根据匹配结果和结果匹配度，确定反馈信息；将反馈信息发送到用户终端。该信息处理方法可以为用户提供高效准确的号码查询服务。
G06F18/2415  ,一种多模态情感识别方法及装置 [发明],本发明涉及情感识别技术领域，尤其是指一种多模态情感识别方法及装置，包括：对长序列的音视频信息预分段处理后，分别输入音视频特征编码提取音视频段级特征序列；将音视频段级特征序列连接后通过全连接层进行映射，得到段级情感相似性特征序列；将各段级情感相似性特征序列查询元素，音视频各段级特征序列作为键元素和值元素，通过多头注意力机制输出音视频段级情感加权特征序列；利用中心映射函数分别计算音视频加权中心向量和情感相似性信息的中心向量，合并后构建多模态联合情感特征；对多模态联合情感特征进行情感识别。本发明充分利用了输入数据的上下文信息，增强了多模态情感识别模型的实时识别性能，提高了情感识别的稳定性。
G10L19/16  ,一种音频编码方法、音频解码方法及相关装置 [发明],本发明涉及音频处理技术领域，尤其涉及一种音频编码方法、音频解码方法及相关装置，所述音频编码方法包括：获取当前帧音频模拟信号，以及音频传输的第一码率；对当前帧音频模拟信号进行采样量化，以获得当前帧音频数字信号；基于当前帧音频数字信号，获得当前帧音频数字信号的平均对数能量值；若平均对数能量值大于第一能量阈值，且第一码率大于编码采样率的预设倍数，则发送当前帧音频数字信号，否则，先对当前帧音频数字信号进行滤波处理，再发送当前帧音频数字信号。该方法通过确定音频信号是否执行滤波的操作，降低算法的复杂度，减少计算资源的占用，提高音频传输效率，从而降低功耗，提升用户体验。
G10L19/018  ,一种音频信息水印加密方法 [发明],本申请涉及数据处理技术领域，尤其涉及一种音频信息水印加密方法。使用了第一加密序列对音频信息中的每一个音频信息都确定了其待更改位，由此，可以避免攻击方破解出水印序列所在的位置；此外，由于第二加密序列按第二预设规则排序得到第四加密序列，之后又使用了第四加密序列中第j位加密信息在所述第二加密序列的位置信息确定了待更改位的目标值，从而实现了目标值的复杂性，并且目标值是根据第二加密序列的位置信息和水印序列中第j位水印信息得到的，保证了嵌入的水印序列在音频序列中的存在感不会太明显，一方面不会影响原始的音频信息，另一方面避免水印序列被直接识别出，从而提高了水印序列的安全性。
G10L15/16  ,语音交互方法、装置、服务器及存储介质 [发明],本公开涉及一种语音交互方法、装置、服务器及存储介质。可以获取语音输入消息；对所述语音输入消息进行拒识判断，得到第一拒识结果；在所述第一拒识结果表征所述语音输入消息是人机交互请求消息的情况下，通过自然语言处理NLP对所述语音输入消息进行拒识判断，得到第二拒识结果；根据所述第二拒识结果进行语音交互。
G10L15/01  ,一种基于RNN语音识别的实时语音风控系统 [发明],本发明提供了一种基于RNN语音识别的实时语音风控系统，包括：语音检测模块用于采集用户当前通讯的双向通讯语音，并进行预处理后获得有效双向通讯语音；语音处理模块用于基于RNN语音识别模型对双向通讯语音进行识别整理，获得双向通讯文本并提取文本语义特征以及关联语义特征；风险检测模块用于基于文本语义特征以及关联语义特征对用户的当前通讯进行风险检测并根据风险检测结果，生成对应的风险控制信号；风险控制模块用于基于风险控制信号对当前通讯进行对应的风控处理。本发明有利于帮助用户及时识别并发现潜在风险，降低用户受骗概率，保护用户的利益和安全，同时，也有利于及时发现泄密行为，降低事件的泄露几率，提高信息安全。
G06F3/14  ,信息显示方法、装置、车辆及计算机存储介质 [发明],本申请公开了一种信息显示方法、装置、车辆及计算机存储介质，其中，信息显示方法包括：接收语音指令；在确定所述语音指令由所述第一用户发出的情况下，基于所述语音指令进行响应，得到第一响应信息，其中，所述第一用户为唤醒所述语音识别系统的用户；识别所述第一用户所在的第一位置；根据所述第一位置确定目标显示区域，并在所述目标显示区域显示所述第一响应信息。上述中，在多个用户同时说话时，可以仅对第一用户发出的语音指令进行响应，避免误响应，提高用户体验，另外，根据第一用户所在位置确定目标显示区域，将第一响应信息显示在目标显示区域，也便于用户查看响应信息。
G10L15/26  ,一种语音交互方法、装置及介质 [发明],本发明提出一种语音交互方法、装置及介质，具有生成语音的语义音色准确和各部分协同程度高的特点。该语音交互方法，包括：对输入的语音信号做分帧处理，得到语音帧序列；所述语音帧序列中，位置在后的后一帧语音包含在其之前的前一帧语音；根据所述语音帧序列中的声学特征信息，获得最终合成语音；根据所述语音帧序列中的语义特征信息，获得最终反馈文本；根据最终合成语音和最终反馈文本，生成用于语音交互的语音文本。
G10L15/22  ,车辆语音交互方法、服务器及存储介质 [发明],本申请公开了一种车辆语音交互方法，包括：接收车辆转发的语音请求，对语音请求进行槽位识别；对语音请求进行应用程序接口预测；根据槽位识别的结果、预测到的应用程序接口以及图形用户界面信息，选择预测到的应用程序接口执行应用程序接口参数填充，输出执行结果下发至车辆完成语音交互。本申请能够将图形用户界面(GUI)加入到用户界面生成以及语音交互过程当中，保持GUI与语音交互用户界面(VUI)之间的统一，避免因为VUI与GUI之间存在差异而造成的交互要素出错，保证了通过语音交互用户界面进行语音交互时的体验与通过图形用户界面进行交互时的体验一致。
G10L15/22  ,一种语音交互教学方法、装置及眼镜 [发明],本发明公开了一种语音交互教学方法，包括以下步骤：首先进行文本预处理，接着，初始化模型参数，构建、训练模型并计算词频以及余弦相似度，然后，将识别到的文本合成为语音，并输出；紧接着，接收语音输入，并录制。通过对录制的语音输入与内置程序进行比对、计算，从而实现书籍阅读、自主授课、智能问答、口语练习的功能，让使用者的交互体验感更好。同时，本发明还公开一种应用了所述语音交互教学方法的装置，以及装配有所述装置的智能眼镜。
G06F16/64  ,音乐动图的生成方法、控制器、车辆及存储介质 [发明],本申请提供一种音乐动图的生成方法、控制器、车辆及存储介质。该方法包括：获取目标图片；获取目标音乐，并提取目标音乐的旋律特征；将旋律特征输入预先确定的目标预测模型，得到目标预测模型输出的虚拟视角；其中，目标预测模型基于音乐视频中旋律的旋律特征和音乐视频中图像的虚拟视角训练得到；以虚拟视角作为循环路径，对目标图片进行处理，得到跟随目标音乐动态变化的音乐动图。本申请能够增强音乐播放时旋律和动态图片的关联度，使得音乐播放更加生动。
G10L25/18  ,特征提取方法、装置、电子设备和存储介质 [发明],本发明提供一种特征提取方法、装置、电子设备和存储介质，其中方法包括：获取多帧流式数据的初始特征；逐帧对所述多帧流式数据的初始特征进行前向特征提取，得到多帧前向特征；对所述多帧流式数据的初始特征进行切分，得到多个分段帧，并对所述多个分段帧进行反向特征提取，得到多帧反向特征；将所述多帧前向特征和所述多帧反向特征进行拼接，并基于拼接后特征，确定所述多帧流式数据的目标特征。本发明提供的方法、装置、电子设备和存储介质，可以更加准确、高效地进行特征提取，提高特征的表达能力和鲁棒性。
G10L19/16  ,一种优化SBC编码器的方法、装置及电子设备 [发明],本申请涉及音频编解码技术领域，公开了一种优化SBC编码器的方法、装置及电子设备。本申请通过将PCM数据输入到多项分析滤波器中得到比例因子和子带数据，并根据比例因子对子带数据的子频段进行比特分配，接着根据子频段的比例因子和比特数对子带数据进行量化处理，并对量化处理后的子带数据进行自适应算术编码，最后将编码后的子带数据进行数据流打包并发送。通过将自适应算术编码与量化处理相结合，可以根据输入数据的特性动态地调整编码概率，使其在高质量音频传输的同时实现更高的压缩效率，从而减少数据的存储成本和传输带宽需求。
G06F16/9535  ,一种风景打卡点的推荐方法、装置、电子设备及存储介质 [发明],本公开提供了一种风景打卡点的推荐方法、装置、电子设备及存储介质，通过实时获取车内乘员的语音信息并进行语义识别，确定语音信息中是否包含针对车外风景进行赞叹的目标关键词；若语音信息中包含所述目标关键词，确定所述目标关键词所归属的预设关键词等级，并确定所述预设关键词等级对应的预设第一推荐评分；在检测到所述目标关键词后，获取当前车辆速度，确定车辆速度所对应的预设车速段，并确定所述预设车速段对应的预设第二推荐评分；根据所述预设第一推荐评分与对应的预设关键词权重、所述预设第二推荐评分与对应的预设车速权重，确定目标推荐评分。可以实现在车辆行驶过程中，针对车外风景进行智能打卡推荐，提升用户户外游玩的体验感。
H04L12/28  ,指令配置方法、装置和计算机设备 [发明],本申请涉及一种指令配置方法、装置、计算机设备、计算机可读存储介质和计算机程序产品，包括获取各受控设备的设备参数和各受控设备的设备指令，基于设备参数将设备指令与自然文本进行匹配，并建立映射关系，响应于调取请求，根据各受控设备的设备参数确定目标设备，并基于映射关系发送与目标设备对应的自然文本。其中，不同设备参数的受控设备具有不同的设备指令，映射关系表征设备指令与自然文本的对应关系。本申请通过建立具有各设备参数的受控设备的设备指令与自然文本之间的映射关系，以使在响应调取请求时，能够准确的根据映射关系发送对应的自然文本，适用于不同类型的受控设备，实现与不同受控设备的交互，便利性得到提升。
G10L15/00  ,语音唤醒方法、装置、设备及可读存储介质 [发明],本申请公开了一种语音唤醒方法、装置、设备及可读存储介质，在获取待识别的语音信号之后，先获取预设唤醒词的语种信息，预设唤醒词的语种信息用于指示预设唤醒词中包含的唤醒词片段，以及每个唤醒词片段对应的语种；然后对语音信号按语种进行切分，得到语种片段集合，语种片段集合中包括至少一个语种片段；最后语种片段集合与预设唤醒词的语种信息的一致性，确定语音信号的唤醒结果为第一唤醒结果还是第二唤醒结果，第一唤醒结果用于指示唤醒成功，第二唤醒结果用于指示唤醒失败。该方案能够实现多个语种的唤醒词的语音唤醒以及由多个语种拼接得到的唤醒词的语音唤醒。
G10L15/06  ,语音处理相关方法、装置、设备及存储介质 [发明],本申请实施例公开了一种语音处理相关方法、装置、设备及存储介质，基于训练好的翻译模型对预训练的语音识别模型做指导训练，在训练过程中，除了通过预训练的语音识别模型对语音样本进行识别处理外，还通过训练好的翻译模型对预训练的语音识别模型对语音样本进行识别处理过程中的目标特征以及语音识别结果中的至少一项进行翻译处理，得到翻译结果，以语音识别结果趋近于语音样本的文本标签，翻译结果趋近于以文本标签作为源语言文本的目标语言文本为目标，对预训练的语音识别模型的参数进行更新。基于本申请训练得到的语音识别模型，提升了语音识别模型的语音识别输出结果的语义准确性，可懂度高，提升了用户主观体验。
H04M3/22  ,外呼结果报表生成方法、系统、终端及存储介质 [发明],本发明提供了一种外呼结果报表生成方法、系统、终端及存储介质，该方法包括：根据外呼语音通话数据的呼叫数据生成固定列数据；对外呼语音通话数据进行语音划分，得到用户语音和机器人语音；对用户语音进行意图分析，根据意图分析结果生成意图动态列数据；对机器人语音进行外呼话术分析，根据外呼话术分析结果生成话术动态列数据；分别获取用户语音和机器人语音中的全局变量信息，根据全局变量信息生成全局变量动态列数据；根据用户报表需求、固定列数据、意图动态列数据、话术动态列数据和全局变量动态列数据生成外呼结果报表。本发明实施例，可以满足不同用户的外呼结果报表的定制化需求，提高了外呼结果报表的生成效率。
H04L12/28  ,设备唤醒方法、系统、终端及存储介质 [发明],本发明提供了一种设备唤醒方法、系统、终端及存储介质，该方法包括：根据组网响应进行设备组网，得到设备集群；接收用户语音指令，若设备集群中响应用户语音指令的设备数量大于数量阈值，则将响应的智能设备设置为候选设备；分别获取候选设备采集的雷达信息，根据雷达信息确定候选设备中的目标设备；控制目标设备执行用户语音指令，控制除目标设备外的候选设备切换至待唤醒状态。本发明实施例，当有多个智能设备处于同一个设备集群且对用户语音指令进行了响应时，基于雷达信息能自动确定到候选设备中的目标设备，控制目标设备执行用户语音指令，并控制除目标设备外的候选设备切换至待唤醒状态，有效地提高了设备唤醒的准确率。
G16H10/60  ,一种可信可控病历生成方法及装置 [发明],一种可信可控病历生成方法和装置，该方法通过LLM语言模型，对真实诊疗场景中的医患对话D进行预测生成病历R；对医患对话D按照医生的会话顺序进行切分，得到医患对话切分结果；对病历R按照病历文书进行切分，得到病历切分结果；采用LLM语言模型对医患对话切分结果的Round_n轮次和病历切分结果的Section_n片段进行嵌入表示；将病历切分结果的Section_n片段的嵌入表示分别和对话切分结果的Round_n轮次进行相似度计算，若相似度大于预设阈值，判定病历文书的信息蕴含在医患对话中，将对话切分作为生成病历文书的解释引证。本发明更灵活贴近真实效果，提升了生成结果的准确性和可解释性。
G10L15/18  ,语音交互方法、系统、终端及存储介质 [发明],本发明提供了一种语音交互方法、系统、终端及存储介质，该方法包括：获取用户语音，对用户语音进行语义识别，得到语义匹配度；若语义匹配度小于第一匹配度阈值，且大于第二匹配度阈值，则将用户语音确定为待唤醒语音，返回执行获取用户语音的步骤；若预设时长内获取到的用户语音满足语音唤醒条件，则根据待唤醒语音确定所述交互语音，根据交互语音对用户进行语音交互。本发明实施例，通过将语义模糊的用户语音设置为待唤醒语音，当检测到预设时长内获取到的用户语音满足语音唤醒条件时，唤醒待唤醒语音执行语音交互操作，有效地提高了语音交互的执行效率，提高了用户的使用体验。
G10L13/02  ,一种语音合成方法、装置、电子设备和存储介质 [发明],本发明涉及一种语音合成方法、装置、电子设备和存储介质，该方法包括：获取包含语气词的文本语音对；使用包含语气词的文本语音对训练得到时长模型、声学模型和神经网络声码器模型；获取包含语气词的多个句子，根据包含语气词的多个句子、声学模型以及神经网络声码器模型确定每个语气词的N个模板语音；获取待合成语音的文本，解析待合成语音的文本得到音素序列；根据预设的重复规则修改音素序列；根据修改后的音素序列、时长模型、声学模型和神经网络声码器模型得到初步合成语音；在初步合成语音的静音部分插入模板语音得到最终合成语音。本发明根据人的实际说话语气，对合成语音进行处理，从而得到更加真实的合成语音。
G10L15/01  ,一种终端到云端的语音识别测试方法及装置 [发明],一种终端到云端的语音识别测试方法及装置，按照路径表格对预置音频进行播放，对播放的预置音频进行录音得到实时录音文件，将得到的实时录音文件以第一命名进行本地保存；对SSP引擎处理后的实时录音文件以第二命名进行本地保存；将上传至云端进行识别的实时录音文件以第三命名进行本地保存；将云端识别收到的音频数据以第四命名进行保存；根据第一命名的实时录音文件生成单声道音频文件，将单声道音频文件、第二命名文件、第三命名文件、第四命名文件的MD5值进行比对，根据预置音频的识别结果和预置音频对应的音频内容比较结果判断是否收集原始音频优化SSP引擎性能。本发明可以实现语音识别测试流程协助排查和定位，提升内部研发效率。
G10K11/178  ,噪音处理方法、装置、电子设备及存储介质 [发明],本公开提供了一种噪音处理方法、装置、电子设备及存储介质。该方法包括：得到第一时段内目标车间中目标人员所在位置的第一噪音信号；基于第一噪音信号，对第二时段内多个信号发射器的整体控制参数进行预测，得到当前参数预测结果；其中，第二时段为第一时段的未来时段；基于当前参数预测结果，从多个信号发射器中确定一个或多个需要在第二时段内工作的目标发射器，以及得到每个目标发射器在第二时段内的参数预测值；控制每个目标发射器按照对应的参数预测值在第二时段内发射噪音干扰信号，以弱化第二时段内目标车间中目标人员所在位置的第二噪音信号。采用本公开方案可以减少目标车间中的噪音污染。
G06T13/40  ,数字人的生成方法、装置和数字人生成系统 [发明],本申请提供了一种数字人的生成方法、装置和数字人生成系统。该方法包括：获取描述文本；构建数字人生成模型，其中，数字人生成模型是使用多组训练数据来通过StableDiffusion算法和Speech2face算法训练得到的，多组训练数据中的每一组训练数据均包括历史时间段内获取的历史描述文本、历史描述文本对应的历史数字人人脸图像、历史描述文本对应的历史数字人音频；将描述文本输入至数字人生成模型，得到描述文本对应的数字人人脸图像和数字人音频，其中，数字人人脸图像为数字人的人脸图像，数字人音频为数字人说话时的音频。该方案解决了现有技术中数字人的制作效率较低的问题。
G06F3/16  ,一种多模态人机交互系统 [发明],本发明涉及人机交互技术领域，具体为一种多模态人机交互系统，包括语音识别模块、手势识别模块和决策与优化模块，其中：语音识别模块用于收集语音数据并进行特征提取，利用长短时记忆网络模型对特征提取后的语音数据进行文本结果和置信度的预测，手势识别模块用于收集用户视频数据，利用卷积神经网络对用户视频数据进行文本结果和置信度的预测，决策与优化模块对语音识别模块和手势识别模块中的文本结果进行比对，根据文本结果是否一致和置信度的高低，确定最终结果，其中，置信度相等，决策与优化模块对语音识别模块和手势识别模块中的算法模型进行优化处理，优化完成再次进行结果比对，不停迭代，直到确定最终结果。
G10L15/06  ,数据传输方法、模型训练方法、装置、芯片及终端 [发明],本发明提供了一种数据传输方法、模型训练方法、装置、芯片及终端，包括：获取语音数据，通过编码模型对语音数据进行编码得到N＆lt;subgt;q＆lt;/subgt;个码字索引值；根据当前网络环境确定目标码率，根据目标码率从N＆lt;subgt;q＆lt;/subgt;个编码向量量化器中确定前N＆lt;subgt;t＆lt;/subgt;个编码向量量化器；目标码率在编码模型的可选码率范围内，则将前N＆lt;subgt;t＆lt;/subgt;个编码向量量化器的码字索引值确定为待处理数据，目标码率不在可选码率范围内，根据目标码率对编码向量量化器进行裁剪得到包含目标码率的裁剪后可选码率范围，将裁剪后的前N＆lt;subgt;t＆lt;/subgt;个编码向量量化器的码字索引值确定为待处理数据；对待处理数据进行数据处理得到数据包，按照目标码率将数据包发送给接收端。本发明在不重新训练模型的情况下可定制化可选码率。
G10L15/22  ,魔方还原方法、装置及电子设备 [发明],本发明公开了一种魔方还原方法、装置及电子设备。其中，该方法包括：采用集成于魔方机器人上的语音交互设备接收来自目标对象的目标语音；采用魔方机器人中的识别设备对目标语音进行识别处理，从多种魔方还原模式中识别出目标魔方还原模式；采用魔方机器人上的魔方检测器检测魔方机器人上的目标魔方，得到检测结果；基于目标魔方还原模式以及检测结果，通过驱动魔方机器人的魔方还原执行设备对目标魔方进行还原处理，得到魔方还原结果。本发明解决了相关技术中的魔方还原方法由于缺少人机互动，导致用户体验感差的技术问题。
G06T13/20  ,基于语音的人脸驱动方法、装置、电子设备及存储介质 [发明],本发明公开了一种基于语音的人脸驱动方法、装置、电子设备及存储介质，本发明在模型训练所使用的真实人脸混合形状参数的获取过程中，结合了多种目标损失函数，如此，保证了人脸混合形状参数的时序平滑性与准确性，解决了因人脸混合形状参数非正交基引起的优化困难问题；同时，在语音到人脸混合形状参数预测的网络结构中加入了时序模块和映射模块，基于此，能够保证人脸驱动的实时性与准确性；因此，本发明可基于语音来精准且实时的驱动人脸，非常适用于在语音驱动人脸领域的大规模应用与推广。
G10L15/22  ,语音处理方法、装置、设备及介质 [发明],本申请涉及语音处理技术领域，具体提供一种语音处理方法、装置、设备及介质，旨在解决现有的语音处理方法无法平衡语音交互响应速度与声源定位准确率的问题。为此目的，本申请通过获取驾驶设备内的多路音频数据；当第一路音频数据首个触发唤醒词时，获取第一能量值以及第二能量值并将第一能量值与第二能量值进行比较，其中第一能量值为第一路音频数据对应的能量值，第二能量值为多路音频数据中其余路音频数据对应的能量值；若第一能量值大于等于第二能量值，则无需其余路音频数据进行唤醒词触发，否则则动态分配其余路音频数据的唤醒词触发时长。这样的设置能够在尽可能保证声源定位准确性的前提下减小交互等待时长。
B60Q9/00  ,面向公交车司乘冲突的人员预警和行车控制方法及系统 [发明],本发明属于道路车辆驾驶控制领域，涉及一种面向公交车司乘冲突的人员预警和行车控制方法及系统，该方法利用传感器、相机等采集数据，并将采集的数据处理后输入提前训练好的愤怒情绪模型，分别对司机和乘客的愤怒情绪进行识别，同时对抢夺方向盘趋势进行预测，之后将司机与乘客的愤怒情绪进行分级，根据司机与乘客愤怒等级，对司机和乘客进行预警和干预，并采取相应的车辆控制措施。该方法考虑了乘客和司机语音冲突的逻辑性，有效避免了因乘客个人情绪产生的愤怒语音造成的误判，且既可对已经发生的肢体接触动作进行识别，同时对于危险动作（如抢夺方向盘）也能提前预测并干预，保证公交车行车安全。
G10L25/18  ,音频文件识别方法及装置 [发明],本申请公开了一种音频文件识别方法及装置。其中，该方法包括：接收待识别音频文件；采用第一线程池中的第一线程，按照待识别音频文件中的音频帧的排列顺序，依次对待识别音频文件中音频帧进行处理，得到多个音频片段；采用第二线程池中的第二线程依次对将多个音频片段进行识别，得到多个识别结果，将多个识别结果进行排序后进行拼接，得到最终识别结果，其中，第一线程和第二线程为异步执行的线程。本申请解决了相关技术中需要等待VAD处理完成后，才会进行ASR处理，导致对音频文件识别效率较低的技术问题。
G06F40/242  ,词典融合方法、装置、电子设备及存储介质 [发明],本公开提供了一种词典融合方法、装置、电子设备及存储介质。本公开的词典融合方法包括：接收用户输入的预训练语料，预训练语料为基于第一语言的预训练语料；响应于用户输入的预训练语料，基于预训练语料训练第一分词器，得到第一语言分词器；以及将第一语言分词器的词表与第二语言分词器的词表进行融合，得到融合后的词典，其中，第二语言分词器为基于第二语言进行训练得到的分词器，第一语言与第二语言不同。
G10L15/02  ,一种实时语音关键词检测方法及系统 [发明],本发明公开一种实时语音关键词检测方法及系统，该方法包括以下步骤：对输入音频进行分帧、特征提取，组成固定时长的片段级特征序列，输入含有空白检测的声学编码器模块，得到去除空白信息的二级声学向量；通过敏感词偏置的文本预测模块获取融合敏感词信息的文本预测概率；将去除空白信息的二级声学向量与融合敏感词信息的文本预测概率进行融合，将结果输入敏感词偏置的文本预测模块；解析当前时刻的候选路径集合，给出是否出现敏感词的判断。本发明设置敏感词偏置的文本预测模块，在常规文本预测模块基础上融合敏感词信息，敏感词检测准确率高，可实时检测输入音频是否包含敏感词且敏感词支持用户自定义，具有计算复杂度小、实时性较高的特点。
G10L25/51  ,一种基于风电故障知识库的声纹监测诊断方法 [发明],本发明公开的属于风电设备监测技术领域，具体为一种基于风电故障知识库的声纹监测诊断方法，包括诊断方法如下：在风电发电机的塔筒底部以及机舱内均安装声纹采集终端，安装于机舱内的声纹检测终端为传动链设备声纹检测，安装于塔筒底部的声纹检测终端为叶片损伤检测，通过各个声纹检测模块电性连接的麦克风对设备运行时的声音进行采集，通过声纹过滤模块的噪声抑制算法、声源增强算法以及盲源分离算法对采集的声音进行过滤，本发明将预测结果反馈给云端服务器和运维人员，实现远程监测和控制，同时，通过控制系统，对风机进行调节和控制，如调节风机转速、控制风机启停等，以保证风机在最佳运行状态下工作，延长风机寿命，提高发电效率。
G06V40/16  ,一种面向情绪识别的多模态数据采集系统及其工作方法 [发明],本发明公开一种面向情绪识别的多模态数据采集系统及其工作方法，涉及情绪识别技术领域，该方法包括：数据采集控制平台向摄像头和麦克风发送控制信号打开摄像头和麦克风；摄像头捕捉用户的面部表情获得图像信号，麦克风记录用户声音和声音特征生成音频数据；将采集到的图像数据和音频数据传输到智能环境适应模块中，采用自适应算法，通过根据图像数据特征来调整摄像头的参数设置；对音频数据进行降噪处理；处理后的图像、音频数据传输至数据采集控制平台中，在处理后的音频中提取文本数据；在数据加密模块中采用AES对称加姆算法对图像、音频和文本数据进行加密储存；采用了智能环境适应模块能够实时调整摄像头参数，以适应不同环境条件。
G10L15/01  ,模型的质量评估方法、服务器及计算机可读存储介质 [发明],本申请公开一种模型的质量评估方法，所述方法包括：获取目标语音请求和所述目标语音请求的第一结构化处理结果，基于第一大语言模型确定目标语音请求的第二结构化处理结果，及根据目标语音请求的第一结构化处理结果和第二结构化处理结果，评估第一大语言模型的质量。如此，在本申请中，服务器可根据目标语音请求和目标语音请求的第一结构化处理结果，以及第一大语言模型根据目标语音请求确定的第二结构化处理结果，评估第一大语言模型的质量，使得第一大语言模型的质量评估可考虑到第一大语言模型的结构化能力，第一大语言模型的质量得以可靠评估。
G10L15/22  ,基于语音控制车辆的方法、电子设备及存储介质 [发明],本申请涉及智能汽车技术领域，具体提供一种基于语音控制车辆的方法、电子设备及存储介质，旨在解决现有车辆语音控制系统难以兼顾安全性和便捷性的问题。为此目的，本申请的基于语音控制车辆的方法包括：获取语音指令；确认所述语音指令的传播方向；判断在沿所述语音指令的传播方向上，车内是否有人；根据车内是否有人的判断结果确认是否执行所述语音指令。本申请在车内所有乘客均能够通过语音控制车辆的前提下，基于语音指令传播方向判断车内是否有人，然后根据判断结果确定是否响应该语音指令，控制车辆作出进一步动作，如此，在保证便捷性的基础上，也提高了车辆语音控制方式的安全性，提高了用户体验。
G10L21/0232  ,回声消除、模型训练方法、装置、电子设备及存储介质 [发明],本发明涉及人工智能技术领域，公开了一种回声消除、模型训练方法、装置、电子设备及存储介质，该非线性回声消除模型训练方法通过训练样本对包括有非线性回声消除模型和语音端点检测模型的多任务模型进行训练，根据预测语音标签概率数据、预测近端频谱信号以及真实语音标签和真实近端频谱信号确定训练目标不同的多个损失函数，并通过多个损失函数更新多任务模型的参数，将训练后的多任务模型中的非线性回声消除模型确定为训练后的非线性回声消除模型，以完成对非线性回声消除模型的训练，通过使用语音端点检测模型作为辅助任务，能对非语音帧减少回声抑制效果，对语音帧正常进行回声抑制，有效提升识别效果和模型稳定性。
G06F16/33  ,基于区块链的数据处理方法、装置、电子设备及介质 [发明],本申请公开了一种基于区块链的数据处理方法、装置、电子设备及介质，应用于语音处理技术领域，方法包括：确定机器人发送的产品引导对话请求信息对应的目标产品，其中，机器人对用户输入语音进行识别，在识别到语音包含目标产品时，将生成的产品引导对话请求信息发送至区块链中的节点；确定区块链内主链中与目标产品对应的目标产品区块，确定挂载至目标产品区块下侧链中与机器人标识匹配的目标侧链区块，将目标侧链区块中挂载的多叉树内存储的产品引导信息发送至机器人；若检测到评价信息，将评价信息发送至区块链内的所有节点进行共识，在共识完成后，将评价信息存储至多叉树。本申请提高了机器人的数据安全性，进而提高了机器人的智能性。
G10L21/028  ,人声分离模型的训练方法、人声分离方法和计算机设备 [发明],本申请涉及一种人声分离模型的训练方法、人声分离方法和计算机设备。方法包括：获取由干净人声信号进行混响得到的第一混响信号，并以此构造第一混合信号；将第一混合信号输入待训练的人声分离模型，得到第一人声分离信号，利用第一人声分离信号与干净人声信号之间的第一差异训练人声分离模型，得到预训练的人声分离模型；获取录制的包含第二混响信号以及第二混响信号匹配的和声信号的第二混合信号；将第二混响信号以及第二混合信号分别输入预训练的人声分离模型，得到第二人声分离信号和第三人声分离信号，利用第二人声分离信号与第三人声分离信号之间的差异训练预训练的人声分离模型，得到训练完成的人声分离模型，如此能够降低成本。
G10L25/18  ,声学场景分类、模型训练、部署方法、模型、芯片、装置、电子设备及存储介质 [发明],本发明涉及人工智能技术领域，公开了一种声学场景分类、模型训练、部署方法、模型、芯片、装置、电子设备及存储介质，该声学场景分类模型包括数据获取模块、音频信号预处理模块、多个依次连接的深度膨胀残差块、卷积层和全连接层，通过采用深度膨胀残差块，能在不增加网络参数和计算量的前提下提高网络感受野，网络捕获全局信息能力更强，将残差操作与膨胀卷积结合可以避免网络训练过程中可能出现的梯度消失，通过实例归一化处理，避免了中间特征的频域信息和时域信息丢失，加快模型训练过程中的收敛速度，该声学场景分类模型合理，可以实现低计算复杂度和实时的声场景分类，使得该方案可以部署到蓝牙耳机、音响等资源受限的设备上。
G10L21/02  ,语音增强方法、系统、设备和存储介质 [发明],本公开涉及计算机技术领域，公开了一种语音增强方法、系统、设备和存储介质，语音增强方法包括获取音频数据，以及在音频数据中检测到语音数据时，提取语音数据的嵌入向量；在嵌入向量中，查找从目标语音数据中提取到的目标嵌入向量，并基于目标嵌入向量，生成注册嵌入向量；将注册嵌入向量与音频数据的音频特征向量进行相关性计算，以确定对目标语音数据进行增强时所需使用的掩蔽值；依据掩蔽值，对音频数据中的目标语音数据进行增强。
A61B5/12  ,一种基于云计算的听力语言智能康复平台 [发明],本发明公开了一种基于云计算的听力语言智能康复平台，包括数据采集模块、检索模块、内容整合模块和康复测试模块，数据采集模块用于获取录音内容的相关信息；检索模块用于对数据采集模块采集的内容信息进行检索；内容整合模块用于将所述检索模块的检索内容进行整合；康复测试模块用于对患者进行康复情况测试，本发明对数据库内存储的录音内容进行分析和整合，筛选出适合对听力障碍患者进行康复测试的录音内容，并通过康复测试模块对患者的康复情况进行分析，精确获取患者的听力能力，在减轻了医疗人员的诊断负担的同时提高了测试内容的日常化程度，最大程度降低了人工诊治监测的不准确性，本发明，具有语言优化能力强和检测精准度高的特点。
G10L21/055  ,说话人脸视频生成方法、计算机设备及存储介质 [发明],本申请涉及计算机技术领域，具体提供一种说话人脸视频生成方法、计算机设备及存储介质，旨在解决现有方法生成的人脸视频质量较低的问题。为此目的，本申请的方法，包括：获取目标对象的初始图像帧，以及与待生成的说话人脸视频对应的音频数据和/或视频数据；基于音频数据和/或视频数据获取驱动信号，驱动信号包括头部位姿参数序列和面部表情参数序列；基于头部位姿参数序列和面部表情参数序列，以及初始图像帧生成目标图像帧序列；基于目标图像帧序列获得说话人脸视频。本申请将与音视频数据关联度不同的人脸参数分别处理，再基于处理结果生成目标图像帧序列，实现了对于说话人脸视频的人脸运动宏观控制和微观细节的补全。
G10L15/16  ,一种自动语音识别方法和系统 [发明],本发明提供一种自动语音识别方法和系统，包括：采集并预处理原始音频信号；从预处理后的原始音频信号中提取信号特征；将信号特征转换为特征序列；基于连接时序分类解码器，利用特征序列生成第一结果；并基于注意力机制解码器，利用特征序列生成第二结果；根据第一结果和第二结果生成最终的识别文本。本发明将声学模型、词汇模型和语言模型替换为单个神经网络，直接将语音映射到文本输出，省去了多个组件的优化和集成，从而避免了错误的累积，使得自动语音识别系统具有更高的准确性、更快的训练推理速度和更好的适应性，且更容易实现和部署，进而有效提高自动语音识别系统的性能和效率，解决了现有自动语音识别系统错误率较高的问题。
G10L15/22  ,声控方法、电气控制设备、储能系统、计算机设备及介质 [发明],本申请提供了一种声控方法、电气控制设备、储能系统、计算机设备及介质。通过本申请提供的声控方法，待控储能场站中的任意一个储能集装箱均可以通过其上设置的收音设备接收环境音，从而接收待控储能场站的发声设备发出的控制提示音，后续可以按照相应的声控信息对该储能集装箱的运行状态进行调控，从而实现按照待控储能场站管理端的指令进行运行调控的目的，使得待控储能场站可以根据调控需求，灵活调控待控储能场站中的任意一个储能集装箱，调控效率更高。
G06F40/232  ,播报文本的纠错方法、装置及电子设备 [发明],本公开提供了播报文本的纠错方法、装置及电子设备，涉及人工智能技术领域，尤其涉及深度学习、自然语言处理、大数据、大模型、计算机视觉、语音技术等技术领域。具体实现方案为：根据针对播报文本中目标文本片段的纠错操作，显示纠错弹窗；根据针对纠错弹窗中目标文本片段中字符以及候选问题选项的操作，确定目标文本片段中的目标问题字符以及对应的目标问题选项；根据目标问题字符以及目标问题字符对应的目标问题选项，对播报文本进行纠错处理，从而能够通过纠错弹窗，获取目标问题字符以及目标问题选项，进行纠错处理，进一步提高纠错效率，且能够及时获取播报应用中新出现的问题，进而针对该问题进行解决处理。
G10L25/18  ,报警声识别方法及装置、报警声识别模型的训练方法 [发明],本申请涉及声音识别领域，公开了一种报警声识别方法及装置、报警声识别模型的训练方法、电子设备及计算机可读存储介质。其中，报警声识别方法，包括：获取输入语音的梅尔频率倒谱系数；根据所述梅尔频率倒谱系数获取所述输入语音的目标时频特征；根据所述目标时频特征确定所述输入语音中是否包含报警声。与现有技术相比，本申请实施例所提供的警声识别方法及装置、报警声识别模型的训练方法、电子设备及计算机可读存储介质具有能够灵活适应多样的报警场景的优点。
G10L25/63  ,语音分类方法、装置、设备、介质和程序产品 [发明],本公开提供了一种语音分类方法，可以应用于人工智能技术领域。该语音情感分类方法包括：对初始语音采样信号进行预处理，获得多个语音信号帧；对每个语音信号帧进行滤波，获得语音信号帧的梅尔特征向量和逆梅尔特征向量；将梅尔特征向量和逆梅尔特征向量进行特征混合，获得混合梅尔特征向量；计算混合梅尔特征向量的特征参数；对全部特征参数进行分类，获得分类结果。本公开还提供了一种语音分类装置、设备、存储介质和程序产品。
G10L25/51  ,车机输出音频检测方法、系统、控制装置及存储介质 [发明],本申请涉及语音处理技术领域，具体提供一种车机输出音频检测方法，旨在解决现有技术中对语音进行检测时效率低的技术问题。为此目的，本申请的车机输出音频检测方法包括：采集车机输出的第一音频；基于预设的第二音频，在第一音频中确定出与第二音频相对应的目标音频；获取目标音频和第二音频的音频特征；基于目标音频特征和第二音频特征，确定第一音频与第二音频的匹配度。通过本申请，可以在采集的第一音频中快速地筛选出无关的音频片段和最有参考价值的音频片段即目标音频，从而提高了音频检测的效率，通过计算目标音频与预设的第二音频的匹配度，能够为分析车机输出音频的准确度提供参考依据。
G10L25/18  ,基于人工智能和设备运行声音的异常设备识别方法及系统 [发明],本发明公开了基于人工智能和设备运行声音的异常设备识别方法及系统，包括：首先获取待定设备运行声音，解析得到音频帧特征向量，进一步解析得到匹配的频域特征。用这些特征构建频谱，执行特征整合，得到联合特征向量。通过合并相应的联合特征向量，得到目标音频帧特征向量，据此进行设备运行状态检测。若设备状态异常，将其标记为异常设备。如此设计，可以自动、快速地识别设备的运行状态，无需人工频繁监控，大大提高了设备检测的效率，实现提前预防潜在故障，从而避免因设备损坏造成的高额维修或更换成本。
G10L21/10  ,一种基于数字人实时问答响应的优化系统及方法 [发明],本发明涉及计算机人工智能技术领域，具体涉及一种基于数字人实时问答响应的优化系统及方法，其中系统包括：问答处理模块，用于接收客户端的提问，并发送客户端的提问到ChatGPT获取相应的答案话术，调用语音合成算法将ChatGPT获取的答案话术生成答案语音文件；过渡处理模块，用于获取当前时段播放的音频的后面一段音频，将后一段音频作为过渡语音文本；口型合成模块，用于根据语音文件生成口型参数，语音文件包括答案语音文件、过渡语音文本；话术播放模块，用于结合口型参数的数字人画面形成与音频配合的数字人动画，将数字人动画与音频组合形成视频，通过话术播放模块播放该视频。本发明能够提高响应速度，有利于实现流畅的人机交互。
G10L15/06  ,语音识别方法、装置、非易失性存储介质及电子设备 [发明],本申请公开了一种语音识别方法、装置、非易失性存储介质及电子设备。其中，该方法包括：持续采集待识别音频帧，并将采集的待识别音频帧输入到目标识别模型中，其中，目标识别模型包括多个依次连接的注意力层，目标识别模型用于通过多个注意力层提取待识别音频帧的特征并输出与待识别音频帧对应的识别结果；在目标识别模型识别待识别音频帧的过程中，对目标识别模型中的各个注意力层的历史状态进行更新，得到更新后的目标识别模型；依据更新后的目标识别模型确定待识别音频帧的识别结果。本申请解决了由于相关技术中在识别音频时采用分块处理的方式导致的识别结果输出不流畅的技术问题。
G10L15/22  ,物联网设备的唤醒方法、唤醒装置和物联网系统 [发明],本申请提供了一种物联网设备的唤醒方法、唤醒装置和物联网系统，多个物联网设备和中控设备组成物联网，该方法包括：中控设备获取语音指令，语音指令为中控设备或者物联网设备识别用户的语音得到的指令；中控设备根据语音指令确定需求功能，需求功能为执行语音指令的功能；中控设备将具有需求功能的物联网设备确定为目标物联网设备，并发送目标物联网设备对应的唤醒指令至目标物联网设备，唤醒指令与物联网设备一一对应，解决现有技术中用户语音唤醒某个家居设备时多个家居设备均被唤醒导致体验差的问题。
G10L25/63  ,用于客服人员的智能化座席考核方法及系统 [发明],本申请涉及智能考核技术领域，其具体地公开了一种用于客服人员的智能化座席考核方法及系统，其采集客服人员与客户的对话过程中的语音信号，结合智能化算法分析所述语音信号中的声学语义特征，捕捉客服人员的声学语义波动模式，以此来实现对客服人员的情绪波动进行识别。这样，能够从语音数据中高效地识别和分析人员的情绪波动，无需人工干预，从而更加准确客观地评估客服人员的表现。
H04W28/06  ,一种蓝牙耳机低延迟传输方法 [发明],本发明涉及信号处理技术领域，具体为一种蓝牙耳机低延迟传输方法，包括以下步骤，基于自适应编码算法优化，采用实时网络状态分析技术，进行网络状况的实时评估，并生成网络状况评估报告。本发明中，通过自适应编码算法优化结合实时网络状态分析技术，允许音频流根据网络条件动态调整比特率和压缩率，保障网络不稳定时的音频传输稳定性，多路径传输与选择性接收技术通过并行发送音频信号并选择最优传输路径，有效增强信号稳定性和抗干扰能力，边缘计算处理策略能够减轻耳机处理负担，提高效率和节能性，深度神经网络降噪技术有效消除环境噪声，提升音频清晰度，结合环境自适应学习算法和频谱感知数据压缩算法，实现音质优化与延迟平衡。
G10L21/0208  ,一种折叠终端设备的语音降噪方法、折叠终端设备 [发明],本申请公开了一种折叠终端设备的语音降噪方法、折叠终端设备及存储介质，该方法包括：在折叠终端设备处于悬停状态的情况下，获取第一屏幕和第二屏幕的悬停角度；获取多个麦克风采集的多个语音信号；根据悬停角度和多个语音信号进行语音降噪处理，得到折叠终端设备的目标语音信号。如此，将悬停角度作为新增特征对多通道的语音信号进行处理，实现在不同悬停角度下对来自不同空间方向的噪声和干扰源抑制力度保持不变，目标语音保真度性能保持不变，折叠终端设备的降噪效果不受悬停角度的影响。
G10L13/02  ,语音合成方法、装置、系统及存储介质 [发明],本申请的实施方式提供了一种语音合成方法、装置、系统及存储介质。包括：获取目标文本的语音合成请求；从预设的前处理服务器中确定当前空闲的第一目标CPU，并在第一目标CPU运行前处理服务；在前处理服务完成的情况下，从预设的音频合成服务器中确定当前空闲的第一目标GPU，并在第一目标GPU运行音频合成服务；在音频合成服务完成的情况下，从预设的后处理服务器中确定当前空闲的第二目标CPU，并在第二目标CPU运行后处理服务。该方法，将前处理服务在前处理服务器中处理，将音频合成服务在音频合成服务器中处理，将后处理服务在后处理服务器中处理，每一个处理步骤中都是从对应的服务器中选择空闲的CPU或GPU处理，可以避免等待时间，提高了GPU的利用率。
G10L13/02  ,一种语音播报方法、计算机可读存储介质及智能设备 [发明],本申请涉及通信技术领域，具体提供一种语音播报方法、计算机可读存储介质及智能设备，旨在解决现有语音播报效果较差的问题。为此目的，本申请的语音播报方法包括：智能终端能够获取待播报任务；判断是否存在与待播报任务对应的音频信息；如果否，将待播报任务发送至移动终端，接收移动终端传输的第一音频信息；至少基于所述第一音频信息进行语音播报。该方法利用移动终端数据传输性能更好的特性，基于移动终端的第一音频信息进行语音播报，可以有效避免播报延迟、卡顿等问题，有利于提高语音播报效果。
G10L21/0208  ,一种基于神经网络的实时回声消除方法 [发明],本发明公开了一种基于神经网络的实时回声消除方法，包括：步骤1、构建回声消除模型；步骤2、对所述回声消除模型进行训练；步骤3、构建回声检测模型；步骤4、对所述回声检测模型进行训练；步骤5、将近端音频信号和远端音频信号作为训练后的所述回声消除模型的输入，得到训练后的所述回声消除模型的输出；步骤6、将训练后的所述回声消除模型的输出和远端音频信号作为训练后的所述回声检测模型的输入，得到训练后的所述回声检测模型的输出作为回声检测的标签；步骤7、根据所述回声检测的标签判断当前回声消除模型输出帧的状态，得到最终的目标音频。本发明是结合回声消除模型和回声检测模型，在只采集少量数据的情况下，提高回声消除模型的效果，减小模型的部署难度。
G10L15/02  ,副歌检测方法、装置、设备及存储介质 [发明],本申请公开了一种副歌检测方法、装置、设备及存储介质，涉及音频处理领域。该方法包括：调用旋律特征提取模型对待检测歌曲进行特征提取，得到歌曲特征；调用旋律特征提取模型对参考副歌片段进行特征提取，得到副歌特征；参考副歌片段是待检测歌曲中已标定的副歌片段；将歌曲特征与副歌特征相乘，计算歌曲特征与副歌特征的相关性矩阵；相关性矩阵为二维矩阵，相关性矩阵的行数与副歌片段的音频帧数相对应，相关性矩阵的列数与待检测歌曲的音频帧数相对应；确定相关性矩阵中数值满足阈值条件的目标列数区间；将目标列数区间所对应的待检测歌曲的目标音频帧区间，确定为待检测歌曲的预测副歌片段。该方法可以提高副歌标注效率。
G10L17/02  ,一种基于原生声纹特征的拾音翻译方法、设备及存储介质 [发明],本发明公开一种基于原生声纹特征的拾音翻译方法、设备及存储介质，涉及语音识别技术领域。本发明包括，获取原生音频；将原生音频进行分割得到多个原音素以及对应的顺序；获取每个原音素的若干个种类的声纹特征；对原生音频进行语义识别得到原语种文本；将原语种文本翻译为转译语义文本；对转译语义文本进行音素拟合得到多个转译音素以及对应的顺序；根据原音素和对应的顺序以及对应的若干个种类的声纹特征对转译音素进行修正得到转译音频。本发明通过对发言者的原生声纹特征进行识别提取，实现对语音翻译结果的修正，同时实现对翻译结果的润色。
G06Q10/10  ,一种电力平台工单数据生成方法、系统、电子设备及介质 [发明],本发明涉及电力工单分析处理技术领域，具体是基于一种电力平台工单数据生成方法、系统、电子设备及介质，包括监测客户接入电网客服中心时，将客户端的通话音频通过转化为文本内容并提取出关键词，将关键词与故障特征词通过相似度计算后录入，同时根据关键词获取工单的处理部门。若未在设定时间完成工单数据，则生成标准问句，并通过可视化界面提醒客户代表进行询问，当监测工单数据生成完成后，则由客户代表复核工单数据后进行下发。本发明通过数据挖掘客户端的通话音频得到关键词，判定该关键词是工单数据的所需信息后录入，使得生成的工单数据更加具有准确性。
G06F11/36  ,智能引擎的测试方法、装置、电子设备及存储介质 [发明],本发明提供一种智能引擎的测试方法、装置、电子设备及存储介质，该方法包括：确定智能引擎的测试项，测试项包括如下至少一项：翻译能力、转写能力、合成能力和图文转换能力；将测试数据输入翻译引擎，得到翻译引擎输出的第一译文，翻译引擎的翻译准确度大于第一预设准确度；将第一译文输入智能引擎，得到智能引擎输出的目标数据；基于目标数据，对智能引擎的测试项进行测试。基于本方法，可由翻译准确度大于第一预设准确度的翻译引擎对测试数据进行准确度较高的翻译，得到第一译文，将第一译文输入待测试的智能引擎输出目标数据，即可进行测试，降低了对测试人员的依赖度，减少了人工参与的程度，可以提升测试效率。
G10L25/03  ,一种音频数据的检测方法、装置及电子设备 [发明],一种音频数据的检测方法、装置及电子设备，该方法包括：获得待检测音频数据，将待检测音频数据输入目标音频检测模型进行训练，得到至少一个音频事件与每个音频事件对应的音频事件概率值的对应关系，按照预设规则从所有音频事件概率值中筛选出目标音频事件概率值，并将目标音频事件概率值对应的音频事件作为待检测音频数据对应的目标音频事件。通过上述的方法，确定出训练之后的目标音频检测模型，确保了确定出的目标音频检测模型的准确性，并通过目标音频检测模型检测待检测音频数据中的目标音频事件，确保了确定出的目标音频事件的准确性。
G10L25/51  ,基于滑动窗口的部分合成伪造语音检测方法和系统 [发明],本发明提供一种基于滑动窗口的部分合成伪造语音检测方法和系统。通过获取待检测部分合成伪造语音，设定滑动窗口长度，并基于滑动窗口长度对待检测部分合成伪造语音进行滑动窗口划分，以获取多个语音子序列。遍历多个语音子序列，以确定目标语音子序列。对目标语音子序列进行真实语音检测。如果目标语音子序列是真实语音，则基于预设的第一语音检测模型获取语音拼接点；如果目标语音子序列不是真实语音，则基于预设的第二语音检测模型对所述目标语音子序列进行处理，以获取语音拼接点。本申请能够检测到部分合成伪造语音中的语音拼接点，以提高部分合成伪造语音检测与定位的准确性。
G10H1/00  ,音频评价方法、装置、设备、存储介质和程序产品 [发明],本申请涉及一种音频评价方法、装置、设备、存储介质和程序产品。方法包括：获取待评价的目标音频和与目标音频对应的模板音频；分别对目标音频和模板音频进行音名识别处理，得到目标音频对应的第一时间序列和模板音频对应的第二时间序列，第一时间序列包括目标音频中的各个音名对应的演唱时间信息，第二时间序列包括模板音频中的各个音名对应的演唱时间信息；根据第一时间序列和第二时间序列确定目标音频的节奏稳定性评价结果，并根据第一时间序列和第二时间序列确定目标音频的停顿换气准确性评价结果；根据节奏稳定性评价结果和停顿换气准确性评价结果确定目标音频的综合评价结果。采用本方法能够提高音频评价的准确性。
G10L25/51  ,一种纯软件音频自动化测试方法、系统、设备及介质 [发明],本申请涉及音频测试技术领域，尤其是涉及一种纯软件音频自动化测试方法、系统、设备及介质，获取测试音频信号，判断测试音频信号的格式是否为标准待测格式，在测试音频信号的格式不是标准待测格式的情况下进行格式转换，得到标准待测音频；分析标准待测音频的波形，在波形为正弦波的情况下，获取指标预设范围，根据指标预设范围判断音频质量；在波形为非正弦波的情况下，将标准待测音频进行文本转换，得到转换文本，获取预期文本，根据预期文本对转换文本进行比对，减少音频测试繁杂且重复的操作，提升音频测试的效率。
G10L15/18  ,音频分析方法和装置、存储介质及电子设备 [发明],本申请公开了一种音频分析方法和装置、存储介质及电子设备，其中，上述方法包括：获取待分析音频中局部平稳的音频特征，通过音频编码器提取音频特征在不同层次的音频特征序列；通过查询变换器模型提取音频特征序列的多尺度语义特征；将多尺度语义特征输入至大语言模型，得到待分析音频的分析结果。采用上述技术方案，解决了大语言模型仅能基于单一尺度分析音频的问题。
G10L21/0232  ,回声消除方法、装置、音频设备及存储介质 [发明],本申请提供一种回声消除方法、装置、音频设备及存储介质。回声消除方法包括：获取麦克风数据经线性回声消除后的初始回声消除结果；将远端语音数据和所述初始回声消除结果输入到预设的深度学习残余回声消除网络，得到频域信号掩码；所述深度学习残余回声消除网络用于以所述远端语音数据为参考信号，确定出所述初始回声消除结果中的非线性回声部分，所述频域信号掩码表征所述初始回声消除结果中需被抑制的信息和/或需保留的信息；基于所述频域信号掩码对所述初始回声消除结果进行残余回声消除，得到残余回声消除后的麦克风数据。该回声消除方法可以提高对不同场景下的麦克风数据进行残余回声消除后的信号质量。
G10L15/22  ,用于高空作业机械的控制方法、装置及存储介质 [发明],本申请实施例提供一种用于高空作业机械的控制方法、装置及存储介质。方法包括：获取高空作业机械所处作业区域的环境特征信息，环境特征信息至少包括声音特征数据、光照特征数据以及振动特征数据；根据环境特征信息以及与环境特征信息对应的权重系数确定作业区域的环境复杂度；根据环境复杂度和声音特征数据确定作业区域的语音可信度；根据语音可信度确定高空作业机械的控制模式，控制模式包括语音控制模式和/或手势控制模式；基于控制模式控制高空作业机械执行对应的操作，使得高空作业机械在复杂作业环境下的控制模式更为合理和准确，提升高空作业的作业效率。
G10L15/25  ,面部生成方法和装置 [发明],本申请公开了一种面部生成方法和装置，属于数字人领域。所述面部生成方法，包括：获取目标音频和目标风格特征序列；目标风格特征序列为目标风格对象在口播任意音频情况下对应的面部特征序列；基于目标音频和目标风格特征序列，预测得到目标口型特征；目标口型特征为目标风格对象对应的唇形风格下与目标音频匹配的口型特征；基于目标口型特征和目标风格特征序列，生成整体面部特征序列。本申请的面部生成方法，可以生成不同风格且风格差异较大的不同的口型特征，有利于个性化风格的实现。
G10L13/033  ,音频数据集的生成方法、装置、设备、存储介质及产品 [发明],本申请公开了一种音频数据集的生成方法、装置、设备、存储介质及产品，属于数据处理技术领域。该方法包括：获取源音频数据集和指定音色对应的音色特征；提取源音频数据对应的音频内容特征和音频发音特征，所述音频内容特征用于表征所述源音频数据的音频内容，所述音频发音特征用于表示所述源音频数据的发音特点；将所述音色特征、所述音频内容特征和音频发音特征输入至音色转化模型进行音色转化，得到所述指定音色下的音频数据；基于转化后的所述音频数据生成所述音频数据集。通过上述方法，可在保留源音频数据的音频内容和发音特点的基础上，转化源音频数据对应的音色，从而得到指定音色下的音频数据，提高了音频数据集的生成效率。
G10L25/03  ,一种音频事件检测模型生成方法、装置、设备及存储介质 [发明],本申请公开了一种音频事件检测模型生成方法、装置、设备及存储介质，涉及音频事件检测技术领域。该方法包括：对获取到的N个原始音频数据进行标注，得到标注后的N个目标音频数据，以及N个目标音频数据各自的标签信息，N为大于1的整数；对N个目标音频数据进行特征提取，得到N个目标音频数据的第一特征向量数据；基于扩散模型以及设定的增强模式，对第一特征向量数据进行特征增强，得到增强后的特征向量数据；对该增强后的特征向量数据进行筛选，得到符合筛选要求的目标特征向量数据；根据N个目标音频数据各自的标签信息、第一特征向量数据，以及目标特征向量数据，生成音频事件检测模型，用以提高音频事件检测模型的泛化性和检测性能。
G10L15/26  ,一种样本音频的采集方法、装置、存储介质及电子设备 [发明],本说明书公开了一种样本音频的采集方法、装置、存储介质及电子设备，本说明书实施例根据目标用户的属性，从预设的主题中选取与该目标用户匹配的目标主题，并向其展示目标主题中的问题以及参考回复，使目标用户根据参考回复回答展示的问题，由此采集目标用户的音频作为样本音频，可更加稳定且高效的采集用于训练语音合成模型的样本音频。
A61B5/00  ,一种基于多源生物信号采集的口才表达分析系统 [发明],本发明提供了一种基于多源生物信号采集的口才表达分析系统，涉及口才表达分析领域，包括：多源生物信号采集模块，用于采集口才表达者的多模态生物信号数据；生物特征提取和异构数据融合模块，用于提取所述多模态生物信号数据中的生物特征，并基于所述生物特征，利用深度学习模型以及决策模型，将口才表达者的情感状态以及个人风格与声音特征相关联，生成口才表达分析结果；所述生物特征包括情感特征、微表情特征以及振动特征；知识库和决策模块，用于根据所述口才表达分析结果对口才表达者进行综合评价，生成口才表达分析报告。本发明能够降低分析结果误差，提供正确的针对性建议。
G06F40/30  ,敏感词检测方法、装置、电子设备和计算机可读存储介质 [发明],本发明实施例提供了一种敏感词检测方法、装置、电子设备和计算机可读存储介质。其中，该方法包括：获取语音数据；将语音数据转化为文本数据；基于预设的分词算法将文本数据分词，得到分词后的文本数据；将分词后的文本数据进行预处理，将预处理后的数据确定为目标数据；其中预处理至少包括以下之一：停用词表过滤处理和提取关键词处理；基于预设的敏感词库抽取目标数据中的敏感词；基于敏感词发送警报信息；通过将语音数据转化为文本数据，进一步做分词和预处理后，再进行敏感词检测，减少了敏感词检测的工作量，从而降低了检测时间，提高了检测的时效性，提升了用户体验。
G10L25/63  ,基于AI的语音情绪识别模型的训练方法 [发明],本发明提供了一种基于AI的语音情绪识别模型的训练方法，包括：获取来电用户信息，根据来电用户信息建立来电用户的来电特征；根据来电特征对预设数据库进行筛选，匹配得到基于深度学习暨神经网络的语音情绪识别模型，其中，来电特征和语音情绪识别模型一一对应；获取来电用户信息中包含的用户语音信息，输入用户语音信息至语音情绪识别模型，得到识别结果；获取当前用户语音信息对应的语音情绪标签，根据识别结果和语音情绪标签，对当前来电用户的语音情绪识别模型的模型参数进行更新，得到新的语音情绪识别模型。
G10L15/22  ,一种语音智能遥控装置 [发明],本发明公开了一种语音智能遥控装置，包括内置有PCB电路板的控制面板、操作机械臂以及遥控器磁吸结构，所述控制面板上表面标有遥控器放置区域，所述放置区域设置所述遥控器磁吸结构用于固定遥控器，所述控制面板的一侧设置有所述操作机械臂，所述机械臂内设置有机械控制装置，所述PCB电路板内置有语音识别与控制电路，所述机械控制装置能够接收控制信号并根据该控制信号中的指令操作所述机械臂，所述语音智能遥控装置通过所述语音识别与控制电路接收语音指令转化成控制信号并通过机械控制装置控制所述机械臂对所述遥控器磁吸结构上的遥控装置上的对应按键进行按压。
G10L21/0208  ,语音数据的清洗方法及电子设备 [发明],本申请公开了一种语音数据的清洗方法及电子设备，该语音数据的清洗方法包括：获取待清洗的原始语音，将原始语音输入至预先训练的目标降噪模型中进行噪音清洗处理，得到候选清洗语音；将原始语音划分为多个原始语音片段，以及将候选清洗语音划分为多个候选语音片段，原始语音片段与候选语音片段一一对应；检测相互对应的原始语音片段和候选语音片段的语音质量，基于质量检测结果确定目标语音片段；对每个目标语音片段进行组合，得到目标清洗语音。通过进行数据清洗效果的判定，根据语音质量确定要保留的目标语音片段，可以在保证语音信息不被损坏的前提下，对语音数据进行噪音清除，有效保证数据清洗的准确度。
G10L13/10  ,一种说唱歌曲合成方法、装置、电子设备和存储介质 [发明],本发明涉及一种说唱歌曲合成方法、装置、电子设备和存储介质，该方法包括：训练时长模型和合成模型；获取待合成说唱歌曲的文本，解析文本得到音素信息；将音素信息进行停顿处理得到处理停顿后的信息；将处理停顿后的信息送入时长模型，得到每个音素的时长信息；然后送入合成模型，得到合成说唱语音。本发明通过使用说唱歌曲库训练得到时长模型和合成模型，合成时，解析待合成说唱歌曲的文本得到音素信息，对音素信息进行停顿处理得到押韵的停顿方式，停顿后的待合成说唱歌曲的文本通过时长模型和合成模型得到合成说唱歌曲，不仅摆脱了对原始歌词和乐谱的高要求，而且提升了合成说唱歌曲的自然度和节奏感。
G10L21/0208  ,一种基于智慧燃气平台的噪音管控方法与物联网系统 [发明],本发明提供一种基于智慧燃气平台的噪音管控方法与物联网系统，该方法包括：通过声音传感器获取燃气场站的噪音数据，声音传感器布设在燃气场站的多个监测位置，每一个监测位置具有与之对应的监测时段；基于噪音数据，确定监测位置的噪音变化特征；基于噪音变化特征，确定燃气场站的目标运行参数，目标运行参数至少包括燃气场站内燃气管道的目标燃气流速。该物联网系统包括智慧燃气用户平台、智慧燃气服务平台、智慧燃气安全管理平台、智慧燃气管网设备传感网络平台和智慧燃气管网设备对象平台，智慧燃气安全管理平台被配置为执行上述噪音管控方法。通过上述方法，能够结合不同环境下的噪音污染情况对燃气管道进行调整，减少噪音的影响。
G10L21/013  ,坐席人员的通话的处理方法、装置和电子设备 [发明],本申请提供了一种坐席人员的通话的处理方法、装置和电子设备，该方法包括：获取用户端发送的用户的语音数据，并对语音数据进行音色分类处理，得到用户的编号，并确定与用户的编号对应的目标用户画像；对目标用户画像进行处理，得到目标转换音色编号；将坐席人员的实时语音数据的音色转换为与目标转换音色编号对应的目标转换音色，得到转换后的实时语音数据，并将转换后的实时语音数据发送至用户端，目标转换音色为多个转换音色中的一个，转换后的实时语音数据的音色为目标转换音色。解决了现有方案缺乏基于用户的音色喜爱程度来改变坐席人员通话的音色，从而提高服务质量的技术方案的问题。
G06T13/40  ,基于语音的三维面部驱动方法、模型训练方法及装置 [发明],本公开提供了一种基于语音的三维面部驱动方法、模型训练方法及装置，涉及人工智能技术中的计算机视觉、深度学习、增强显示、虚拟现实等领域，可应用于元宇宙、数字人和生成式人工智能等场景。该方法包括：确定待处理语音的待处理驱动序列；根据风格转换模型，对待处理驱动序列进行风格转换得到目标驱动序列；目标驱动序列用于指示第二对象输出待处理语音时的三维面部动作；风格转换模型为根据第一驱动序列和第二驱动序列训练所得到的；第一驱动序列用于指示第一对象输出目标语音时的三维面部动作；第二驱动序列用于指示第二对象输出目标语音时的三维面部动作；根据目标驱动序列，驱动第二对象对应的三维面部模型进行面部动作。
G06T13/20  ,数字人驱动模型的训练方法、数字人驱动方法及其装置 [发明],本公开提供了一种数字人驱动模型的训练方法、数字人驱动方法及其装置，涉及人工智能技术领域，具体为计算机视觉、增强现实、虚拟现实、深度学习等技术领域。该方法包括：基于样本视频确定目标图像的真值特征和参考图像的参考特征；基于样本音频确定目标图像的目标音频帧及对应的目标音频特征；从样本视频中选取视频帧集合，确定样本音频中视频帧集合对应的音频帧集合，基于音频帧集合的每个音频帧和目标音频帧的余弦相似度，确定目标图像的模板特征；基于参考图像、目标音频特征及模板特征生成目标图像特征，基于目标图像特征与真值特征之间的重建损失，对初始模型进行训练，得到数字人驱动模型。该方法提升了数字人驱动模型的驱动准确性。
H04L67/1095  ,一种基于消息的数据同步方法 [发明],本发明公开了一种基于消息的数据同步方法，属于数据处理技术领域，包括以下步骤：S1、采集原始语音数据，对原始语音数据进行预处理，生成去噪语音数据，将原始语音数据和去噪语音数据输入至构建的语音处理模型中，生成语音消息队列；S2、根据语音消息队列，确定语音消息权重，生成语音消息报表；S3、将语音消息报表和去噪语音数据同步传输至用户终端。本发明将预处理后的语音数据和语音消息报表同步至用户终端，如手机等，便于用户及时同步查看语音数据，并根据语音消息报表获取语音消息的音频变化情况，快速了解音频情况。
G10L25/51  ,音频处理方法及装置、电子设备及计算机可读存储介质 [发明],本申请公开了一种音频处理方法及装置、电子设备及计算机可读存储介质。该方法包括：获取第一待测音频和目标音频处理算法；利用目标音频处理算法对第一待测音频进行处理，得到第一结果数据，第一结果数据包括第一结果音频，第一结果音频为利用目标音频处理算法对第一待测音频进行处理得到的音频；根据第一结果音频中的语音，确定目标音频处理算法对语音的处理效果，得到第一评测结果；根据第一结果数据中的非语音数据确定目标音频处理算法对音频的处理效果，得到第二评测结果；根据第一评测结果和第二评测结果，确定目标音频处理算法对音频的处理效果。通过该方法可评测音频处理算法的处理效果。
G06V10/764  ,一种用于抑郁症辅助诊断的多模态数据的音视频分类方法 [发明],本发明公开了一种基于多模态数据的音视频分类方法，包括以下步骤：步骤S1、利用基于对比学习的掩码自动编码器进行音频和视频图像数据特征提取；步骤S2、利用提取的特征建立基于多模态时间注意力的检测模型；步骤S3、通过检测模型生成最终的音频的特征表示A和视频图像的特征表示V，再经过分类器得到最终的分类结果。本发明解决了现有深度学习方法对音视频图像检测精度不高的问题。
G10L15/22  ,语音控制方法、装置、设备及计算机可读存储介质 [发明],本申请公开了一种语音控制方法、装置、设备及计算机可读存储介质，属于智能控制技术领域。方法包括：对获取到的控制语音进行转换，得到所述控制语音对应的文本内容；确定各个控制文本和所述文本内容之间的匹配度，任一控制文本对应一种控制操作；在所述各个控制文本中确定目标控制文本，所述目标控制文本为所述各个控制文本中和所述文本内容之间的匹配度大于匹配度阈值，且满足匹配要求的控制文本；执行所述目标控制文本对应的控制操作。该方法提高了语音控制的灵活性、自由度以及准确性。
G07F17/12  ,一种无接触式社区外卖配送方法及装置 [发明],一种无接触式社区外卖配送方法及装置，该方法获取送餐人员的语音录入指令，通过语音录入指令录入外卖订单号，并打开用于录入的外卖订单号对应的物品存放的柜体仓门；判断录入的外卖订单号对应的物品是否放入打开的柜体仓门，若外卖订单号对应的物品放入打开的柜体仓门，且柜体仓门关闭，下发对放入的外卖订单号对应的物品的消毒指令；当紫外线消毒设备收到消毒指令后，对放入的外卖订单号对应的物品按照预设的消毒时间进行紫外线消毒；对取餐人员的身份信息进行确认，若取餐人员的身份信息确认成功，打开存放取餐人员的外卖订单号的物品的柜体仓门。本发明减少了细菌和病毒的传播风险，提高了卫生水平，保障了人民群众的食品卫生安全。
H04N21/234  ,视频处理方法、装置、设备及存储介质 [发明],本公开提供一种视频处理方法、装置、设备及存储介质，方法包括：获取待拼接的至少两个视频片段，对每个视频片段提取至少一个视频帧；构建包含每个视频片段的视频帧的视觉序列；对每个视频片段识别字幕，构建包含每个视频片段的字幕的文本序列；将视觉序列和文本序列输入至视频检测模型，由视频检测模型提取视觉序列的视觉特征和提取文本序列的文本特征后，确定至少两个视频片段是否具有关联性；视频检测模型的训练数据集中，正样本包括来自于同一个视频样本中连续的至少两个视频片段样本中的视频帧所构建出的视觉序列和文本序列，训练数据集中的负样本包括来自于未连续的至少两个视频片段样本中的视频帧所构建出的视觉序列和文本序列。
G10L21/0216  ,一种用于传声器的声音信号优化传输方法 [发明],本发明涉及语音处理技术领域，具体涉及一种用于传声器的声音信号优化传输方法，包括：通过传声器采集声音信号，根据声音信号获取若干IMF分量；根据声音信号与IMF分量，获取每个IMF分量中的信号段为噪声信号的可能性；根据每个IMF分量中的信号段为噪声信号的可能性，获取每个声音信号段处于多人同时说话的可能性；根据每个声音信号段处于多人同时说话的可能性，自适应生成每个声音信号段的小波阈值去噪的阈值大小；根据每个声音信号段的小波阈值去噪的阈值大小，对声音信号进行去噪。本发明通过对传声器采集声音信号进行分解与分段，获取每段声音信号为人说话时的可能性，避免了在对声音信号进行去噪时，丢失人说话时的信号特征。
G06F16/332  ,电网人机交互终端的数据处理方法及系统 [发明],本发明提供一种电网人机交互终端的数据处理方法及系统，涉及数据处理技术领域，包括：通过语音识别引擎将用户的语音信息转换为转录文本，将转录文本通过自然语言处理技术进行分析，得到依存关系图，通过预设的递归神经网络编辑对话历史，根据对话历史确定对话上下文信息；通过意图识别模型识别将对话上下文信息转换为嵌入向量，通过意图识别模型的位置编码层和自注意力层对对话上下文信息进行分析，结合意图识别损失函数，得到用户意图；将用户意图和对话上下文信息转换为特征序列，通过双向搜索算法对预先构建的电网知识图谱进行检索，得到匹配信息，根据匹配信息生成回应文本。
G10L25/51  ,音频处理方法及装置、电子设备及计算机可读存储介质 [发明],本申请公开了一种音频处理方法及装置、电子设备及计算机可读存储介质。该方法包括：获取原始音频、带噪音频和待测音频，原始音频包括语音，带噪音频通过向原始音频添加噪声得到，待测音频通过利用目标音频处理算法对带噪音频进行降噪得到；根据原始音频和待测音频，确定目标音频处理算法对带噪音频中的语音的第一降噪效果；根据带噪音频和待测音频，确定目标音频处理算法对带噪音频中的非语音的第二降噪效果；根据第一降噪效果和第二降噪效果，确定目标音频处理算法的第三降噪效果。通过该方法可实现从不同角度评价目标音频处理算法的降噪效果，以及评估音频处理算法的降噪效果。
G10L25/60  ,一种音频质量评测方法及相关装置 [发明],本申请提供了一种音频质量评测方法及相关装置，所述方法涉及音视频领域，所述方法包括：获取待评测音频；对待评测音频进行分类处理，确定待评测音频中的语音片段和音乐片段；根据语音片段的位置信息和音乐片段的位置信息，从待评测音频中提取多个语音片段；对多个语音片段进行质量评测，获得多个语音片段中的每一语音片段的评测结果；基于每一语音片段的评测结果，获得待评测音频的评测结果。根据本申请提供的方法，能够克服现有技术的缺陷，使得音频质量评测结果更为准确。
G10L15/22  ,一种人机交互方法、系统、电子设备以及存储介质 [发明],本发明公开了一种人机交互方法、系统、电子设备以及存储介质，其中，所述方法包括：在电子设备中的人机交互应用运行的过程中，获取当前界面上的至少一个第一控件，并获取所述至少一个第一控件对应的标识信息以及与所述标识信息对应的泛化信息，所述标识信息基于第一标识或第二标识生成，所述第一标识根据第一控件的属性信息确定，所述第二标识根据第一控件的视图布局信息确定；获取用户的语音指令；根据所述语音指令从所述泛化信息中匹配得到目标泛化信息，基于所述目标泛化信息所对应的标识信息确定目标控件；响应于所述语音指令，执行对所述目标控件的控制。本发明能够提升控件匹配的准确性以及交互体验，且不需要第三方进行适配。
G10L25/51  ,一种基于深度学习的中小学演奏评分方法及系统 [发明],本发明公开了一种基于深度学习的中小学演奏评分方法及系统，包括S1、收集学生录音进行噪声提取和训练；S2、收集相应乐器的演奏声作为训练样本，随机筛选学生考试乐器演奏的音频作为测试样本，并训练神经卷积网络的输出模型结构；S3、对学生的录音、演奏题目的xml文件和标准的泛音样本进行处理；S4、采用多维度评价模块进行打分，并通过输出模块将多维度评价模块的分数根据加权值进行汇总，得到学生演奏乐器的最终成绩。本发明提出的基于深度学习的音乐演奏评分系统解决了现有技术的多个缺陷。通过自动化和智能化的方法提高了评分的效率和准确性。
G10L21/0208  ,语音降噪方法及车辆 [发明],本申请提供一种语音降噪方法及车辆，所述方法包括：获取车辆行驶过程中用户发出的待识别语音；利用预先训练的非稳态噪声识别模型识别待识别语音，得到非稳态噪声；在待识别语音中去除非稳态噪声，得到去除非稳态噪声后的语音。所述方法利用非稳态噪声识别模型识别待识别语音中的非稳态噪声，能够准确识别出待识别语音中存在的非稳态噪声，并输出非稳态噪声；在待识别语音中去除非稳态噪声，得到去除非稳态噪声后的语音。通过非稳态噪声识别模型对待识别语音进行识别，能够准确的确定待识别语音中的非稳态噪声，在将待识别语音中的非稳态噪声去除，得到的语音中干扰项更少，有利于提升语音识别的准确率，进而提升用户的驾驶体验感。
G10L15/06  ,基于热词特征向量自注意力机制的语音识别模型构建方法 [发明],本发明提供一种基于热词特征向量自注意力机制的语音识别模型构建方法，具体包括：训练预训练模型，获取词嵌入层，以Decoder‑Only的方式进行训练，对词嵌入层进行优化；训练热词编码模型，以指定热词作为输入，并将热词编码为热词特征向量；将热词信息与声学特征信息融合，得到编码向量并作为最终的解码器输入，使得热词信息与声学模型信息联系更紧密，得到对热词识别准确率更高的语音识别模型。在用户使用过程中，可以主动指定多个热词，初始化语音识别引擎时将会使用热词编码模型对热词进行编码得到热词特征向量序列。在用户使用过程中，该热词特征序列将会作为模型输入与用户每次输入的声学特征进行拼接并进行解码。
G08B7/06  ,一种防跑道侵入监测及示警系统及方法 [发明],一种防跑道侵入监测及示警系统及方法，包括示警箱、设置在示警箱内的语音识别模块、与语音识别模块连接的跑道警示灯，语音识别模块与灯带电性连接，示警箱上设置有机场控制区的示意图，灯带设置在示警箱上，示意图上有若干区域，若干区域分别连接有若干不同的灯带，语音识别模块与音响电性连接，音响用于发出语音提示，且连接在示警箱上。本发明提供的防跑道侵入监测及示警系统，可以监测识别管制员发出的指令，并且在通过语音识别判断出机场跑道存在车辆或人员时，会开启跑道警示灯，起到示警作用。
H04N21/233  ,录播检测方法、装置、电子设备以及存储介质 [发明],本公开提供了录播检测方法、装置、电子设备以及存储介质，涉及人工智能技术领域，尤其涉及自然语言处理、语音技术、智能搜索、直播流检测技术领域。具体实现方案为：响应于周期任务被触发，对文本库包括的目标直播文本进行采样处理，得到多个目标直播文本段落，其中，目标直播文本由与目标直播间在当前直播场次的直播内容相关的多个直播文本段落构成；基于文本库包括的多个直播文本，分别对多个目标直播文本段落进行召回匹配，得到多个匹配结果，其中，每一个直播文本由与每一个直播间在每一个历史直播场次的直播内容相关的多个直播文本段落构成；以及基于多个匹配结果，得到目标直播间的录播检测结果。
G06T5/70  ,基于区域声音参数的点云数据处理方法及装置 [发明],本发明公开了一种基于区域声音参数的点云数据处理方法及装置，该方法包括：根据已采集点云数据的采集区域的区域声音参数，确定采集区域的区域声音对用于采集点云数据的激光扫描设备所造成的采集受影响情况；根据采集受影响情况，判断是否需要对点云数据进行去噪处理，若是，则根据采集受影响情况，确定与点云数据相匹配的修正参数，并根据修正参数，对点云数据进行去噪处理。可见，实施本发明能够通过采集区域的区域声音参数，确定区域声音对激光扫描设备造成的采集受影响情况，继而对点云数据进行修正判定及修正操作，有利于提高对点云数据的修正可靠性及准确性，进而有利于提高点云数据的有效性，从而有利于提高后续对三维场景模型的精准构建。
G10L25/24  ,低功耗MFCC特征提取方法及装置 [发明],本发明公开了一种低功耗MFCC特征提取方法及装置，其中，该方法包括获取语音信号；采用不同的处理模块对语音信号进行预加重、分帧、加窗、快速傅里叶变换、梅尔滤波、对数运算和离散余弦变换处理，以得到语音信号对应的MFCC特征；获取MFCC特征中的第一阶幅值，并根据第一阶幅值生成对应的初始位宽，以便根据初始位宽对不同处理模块对应的位宽进行调整；由此，通过获取MFCC特征中的第一阶幅值并量化位宽，以及将位宽反馈到前级精准量化每一级运算的输入位宽，从而在保证识别准确率的前提下对数据位宽进行截断，从而降低运算功耗。
G06F18/24  ,音视频智能处理方法、装置、存储介质和电子设备 [发明],本申请涉及智能监控技术领域，其具体地公开了一种音视频智能处理方法、装置、存储介质和电子设备，其首先采集动物园区监控视频，并从动物园区监控视频中提取音频数据，利用深度学习技术分别从视频数据和音频数据中提取重要语义特征，并基于视频语义特征和音频语义特征的融合特征来判断游客是否有违规行为。这样，能够实现对动物园区内游客违规行为的实时监测和识别，提高了监管效果并节省了大量人力资源。
G10L15/26  ,口语复述题测评方法、装置、设备及存储介质 [发明],本申请公开了一种口语复述题测评方法、装置、设备及存储介质，本申请设计的提示指令格式模板包含任务指令、作答文本槽和要点信息槽，任务指令用于指示模型按照各要点信息，对作答文本进行逐个要点的评分及内容诊断，整理成测评结果输出，通过调用大语言模型，可以借助大语言模型的语义理解及文本生成能力实现口语复述题的测评，提升口语复述题的测评结果的准确性。此外，按照本申请设计的提示指令格式模板，可以从细粒度的要点维度进行评分及内容诊断，更加方便用户清晰的了解自己的真实口语水平，以及出错或不熟练的要点，结合模型输出的要点的内容诊断，可以辅助用户进行更精准的学习。
G10L25/51  ,基于频带熵和像素显著性的带式输送机巡检机器人音频关键帧提取方法 [发明],本发明涉及一种基于频带熵和像素显著性的带式输送机巡检机器人音频关键帧提取方法，属于带式输送机托辊故障检测领域。该方法包括：输入巡检机器人采集的音频信号，通过短时傅里叶变换得到输入音频信号的时频矩阵；对时频矩阵的每一行计算熵值得到每个频率段的信息熵，得到频带熵；判断频带熵是否存在低于下阈值的情况，若存在则将该音频帧作为异常关键帧提取，否则判断是否存在一段时间内n个频带熵低于上阈值的情况，若存在则将该音频帧作为异常关键帧提取；基于时频矩阵计算像素显著性指标，判断音频信号在中高频的显著性加和是否超过设定超限阈值，若超过则该音频帧作为异常关键帧提取，否则判断输送机托辊无异常。
G06T13/80  ,一种数字人生成方法及系统 [发明],本发明公开了一种数字人生成方法及系统，涉及计算机视觉和计算机图形学技术领域，包括步骤：对二维数字人的多个原子姿态动画设置对应的标签；获取言语音频数据集，提取音频对应的言语文本进行分词，得到分词序列，并统计每个分词的音频时间；计算分词音频时间之和获得执行时间；以不同原子姿态动画中执行时间的关系，确定原子姿态动画；将分词序列输入脸部动画生成模型，生成脸部动画，利用脸部动画替换原子姿态动画中的脸部，生成文本与姿态匹配的二维数字人视频。本发明实现文本与原子姿态动画的匹配，数字人可以根据内置文本实时生成的回复，针对性进行姿态交互，并通过插帧算法实现姿态动画之间的平滑过渡，增强人机交互体验。
G10L25/54  ,一种音乐文件识别方法及装置、设备和介质 [发明],本公开提供一种音乐文件识别方法及装置、设备和介质，所述方法包括：对待识别音乐文件包含的人声音频数据进行文本识别，确定待识别音乐文件的音频文本数据，对待识别音乐文件包含的伴奏音频数据进行情感分析，获得待识别音乐文件的情感预测结果，基于情感预测结果和音频文本数据，获取目标音乐相关信息。所述方法可以填补音乐应用在音乐文件识别的空白，还可以提高音频识别效果和识别效率。
G06F18/24  ,基于视音频特征的关键场景自动分割系统及方法 [发明],本申请涉及视频自动分割技术领域，且更为具体地公开了一种基于视音频特征的关键场景自动分割系统及方法，其通过获取体育赛事中篮球比赛中预定帧往后一段时间内的视频和声音信号，并提取视频中的多个比赛关键帧中颜色直方图，以及对声音信号进行降噪处理并提取声音特征，通过基于时间注意力机制的卷积神经网络模型和过滤器网络，分别得到颜色特征向量、声音梅尔谱图特征向量和耳蜗谱图特征向量，然后将这些特征向量进行融合，得到颜色‑声音关联特征向量，基于所述颜色‑声音关联特征向量，以确定预定帧所属的分类标签，包括：得分、进攻、防守、换人、三分球、扣篮、罚球，从而实现关键场景的自动分割。
G10L25/63  ,一种基于语音文本跨模态融合的情感识别方法及系统 [发明],本发明公开了一种基于语音文本跨模态融合情感识别方法及系统。采用公开的带有情感标注的语音文本多模态对话数据集并进行预处理，建立对应的训练集和测试集；其次构建跨模态注意力交互融合情感识别模型；然后进行模型训练，并进行方法性能的测试评估；最后搭建多模态情感识别系统，进行方法的有效性验证。本发明的优点包括：设计跨模态注意力交互融合的多模态情感识别模型，通过计算与音频强关联的文本特征和与文本强关联的音频特征，提高了情感识别结果的准确率；搭建基于跨模态融合的情感识别系统，通过多模态共情交互，增强了人机自然交互的情感表达效果。本发明方法在公开数据集IEMOCAP和MELD上，平均识别准确率达到了76.0％和64.5％，均优于现有最优方法。
G10L15/04  ,一种语料收集方法、装置、电子设备及存储介质 [发明],本发明涉及一种语料收集方法、装置、电子设备及存储介质，语料收集方法包括：在目标视频对应的音频文件中获取包含语音信号的语料片段；对所述语料片段进行语音识别，得到多个候选语句；利用语言模型在多个所述候选语句中确定出现几率最高的目标语句，其中，所述语言模型是利用所述目标视频对应的字幕文件进行训练得到的；基于所述目标语句确定所述语料片段的标注文本。本申请实施例能够实现高效率的自动收集语料，节省大量人力与时间去搜集音频和进行标注；而且，采用语音识别结合用影片字幕文本训练的语言模型去产生标注，同时保留了语音识别能产生口语化标注和语言模型能产生与影片内容高相关度标注的优点，提高标注的准确性。
G06Q50/20  ,基于MR设备的智能助教方法及系统 [发明],本发明公开了基于MR设备的智能助教方法及系统，方法包括：服务器若确定当前交互模式为AI助教语音交互模式及机器视觉交互模式中的机器视觉交互模式时，则将当前操作实训实验对应的工具图像采集指令发送至第一用户MR设备；第一用户MR设备基于虚实拍照框碰撞检测策略采集工具操作视频或工具操作图片集并发送至服务器以识别得到操作工具识别结果集；服务器基于操作工具识别结果集与当前操作实训实验对应的标准操作工具集的匹配结果，生成与对应的最终评价结果并发送至第一用户MR设备。本发明实施例能结合MR设备对用户的操作实训实验进行智能语音引导，也能对用户操作实训实验的过程进行记录和自动评分，提升了实训教学的用户体验。
G10L25/51  ,模型训练方法、音频识别方法及相关设备 [发明],本申请公开了模型训练方法、音频识别方法及相关设备，包括：对库内每条无标签音频的主旋律特征note序列进行增强处理；使用增强后的note序列训练初始模型，得到中期模型；将改版音频的note序列和改版音频的源音频的note序列输入中期模型，并计算中期模型分别输出的改版音频嵌入特征和源音频嵌入特征间的特征相似度；基于特征相似度训练中期模型，得到目标模型。其中，对无标签音频的note序列做增强处理，能丰富训练样本及提高模型落地时的鲁棒性，有助于提高模型的自监督学习效果，并降低对有标签样本数据的成本投入和用时。此外，使用少量的有标签note特征对模型再训练，能进一步增强模型在音频识别任务中的实际预测性能，提升用户体验。
G06F11/36  ,热词扫描调试方法、装置及设备 [发明],本发明实施例涉及可见即可说技术领域，公开了一种热词扫描调试方法、装置及设备，该方法包括：显示当前页面，当前页面包括按照第一显示方式显示的多个控件；在对所述当前页面进行热词扫描时，在所述多个控件中将已扫描到的控件确定为有效控件，在当前页面按照第二显示方式显示有效控件；第一显示方式与第二显示方式不同。应用本发明的技术方案，能够识别出当前页面中已注册热词的有效控件，并在当前页面中以不同的第二显示方式显示该有效控件，用户通过观看所显示的当前页面，可以直观地确定当前页面中哪些控件已注册热词，可以辅助用户实现快速调试，能够极大提高开发调试效率，节省开发时间。
G06F3/01  ,基于多模态输入的识别方法、装置、车辆及存储介质 [发明],本申请提供一种基于多模态输入的识别方法、装置、车辆及存储介质。该方法包括：在检测到车辆上目标用户的交互操作信息时，检测目标用户的视线是否朝向车辆的车载显示屏；若目标用户的视线朝向车辆的车载显示屏，则确定执行度阈值为第一阈值；若目标用户的视线未朝向车辆的车载显示屏，则确定执行度阈值为第二阈值；其中，第二阈值大于第一阈值；对交互操作信息进行识别，得到交互操作信息对应的控制操作和执行度分值；在执行度分值达到执行度阈值时，执行交互操作信息对应的控制操作和/或对交互操作信息对应的控制操作进行提示。本申请基于目标用户的视线自适应调整执行度阈值，避免将用户的日常行为动作误识别为交互控制动作。
G06T13/40  ,一种基于虚拟主播的直播方法与系统 [发明],本发明公开了一种基于虚拟主播的直播方法与系统，先根据虚拟主播的整体概念和形象进行角色设计和3D建模，得到虚拟角色，再通过运动捕捉系统将人类表演者的动作转化为虚拟角色的动作，然后使用语音合成技术给虚拟角色添加语音，再建立实时互动模型，利用机器学习方法训练实时互动模型，并根据训练结果对实时互动模型进行优化，得到虚拟主播，最后利用虚拟主播进行实时直播，在互动时通过对虚拟角色添加的动作和语音以及对观众自然语言的处理以提高虚拟主播形象和表现的真实感和流畅度，通过使用机器学习方法训练实时互动模型来提高实时互动模型的准确性和智能度，提高了虚拟主播与观众之间的实时互动的灵活性和自由性。
G10L25/51  ,歌声评价信息获取方法、计算机设备和存储介质 [发明],本申请涉及一种歌声评价信息获取方法、计算机设备和存储介质，涉及歌声评价技术领域，能够提升歌声评价信息的精准性。所述方法包括：获取待评价歌声对应的歌声特征；将所述歌声特征与预先获取的正样本歌声对应的正样本歌声特征和负样本歌声对应的负样本歌声特征进行比较，得到所述歌声特征与所述正样本歌声特征的第一相似度，及所述歌声特征与所述负样本歌声特征的第二相似度；其中，所述正样本歌声的歌声质量高于所述负样本歌声的歌声质量；根据所述第一相似度和所述第二相似度，确定所述待评价歌声的歌声评价信息。
H04N21/234  ,音画同步检测方法、装置、设备及存储介质 [发明],本申请实施例公开了一种音画同步检测方法、装置、设备及存储介质，属于音视频测试技术领域，该方法包括：基于对视频帧的唇部识别结果，确定视频帧中唇部的唇部纵横比，唇部纵横比为纵向唇边距与横向唇部宽度的比值；基于唇部纵横比确定视频帧对应的嘴部开闭状态；确定音频中的同步检测点，同步检测点是人声从无到有的时间点；基于同步检测点对应检测范围内视频帧对应的嘴部开闭状态进行音画同步检测，得到音画同步检测结果；采用本申请实施例提供的方案能够提高音画同步检测的效率以及准确性。
G10L17/26  ,基于TBTA网络的海洋哺乳动物叫声识别分类方法 [发明],本发明涉及海洋动物叫声识别分类技术领域，具体为基于TBTA网络的海洋哺乳动物叫声识别分类方法。并基于DenseNet和3D‑CNN，提出了双支路双层注意力机制网络TBTA深度学习框架，TBTA设计了两个分支，使用双支路分别提取海洋哺乳动物叫声音频时频谱图的光谱特征和空间特征，无需进行繁琐的特征工程，并且在光谱维度和空间维度上引入了自适应的自注意机制，分别应用于光谱分支和空间分支，光谱型注意块聚焦于信息丰富的波段，而空间型注意块聚焦于信息丰富的像素，这使得TBTA能够对提取的特征图进行有效的细分和优化，在数据集有限的情况下，可以大幅度提高分类的精度。
A63F13/795  ,一种匹配关系图更新方法及游戏队友匹配方法 [发明],本申请提供的一种匹配关系图更新方法及游戏队友匹配方法，当更新待匹配用户的匹配关系图时，可以通过客户端获取待匹配用户及其他用户在组队期间不同采集时刻产生的多个麦上音频，并利用客户端对各个麦上音频进行情感检测，得到待匹配用户的情感类型及其他用户的情感类型，接着可以获取待匹配用户上一次更新后的匹配关系图，并基于匹配关系图确定待匹配用户与其他用户之间的互动分数，以基于两个情感类型对互动分数进行计算，得到最终互动分数，并根据最终互动分数更新匹配关系图。因此本申请在接收到待匹配用户发起的队友匹配请求时，可以根据该匹配关系图进行游戏队友的匹配，能够保证匹配到的队友与待匹配用户的默契程度，进而提高了匹配质量。
G10L25/51  ,一种高效低延迟的声音事件检测的模型及其训练方法 [发明],本发明涉及一种高效低延迟的声音事件检测的模型及其训练方法，采用Vit作为模型骨干，具有更强的信息抽取能力，相较于卷积结构具有更高效的矩阵运算效率，对声学表征的时域、频域进行独立建模，可以根据设备性能灵活选定输入序列的长度，极大地减小模型的延迟，提升推理效率；采用知识蒸馏的方式进行预训练，产出小、推理效率高的模型，并通过预训练使模型获得抽取声音事件表征的能力，利用先验知识使得模型具有良好的泛化性；在预训练模型的基础上，在少量目标事件的数据集上进行微调，产出目标事件的检测模型，而无需进行细粒度标注，省时省力。
H02J13/00  ,调度自动化主站智能语音联调系统 [发明],本发明涉及电网厂站并网调试技术领域，具体地说，涉及调度自动化主站智能语音联调系统。该系统以组件化、服务化模式实现功能模块交互，采用微服务体系架构实现，主要由语音处理及交互平台、自动化调试知识平台、数据自动提起与预处理组件、智能处理与人机交互界面组成。本发明设计从调度自动化主站四遥信息联调方面进行研究，采用人工智能和语音识别技术，根据厂站端调试内容，智能识别和分析调度自动化主站系统收到的调试信息，完成自动比对，与厂站端调试人员在线、自助式调试交互，实现联调过程主站端无人值守，代替传统人工核对工作模式，实现调度自动化厂站信息接入智能高效调试。
G10L15/22  ,语音交互方法、服务器以及存储介质 [发明],本申请公开了一种语音交互方法，包括：根据预存储的设备列表、提示文本以及预设的大语言模型，确定与设备列表中各设备项对应的车辆功能点描述数据；确定车辆功能点描述数据以及当前语音请求间的相似度参数；根据相似度参数，确定当前语音请求对应的车辆功能点。本申请能够根据车辆自身的设备、以及针对预设大语言模型的提示文本，生成对应于车辆自身设备各个最小功能点的描述数据，并在实际应用过程中根据描述数据自身与用户输入的语音请求进行相似度比较，根据比较结果确定出用户通过语音请求希望触发的功能点并执行，完成语音交互过程。通过大语言模型针对功能点描述数据的生成，大大简化数据集的生成过程，同时提高数据集中的数据更新效率。
G10L13/027  ,模型训练及语音生成方法、装置、设备及存储介质 [发明],本公开实施例公开了一种模型训练及语音生成方法、装置、设备及存储介质。该方法包括：获取初始生成模型，初始生成模型为经过预训练的条件扩散模型；获取用户数据，用户数据包括用于反映目标人物特性的文本语音对数据；将初始生成模型作为待训练模型，并基于用户数据，调整待训练模型的激活函数，得到目标模型，目标模型用于语音生成。
G10L25/63  ,一种语音情感识别方法、装置、电子设备和存储介质 [发明],本公开涉及一种语音情感识别方法、装置、电子设备和存储介质，所述方法包括：对音频进行切分得到时序排列的音频片段；对时序的第i个音频片段进行语义提取，得到语义信息，其中，所述语义信息中融合了前i‑1个视频片段的语义信息，i为大于1的正整数；对第i个音频片段进行说话人识别，得到说话人信息；基于第i‑1个音频片段的情感向量、第i个音频片段的语义信息以及所述说话人信息，得到第i个音频片段的情感向量；根据第i个音频片段的情感向量，得到第i个音频片段的情感类别。本公开实施例可提高语音情感识别的准确率。
G10L17/04  ,一种用户身份识别方法 [发明],本申请的实施例提供了一种用户身份识别方法，所述方法包括：获取预先构建的包括嵌入层模型的识别模型；获取训练样本集，训练样本集包括含有语音音频的第一训练样本子集和含有平凡发音音频的第二训练样本子集；将训练样本集输入识别模型，得到输出结果；根据输出结果，通过包括交叉熵损失函数和设定的三元损失函数的目标损失函数，确定识别模型的损失值；基于损失值，更新识别模型的模型参数，得到一个新的识别模型，并返回执行获取训练样本集的步骤，直至识别模型收敛，得到目标识别模型；通过目标识别模型中的嵌入层模型，对实时发音音频进行识别。本申请的实施例提供的技术方案能提高使用平凡发音音频识别用户身份时的识别效果。
G10L19/04  ,基于深度学习和矢量预测的语音压缩方法及系统 [发明],本公开提供了基于深度学习和矢量预测的语音压缩方法及系统，涉及语音信号处理技术领域，包括：获取低速率下的多帧语音信号，并预处理为语音序列；将当前帧语音序列作为第一深度网络的输入信号提取声学特征，利用所述声学特征预测下一帧语音序列的声学特征，并作为预测矢量；对原声学特征与预测矢量作差，获取差值矢量，并在设计的码本中寻找与差值矢量最匹配的量化矢量，作为残差索引传输到第二深度网络，第二深度网络根据接收的残差索引，在码本中找到相应的差值量化矢量，将差值量化矢量与预测矢量相加，得到重构矢量，对所述重构矢量解码输出合成语音，本公开提高了语音压缩编码合成的质量。
G10L21/013  ,语音交互映射模型训练方法、语音交互方法及装置 [发明],本发明公开了语音交互映射模型训练方法、语音交互方法及装置，属于语音交互技术领域。本发明首先获取用户语音数据并确定用户选择的语音交互模式，在用户未确定语音交互模式的情况下，以用户使用的地域语言确定语音交互模式；并提取用户语音特征，并将用户语言特征输入至用户选择的语音交互模式相应的语音交互训练通道；在语音交互训练通道中基于地域语言对用户语音数据进行文本修正处理，将修正后的文本信息输入至语音交互训练模型，进行语音交互训练，并根据语音交互模式确定是否对训练完成的语音交互进行语音转换，从而完成语音交互。本发明能够基于用户所使用的地域语言进行语音交互训练，提高语音交互的准确性和效率。
G06F16/65  ,一种基于大语言模型的车载数据语音标签系统 [发明],本发明涉及一种基于大语言模型的车载数据语音标签系统，尤其涉及汽车数据处理技术领域，包括数据记录模块，用以对车辆的路测数据进行采集；语音记录模块，用以对语音记录的开启进行判断，并对语音记录开启的判断过程进行修正，还用以对记录后的语音进行预处理和存储；语音处理模块，用以通过LLM大语言模型对已存储的语音进行标签识别并设置索引；数据上传模块，用以将语音识别后的语音进行切片处理并上传至云端进行分类存储；反馈训练模块，用以根据对LLM大语言模型进行训练，并对语音处理的有效性进行反馈，还用以对反馈过程进行补偿。本发明提高了车载数据的语音标签效率。
H04L67/125  ,远程控制方法、装置、设备、系统和存储介质 [发明],本申请涉及一种远程控制方法、装置、设备、系统和存储介质，涉及通信技术领域，可用于金融科技领域或其他相关领域。该方法包括：响应于多个自助机发送的语音连接请求，在所述远程机的当前显示界面上显示各自助机的图标；响应于指导用户在当前显示界面针对目标自助机的图标的选取操作，建立与所述目标自助机的语音连接；向所述目标自助机发送语音指导数据，用于指示所述目标自助机响应于被指导用户根据所述语音指导数据在当前业务界面的业务操作，进行界面展示；其中，所述当前显示界面上显示多个自助机的语音连接状态，不同的语音连接状态下自助机的图标的第一显示属性不同。根据本公开的技术，提高了远程指导的效率。
G10L17/02  ,一种高效低延迟的在线说话人日志系统及其训练方法 [发明],本发明涉及一种高效低延迟的在线说话人日志系统及其训练方法，从模型结构和模型训练方法着手，对TSVAD模型进行改进，包括利用RepVGG作为TSVAD的骨干网络，在训练时使用多残差支路来最大限度保留模型的非线性，在推理时则融合各残差支路来降低骨干网络的计算复杂度和内存占用；对骨干网络进行声纹预训练，使用类别中心迁移，采用多任务训练策略对TSVAD网络进行微调；从而在有效降低计算量、减小延迟的同时，避免TSVAD骨干模型在训练过程中产生灾难遗忘，并减小训练与推理的不一致性。
G10L15/06  ,语音识别模型的训练、语音识别方法、装置、设备及介质 [发明],本发明提供一种语音识别模型的训练、语音识别方法、装置、设备及介质，其中方法包括：获取初始编码器；基于不同语种下语音的语种共享表征和/或语种特定表征，对初始编码器进行预训练，得到预训练编码器；基于预训练编码器，构建预训练识别模型；对预训练识别模型进行有监督微调，得到语音识别模型。基于不同语种下语音的语种共享表征和/或语种特定表征，对初始编码器进行预训练，得到预训练编码器，可以抑制语种间串扰问题，指导初始编码器学习更易于适应不同语种的语音表征，在不显著增加模型参数量和计算量的情况下，既能提升低资源语种识别性能，又能保持高资源语种性能相较于单语模型不降，从而提供一个高效、准确的多语种语音识别模型。
G10L25/60  ,口语评测方法、系统、电子设备及存储介质 [发明],本公开实施例公开了一种口语评测方法、系统、电子设备及存储介质，所述方法包括：第一终端设备和第二终端设备之间建立语音通信；第一终端设备向第一待测评对象输出口语测试题，第二终端设备向第二待测评对象输出所述口语测试题；在语音通信过程中，第一终端设备采集并存储第一待评测对象的语音信息，传送至所述第二终端设备，第二终端设备采集并存储第二待评测对象的语音信息，传送至所述第一终端设备；第一终端设备输出从第二终端设备接收到的所述语音信息，第二终端设备输出从第一终端设备接收到的所述语音信息；云端服务设备提取音频文件中的发音特征和语言特征，对第一待评测对象和第二待评测对象进行口语评测。
G09B5/04  ,基于课堂语音识别的辅助教学方法及相关设备 [发明],本发明涉及语音识别技术领域，公开了一种基于课堂语音识别的辅助教学方法及相关设备。该方法包括：获取目标课堂对应授课的教学音频数据，并基于预设的音频存储策略，提取所述教学音频数据中至少一种音频标记信息；提取所述教学音频数据的多个音频口音特征，并基于所述音频口音特征，确定所述目标课堂中对应授课的目标授课人员；基于所述目标授课人员，提取所述教学音频数据对应的授课语音片段，并基于所述音频标记信息，对授课语音片段的进行语言转换，得到目标教学信息；基于目标教学信息，生成预设教学设备的控制指令信息和辅助教学信息，得到辅助教学结果。本申请提高了对相关开发课类型的课堂语音识别和转化的准确度。
G10L15/06  ,训练数据的确定方法、服务器及计算机可读存储介质 [发明],本申请公开一种训练数据的确定方法，所述方法包括：获取原始训练数据，基于目标模型，生成原始训练数据中第一语音请求样本的预测结果，根据预测结果和处理结果存在差异的第一语音请求样本，对原始训练数据进行降噪处理，根据降噪处理的结果，确定目标训练数据。如此，本申请的服务器可利用由原始训练数据和基于降噪处理得到的基础训练数据训练完成的目标模型，对原始训练数据中第一语音请求样本进行预测以得到预测结果，基于目标模型的预测结果和预先标定的处理结果存在差异的第一语音请求样本，执行原始训练数据的降噪，使得原始训练数据的降噪得以合理进行，目标训练数据的可靠性得以保障，通过目标训练数据训练的模型的性能得以保障。
G10L15/26  ,用于音频处理的方法、装置、设备和存储介质 [发明],本公开的实施例提供用于音频处理的方法、装置、设备和介质。该方法包括：获取目标语音中的多个音频片段对应的多个音频特征表示，多个音频片段至少包括第一音频片段和第二音频片段；利用经训练的机器学习模型，执行以下操作：基于第一音频片段对应的第一音频特征表示，确定第一文本；提取第一文本的第一文本特征表示；基于第二音频片段对应的第二音频特征表示和第一文本特征表示，确定第二文本；以及至少基于第一文本和第二文本，确定与目标语音相关联的目标文本序列，目标文本序列包括在目标语音中出现的至少一个实体词和对应的实体类型。由此，可以直接通过语音生成对应的实体结果，实现端到端实体识别，提高识别准确性。
G10L15/18  ,语音交互方法、系统、设备及存储介质 [发明],本发明涉及智能语音交互技术领域，提供一种语音交互方法、系统、设备及存储介质，该方法通过确定当前识别结果在历史轮次中的重复次数，并将重复次数作为判断依据，不仅可以避免用户多次输入导致体验感降低的情况发生，还可以避免因系统超时设定导致脱离语音识别状态的情况发生，提高用户体验感。在重复次数满足大于等于第一次数的情况下，向用户提供引导信息，当接收到用户的回复信息时，基于回复信息，对当前识别结果进行更正，并对当前用户语音进行响应，保证响应结果的准确性，使响应结果更加符合用户的预期，进一步提升用户体验。
G08B21/18  ,一种自动化电话报警系统及方法 [发明],本发明公开了一种自动化电话报警系统，包括：信息接收装置，用于接收外部文本信息；文本语音转换模块，用于接收外部文本信息，并转换为告警音频信息；语音呼叫模块，用于将告警音频信息通过预设电话号码播放给目标用户。一种自动化电话报警方法，包括：注册预设电话号码；通过HTTP接口获取外部文本信息；将外部文本信息以队列方式进行存储；将外部文本信息按照队列的顺序，转换为告警音频信息；将告警音频信息按照队列的顺序依次通过VOIP语音接口调用预设电话号码播放给目标用户；记录告警音频信息以及对应的呼叫时间、呼叫状态及目标用户反馈。通过整合文本语音转换模块、VOIP语音接口和WEB服务程序，能有效接收、处理告警信息。
G10L25/51  ,实时唱歌评价方法、系统、电子设备和介质 [发明],本公开涉及实时唱歌评价方法、系统、电子设备和介质。该方法包括：实时拉取用户音频流，去除音频流的伴奏；逐帧判断去除伴奏后的音频流是否为噪声，在当前帧不是噪声时提取当前帧的用户音高；根据原唱音准线和用户历史音高信息对用户音高进行自适应调整得到调整后的用户音高；通过确定调整后的用户音高与原唱音高的差值是否在预设区间内来判断音高的准确性；判断当前乐句是否结束，在未结束时实时显示当前帧的用户音高值，并在已结束时根据当前乐句中准确帧数在总帧数中的占比计算并实时显示当前乐句得分；判断歌曲是否结束，在未结束时继续拉取用户音频流进行下一乐句得分计算，并在已结束时通过累计各个乐句得分得到并显示整首歌曲的最终得分。
G10L15/06  ,基于单火面板的语音识别控制系统 [发明],本发明涉及自动控制技术领域，尤其涉及一种基于单火面板的语音识别控制系统，该系统包括语音识别主控电路、开关电路、所述电压转换电路、开态取电电路、闭态取电电路，所述语音识别芯片初始化，并关闭开关驱动，开启低功耗监听模式，实时获取语音信息，所述语音识别芯片根据实时获取的语音信息通过电源管理芯片控制电源管理打开或关闭开关驱动完成控制工作。系统能够根据所述语音识别芯片中建立并训练好的卷积神经网络模型精准识别语音，能够被广泛应用于语音识别任务中，同时选用了低耗能的电路方案，减少了数据传输，功耗大大降低，有望推动智能家居控制系统在节能和环保方面的广泛应用。
H04N21/81  ,基于多模态三维可塑模型的单样本说话人生成方法及系统 [发明],本公开提供了基于多模态三维可塑模型的单样本说话人生成方法及系统，涉及说话人生成技术领域，获取音频以及参考图像，输入至多模态3DMM参数预测网络模型中，首先提取音频特征以及文本特征，并对音频特征以及文本特征进行上下文特征增强，得到注入上下文信息的音频表征和语义表征；获取初始的头部姿态嵌入参数以及初始表情描述，利用初始的头部姿态嵌入参数预测下一时刻的头部姿态参数；利用初始表情描述预测下一时刻表情参数，将预测的头部姿态参数和表情参数融合嵌入至参考图像中，通过视频合成网络将多帧图像合成说话人的头部视频序列。
G10L25/27  ,一种基于小波变换的变压器声纹故障识别方法及设备 [发明],本发明涉及一种基于小波变换的变压器声纹故障识别方法，包括：分别从安装在变压器不同位置处的多个声纹传感器处获取声纹信号；对各声纹传感器设置权重；通过小波转换获取声纹信号的小波系数；根据声纹信号的小波系数及对应传感器的权重，计算融合图谱；构建并训练故障识别模型；将融合图谱输入至故障识别模型，得到故障类型。
H04N21/234  ,一种实时音视频流轨道分离提取系统及方法 [发明],本发明公开了一种实时音视频流轨道分离提取系统及方法，涉及音视频处理领域，包括相关联的音频信号处理模块、视觉目标检测与跟踪模块、视频背景建模与分割模块、视频特征提取与描述模块、音频特征提取与描述模块和数据融合与同步模块；能够将音频和视频分离提取出来，分别进行处理和优化，从而提高音频和视频的质量。比如，可以对音频进行降噪、增强和音频编码优化，对视频进行去噪、增强和视频编码优化，从而提供更清晰、更稳定的音视频服务。
G10L15/22  ,语音交互方法、装置、电子设备和可读存储介质 [发明],本申请提出了一种语音交互方法、装置、电子设备和可读存储介质，属于数据处理技术领域，其中，语音交互方法包括：将多个设备划分为多个设备组；控制设备根据唤醒语音生成响应信息；控制多个设备中的主设备接收响应信息；在主设备接收到每个设备组中的任一响应信息的情况下，根据响应信息，确定目标设备组；根据目标设备组中的多个设备的响应信息，确定目标设备；控制目标设备开启语音交互。本申请提供的语音交互方法，可以减少主设备对响应信息的接收和处理时长，进而可以有效地缩短目标设备开启语音交互所需的时长，提高了语音交互的开启效率。
G10L15/22  ,一种数字人交互对话方法和系统 [发明],本发明涉及数据处理技术领域，具体涉及一种数字人交互对话方法和系统，包括：获取音频数据；对所有数据点进行迭代自组织聚类，得到第一次聚类结果；获取邻域数据点和参考数据点；获取数据点的局部显著性程度；获取第一数据点；获取数据点和第一数据点的邻域分布曲线；获取数据点与第一数据点的待计算数据点匹配程度；获取待计算数据点；获取数据点的总体显著性程度；根据数据点的总体显著性程度进行聚簇中心更新；根据更新后的聚簇中心进行迭代自组织聚类；根据最终的迭代自组织聚类结果获取数据点的异常程度，根据所述数据点的异常程度获取去噪后的音频数据，并进行音频数据的语义识别，实现准确的语义识别。
G10L25/18  ,音频处理方法及装置 [发明],本申请实施例提供一种音频处理方法，方法包括：获取预先构建的训练数据集，其中，训练数据集包括多个音频‑文本对，每一音频‑文本对中一个音频对应多个文本，文本为与文本对应音频不同角度的音乐描述；获取音频的音频特征，将音频特征输入至预先构建的音乐描述模型中生成音乐描述文本，根据音乐描述文本、音频‑文本对的文本和预先构建的损失函数训练音乐描述模型，以得到训练好的音乐描述模型；获取目标音频的目标音频特征；将目标音频特征输入至训练好的音乐描述模型中，利用训练好的音乐描述模型生成目标音频的目标音乐描述文本。本申请实施例提供的音频处理方法，可以对音乐提供多种角度的音乐描述，为用户提供更多的音乐信息。
G10L19/008  ,音频的合成方法、装置、移动终端和可读存储介质 [发明],本申请适用于音频合成技术领域，提供了一种音频的合成方法、装置、移动终端和可读存储介质。上述音频的合成方法包括：获取MobileFFmpeg封装库，并将MobileFFmpeg封装库添加至移动终端；获取原始音频文件以及背景音频文件；利用MobileFFmpeg封装库对背景音频文件进行配平，得到配平后的配平背景音频文件，配平背景音频文件的背景音频长度与原始音频文件的原始音频长度相等；利用MobileFFmpeg封装库，对原始音频文件以及配平背景音频文件进行混合，得到混合音频文件。本申请实施例可以在移动终端上对两份音频文件进行混合。
H04N9/31  ,一种投影仪智能交互控制方法及系统 [发明],本发明公开了一种投影仪智能交互控制方法及系统，涉及投影仪技术领域，包括：判断投影仪控制者的第一手势是否为控制手势；识别残影辅助画面中与第二手势一致的遥控手势，调用与遥控手势对应的控制描述，依据控制描述对投影画面作出切换；对投影仪控制者的手指进行触摸识别，当投影仪控制者的手指触摸投影画面时，则根据投影仪控制者的手指移动的路径，在投影画面上书写或绘画；依据投影仪控制者的语音调整线条粗细和颜色；当投影仪完成智能交互时，判断投影仪控制者的第三手势是否为回调手势。通过设置语音判断模块、图像判断模块、画面切换模块和触摸控制模块，使用者不必记住每个操控手势，能减小使用者的使用负担。
G10L21/0208  ,基于标准化流的音频生成方法、装置、设备及存储介质 [发明],本发明涉及深度学习技术领域，公开了一种基于标准化流的音频生成方法、装置、计算机设备及存储介质，包括：对标准高斯分布进行随机采样，得到第一变量向量；将所述第一变量向量输入到音频生成模型中的先验网络进行逆变换，得到第一隐变量向量；将所述第一隐变量向量输入到音频生成模型中的降噪解码器进行解码，得到音频数据。可见，虽然先验网络需要对第一变量向量进行压缩操作，得到存在周期性噪声的第一隐变量向量，但通过降噪解码器，能有效的中和这部分噪声，最终生成清晰无噪声的高质量音频数据，可以达到提高音频质量的目的。
G10L21/007  ,一种适用于高噪音环境的语音交互系统 [发明],本申请提供了一种适用于高噪音环境的语音交互系统，包括处理端和语音收发端；处理端用于：若语音收发端将通话模式设置为降噪模式，则获取语音收发端选择的语音降噪类型；提取语音收发端发送的语音信号的语音特征；基于通话环境基准特征以及语音收发端使用者的样本语音的音色，将语音特征划分为通话环境特征、语音收发端使用者的人声特征、其他人声特征；删除符合语音收发端选择的语音降噪类型的通话环境特征和/或其他人声特征，得到降噪后的语音特征；将降噪后的语音特征输入包含声学模型和语言模型的解码器中，得到降噪后的语音文本；将降噪后的语音文本发送给其他语音收发端。本申请能够对语音信号灵活降噪、精准降噪，提高通话质量。
H04N21/234  ,在数字人领域驱动中文语音精准生成唇形视频的方法 [发明],本发明提供了一种在数字人领域驱动中文语音精准生成唇形视频的方法，包括：下载CMLR中文数据集并进行预处理，得到预处理后的CMLR中文数据集；将预处理后的CMLR中文数据集作为训练数据，按照设置的训练标准对wav2lip唇形同步模型进行训练，得到新的模型；将预处理后的视频帧输入到新的模型进行唇部推理，输出新的口型驱动视频。本发明针对现有的模型中对中文语音支持度差的缺陷，通过采用中文语音的数据集进行了重训练，使得中文发音口型得到校准；避免了现有模型在匹配到中文语音时口型开合过快的问题。此外，新的模型在训练时采用人脸关键点检测技术，从而能够更好的适配了下半脸，使上下脸看起来更加协调。
G10L15/06  ,一种实时高保真语音驱动数字人系统 [发明],本发明公开了一种实时高保真语音驱动数字人系统，涉及语音驱动数字人技术领域。包括数据采集模块、数据预处理模块、数字人训练模块、数字人推理模块；数据采集模块收集数字人模型训练所需要的训练资料；数据预处理模块将收集到的视频音频转换成数字人训练所需的格式；数字人训练模块训练数字人模型，数字人模型基于3D Gaussian Splatting；数字人推理模块给定任意语音音频和相机参数，渲染合成指定人物形象的说话视频。本发明语音驱动数字人，生成实时性高，画面质量好，极大的减小了数字人的训练代价，丰富了数字人的应用场景。
G10L25/51  ,一种智慧坐席语音监控分析方法与系统 [发明],本发明提供一种智慧坐席语音监控分析方法与系统，属于语音识别技术领域，具体包括：基于不同的坐席语音的监控分析结果进行投诉用户的识别，并根据投诉用户的语音识别结果进行投诉用户所处的供电工区以及投诉用户的故障类型的识别，获取投诉用户的故障类型的匹配的故障电气设备的型号，并将其作为关注型号，通过不同的供电工区的不同的关注型号的电气设备的使用数据、关联的投诉用户以及故障状态值进行不同的供电工区的供电可靠性系数以及运维处理顺序的确定，从而进一步提升了运维管理的可靠性。
G06Q40/03  ,一种基于智能对话系统与微表情识别的审核装置及方法 [发明],本发明涉及一种基于智能对话系统与微表情识别的审核装置及方法，主要涉及人工智能技术领域，该审核装置包括采集模块，用以采集目标用户的语音信息和面部图像数据；存储模块，用以存储数据；处理模块，用以进行数据处理；确定模块，用以确定目标用户的可信度评分和情绪变化评分；判断模块，用以依次判断第一异常语音信息以及第二异常语音信息；计算模块，用以计算得到目标用户的信用评分；评估模块，用以根据信用评分评估目标用户的信用等级。本发明通过依次判断异常语音信息并结合不同类别的异常语音信息对可信度评分和情绪变化评分的影响因素对目标用户进行信用评分得到评估结果，可以取代人工审核，提高了审核结论的准确性和审核效率。
H05B47/12  ,基于音乐基调变化的灯光控制系统及控制方法 [发明],本发明公开了基于音乐基调变化的灯光控制系统及控制方法，灯光控制技术领域。解决了现有灯光的照射方案的交付时间以及最终效果有一定的不可控性的问题。控制方法包括：获取音乐信息，根据音乐信息确定简谱信息和时间轴；根据简谱信息和时间轴，确定各音阶的排列顺序；获取灯光数据库，根据灯光数据库获取各灯光动作；根据各基础音级建立灯光库，各基础音级均绑定一灯光库；根据各灯光库和各灯光动作，以使各灯光库内储存至少一灯光动作；根据排列顺序和各灯光库，确定并执行照射方案。本发明实现了照射方案的确定模块化，确保了交付时间，并保证照射方案的质量，以使商演正常运行。
G10L25/03  ,用于环境声音分类的方法、装置、设备及存储介质 [发明],本申请涉及智能设备技术领域，公开一种用于环境声音分类的方法、装置、设备及存储介质。该方法包括：在获取到当前环境声音的二维时频特征图的情况下，基于时域注意力机制，对二维时频特征图进行特征加强，得到时域注意力谱图；基于两个或多个不同尺寸的卷积核，对时域注意力谱图进行深度学习处理，得到当前环境声音对应的当前特征向量；根据当前特征向量，确定当前环境声音对应的当前分类信息。这样，可适应各种声音结构，也降低了分类中对无关帧的敏感度，进而提高了环境声音分类的准确性。
G06V20/40  ,事件分析方法、设备、介质及系统 [发明],本申请提供一种事件分析方法、设备、介质及系统，可用于计算机领域。在该方法中，通过确定出目标分析策略后，对其中包含的每一目标图像区域属性对应的目标图像区域，确定利用所对应的目标分析算法对目标图像区域的图像/音频进行分析的区域分析结果；进而采用目标分析策略中配置的区域结果策略，对区域分析结果进行处理，确定目标分析策略对应的事件分析结果。本方案通过对于目标图像区域属性对应的每个目标图像区域，确定出区域分析结果，再使用区域结果策略对区域分析结果进行处理，得到事件分析结果，无需人工分析，有效提高了分析效率。
G10L15/22  ,一种语音控制设备或应用软件的处理方法和系统 [发明],本发明公开了一种语音控制设备或应用软件的处理方法，其包括步骤S100：收录操控智能设备的语音音频信息，并将语音音频信息传输至语音提供端；步骤S200：接收语音提供端下发的根据语音音频信息解析而成的语义信息；步骤S300：将语义信息转换成内部可识别的标准语义信息；步骤S400：根据标准语义信息，查询对应的指令信息，并输出至智能设备或应用软件；步骤S500：智能设备或应用软件执行指令，并反馈执行结果。本发明能处理不同语音提供商与设备或或应用软件之间发生语义冲突，并形成标准化平台，能使其在每个设备或应用软件调用一套处理逻辑，解决了费时费力的问题，大大提高生产效率。
G06V40/70  ,一种身份快速识别方法及系统 [发明],本发明涉及一种身份快速识别方法及系统，包括以下步骤：1)数据总处理模块对数据采集模块发出指令，通过数据采集模块对人物的面部、声音、指纹、虹膜和身高进行采集；2)通过数据采集模块将采集的数据通过数据预处理模块进行处理，通过数据清洗，把错误的数据更换的同时避免数据冲突。该身份快速识别方法及系统，通过数据采集模块、数据预处理模块、身份对比模块和输出模块，快速准确的对人物的身份进行识别处理，通过数据采集模块对人物的外观进行识别处理，通过数据预处理模块对人物整体进行清晰化和特征增强处理，通过身份对比模块快速的与往期的身份数据对比，通过输出模块将对比后的数据输出。
G06F40/58  ,模型训练方法、翻译方法、装置、电子设备及存储介质 [发明],本申请实施例公开了一种模型训练方法、翻译方法、装置、电子设备及存储介质。所述方法包括：获取训练数据，所述训练数据为文本数据或者语音数据；将所述训练数据输入到待训练模型的编码器中，获取所述编码器输出的所述训练数据的原始表示向量；对所述原始表示向量施加扰动，得到所述训练数据的有噪表示向量；将所述原始表示向量和所述有噪表示向量输入到所述待训练模型的解码器中，获取所述解码器输出的所述训练数据的第一概率分布和第二概率分布；基于所述第一概率分布和所述第二概率分布，对所述待训练模型进行迭代训练，直至满足训练结束条件，得到目标翻译模型。通过上述方法，提高了训练得到的目标翻译模型的鲁棒性。
H04L41/08  ,一种无线对讲机的参数配置方法及其对讲系统 [发明],本发明公开了一种无线对讲机的参数配置方法，采用对讲系统中的离线语音识别模块进行语音识别，且采用对讲系统中的存储模块进行存储，包括规划信道和存储信道参数、在信道模式下采用语音识别对对讲机参数进行设置和在频率模式下采用语音识别对对讲机参数进行设置；与现有技术相比，本发明采用分区域存储，每个区域中存储有一定数量的信道索引值，在用户选择区域后，将再所选区域中的信道名称动态配置给离线语音识别模块，并进行播报，以此支持较多信道。本发明还提供了一种无线对讲机的对讲系统。
G10L15/01  ,一种综合语音和文本的自纠错方法、存储介质和电子设备 [发明],本申请提供一种综合语音和文本的自纠错方法，属于语音检索技术领域，包括以下步骤：S1、收集用户检索的语音；S2、对步骤S1收集的语音使用语音纠错神经网络进行纠错，将纠错后的语音转化为文本信息；S3、对步骤S2得到的文本信息与数据库中已存储的检索词句进行匹配，当无法匹配时对文本信息进行文本纠错然后进入步骤S4，所述文本纠错包括字数错误纠正、模糊匹配和特定文本替换；当存在相匹配的检索词句时直接进入步骤S4；S4、根据文本信息匹配相应的检索结果并合成结果语音返回给用户；本方法能够对发音不准、存在背景噪声和字母与数字组合等不易识别的语音纠错，将纠错后的语音生成对应的文本信息，对文本信息再进行纠错以匹配更准确的检索结果。
G10L15/26  ,一种文本纠错模型训练方法、装置、存储介质及电子设备 [发明],本说明书公开了一种文本纠错模型训练方法、装置、存储介质及电子设备。将预先采集的语音样本输入到语音识别模型，得到所述语音识别模型输出的转译文本，判断所述转译文本中是否包含预先确定的易错词汇，若包含，则确定所述转译文本中包含的易错词汇对应的扩展词汇，根据所述扩展词汇，对所述转译文本进行扩展，得到增强样本，将所述增强样本作为样本，所述转译文本作为标注，对文本纠错模型进行训练。通过这种方法，能快速构造出了大量的增强样本，并确定所述增强样本对应的标注，对所述文本纠错模型进行训练，提升所述文本纠错模型的纠错性能。
G10L15/20  ,一种自适应近远场的离线语音命令词识别方法、系统及介质 [发明],本发明公开了一种自适应近远场的离线语音命令词识别方法、系统及介质，方法包括：以指定的时间间隔获取语音数据片段并更新语音数据，对语音数据音量自适应增强后进行唤醒识别，若能识别则提取人声部分，保存人声部分特征与识别词，若无法识别则提取人声部分，将人声部分特征与已保存的人声部分特征进行匹配，将匹配结果的识别词作为唤醒词；若识别到唤醒词，获取新的语音数据，对语音数据音量自适应增强后进行命令识别，若能识别则提取人声部分，保存人声部分特征与识别词，若无法识别则提取人声部分，将人声部分特征与已保存的人声部分特征进行匹配，将匹配结果的识别词作为命令词。本发明解决了近远场不定环境下，远场声音难以识别的问题。
G10L13/02  ,人和动物情势语言智能沟通系统 [发明],本发明属于语言沟通领域，提供了人和动物情势语言智能沟通系统，包括数据库，数据库内存储有动物信息和动物模型信息；语音和文字识别模块，语音和文字识别模块包括语音信号预处理组件、特征提取组件、声学模型组件和语音模型组件；语音信号预处理组件用于对输入的语音信号进行噪声消除和语音增强；特征提取组件用于提取语音信号中的频谱特征；声学模型组件用于对频谱特征进行语音识别；语音模型组件用于对识别结果进行进一步修正和优化；本发明通过结合语音识别、图像处理、动物模型建立和语音合成等技术，实现了人和动物之间的情境语言智能沟通，能够在动物的语言和行动上给用户提供真实动物的反馈，可以实现个性化互动和提供更精准的反馈。
G10L13/02  ,基于提示学习的多风格语音合成方法、设备及介质 [发明],本发明公开了一种基于提示学习的多风格语音合成方法、设备及介质，属于语音合成技术领域，包括：步骤S1、构造包括提示模板的数据集；步骤S2、对数据集中的待合成文本进行预处理；步骤S3、提示模板语义提取预训练；步骤S4、带有提示模板的声学模型训练，获取待合成语音的梅尔频谱；步骤S5、利用声码器生成语音时域信号。本发明能够通过提示学习和语音合成两种技术的结合，实现多种风格的语音合成。
H04N7/18  ,智慧楼宇运营管理方法、系统与存储介质 [发明],本发明提供一种智慧楼宇运营管理方法、系统与存储介质，属于安防管理技术领域，具体包括：根据不同区域在不同时段的历史声音监控数据和历史图像监控数据进行不同区域在不同时段的安防问题概率以及总体问题概率的确定，通过抽帧分析模式进行不同区域的监控图像以及声音监控数据的解析得到解析结果，并根据不同区域的监控图像的人员动作的解析结果、声音监控数据的解析结果以及监控图像所对应时刻的安防问题概率进行不同区域的安防问题评估量的确定，基于不同区域的安防防护等级以及安防问题评估量确定楼宇的安防等级，从而进一步提升了安防管理的可靠性。
G10L15/00  ,语种识别方法、系统、设备及存储介质 [发明],本发明公开了一种语种识别方法、系统、设备及存储介质，该方法包括：获取多语种音频数据集，采用数据混淆方法对多语种音频数据集进行处理；从处理后的多语种音频数据集中提取文本信息和语音信息；将文本信息和语音信息进行融合，得到融合表征信息；根据融合表征信息训练神经网络，得到语种模型；将待识别语种输入语种模型，得到语种类别。本发明获取包括短时音频数据和场景音频数据的多语种音频数据集，采用数据混淆方法对多语种音频数据集进行处理；将提取的文本信息和语音信息进行融合，将待识别语种输入根据融合表征信息训练得到的语种模型，得到语种类别，提升了语种模型的识别效果和准确率，改善了短时音频识别效果差以及语种混淆的问题。
G10L21/0232  ,噪声估计方法、装置、终端及计算机可读存储介质 [发明],本发明提供一种噪声估计方法，包括：使用宽带参考信号计算第一噪声协方差矩阵；使用解调参考信号计算第二噪声协方差矩阵；分别计算所述第一噪声协方差矩阵的第一度量值，以及所述第二噪声协方差矩阵的第二度量值，所述第一度量值和第二度量值用于判定所述第一噪声协方差矩阵和所述第一噪声协方差矩阵的相似性；根据所述第一度量值与第二度量值的大小关系，选择第一噪声协方差矩阵或第二噪声协方差矩阵作为最终的噪声协方差矩阵，进行噪声估计。本发明能够将使用宽带参考信号和解调参考信号进行噪声估计的特点相结合，自适应选取不同的噪声估计方式，弥补单纯使用解调参考信号进行噪声估计的不足，有效提升物理下行共享信道的检测性能。
G10L13/08  ,多音字读音的确定方法和装置、存储介质及电子设备 [发明],本申请公开了一种多音字读音的确定方法和装置、存储介质及电子设备，上述方法包括：对待处理语料进行解析，确定出待处理语料中的第一多音字，其中，第一多音字对应有字符特征；使用字符编码模型对待处理语料中的待处理语句进行掩码处理，得到待处理语句的语句嵌入向量；根据语句嵌入向量，字符特征以及与字符特征对应的相关词特征生成特征向量；将特征向量输入至训练后的深度学习模型，根据深度学习模型的输出结果确定出第一多音字对应的目标读音。采用上述技术方案，解决了如何准确确定多音字的读音的问题。
G10L15/02  ,语音识别方法、装置、设备及存储介质 [发明],本申请实施例公开了一种语音识别方法、装置、设备及存储介质，对语音进行特征提取，得到语音的各个语音帧的特征；通过端到端网络对各个语音帧的特征进行编码，得到各个语音帧的编码特征；通过端到端网络对各个语音帧的编码特征进行解码，得到多个字序列；通过第一解码网络对多个字序列进行解码，得到第一词序列；通过基于热词激励的第二解码网络对各个语音帧的编码特征进行解码，得到第二词序列；在第一词序列和第二词序列中筛选出置信度高的词序列作为语音识别结果。本申请提高了特定业务场景下热词的语音识别效果，实现了整个识别系统在通用语音识别效果与个性化需求之间的平衡。
G10L21/0232  ,噪声估计方法、装置、终端及计算机可读存储介质 [发明],本发明提供一种噪声估计方法、装置、终端及计算机可读存储介质。所述方法包括：对每个频域解调参考信号资源元素计算噪声协方差矩阵；提取各噪声协方差矩阵相同位置的非对角线元素组成序列；对所组成的序列分别计算度量值；根据所述度量值判断所述噪声协方差矩阵的相关性是否较高；若所述噪声协方差矩阵的相关性较高，则对所述噪声协方差矩阵进行平均或平滑操作，进行噪声估计。本发明能够有效判断噪声协方差矩阵的相关性，以便在噪声协方差矩阵相关性较高的频域范围内对噪声协方差矩阵进行平均或平滑操作，从而减小信道估计误差给噪声估计带来的影响，提高噪声估计准确性。
H04L67/125  ,一种基于文本生成大模型的物联控制模型微调方法 [发明],本发明公开了一种基于文本生成大模型的物联控制模型微调方法，包括：采集设备信息，并根据所述设备信息，建立相互关联的多个信息表格，根据所述多个信息表格中的数据，自动生成N个样本文本；其中，N为正整数；根据所述N个样本文本，为经过训练的基于文本生成大模型的第一物联控制模型进行微调，得到第二物联控制模型；其中，所述第二物联控制模型用于根据实时命令对设备进行控制；采用本发明能够提高基于文本生成大模型的物联控制模型的准确度。
G10L15/187  ,一种基于沙发的分享方法及相关产品 [发明],一种基于沙发的分享方法及相关产品，该方法包括：第一沙发获取有声手指点读本发送的某一生字及该生字对应的标准读音；其中，有声手指点读本在根据第一沙发的使用者手指点击的某一页面中的该生字所占的唯一区域识别出该生字时播放该生字对应的标准读音，并将该生字及该生字对应的标准读音发送给第一沙发；第一沙发将第二沙发的唯一身份ID、该生字及该生字对应的标准读音上报给物联网平台；物联网平台将该生字和该生字对应的标准读音下发给第二沙发；第二沙发显示出该生字并播放该生字对应的标准读音，以实现向第二沙发的使用者分享该生字及该生字对应的标准读音。能够提升生字及该生字对应的标准读音的分享效率，有利于减少儿童对手机的依赖。
G10L25/63  ,语音情绪识别方法 [发明],公开了一种语音情绪识别方法，所述方法包括：采集语音数据；基于语音数据提取至少两种图像化语音特征；以及使用预训练的语音情绪识别模型对至少两种图像化语音特征进行识别，并获得情绪预测结果，其中，所述语音情绪识别模型包括：卷积层，被配置为以至少两种图像化语音特征作为输入提取全局特征信息；注意力层，被配置基于全局特征信息根据局部‑全局广播注意力或移动视觉变换器注意力并且还根据通道注意力、空间注意力、深层注意力提取注意力特征；以及输出层，被配置为根据注意力特征确定情绪预测结果。
G10L15/22  ,一种智能交互方法、云服务器、智能交互系统及存储介质 [发明],本发明涉及通信技术领域，具体的说是一种智能交互方法、云服务器、智能交互系统及存储介质，包括注册模块、位置侦测模块和云服务器，所述云服务器中包括储存模块、获取模块、处理模块、通信模块和控制模块，所述位置侦测模块将环境图像传输给获取模块，所述获取模块用于接收位置侦测模块传输的环境图像并识别环境图像，所述获取模块将识别后的环境图像和智能设备的数据信息储存在储存模块中，所述处理模块将位置侦测模块拍摄的环境图像信息与储存模块中的预设环境图像信息进行比对，然后从环境大数据库中调取与环境图像信息相匹配的数据并储存在储存模块中，本发明具有如下有益效果：减少储存空间的占用，减少数据处理量，提高交互体验。
G06F18/22  ,经颅交流电设备的刺激效果评估方法、装置、终端及介质 [发明],本发明公开了经颅交流电设备的刺激效果评估方法、装置、终端及介质，方法包括：获取经颅交流电设备的交流电刺激部在脑部区域的定位信息，基于定位信息，确定交流电刺激部的点位匹配结果；获取经颅交流电设备的信号检测部在若干个目标脑部点位所检测到的实时脑电信号，并基于实时脑电信号，确定实时脑电信号的信号同步度；基于点位匹配结果以及信号同步程度，确定经颅交流电设备的刺激效果。本发明的点位匹配度可反映出交流电刺激部的位置与目标脑部点位是否匹配，信号同步程度可反映出不同的目标脑部点位之间的信号同步程度，因此，基于点位匹配结果以及信号同步程度，可从多个维度准确地确定出经颅交流电设备的刺激效果，满足用户的使用需求。
G06F16/332  ,基于大语言模型的智能系统 [发明],本发明属于自然语言处理和人工智能技术领域，尤其为基于大语言模型的智能系统，包括自然语言交互模块，用于将用户的语音等转换成中文文字，大语言模型，用于将文字信息转换为指令信息，需求推理模块，用于将自然语言交互模块中转化的中文汉字输入到大语言模型中，并调用大语言模型进行调整，以将用户输入数据转化为指令信息，在大语言模型的智能系统中设置自然语言交互模块、需求推理模块、指令处理模块、微服务模块、数据储存模块以及结果反馈模块，在这些模块的相互配合下，能够针对现在用户的多样化需求，并且可以更好地理解用户的意图，替代掉只具有简单智能的服务机器人，减少人力资源的浪费。
G10L25/51  ,一种基于改进DSC-DenseNet的变压器声纹图谱识别方法及系统 [发明],本发明公开了一种基于改进DSC‑DenseNet的变压器声纹图谱识别方法及系统，该方法包括：搭建采集环境，采集变压器铁芯的振动声音信号；对采集到的原始声纹信号进行预处理，将Mel滤波非线性处理用在变压器铁芯声纹的提取中；构建基于改进的DSC‑DenseNet架构的图像分类网络。本申请通过Mel时频谱分析技术对声纹数据进行了预处理，强化了低频和中低频部分的能量特征，同时准确描述了变压器铁芯在运行状态下的平稳声波信号特性；构建了基于改进DSC‑DenseNet架构的图像分类网络模型，该模型具有更高的精度和特异性，尤其在捕捉铁芯声纹的细微特征上取得了革命性进步。
G10L25/63  ,一种基于自适应位移模块的语音情感识别方法 [发明],本发明涉及基于深度学习的语音情感识别领域。本发明公开了一种基于自适应位移模块的语音情感识别方法。本发明的方法包括：音频预处理，将音频的长度设置为7.5秒，采样率使用16kHz；使用预训练模型提取预训练表征；通过通道注意力机制使模型更关注情感相关区域；自适应位移，先根据通道数据计算位移尺度，再根据这个位移尺度对该通道数据进行位移。使得不同通道之间的异质特征在时间轴上混合，提升模型提取情感特征的能力；使用MLP结构捕捉特征之间的依赖；使用全连接层对聚合后的特征进行情感预测。其中自适应位移模块细节图如图1所示。本发明能够以相对较少的参数量，实现情感特征提取，以提高情感识别准确率。
H04N7/15  ,一种会议同声智能系统 [发明],本发明公开了一种会议同声智能系统，包括同声传译耳机、音频采集端和控制终端，发言会同步经过音频存储翻译模块的翻译后传输到同声传译耳机中，在参会人员暂时离场时只需要摘下耳机就不再播放翻译内容，翻译音频信息进入同步单元内进行处理，将翻译音频信息中空白未发言的片段进行删除缩减翻译音频信息的长度，在参会人员回来时只需要戴上同声传译耳机，就可以继续错过的发言内容，同时根据与当前发言的时间的差距即存储数量来对同步音频信息进行倍速播放追赶当前发言的进度，直至与当前的发言内容同步后，同声传译耳机继续正常的翻译播放过程。保证参会人员可以全程参与发言内容，避免上下文内容跟无法联系影响听讲效果。
H04N5/265  ,一种基于动作驱动和口型驱动的照片驱动方法 [发明],本发明公开了一种基于动作驱动和口型驱动的照片驱动方法，根据用户输入的音频或文本信息，驱动模型内置人物的口型，得到目标人物的说话的动作；根据音频驱动得到的动作，驱动用户上传的照片，实现照片驱动；最后为了实现实时驱动速度，将全部网络在TensorRT框架下进行推理。优点是：既能够实现动作效果，又无需进行训练，且能够实现实时照片驱动。通过结合语音驱动和动作驱动相结合的方式，达到提高照片驱动的效率和用户体验，从而满足用户对于高效、便捷和快速响应的需求。
G10L15/06  ,用于语音交互的训练数据生成方法、服务器及存储介质 [发明],本申请公开一种用于语音交互的训练数据生成方法，方法包括：获取目标语音请求，根据大语言模型，确定目标语音请求相对应的参考槽位信息，反馈参考槽位信息的置信度，响应于根据置信度的针对参考槽位信息的标记操作，确定目标语音请求的目标槽位信息，根据目标语音请求及目标槽位信息生成训练数据。如此，本申请的服务器可根据大语言模型，确定参考槽位信息，反馈参考槽位信息的置信度，响应标记操作以确定目标语音请求的目标槽位信息，完成目标语音请求的标注。本申请使得目标槽位信息的获取基于大语言模型及标注操作完成，避免目标槽位信息完全基于人工得到，人工参与环节减少，降低标注对人工的依赖，标注效率得以提升，标注所需时间降低。
G10L25/63  ,一种基于CNN-GRU融合模型的婴儿哭声分类方法 [发明],本发明公开一种基于CNN‑GRU融合模型的婴儿哭声分类方法；通过音频处理模块对输入的音频样本进行处理，得到音频的频谱图，将得到的频谱图通过预训练的Resnet‑50模型，得到频谱图特征；然后，通过GRU模型对特征进行编码，突出有用信息，抑制冗余信息，进一步增强特征图的表征能力；最后将特征图进行婴儿哭声分类，通过多次迭代训练得到最终分类结果。本发明将音频文本转化为频谱图，用融合模型处理图像问题，可用于处理哭声存在的上述问题及可以智能、快速、准确地的进行检测。
G10L25/66  ,一种基于人工智能的人体嗓音检测分析方法 [发明],本发明公开了一种基于人工智能的人体嗓音检测分析方法，该方法包括S1嗓音数据的采集和预处理；S2、采集数据划分为训练数据集、验证数据集和测试数据集；S3、训练数据集及其标识信息构建复合前馈神经网络模型，输出为不同标识信息对于人体嗓音输出特征量；S4、验证数据集与复合前馈神经网络模型输出比较判断是否匹配，不断更新完善该复合前馈神经网络模型；S5、将测试数据集作为S4步获得的复合前馈神经网络模型输入参数进行测试，从测试嗓音输出特征获得测试嗓音和最佳标识相应最佳特征之间的差异性，从而确定该嗓音的缺陷。本申请的方法实现了对不同人群的嗓音数据进行定量准确分析，并为特定嗓音的形成提出训练针对性。
G06T13/40  ,面部驱动方法、装置、电子设备及可读存储介质 [发明],本申请公开了一种面部驱动方法、装置、电子设备及可读存储介质，属于计算机技术领域。本申请实施例中的面部驱动方法包括：获取语音信息；对所述语音信息进行音素识别，得到所述语音信息对应的音素序列；根据所述音素序列，构建音素路径图，其中，所述音素路径图中的每条音素路径表征对所述音素序列中的音素的一种分组方式；根据预先构建的音素动作库中存储的音素组合单元和与其对应的面部动作系数序列，从所述音素路径图中选择目标音素路径，并确定所述目标音素路径对应的面部动作系数序列；利用所述面部动作系数序列执行面部驱动。由此，可以提升面部驱动效果。
G10L15/00  ,语音信息的分类方法、装置、存储介质和电子设备 [发明],本申请公开了一种语音信息的分类方法、装置、存储介质和电子设备。其中，该方法包括：获取目标语音信息的编码结果和语音特征，其中，编码结果为对目标语音信息进行编码得到；对编码结果和语音特征进行融合处理，得到融合结果；基于融合结果，对目标语音信息进行分类，得到目标分类结果，其中，目标分类结果用于表示目标语音信息所属的语音类型。本申请解决了语音信息的分类准确率低的技术问题。
G10L17/26  ,一种声音监测与识别设备、系统、计算机设备和存储介质 [发明],本发明适用于声音监测设备，提供了一种声音监测与识别设备，所述设备包括：感知仓，所述感知仓为长方体，表面设置有收音装置，用于收集野外声音，并将声音发送到边缘计算仓；所述边缘计算仓，用于处理声音数据，执行实时音频处理算法；能源仓，用于所述边缘计算仓和所述感知仓的供电；安装支架，所述安装支架顶部安装用太阳能板，所述太阳能板下方安装有所述感知仓、边缘计算仓以及能源仓；本设备具有的稳定性与可推广性，为野生动物保护、生态环境监测和生物多样性研究等领域提供更全面和精确的数据支持。
G10L15/02  ,呼叫中心的多语言语音识别方法、系统、设备及存储介质 [发明],本申请提供了一种呼叫中心的多语言语音识别方法、系统、设备及存储介质，该方法包括：获取样本音频，提取样本音频的音频特征，并基于发音字典得到第一音素标签；基于样本音频的音频特征和第一音素标签训练三音素模型，获取样本音频的第二音素标签；基于样本音频的音频特征和第二音素标签训练第一声学模型，基于训练好的第一声学模型获取样本音频的第三音素标签；基于样本音频的音频特征和样本音频的第三音素标签训练第二声学模型，获得训练好的第二声学模型；获取待识别音频，提取待识别音频的音频特征，输入第二声学模型中，获取待识别音频的预测音素数据，进行解码，得到对应的文本。本申请提高了多语言环境下语音识别的准确性。
G06F40/58  ,一种Mac系统语言处理一体化应用系统 [发明],本发明涉及应用系统技术领域，尤指一种Mac系统语言处理一体化应用系统。系统包括语音识别、自然语言处理、划词、翻译、朗读、润色与分析、信息检索与知识图谱模块，实现全方位语言功能。语音识别模块将用户语音输入转为文本，自然语言处理模块进行实体、语法、语义和情感分析。划词模块提供选词解释，翻译模块支持多语言转换，朗读模块以语音合成技术提供自然语音输出。润色与分析模块智能校对文章，信息检索与知识图谱模块检索相关信息构建知识图谱。本发明通过多模块的集成和协同工作，为用户提供了全方位、高效的语言处理能力，大大提高了用户在语言处理方面的工作和学习效率。
G10L15/28  ,一种语音分析处理系统 [发明],本发明涉及语音分析技术领域，更具体的说是一种语音分析处理系统；包括语音识别单元、收集单元和后台处理单元，语音识别单元能够对语音的内容信息进行识别，语音识别单元识别语音后通过传感器传递给后台处理单元，后台处理单元根据需要通过电信号驱动收集单元进行自身调节来增强收集语音时的范围大小和强度。所述的收集单元包括前端固定连接有收音器的主杆，主杆前侧固定有固定环，固定环上通过扭簧转动连接有多个转臂，每个转臂上均固定有护板，多个护板能够相互接触扣合起来；能够在对语音信息进行采集的时候，调节采集声波的强度。
G10L25/51  ,基于深度U型网络的声纹异常检测方法、设备及存储介质 [发明],本发明的一种基于深度U型网络的声纹异常检测方法、设备及存储介质，包括以下步骤，采用改进格拉姆角场实现将声纹数据转换为相应的格拉姆谱图，并提取出相应的声纹特征；基于浅层的U型网络构建声纹去噪模型；基于深层的U‑Net网络构建声纹检测模型；基于训练好的声纹去噪模型、声纹检测模型以及阈值，将在现场实际工况下采集到的待检测声纹数据，输入到声纹去噪模型进行降噪，然后再进行声纹检测，最终根据阈值与声纹检测模型输出的结构衡量指标损失值进行比对与分析。本发明全程采用了无监督的深度U型网络来避免在实际工况下难以获取异常状态电力设备的声纹数据的问题。无监督的学习方式也解决了标注数据少以及标注成本高的问题。
G10L13/02  ,一种语音合成自动化实现方法 [发明],本发明涉及语音合成相关技术领域，公开了一种语音合成自动化实现方法，包括用深度学习技术构建端到端的语音合成模型，并用开源数据集训练得到预训练模型；开发具有录音功能的APP或者微信小程序，说话人通过APP或者微信小程序在手机上录音，录音音频通过互联网自动发送到服务器；录完音频之后，程序自动把说话人的音频数据输入预训练模型进行微调，得到说话人的模型权值；微调得到的语音合成模型可以实现文本转语音，并且能够模仿说话人声音；本申请应用互联网、人工智能技术、人机互动，可以自动实现语音合成，且模仿说话人声音；通过计算机程序把语音合成的多个步骤自动实现，使得语音合成更加方便快捷。
G10L13/08  ,一种语音风格迁移方法、系统、装置、设备及计算机介质 [发明],本申请公开了一种语音风格迁移方法、系统、装置、设备及计算机介质，涉及语音合成技术领域，获取目标对象的音色特征信息；获取目标对象在目标风格下的目标文本；获取源对象在目标风格下的源语音；解析出源语音中源对象的第一目标基频和音素时长；根据第一目标基频预测目标对象的第二目标基频；按照音素时长和第二目标基频，应用音色特征信息对目标文本进行语音合成，得到目标对象在目标风格下的目标语音。本申请实现了将源对象在目标风格下的基频迁移到同风格的目标对象上，将源对象在目标风格下的音素时长迁移到同风格的目标对象上，最终实现了将源对象的目标风格迁移到目标对象上，准确性好，且无需过多依赖目标对象的其他风格信息，适用性好。
G10L21/0224  ,一种耳鸣治疗声的优化方法及系统 [发明],本发明提供了一种耳鸣治疗声的优化方法及系统。优化方法包括：步骤S1：将需要播放的音源进行分段；步骤S2：每次仅实时输入一段音源数据；步骤S3：对输入的每段音源数据中的所有采样点的时域数据，计算其平方值之和；步骤S4：对每段音源数据中的所述平方值之和取二次方根，并依次存储每段音源数据的时域总幅度；步骤S5：计算A＆lt;subgt;max＆lt;/subgt;；步骤S6：更新Amax的值；步骤S7：更新A的值；步骤S8：计算每段音源数据的增益系数G；步骤S9：将所处理数据段的每个采样点的时域数据除以该段音源对应的增益系数G；步骤S10：实时输出处理后的数据。本申请使每重复播放同一首音乐时，都可以使细节处的声音频率会有所不同。
G10L25/51  ,一种基于声音信号的设备故障检测方法及系统 [发明],本发明涉及故障检测技术领域，其公开了一种基于声音信号的设备故障检测方法及系统，该方法包括：实时采集设备声音信息，将声音信息输入至预先建立的故障检测模型；根据故障检测模型输出当前采集的设备声音信息是否具备故障特征；当具备故障特征时，划分为若干段声音特征段与故障声音特征集进行比对，以获取设备声音信息所对应的至少一种故障类型。本发明通过实时监听设备运行时的声音信息进行故障判定，事先建立故障检测模型，将实时采集的设备声音信息输入至故障检测模型进行故障判定，对经过故障检测模型输出为故障的设备声音信息进行分段详细检测，进而获取设备当前的故障类型，进而可以有针对性的对不同故障的设备进行后续的维护。
G10L25/51  ,一种车内音效识别方法、装置及相关设备 [发明],本公开提供一种车内音效识别方法、装置及相关设备，涉及车联网的技术领域，其中方法包括：接收目标终端发送的至少两个单声道音频数据以及每一所述单声道音频数据对应的采集位置，所述单声道音频数据为所述目标终端在对应的采集位置采集目标车辆播放的目标音频获得的音频数据，不同的单声道音频数据对应的采集位置不同；根据所述至少两个单声道音频数据分别计算至少两个目标强度数据，所述至少两个目标强度数据和所述至少两个单声道音频数据一一对应，所述目标强度数据用于指示在对应的采集位置采集的所述目标音频的声音强度；根据所述至少两个目标强度数据，确定所述目标车辆的音效类别。本公开能便利用户对车内音效类别的确定。
G06F16/432  ,基于人工智能语音与图像识别技术的声像档案利用系统 [发明],本申请涉及智能检索领域，其具体地公开了一种基于人工智能语音与图像识别技术的声像档案利用系统，其采用基于深度学习的人工智能分析技术，通过对声像档案中的照片数据、音频数据和视频数据进行特征编码以得到档案数据搜索特征矩阵，并将所述档案数据搜索特征矩阵通过生成器以生成搜索关键词，这样便于用户按照搜索关键词进行搜索时能够快速搜索出相关档案数据。
G10L13/027  ,基于频率调制的人声合成方法、装置、设备及存储介质 [发明],本发明涉及数据处理的技术领域，公开了一种基于频率调制的人声合成方法、装置、设备及存储介质。所述基于频率调制的人声合成方法包括：通过目标设备获取源人声信号，并对所述源人声信号进行预处理，得到目标信号；通过预设的第一分析算法对所述目标信号进行第一分析，得到人声音色参数，并通过预设的第二分析算法对所述目标信号进行第二分析，得到人声语义信息；基于所述人声语义信息和所述人声音色参数，从预设的参数数据库中匹配对应的调制参数；本发明不仅确保了人声信号处理的准确性和效率，而且通过精确的特征提取、高效的参数匹配、个性化的声音重构以及全面的声音评估，大大提高了重构语音的质量和用户满意度。
H04M3/493  ,一种用于智能IVR的自动转接人工方法及系统 [发明],本发明提供了一种用于智能IVR的自动转接人工方法及系统，所述方法包括：通过IVR系统获取用户的语音数据，并基于预设的语音识别模型将所述语音数据转换为文本数据；根据预设的人工需求识别模型识别所述文本数据，确定用户是否需要转接人工服务；当确定客户需要转接人工服务时，根据预设的专业项目识别模型识别所述文本数据，确定用户需要的专业项目；根据所述专业项目匹配对应的人工坐席；匹配完成后，建立用户与所匹配到的人工坐席的语音通话连接。本发明根据用户的语音识别用户意图，转接对应专业的人工，提高了IVR系统转接人工的准确性和效率。
G06F16/632  ,身份信息的处理方法、装置和电子设备 [发明],本申请提供了一种身份信息的处理方法、装置和电子设备，该方法通过根据发声者的人声特点描述文本和人脸特点描述文本，来分别生成语音和人像，并根据语音和人像生成的多个查询身份，来综合确定未知身份人的身份信息，提高了身份确认的准确度，从而解决了现有技术中缺少根据发声者描述未知身份人的特征的文本来直接生成语音和人像，并同时根据语音和人像来确定未知身份人的身份的技术方案的问题。
G10L15/22  ,应用于车辆的语音处理方法及装置 [发明],本申请提供的应用于车辆的语音处理方法及装置，该方法包括：采集当前车辆中的语音信号；若确定语音信号命中车辆的语音控制指令集中的目标指令，则确定目标指令对应的指令类型；其中，指令类型用于指示是否为驾驶员专用指令；语音控制指令集包括至少一个控制指令；控制指令用于对车辆进行控制；根据指令类型，确定目标指令的处理结果；处理结果用于表征是否执行目标指令。进而，通过在车辆所支持的语音控制指令集中，划分出驾驶员专用指令类型的控制指令，以便后续可以结合目标指令是否被归属于驾驶员专用指令，来进一步确定是否可以执行语音信号所命中的目标指令，以确保车辆语音控制的安全性。
G10L15/06  ,违规音频识别模型的训练方法、装置和违规音频识别方法 [发明],本申请提供了一种违规音频识别模型的训练方法、装置、违规音频识别方法、计算机设备和存储介质。该训练方法包括：获取训练数据集；利用训练数据集对第一初始模型进行训练，得到第一识别模型；以第一识别模型为监督，利用训练数据集对第二初始模型进行训练，得到第二识别模型；第二识别模型中的参数少于第一识别模型，第二识别模型将作为违规音频识别模型下发到目标移动端，以在目标移动端本地进行违规音频识别。利用本方案训练得到模型与服务器端的模型具有相近的预测能力，但由于参数较少，可以部署算力有限的设备上进行本地识别，保证用户语音隐私，降低数据泄露风险。还可减少网络与服务器成本，提高运行稳定性。
G10L15/22  ,一种语音唤醒方法、装置、系统及可读介质 [发明],本发明提供了一种语音唤醒方法、装置、系统及可读介质，涉及语音识别技术领域，应用于语音唤醒系统的前端，前端与语音唤醒系统的后端通信连接，方法包括：响应于语音交互发起操作，启动语音唤醒系统的前端的语音识别元件；获取语音数据，通过语音识别元件识别语音数据得到语音数据对应的文字数据；基于文字数据确定语音数据中是否存在预设唤醒词；若语音数据中存在唤醒词，停止语音识别元件识别语音数据的操作，向后端发送语音唤醒指令以进行语音交互；若语音数据中不存在唤醒词，重新启动语音识别元件对语音数据进行识别，直至语音数据中存在唤醒词，停止语音识别元件识别语音数据的操作，减少唤醒阶段中服务器负载压力，提高机器唤醒响应效率。
G10L13/08  ,声学模型训练方法、音色融合方法、装置、设备及介质 [发明],本申请公开了一种声学模型训练方法、音色融合方法、装置、设备及介质，涉及音色融合领域，包括：根据权重对多个音色的文本的真实编码谱特征进行融合；将真实编码谱特征和文本输入待训练声学模型得到预测谱特征，对预测谱特征进行编码得到预测编码谱特征，根据权重对预测编码谱特征进行融合；根据真实谱特征和预测谱特征确定第一损失，根据融合后真实编码谱特征和融合后预测编码谱特征确定第二损失；对融合后真实编码谱特征进行分类，根据分类概率和权重确定第三损失；根据第一损失、第二损失和第三损失训练得到声学模型。本申请通过基于上述方式训练的声学模型实现了一种无监督的音色融合算法，能够产生数据库中所没有的任意多个融合音色。
H04M3/493  ,一种IVR服务方法、装置、设备以及存储介质 [发明],本发明公开了一种IVR服务方法、装置、设备以及存储介质，所述方法包括：根据用户输入的语音信息生成对应的交互数据；提取所述交互数据对应的交互特征信息；若预设的自动回复特征库内包含所述交互特征信息，则从所述自动回复特征库中匹配与所述交互特征信息对应的自动回复数据，根据所述自动回复数据生成一语音控制信号，以使所述语音控制信号控制语音端中预设的语音虚拟形象对所述语音信息进行回复；否则将所述语音信息发送至对应的语音端后台，以使语音端后台的客服工作人员对所述语音信息进行回复。通过本发明可以有效解决IVR系统中的客服工作人员出现回复错误的问题，提高语音回复的准确性。
G10L17/02  ,一种耳机语音控制方法、装置、计算机设备及存储介质 [发明],本申请涉及一种耳机语音控制方法、装置、计算机设备及存储介质，其包括获取耳机收音数据，从耳机收音数据中获取用户语音数据；获取耳机佩戴感应数据，根据耳机佩戴感应数据获取对应的佩戴者声纹特征，根据佩戴者声纹特征从用户语音数据中提取佩戴者语音数据；对佩戴者语音数据进行语义识别，得到对应的佩戴者语义数据；获取预设的耳机控制词，逐个将耳机控制词在佩戴者语义数据中进行匹配查询，根据耳机控制词和对应的匹配结果生成耳机操控指令。本申请具有更便捷的使用蓝牙耳机，减少在使用蓝牙耳机时会有误触与触摸不灵敏的现象产生的效果。
G06F3/16  ,基于车载虚拟形象的交互方法、装置、车辆和可读介质 [发明],本申请涉及一种基于车载虚拟形象的交互方法、装置、车辆和可读介质。该方法包括：获取目标用户的语音交互指令，和/或，获取目标用户的情绪类别信息；根据语音交互指令和/或情绪类别信息，调整车载虚拟形象的交互状态；交互状态用于表征车载虚拟形象与目标用户交互过程中所呈现的状态。本申请提供的方案，能够提高用户使用语音助手的频率和粘性。
G10L15/00  ,语音识别的方法、装置及电子设备 [发明],本申请公开了一种语音识别的方法、装置及电子设备。其中，该方法包括：获取流式语音场景中的语音信息，其中，语音信息包括普通话和方言；采用训练好的声学模型对语音信息进行识别，得到识别结果，其中，识别结果包括方言分类结果和语音识别结果；依据方言分类结果确定语言模型，并依据语言模型对语音识别结果进行识别，得到语言模型概率，其中，语言模型概率用于确定语音识别结果中的词序出现的概率；依据声学模型对语音信息进行识别得到的后验概率和语言模型概率，确定语音信息的目标识别结果。本申请解决了相关技术中的多语音识别方法基于基础模型叠加方言分类器判断选择具体方言模型，降低流式语音识别的体验的技术问题。
G10L15/06  ,语音识别模型的训练方法、语音识别方法和相关装置 [发明],本申请公开了一种语音识别模型的训练方法、语音识别方法和相关装置，该方法包括：获取若干样本音频段；利用语音识别模型分别对各样本音频段进行特征提取，得到各样本音频段的音频特征和至少一个场景特征，场景特征用于表征样本音频段的说话人、采集通道和所属音频源中的至少一者的信息；利用语音识别模型至少基于各样本音频段的音频特征，得到各样本音频段的样本识别文本；基于样本识别文本和样本音频段的标注文本之间的文本差异、以及各样本音频段的场景特征之间的特征相似度，调整语音识别模型。通过上述方式，本申请能够提高语音识别的准确性。
G06F16/2458  ,语音文本数据处理方法、服务器及存储介质 [发明],本申请公开了一种语音文本数据处理方法，包括：根据预存储的第一语音文本数据集合，拟合确定数据划分函数；根据数据划分函数以及待测试的第二语音文本数据集合，对第二语音文本数据中语音文本数据进行划分处理。本申请可以根据预先存储的、已经上线一段时间的老产品用户车辆在服务器中留存的语音文本数据集合，通过具有庞大数据量的语音文本数据集合进行统计，拟合得到能够相对精确地描述刚刚上线的新产品用户车辆在服务器中留存的语音文本数据集合的数据划分函数，并利用该函数对新产品用户车辆的语音文本数据集合进行数据划分，以便于对明确新产品用户车辆的语音文本数据集合中语音文本数据的重要程度，为针对车辆功能编写测试集做好数据准备。
G10L15/06  ,一种语料标注方法、装置、电子设备及存储介质 [发明],本发明涉及一种语料标注方法、装置、电子设备及存储介质，语料标注方法包括：获取目标视频中属于不同人物的多个人脸图像所对应的语料片段；针对每个人物，在该人物的多个人脸图像所对应的语料片段中，确定由所述人物作为实际的语者进行发声的语料片段；按照各所述语者的语者信息确定各所述语料片段的标注文本。本申请实施例可以实现自动对目标视频中的语料片段进行标注，进而可以便于得到大量的训练语料，以用于模型的训练，在保证训练语料获取的准确性的同时，提高训练语料的获取效率。
G10L15/22  ,一种基于智能机顶盒的人机交互管理系统 [发明],本发明公开了一种基于智能机顶盒的人机交互管理系统，涉及机顶盒人机交互技术领域；本发明通过使用文本匹配算法与语音模型内预设的语音指令进行匹配，若匹配失败，则获取语音模型内与该文本结果匹配的可能结果；并通过对分析时区内智能机顶盒所处周围环境的人声环境评估指数和户外环境评估指数进行综合分析，得到当前分析时区内环境误差评估指数，由此评估当前唤醒用户发送语音指令时的周围环境影响程度，基于当前分析时区的周围环境影响程度判断当前语音指令匹配结果的准确程度，提高了用户的语音指令识别的准确性，避免误解用户的意思从而错误的执行。
G10L13/027  ,可扩展发音人的声学模型实现方法、装置 [发明],本申请公开了一种可扩展发音人的声学模型实现方法、装置。包括：响应于多个目标新增发音人的语音合成请求，确定语音合成请求中各个目标新增发音人的目标发音人标识；预设的发音人索引表中确定与目标发音人标识对应的目标新增发音人的目标嵌入向量；基于多个目标新增发音人的目标嵌入向量确定目标声学模型内的目标适配器参数，并将目标适配器参数与目标声学模型进行重新组合，通过组合后的目标声学模型对多个目标发音人的语音合成请求进行响应。本申请解决了相关声学模型多个发音人批输入语音文本进行语音合成时，通过调用各个发音人的自适应模型参数依次对每个发音人的语音文本进行推理，导致推理处理效率较低的技术问题。
G10L15/22  ,一种通过语音控制的信息传输通讯控制方法及系统 [发明],本发明涉及语音控制技术领域，揭露一种通过语音控制的信息传输通讯控制方法及系统，所述方法包括：进行语音交互，在语音交互结果为第一模式时，发起语音通讯请求，完成语音用户的语音通讯控制，得到语音用户的第一信息传输通讯控制结果；在语音通讯模式为第二模式时，采集语音用户的通讯语音，计算通讯语音的噪声强度；在噪声强度不满足预设强度时，对通讯语音进行语音更新之后，返回检测噪声强度的步骤；在噪声强度满足预设强度时，进行语音解码，得到解码文字，并构建语音用户的文字通讯任务，发起文字通讯请求，以通过文字通讯请求完成语音用户的文字通讯控制，得到第二信息传输通讯控制结果。本发明可以提高语音控制的灵活性。
G10L15/22  ,解码处理方法、装置、设备及存储介质 [发明],本申请涉及语音解码技术领域，特别是涉及到一种解码处理方法、装置、设备及存储介质，其中方法包括：基于第一语音命令词对应的解码矩阵，得到预测文本结果；判断所述预测文本结果与预设结果的编辑距离是否小于第一预设阈值；若小于第一预设阈值，将所述解码矩阵以所述预设结果为解码路径进行路径对齐；若在所述解码矩阵中某一时间点对应的音素列中，存在所述预设结果的音素得分值低于第二预设阈值，且最大的音素得分值对应的音素与所述预设结果对应的音素词性不同，则将对应的音素得分值进行修正；若修正后的解码矩阵的识别结果大于第三预设阈值，判定为有效识别。本申请能够以可控的计算耗时和简洁的算法过程实现提升语音识别的准确率。
G10L15/22  ,基于API信息的语音识别方法、装置、设备及存储介质 [发明],本发明属于语音识别技术领域，公开了一种基于API信息的语音识别方法、装置、设备及存储介质。该方法包括：基于用户指令数据，构建训练数据；基于所述训练数据，训练大语言模型，得到初始语音识别模型；基于API定义信息集合，构建提示语，所述API定义信息集合包括多个API定义信息；基于所述提示语，对所述初始语音识别模型进行微调，得到语音识别模型；基于所述语音识别模型，对目标用户指令进行识别，输出识别结果。通过上述方式，在模型训练和推理使用的提示语中加入了对API的描述，使得模型能够额外学习将用户指令判别为特定API的标准，通过嵌入API信息，模型对于API的识别准确率获得了显著提升。
H04L9/40  ,一种语音电网调度系统 [发明],本发明公开了一种语音电网调度系统，本发明通过设置地级认证单元对传输工作音频数据的地级调度机构工作人员进行身份认证，认证成功后由调度传输单元优先对本次传输的工作音频数据分组来进行是否内插判定，基于判定结果对其面部图像数据使用双线性内插算法进行指定倍数放大，选定像素点与工作音频数据中的内容进行对应得到工作音频数据的转换序列，使之对数据的隐藏更加的细粒和琐碎，保证了传输中的工作音频数据的安全，同时语料训练单元对地级调度机构的工作音频数据进行训练，将训练对象延伸到地调工作联系，使语音识别能力覆盖到地级调度机构，提升电网调度防误能力与智能辅助能力，进一步提升调度智能化水平。
H04L9/40  ,音频加密方法和音频解密方法 [发明],本申请提供了一种音频加密方法和音频解密方法。该方法包括：获取用户的待加密音频；对待加密音频进行音色转换处理，得到加密音频；将加密音频发送至音频接收端。该方法解决了现有技术中传统的语音加密技术无法保证用户的音色不被泄露的问题。
G10L17/22  ,一种基于深度学习的多功能语音交互装置 [发明],本发明提供了一种基于深度学习的多功能语音交互装置，属于语音交互领域，装置包括：人机交互模块，用于为用户提供人机交互界面，接收用户输入的语音及指令，并显示语音文本及情绪类别，播放多风格语音；语音识别模块，用于基于深度学习模型，对用户输入的语音进行文字识别及情绪识别，得到语音文本及情绪类别；语音合成模块，用于基于语音合成模型，根据用户输入的语音生成多风格语音。本发明提高了语音交互的灵活性，并将情绪识别加入语音识别中，可以根据语音同时识别出文字和情绪，使得语音交互更加贴近实际交流场景。
G10L15/00  ,一种多语种全语音处理方法、装置、设备以及存储介质 [发明],本发明公开了一种多语种全语音处理方法、装置、设备以及存储介质，所述方法包括：获取待识别的语音数据；将所述语音数据转化为对应的文本数据；将所述文本数据输入一预设的多语种语言处理模型，以使所述多语种语言处理模型提取所述文本数据的语言特征，并对所述语言特征进行识别处理，输出所述文本数据对应的用户意图；根据所述用户意图，匹配与所述用户意图对应的用户服务路径；其中，所述多语种语言处理模型以若干不同语种的文本数据样本为输入，以各文本数据样本对应的用户意图为输出，对一预设的深度学习模型进行训练而成。通过本发明可以实现多语种环境下的语音识别，提高语音识别的效果。
G10L25/51  ,一种车内音效识别方法、装置及相关设备 [发明],本公开提供一种车内音效识别方法、装置及相关设备，涉及车联网的技术领域，包括：接收目标终端发送的多声道音频数据，所述多声道音频数据为所述目标终端采集目标车辆播放的目标音频获得的音频数据；将所述多声道音频数据拆分为左声道音频数据和右声道音频数据；根据所述左声道音频数据和所述右声道音频数据，分别计算左声道强度数据和右声道强度数据，其中，所述左声道强度数据用于指示所述目标音频在所述目标终端的左声道采集模块对应的声音强度，所述右声道强度数据用于指示目标音频在目标终端的右声道采集模块对应的声音强度；基于左声道强度数据和右声道强度数据确定目标车辆的音效类别。本公开能便利用户对车内音效类别的确定。
G10L15/22  ,一种应用于AI数字人语音交互方法及系统 [发明],本发明公开了一种应用于AI数字人语音交互方法及系统，该方法包括：获取说话人的语音，并根据所述说话人的语音获得文本特征和语调特征；对所述文本特征和所述语调特征进行交互特征提取，得到文本语调交互特征和语调文本交互特征；将所述文本语调交互特征和所述语调文本交互特征输入注意力网络，得到注意力权重；根据所述注意力权重对所述文本语调交互特征和所述语调文本交互特征进行叠加融合，得到情感融合特征，并根据所述情感融合特征得到所述说话人的语音的情感分类。本发明通过融合文本特征和语调特征，提高了AI数字人情感识别的准确性。
H04M3/22  ,一种非标语料的用户感知评测方法及装置 [发明],本申请提供了一种非标语料的用户感知评测方法及装置，涉及无线传输技术领域，所述方法包括：接收主叫终端发送的不同原始音频和相应原始音频的第一用户体验质量评分值；对经过网络传输处理后的不同原始音频进行评测，得到相应第二用户体验质量评分值；计算不同原始音频对应的第一用户体验质量评分值和相应第二用户体验质量评分值的差，得到不同原始音频对应的非标语料的差分值；统计不同原始音频对应的非标语料的差分值，得到用户感知评测结果。
G10L25/51  ,一种基于音律识别的乐器节奏分析系统 [发明],本发明公开了一种基于音律识别的乐器节奏分析系统，音乐提取器、音律预处理模块、信号缓冲放大模块、V/F转换模块、程控增益模块、音律特征提取模块、干扰消除模块、控制信号产生模块、音律特征对比模块、音乐节奏输出模块、音乐数据储存模块、音频能量输出模块、音乐数据相似鉴定模块和音乐对比结果输出模块，本发明一种基于音律识别的乐器节奏分析系统，能够快速对演奏的音律进行识别以及分析，通过该系统，能够快速的对演奏中出现的节奏问题进行及时的纠正，让演奏者能够在演奏练习的过程中，即时的进行纠错，然后增加演奏的效果。
G08B21/02  ,校园异常事件的处理方法、智能手表和电子设备 [发明],本申请提供了一种校园异常事件的处理方法、智能手表和电子设备，该方法通过根据用户所处环境的当前音频、当前生理信息和地理位置信息，来确定是否开始采集用户所处环境的当前音视频，以避免没有必要的当前音视频的采集，再根据当前音视频的音频和当前生理信息，确定最终得分，并根据最终得分所处的范围，执行对应的等级处理方式，即实现了根据实际事态发展来进行判断的目的，从而解决了现有方案采集佩戴者周围环境数据，并没有根据实际事态发展情况，提供分级别的处理方案问题。
G10L15/22  ,一种语音控制的智能升降桌 [发明],本发明涉及智能升降桌的技术领域，特别是涉及一种语音控制的智能升降桌，包括桌面和升降桌腿，桌面的下方安装升降桌腿；还包括多个检测器、两个电机、两个拾音器、两个透音盖板和智能模组，多个检测器均匀安装在桌面的边缘处，两个电机分别安装在桌面的两个槽口底部，两个拾音器分别安装在两个电机的转子轴上，两个透音盖板分别安装在所述两个槽口顶部，智能模组中设置录入模块、控制单元、语音识别单元和用户跟踪单元，控制单元与升降桌腿电性连接，多个检测器和两个电机与用户跟踪单元电性连接，语音识别单元和录入模块与两个拾音器电性连接；其能够自动识别并使拾音器跟踪用户，拾音及时准确，避免误操作，提高智能升降桌的使用体验。
G10L21/0208  ,一种滤除变压器振动噪音的声波检测方法 [发明],本发明涉及变压器振动噪音声波检测技术领域，具体为一种滤除变压器振动噪音的声波检测方法，分别采集变压器在非故障和故障情况下的振动噪音数据信号，转换得到对应的时频谱图，在变压器自身存在振动噪音的基础上识别出与故障相关的特征频率，提取出故障特征点，建立变压器的有限元仿真模型，从有限元仿真模型中获取与变压器故障相关的特征，将其作为神经网络模型的输入，对神经网络模型进行训练，训练好的神经网络模型可以对输入的实际检测到的变压器振动噪音时频谱图进行自动识别，实现变压器故障的分类推断。
H04B13/02  ,一种超短脉冲水下声信号多通道接收方法与系统 [发明],本发明涉及水下通信技术领域，本发明提供了一种超短脉冲水下声信号多通道接收方法与系统，包括：集成了自主学习模块，可根据环境参数自动调整接收参数以优化信号质量；使用动态声束形成模块，实时调整接收阵列的灵敏度方向，以跟踪和定位多个目标；集成有机器学习算法，通过历史数据和实时数据自动优化滤波器和放大器参数，提高信号处理效率和定位精度。这个系统通过整合多种先进的技术和模块，为在水下环境中进行声信号接收和处理提供了高效、准确的解决方案，具有广泛的应用前景，尤其在水下导航、定位等领域有着重要的实用价值。
G06F16/332  ,一种数据处理方法和装置 [发明],本发明公开了一种数据处理方法和装置，涉及数据处理技术领域。该方法的一具体实施方式包括：接收客户端采集的用户回答每个问题的人脸图像数据，基于人脸表情识别模型，识别每帧人脸图像数据中的表情特征，确定每个表情特征的情绪类型；确定每个情绪类型的开始时间和结束时间，将情绪类型、开始时间、结束时间、每个问题的第一参数，输入情绪数值计算模型中，得到用户回答所述每个问题的情绪数值；确定用户回答每个问题的正确率，将情绪数值、正确率、每个问题的第二参数输入综合评价模型中，得到用户回答所有问题的综合评分，将综合评分返回给客户端进行显示。该实施方式加入表情识别机制，分析用户回答问题的情绪波动情况，便于面试官决策。
G10L19/16  ,一种音频转换方法、装置、设备及介质 [发明],本公开实施例涉及一种音频转换方法、装置、设备及介质，其中方法包括：获取音频文件标识，并根据音频文件标识在对象存储服务中获取源音频文件，对源音频文件进行处理，得到解密音频流，获取目标音频格式，根据源音频文件的源音频格式和目标音频格式确定音频转换适配器对解密音频流进行处理，得到目标格式音频流。采用上述技术方案，利用定制化来进行音频流的格式转换，提供音频转换适配器用于对音频数据进行处理和转换，可以快速便捷实现各种音频格式的转换，无需深入了解底层的音频处理和编解码细节，而不需要依赖和安装音频转换的运行环境。
G10L21/0232  ,语音唤醒处理方法、装置、存储介质及电子设备 [发明],本申请公开了一种语音唤醒处理方法、装置、存储介质及电子设备，涉及音频处理技术领域，该方法包括：获取待处理语音信号；对待处理语音信号进行自适应滤波回声消除处理，得到误差信号；采用非线性后处理网络，基于后处理输入信号及待处理语音信号进行回声消除非线性后处理，得到回声消除信号；采用唤醒网络，基于回声消除信号进行唤醒检测处理，非线性后处理网络与所述唤醒网络为联合进行对抗训练得到的，其中，对抗训练中非线性后处理网络作为生成器且所述唤醒网络作为判别器，所述对抗训练的目标为所述判别器对所述生成器生成的数据的真假识别准确性越来越高。本申请可以能够增强唤醒率的同时降低唤醒处理流程自身导致的误唤醒率。
G10L25/30  ,基于多层卷积稀疏编码的传动装置故障定位优化方法 [发明],本发明涉及一种基于多层卷积稀疏编码的传动装置故障定位优化方法，属于机械故障诊断领域。该方法包括以下步骤：根据被测传动装置设计合适的麦克风阵列；利用麦克风阵列采集被测传动装置的声学信号；根据采集的声学阵列信号和成像算法生成被测传动装置的故障定位图；构建基于多层卷积稀疏编码的传动装置故障定位优化模型；将生成的故障定位图作为测试集，输入到训练好的传动装置故障定位优化模型中，得到传动装置故障定位优化结果。本发明优化了原本声学检测方法在传动装置故障定位上不够精确的问题，实现了具有较高精度的传动装置故障定位。
G16H50/20  ,一种基于大语言模型的疾病问诊过程辅助信息生成方法 [发明],本发明公开了一种基于大语言模型的疾病问诊过程辅助信息生成方法，属于医疗问诊领域。该方法主要包括以下步骤：一、信息识别：系统自动记录医生与患者的交流内容，支持语音和文本输入，将语音输入转换为文本，然后理解对话内容，提取关键信息，根据关键信息在疾病库中匹配相应疾病作为参考。二、病例信息生成与导出：自动整合问诊内容、病史、症状、体征等，根据整合信息，自动生成病例模板，医生可根据需要编辑病例模板和相关信息，再将编辑好的病例以文本、PDF等格式导出。本发明能为医生和患者提供一个便捷、高效的疾病问诊过程的辅助信息生成功能，有助于提高医疗服务的质量和效率。
G06F3/01  ,一种虚拟数字人的交互方法及装置 [发明],本发明提供一种虚拟数字人的交互方法及装置，获取包含身份信息和业务信息的前置信息，从标签库中提取身份信息对应的用户标签，基于业务信息和用户标签，获取相应的外貌信息和发音信息，基于外貌信息生成并展示虚拟数字人，获取用户输入的交互信息，匹配得到交互信息对应的语音回复信息和动作回复信息，基于动作回复信息控制虚拟数字人执行相应的动作，并基于发音信息和语音回复信息播放语音。在本方案中，获取包含身份信息和业务信息的前置信息，在标签库中查找身份信息对应的用户标签，基于业务信息和用户标签生成虚拟数字人，控制虚拟数字人与用户进行交互从而提供服务，从而实现了根据用户标签提供相对应的交互服务，提高用户体验感的目的。
G10L15/18  ,语音信息处理方法及装置 [发明],本说明书涉及智慧医疗技术领域，尤其涉及一种语音信息处理方法及装置。其中所述语音信息处理方法，包括：采集术者在手术过程中的语音信息；获取手术机器人的状态数据和病灶区域的图像数据；根据状态数据和图像数据提炼语音信息的语义，得到第一语义提示信息；发送第一语义提示信息，以向术者的辅助医护人员呈现第一语义提示信息。本说明书实施例可以结合手术机器人的状态数据和病灶区域的图像数据等术中信息，提炼语音信息的语义，从而向辅助医护人员呈现语义提示信息。避免了由于手术现场噪音的存在造成手术信息传递不及时、不准确等情况，从而降低了手术风险。
G10L17/02  ,一种用于提升语音外呼辨音准确率的声纹识别方法 [发明],本发明涉及语音识别技术领域，具体涉及一种用于提升语音外呼辨音准确率的声纹识别方法，包括采集待识别语音信号，并对语音信号进行预处理，得到预处理信号。将所述预处理信号分帧，并对每一帧进行小波包变换，得到多个频带。对多个所述频带进行频域线性预测，以提取语音信号的谐波信息和声道信息，得到语音特征。将所述语音特征进行聚合，得到每个说话人的声纹特征，本发明提供了一种创新性的声纹特征提取方法，通过使用小波包变换、频域线性预测等技术，对语音信号进行高效、准确的特征提取。解决了现有的语音识别技术在语音外呼领域中的准确率较低的问题。
G10L25/51  ,储能变流器PCS故障检测方法及相关装置 [发明],本申请公开了一种储能变流器PCS故障检测方法及相关装置，方法包括：获取PCS实时运行时的音频数据集合；对音频数据集合进行数据预处理，得到运行音频数据对应的第一音频段数据集合和环境音频数据对应的第二音频段数据集合；通过特征提取得到第一特征信息；根据第一特征信息对第一音频段数据集合进行降噪处理，得到待检测音频段数据集合；根据待检测音频段数据集合和标准音频段数据集合，判断PCS是否发生故障；若发生故障，则确定故障类型并生成故障检测报告；发送故障检测报告。如此可以实现，通过对音频数据的降噪处理和数据分析判断PCS是否故障，并对应性生成故障检测报告，更有利于PCS的正常运行和维护的及时性。
G10L15/26  ,一种基于最优运输方法的跨模态表示方法 [发明],一种基于最优运输方法的跨模态表示方法，涉及语音翻译方法领域，主要包括以下步骤：构建多任务通用框架的最优运输模型；采用最优运输方法实现跨模态表示，包括定义离散概率分布、利用最优运输模型找到运输成本最低的运输计划、利用运输成本最低的运输计划找到两个离散概率分布之间的最优传输方案和训练损失函数。本发明在模型输入端缩小了语音和文本之间的模态差异，能够更准确地捕捉语音信号和文本之间的对应关系。通过缩小模态差异并提高关联性，本发明的方法能够在语音翻译任务中实现更高的性能。本发明注重处理语音翻译模型输入模态之间的差异，更适用于广泛的语音翻译任务，尤其是在标记数据有限的情况下，表现更为出色。
H05B47/12  ,基于HDMI视频色彩识别与音频同步灯光显示方法及系统 [发明],本申请涉及一种基于HDMI视频色彩识别与音频同步灯光显示方法及系统，该方法包括通过实时获取播放中的视频内容，获取HSL色彩数据和PCM格式的音频；同时将所述HSL色彩数据转换为RGB色彩数据、所述PCM格式的音频转换为对应的频率域；显示区域根据所述RGB色彩数据和所述频率域，展现灯光律动效果，以实时且同步地反映所述播放中的视频内容的色彩和音频。从而提供更加真实准确的律动效果显示。
G10L25/84  ,基于OTA场景的语音端点检测方法、系统、设备及存储介质 [发明],本发明提供了基于OTA场景的语音端点检测方法、系统、设备及存储介质，该方法包括：对音频帧序列中未被识别的音频帧依序进行逐帧识别获得对应各类标签的置信度；当最大置信度大于预设第一阈值且为人声标签，则将语音状态转化为人声状态，标记当前音频帧为人声起点帧；当最大置信度大于预设第一阈值且为非人声标签，则对非人声持续帧数进行加一累计，当非人声持续帧数大于预设第二阈值时，将语音状态转化为后置非人声状态，标记当前帧为人声结束帧。本发明能够在OTA语音搜索场景中可以实时处理移动设备传入的音频数据块，极大提升了对复杂噪声场景的鲁棒性，提高了人声起止点判定的精准度。
H04L67/12  ,基于通讯标识信息的物联网通信平台和物联网通信方法 [发明],本发明涉及物联网领域，公开了基于通讯标识信息的物联网通信平台和物联网通信方法，该平台包括物联网设备、云端服务器、设备智能管理模块、应用服务器、网络服务器及档案信息管理器；该基于通讯标识信息的物联网通信方法包括以下步骤：收集各种类型的数据，并将数据转换为数字信号；对转化为数字信号的数据进行存储、分析、处理及展示，并提供服务及应用；对物联网设备进行智能化的管理；通过若干方式与物联网设备交换通信数据；接收、处理和转发应用服务器发送的通信数据；存储和管理预设通讯标识信息的数据库，根据不同的通讯标识信息将通信数据分配给相应的网络服务器。实现对用户的个性化和智能化的服务，提高用户体验和满意度。
G10L25/63  ,一种基于语义理解的情绪识别方法及系统 [发明],本发明公开了一种基于语义理解的情绪识别方法及系统，其中方法包括：获取语音信息；根据语音信息，得到对应语音信息中的关键词；根据所述关键词在预设情绪等级表中查询，得到关键词对应的第一情绪等级；获取对应关键词的位置以及数量信息；根据关键词的位置以及数量信息，得到关键词对应的第一情绪等级的概率值；获取对应关键词的声音特征以及对应特征值；根据对应关键词的声音特征值，得到关键词对应的第二情绪等级；根据关键词对应的第一情绪等级、第一情绪等级的概率值和第二情绪等级，得到对应语音的情绪等级。本发明通过语义和声音的特征进行结合，提高了情绪识别的准确性。
G10L15/26  ,基于大语言模型的语音自动化操作方法、装置、电子设备和存储介质 [发明],本申请提供一种基于大语言模型的语音自动化操作方法、装置、电子设备和存储介质，其中，基于大语言模型的语音自动化操作方法包括：接收用户输入的控制语音；将控制语音作为大语言模型的输入，以使大语言模型输出控制语音的识别文本，并基于控制语音的识别文本提取第一文本内容和第二文本内容，以及使大语言模型确定第一文本内容的提示词和第二文本内容的提示词，并基于预回答模板输出第一文本内容、第二文本内容和第一文本内容的提示词、第二文本内容的提示词；基于第一文本内容、第二文本内容和第一文本内容的提示词、第二文本内容的提示词确定操作指令；执行操作指令。本申请能够基于用户输入语音执行操作指令，并提高大语言模型回答的准确性。
G10L21/0208  ,一种基于集合经验模态分解法(EEMD)联合改进小波阈值的声音信号降噪方法 [发明],本发明公开了一种基于集合经验模态分解法(EEMD)联合改进小波阈值的声音信号降噪方法，涉及信号处理和噪声控制领域，包括以下步骤：S10，确定含噪声音信号；S20，对声音信号进行初步降噪；S30，对含噪IMF分量进过改进后的小波阈值进行二次降噪处理；S40，将分量进行信号重构，得到降噪后的声音信号；S50，验证基于EEMD联合改进小波阈值的声音信号降噪方法的优越性；本发明的有益效果：该方法利用EEMD分解算法良好的自适应性，并结合小波分解能同时处理高低频噪声的特点，减少外部因素对信号的干扰。最后通过实验结果表明，本发明提出的联合降噪方法与其他降噪方法对比，所得到的信噪比最高提升约62%，均方根误差值为最低的0.124。用来对复杂钻井环境下的声音信号降噪方法的具有更好的优越性。
G10L21/007  ,音频信号处理方法、系统、计算机设备及存储介质 [发明],本发明涉及音频信号处理技术领域，公开了一种音频信号处理方法、系统、计算机设备及存储介质。方法包括：通过音频传输设备接收原始音频信号，并进行时钟同步和数据传输，得到第一音频信号；将第一音频信号输入音频信号调制模型进行音频信号调制，得到第二音频信号；对预置的初始音频传输模型进行初始化，并通过初始音频传输模型对第二音频信号进行音频信号传输，获取音频传输监控参数；对音频传输监控参数进行传输特征提取，得到多个音频传输监控特征，并通过多个音频传输监控特征进行传输参数优化，生成目标参数策略；根据目标参数策略，对初始音频传输模型进行参数优化，得到目标音频传输模型，进而提高了音频的实时传输质量。
G10L25/51  ,一种基于BP神经网络燃气调压器声发射故障诊断方法 [发明],本发明涉及一种基于BP神经网络燃气调压器声发射故障诊断方法，具体步骤包括，S1、对声发射信号进行预处理，划分得到训练集和测试集；S2、采用BP神经网络的方法，构建以燃气调压器的运行参数为输入，以燃气调压器的运行状态为输出的故障诊断模型；S3、通过训练集数据对BP神经网络模型进行训练，通过调整模型参数来优化模型；S4、将测试集数据输入故障诊断模型，得到燃气调压器当前运行的状态，判断燃气调压器当前是否处于故障状态。本发明具有如下优点：直接利用声发射时域信号对调压器的运行状态进行诊断，基于BP神经网络调压器故障判别准确率达95%以上。
G10L15/06  ,语音识别方法、装置、电子设备及计算机可读存储介质 [发明],本申请提供了一种语音识别方法、装置、电子设备及计算机可读存储介质，其中，该方法包括：获取使用通用训练样本训练得到的通用语音识别模型；使用目标垂域训练样本对通用语音识别模型进行迁移学习，以得到训练完成的垂域语音识别模型；将属于目标垂域的目标语音数据输入到训练完成的垂域语音识别模型，并结合目标垂域中的热词，以得到目标语音数据的识别结果。通过该方法，有利于保证使用垂域语音识别模型对属于目标垂域的目标语音数据进行语音识别的准确度。同时，还在使用垂域语音识别模型时，利用了热词进行辅助，进一步提高了识别结果的准确度。
G10L15/18  ,一种基于上下文关联的说话人识别方法 [发明],本发明公开了一种基于上下文关联的说话人识别方法，涉及语音识别领域。本发明包括以下步骤：切割音频文件中的说话音频片段；针对每段音频片段对人声部分提取，获得音色特征数据和对应的说话内容；按照音频片段中每个音频的时间长短进行降序排列得到待处理的音频段；根据音色特征数据和对应的说话内容对每个音频段确定出说话人，完成说话人标记。本发明效果可控。整体优于目前市面上单模态的说话人识别方案。自然语言处理的上下文部分，算法效果可控，可以针对不同的行业来使用数据源进行训练，提高上下文预测准确率。
G10L15/07  ,语音识别方法、系统及计算机可读存储介质 [发明],本发明公开了语音识别方法、系统及计算机可读存储介质，属于语音识别技术领域。本发明基于用户基础信息，确定用户的口音导向量集，并获取用户的语音数据信息，并输入至表征向量提取层利用口音编码器提取口音相关特征，根据提取口音相关特征构建用户口音特征向量；将所述口音特征向量输入到自适应层，并以用户的口音导向量集作为初始指导选择正确的用户的口音导向量；将用户的口音特征向量输入至识别层，以正确的用户口音导向量作为识别层引导向量，引导修正用户的口音特征向量并进行语音识别。本发明能够在一定程度上提高语音识别的效率和准确度。
G10L15/22  ,车载语音答题交互方法、装置、设备及存储介质 [发明],本申请提供一种车载语音答题交互方法、装置、设备及存储介质。该方法包括：根据车辆的乘坐人员的位置分布，确定目标题目集合、每个目标题目答题人员的位置信息以及答题顺序；根据答题顺序触发目标题目集合中的各问答指令，问答指令中携带答题人员的位置信息；在每个问答指令的预设答题时间阈值内，采集车辆内部的语音信息；在语音信息中，根据各问答指令中携带的位置信息提取对应位置的答案语音；根据答案语音识别出对问答指令的答题结果，并得到目标题目集合对应的答题结果。本申请的方法，提高了车载语音答题交互的用户体验。
G10L25/51  ,在线考试智能管理系统及方法 [发明],本发明公开了一种在线考试智能管理系统及方法，其获取被监控考生群体的人声声波图；提取所述人声声波图的声波时序波动特征以得到人声声波波形时序波动特征向量；提取所述人声声波图的全时域声波语义特征以得到全时域人声声波语义特征向量；以及，基于所述人声声波波形时序波动特征向量和所述全时域人声声波语义特征向量，确定是否产生考场异常提示。这样，可以通过对考生群体的人声信息进行基于声波波形的多维度分析来捕捉考场的异常情况，并及时产生考场异常提示，以提醒相关监考人员采取措施。
G10L15/06  ,一种基于FPGA实现的养老服务机器人语音识别方法 [发明],本发明基于涉及了一种基于FPGA实现的养老服务机器人语音识别方法，所述方法包括：获取语音数据集，在GPU端训练语音识别模型，将模型经过压缩之后部署在FPGA中，在FPGA中进行语音识别，将语音识别结果返回到养老服务机器人中，养老服务机器人进行相应的操作，所述语音识别模型为CNN‑LSTM模型，压缩方法为定点量化和TOP‑K剪枝，本发明通过以FPGA作为硬件平台，鉴于FPGA在深度神经网络加速方面得可行性，设计了一个持稀疏LSTM推理网络的硬件加速架构，实现了在FPGA上进行特定场景的语音识别，减少了计算量和存储量。
H04H60/51  ,定向广播的动态控制方法、装置、设备及存储介质 [发明],本发明涉及定向广播技术领域，公开了一种定向广播的动态控制方法、装置、设备及存储介质，用于提高多场景定向广播的动态控制准确率。包括：将频率特征集合输入广播场景分析模型进行场景分析，得到目标广播场景；对每个音频设备的初始音频信号数据对应的频率特征集合进行高频压缩策略构建，生成目标高频压缩策略；对每个音频设备的初始音频信号数据对应的频率特征集合进行高频压缩处理，得到处理后的候选音频信号数据；对候选音频信号数据进行动态控制范围计算，得到候选音频信号数据对应的动态控制范围，通过动态控制范围，对候选音频信号数据进行动态控制，生成对应的目标音频信号数据。
G10L21/0208  ,声反馈抑制方法、系统、语音播放设备及可读存储介质 [发明],本申请公开一种声反馈抑制方法、系统、语音播放设备及可读存储介质。其中方法可以获取麦克风在当前时刻采集的第一语音信号和第一语音信号对应的参考语音信号，根据参考语音信号解除第一语音信号与对应源信号之间的相关性，得到第二语音信号，再获取第二语音信号对应的语音频域信号和参考语音信号对应的参考频域信号，分别将语音频域信号和参考频域信号进行分段处理，得到多个频段分别对应的语音段信号和参考段信号，分频段对至少一组中语音段信号进行声反馈抑制处理得到对应滤波频域信号，根据各个滤波频域信号生成当前时刻的输出语音信号。本申请能够有效减少声反馈抑制处理过程的计算量，使得声反馈抑制方案具有更强的实时性。
G10L15/18  ,用于语音交互的规则模板的处理方法、服务器及存储介质 [发明],本申请公开一种用于语音交互的规则模板的处理方法，所述方法包括：在第一语音请求与至少两个规则模板形成匹配的情况下，根据至少两个规则模板分别生成相对应的第二语音请求，对第二语音请求的相同元素进行去重处理，根据去重处理的结果对至少两个规则模板进行更新处理以得到相应的目标规则模板。如此，本申请的服务器可根据能与第一语音请求形成匹配的至少两个规则模板，生成第二语音请求，及利用第二语音请求的相同元素处理结果，对规则模板进行更新处理，使得第一语音请求与一个目标规则模板形成匹配，在后续利用目标规则模板进行语音交互的过程中，一个语音请求与一个目标规则模板形成匹配，使得语音交互得以可靠地执行。
G06F40/30  ,基于智慧家庭的语义纠错方法 [发明],本发明公开了一种基于智慧家庭的语义纠错方法，包括：确定所有的智能设备以及智能设备所对应的能力集，对所有的能力集按照控制的指令词进行分类，并按照指令词的类别进行语法组合形成语法规则；获得语音识别的文本结果，检测文本结果中的指令词，判断是否为完整语音控制指令，如否，则检索是否存在指令词；统计所有可能对应的指令规则中缺少的类别词，遍历所有缺少的类别词，并与文本结果中所有的未匹配到的词进行相似度估计，当相似度满足阈值要求则匹配成功，将匹配成功的指令词进行替换；若替换后指令语句完整匹配语法规则，则输出进行设备控制；本发明能够很好的改善在语音识别中的误识别，提高用户体验。
G06F40/216  ,一种确定车主更换方法及装置 [发明],本申请提供了一种确定车主更换方法，包括，确定预测的情感回归方程与车主下一周期真实的情感回归方程差之间的斜率是否满足预设变更条件，确定当前周期内目标词汇对应的第一向量矩阵与下一周期内目标词汇对应的第二向量矩阵之间的相似度是否大于相似度阈值，确定当前周期获取的语音数据中的高频词汇在下一的语音数据中的出现次数与在当前周期的中的出现次数差距是否大于第一阈值，或，当前周期获取的语音数据中的低频词汇在下一周期的中的出现次数与在当前周期中的出现次数差距是否大于第二阈值，当满足上述条件中的至少一个条件时，确定车主发生变更，由此，可以看出，在确定车辆是否进行车主更换时，无需人工参与，因此可以减少人力资源的浪费。
G10L15/06  ,语音识别模型的训练方法、语音识别方法、装置和设备 [发明],本发明提供一种语音识别模型的训练方法、语音识别方法、装置和设备，该语音识别模型的训练方法包括：获取语音信号和含噪语音信号，所述语音信号和所述含噪语音信号为对同一语音进行采集得到的；分别将所述语音信号和含噪语音信号输入至初始语音识别模型中，得到所述初始语音识别模型输出的所述语音信号对应的语音特征向量和含噪语音信号对应的含噪语音特征向量；基于所述语音特征向量和所述含噪语音特征向量，调整所述初始语音识别模型的模型参数，得到所述语音识别模型。本发明实施例提供的语音识别模型的训练方法、语音识别方法、装置和设备能够提高噪声场景或者多说话人的场景中的语音识别效果。
G10L21/0208  ,一种目标噪声分离方法、系统及终端设备 [发明],本发明提供的一种目标噪声分离方法、系统及终端设备，包括：基于编码器构建深度神经网络模型并训练得到深度神经网络音轨分离模型；获取具有目标噪声和环境噪声的待分离混合音频信号，将其混合噪声幅度特征时域图输入深度神经网络音轨分离模型中，通过编码器的融合层将从混合噪声幅度特征时域图中提取的上下文特征和幅度特征进行融合得到目标噪声的幅度特征时域图；上下文特征表征待分离混合音频信号中各个声源的分布结构信息；依据目标噪声的幅度特征时域图得到目标噪声的时域信号。本发明利用深度神经网络音轨分离模型能获得高精度的幅度特征和上下文特征，能转准确分离环境噪声和目标噪声，解决了目前无法同时兼顾准确度和保真的缺陷。
G06F40/58  ,实时视频直播的云计算生成式翻译方法、装置及存储介质 [发明],本发明提供实时视频直播的云计算生成式翻译方法，包括以下步骤：捕获实时直播视频流，并将其实时传输到云服务器；视频流到达云端后，对其进行预处理；预处理后的文本数据被送入到生成式AI翻译模型进行实时翻译；翻译完成的文本根据用户的设置，转换为相应的输出格式；处理后的视频流连同翻译结果，通过云服务器传回用户端；实时翻译包括：确定适合的深度学习模型架构；从语料库中提取关键特征；使用预处理后的数据训练翻译模型；通过调整模型参数，优化翻译的准确性和效率；在独立的测试集上验证模型的翻译效果；将模型集成到云平台，测试整体系统性能。本发明采用生成式AI模型，基于深度学习的神经网络，显著提高了翻译过程中的处理速度和效率。
G10L21/0208  ,一种基于云边端协同的噪声库构建方法及装置 [发明],本发明公开了一种基于云边端协同的噪声库构建方法及装置，根据噪声分布特征模型对边侧接收数据进行噪声消除，得到边侧接收数据的误码率；根据误码率对云边知识图谱的融合策略进行修正，更新云边知识图谱的融合权重参数，并计算得到噪声分布特征的精度欠缺值后，对端侧噪声采集频率上限进行修正，得到端侧噪声采集频率上限，并根据端侧噪声采集频率上限得到噪声分布特征；根据噪声分布特征构建第二噪声知识图谱，并根据融合权重参数和补充融合方法对第二噪声知识图谱进行补全融合，得到广域噪声知识图谱；分析广域噪声知识图谱分析，得到电力线噪声库，完成噪声库构建，能够获取广域电力线噪声分布特征并修正噪声采集方案，提高噪声建模精度。
G10L15/06  ,基于改进LSTM的语音识别模型剪枝方法 [发明],本发明涉及一种基于改进LSTM的语音识别模型剪枝方法，属于语音数据处理领域。S1：初始化基于改进LSTM的语音识别模型；S2：对语音识别模型进行训练；S3：将训练好的参数进行Top‑k剪枝。本发明的方法引入了一种面向硬件的压缩算法，该算法包括结构化的Top‑k剪枝、无乘法量化，在确保精度的情况下可以大大减少语音识别的模型大小。
G10L25/51  ,音阶评分方法、装置、计算机设备和存储介质 [发明],本申请涉及一种音阶评分方法、装置、计算机设备和存储介质。所述方法包括：获取待评分音频对应的初始频率数据，并对初始频率数据进行平滑处理，得到平滑频率数据；将待评分音频输入训练好的歌词对齐模型，得到待评分音频中歌词对应的时间序列，并将平滑频率数据与歌词对应的时间序列合并，得到待评分音频对应的第一对齐频率数据；基于模板音频的第二对齐频率数据中歌词的区间长度，将第一对齐频率数据中歌词的区间长度进行等比缩放，得到待评分音频对应缩放后的缩放频率数据；确定第二对齐频率数据对应的频率范围，并根据缩放频率数据与频率范围的匹配度，确定缩放频率数据对应的音阶评分，作为待评分音频的音阶评分。
G10L21/007  ,一种语音通话中回声消除和防抖动技术方法 [发明],本发明属于智能通话技术设备领域，尤其涉及一种语音通话中回声消除和防抖动技术方法，包括采集音频输入信号过程、滤波器计算后产生输出信号过程、对输出信号与期望信号比较并计算误差信号过程和采用智能滤波算法对系数进行自动调整并学习而获得最优滤波过程。本发明利用智能滤波器算法，将输入和输出的信号等参数根据误差的大小来自适应地调整权值系数，使滤波器的输出尽可能的接近最优信号，同时，滤波器能在工作过程中学习或跟踪信号特性并重新调节参数，以达到最优滤波效果，最终实现高保真、高清晰的电信级语音品质，为煤矿调度系统通话质量提供良好的支持。
G10L15/26  ,测试数据生成方法、服务器及存储介质 [发明],本申请公开了一种测试数据生成方法，包括：根据历史语音请求以及历史语音请求的统计数据，确定历史语音请求对应的意图槽位点；根据意图槽位点的内容与数量，确定每个意图槽位点对应的测试数据。本申请能够根据历史语音请求的内容与统计结果，将历史语音请求中的语音内容进行归类组合得到历史语音请求对应的意图槽位点，并进一步通过对意图槽位点的内容与数量进行修正，最终确定出测试集中包括的测试数据，也即从用户实际使用的数据出发，确定实际进行测试的测试数据，并随着真实用户使用数据的变化而实时更新迭代，从真实用户的应用角度出发，有效提高了测试集相对于真实场景的准确度与更新速度。
H04N17/00  ,基于主被叫终端的5G新通话用户感知评测方法及装置 [发明],本发明提供了一种基于主被叫终端的5G新通话用户感知评测方法及装置。所述方法包括：主叫终端发送预定时长的主叫语料；经过5G网络传输后在被叫终端接收得到主叫降级语料；采用第一打分模型打分得到被叫终端用户感知评分。本发明通过采用侵入式测试方案，实现了双向输入标准语料的方式，并在此基础上在接收端进行标准语料和回收语料的比对打分，可以对卡顿、花屏等感知问题进行准确评估，且便于生产厂家进行规范化实施执行，具有较好的泛化性。
G06F3/16  ,采用ChatGPT和虚幻引擎增强MetaHuman数字人对话效果的方法及系统 [发明],本发明公开了一种采用ChatGPT和虚幻引擎增强MetaHuman数字人对话效果的方法及系统，涉及人工智能技术领域。本发明将ChatGPT与虚幻引擎结合，增强了自然语言处理，实现更自然、流畅的对话体验，系统具备智能适应上下文和用户需求的能力，提供个性化、贴近需求的互动，从而显著提升对话质量和效率；支持多模态输入，包括文本、语音、图像、手势等形式，用户可选择最适合交互的方式，错误处理机制能够处理ChatGPT返回的不确定、不清楚或错误的答案，并通过用户反馈机制进一步优化对话质量；通过口型动画蓝图控制MetaHuman数字人模拟用户口型，并与生成的语音同步，提升对话真实感，结合虚幻引擎的图形、语音技术和MetaHuman数字人系统，创造出生动、精致的对话体验。
G10L15/06  ,语音交互方法、装置、车辆及存储介质 [发明],本申请涉及一种语音交互方法、装置、车辆及存储介质，其中，语音交互方法包括：获取语音识别信息；将语音识别信息输入前置大模型，以从模型配置信息中确定与语音识别信息对应的至少一个初始处理模型；其中，前置大模型用于对语音识别信息进行垂域的确定，模型配置信息包括至少一个处理模型；基于至少一个初始处理模型对语音识别信息进行处理，以确定目标答复信息。本申请中，可以为不同的语音任务匹配合适的处理模型，可以很好的应对复杂、大规模以多变的语言任务，可以提供更高级、更灵活、更人性化、更优质的语音交互体验，而且便于为语音交互带来了多样化的功能选择、定制能力以及持续的技术更新。
G10L21/0216  ,一种音频信号处理方法、装置、设备及存储介质 [发明],本申请提供了一种音频信号处理方法、装置、设备及存储介质；方法包括：获取待输出声源信号，并获取从环境中采集的音频信号，其中，音频信号包括环境声源信号和环境噪声；确定音频信号中多个频点分别对应的噪声估计值；确定多个频点分别对应的噪声掩蔽值；基于多个频点分别对应的噪声估计值和噪声掩蔽值，确定环境噪声在多个频点上分别对应待输出声源信号的掩蔽强度值；根据多个频点分别对应的掩蔽强度值确定多个频点分别对应的抑制增益值；通过多个频点的抑制增益值和待输出声源信号，生成第一降噪信号。通过本申请，能够结合待输出声源信号实时的播放环境中的听觉掩蔽效应调节抑制增益值，提升最终播放的待输出声源信号的清晰度和可理解性。
G01M13/028  ,一种抽油机传动系统故障检测方法 [发明],本发明公开了一种抽油机传动系统故障检测方法，该方法通过声音传感器采集抽油机正常工作声音数据，通过分帧预处理等操作进行离散傅里叶变换得到频谱分析，利用复系数得到能量谱估计；利用MFCC语音特征提取Mel滤波器构建MFCC静态特征，在此基础上同时融合一阶和二阶动态特征；并将能量特征进行零‑均值标准化作为训练集，采用主元分析计算T2统计量和SPE统计量的控制限；对实时待测数据进行相同预处理操作，计算T2和SPE并判断是否低于控制限。该方法降低了人工巡检强度，对于及早发现抽油机系统故障，避免故障扩大，保障生产安全具有重要价值。
F03D17/00  ,故障识别方法、装置、设备以及存储介质 [发明],本申请公开了一种故障识别方法、装置、设备以及存储介质，属于故障识别技术领域，该方法包括：获取风电机组部件的实时声音数据；判断预设正常声音频谱集合中是否存在至少一个预设正常声音频谱与所述实时声音数据的实时声音频谱一致；若不存在至少一个预设正常声音频谱与所述实时声音数据的实时声音频谱一致，则将所述风电机组部件整体识别为异常状态。本申请只需要通过声音频谱即可确定风电机组部件整体是否存在故障，不需要专业人员进行分析和诊断，从而可以及时发现风电机组部件整体的异常情况，进而避免风电机出现更大的故障。
A61B5/00  ,一种睡眠打鼾监测报警系统及方法 [发明],本发明揭示了一种睡眠打鼾监测报警系统及方法，其中，睡眠打鼾监测报警方法包括如下步骤：使用智能设备以及使用者穿戴的穿戴设备对使用者睡眠过程中周边声音分别进行提取，并形成数据参数；将数据参数与后台打鼾数据库比对，判断使用者是否存在打鼾情况，并将判断结果传输至智能设备中；若确定使用者存在打鼾情况，则判断使用者打鼾异常程度；依据使用者打鼾异常程度，发送指令控制穿戴设备刺激使用者改善睡姿；或者发送指令控制穿戴设备唤醒使用者；或者控制智能设备发出求救信息。本发明通过上述步骤，能够有效提升对使用者打鼾声的监测范围，提高监测灵敏度以及准确性，且改善使用者睡姿或提醒他人对使用者进行叫醒。
G10L21/0272  ,一种电力线载波混合噪声识别分离的方法、装置及介质 [发明],本发明公开了一种电力线载波混合噪声识别分离的方法、装置及介质，所述方法包括：采用发性脉冲压缩感知方法对电力载波混合噪声信号中的突发性脉冲噪声信号进行剥离，得到第一噪声信号；依次对第一噪声信号进行多次去噪，剔除其中的工频异步周期性脉冲噪声信号、有色噪声信号和工频同步周期性脉冲噪声信号，获得第二噪声信号；通过最优信息熵匹配对抗生成网络去除第二噪声信号中的窄带噪声信号，得到识别分离结果。本发明提出一种电力线载波混合噪声识别分离的方法、装置及介质，通过对电力载波混合噪声信号中的不同噪声信号类别，采取不同的识别分离措施，能够解决现有技术无法通过差异化滤除方法对载波混合噪声信号进行有效的识别分离的问题。
G10L15/16  ,语音识别的特征提取方法及装置、电子设备和存储介质 [发明],本公开公开了语音识别的特征提取方法及装置、电子设备和存储介质，将待处理语音信号输入SincNet网络，获取第一语音信号，所述SincNet网络包括预设数量的滤波器，所述第一语音信号包含预设数量的采样点；在分别获取所述采样点对应的幅度值的模平方之后，分别调用预设算法对所述第一语音信号进行计算，得到对应的第二语音信号，将所有所述第二语音信号按照频率范围进行组合，得到目标特征信号。本公开提供了一种将SincNet网络作为滤波器来提取目标特征信号的特征提取方法，可直接对提取到的目标特征信号进行数据增强操作，与相关技术中采用傅里叶变换提取目标特征信号的方法相比，避免了傅里叶变换的操作，简化了计算过程，节约了计算成本，减少了计算时间。
G10L21/0224  ,基于深度学习技术的断路器声纹谱图自适应降噪重构方法 [发明],本发明提供了一种基于深度学习技术的断路器声纹谱图自适应降噪重构方法，具体为：首先对无噪声干扰的声音时域信号x在训练过程中加噪后得到含噪的时域信号x＆lt;subgt;noisy＆lt;/subgt;，对x与x＆lt;subgt;noisy＆lt;/subgt;以相同声纹特征提取方式提取出纯净声纹谱图信号x与含噪声纹谱图x＆lt;subgt;noisy＆lt;/subgt;。然后将x＆lt;subgt;noisy＆lt;/subgt;输入自编码器得到隐层特征，将隐层特征输入解码器得到降噪重构后的声纹数据最后使用平均绝对误差作为损失函数计算与x的声纹谱图之间逐像素点的误差并在训练过程中最小化这个误差，以此使模型自动学习如何从复杂噪声干扰下重构出与纯净声纹数据无差别的新声纹数据。本方法在进行声纹谱图特征去噪重构的同时使用重构过程中的产生的重构误差作为异常检测判据，检测出误截取出的非断路器工作声音的噪声信号并进行剔除。
G10L15/06  ,语音交互质量的评估方法、服务器及计算机可读存储介质 [发明],本申请公开一种语音交互质量的评估方法，所述方法包括：获取目标语音请求，基于历史语音交互模型生成对应于目标语音请求的第一车辆操控指令，基于当前语音交互模型生成对应于目标语音请求的第二车辆操控指令，根据第一车辆操作指令和第二车辆操作指令的异同，评估当前语音交互模型的准确程度，确定通过当前语音交互模型进行语音交互的质量。如此，本申请的服务器可根据历史语音交互模型和当前语音交互模型针对于相同目标语音请求分别生成的第一和第二车辆控制指令的异同，确定当前语音交互模型的准确程度，及通过当前语音交互模型进行语音交互的质量，使得模型替换后的语音交互质量得以确定。
G10L25/51  ,歌曲鉴别方法、计算机设备和存储介质 [发明],本申请涉及一种歌曲鉴别方法、计算机设备和存储介质，涉及音频处理技术领域，能够提高针对合成歌声的鉴别结果的准确性。所述方法包括：获取待鉴别歌曲中人声信号所对应的特征参数；将所述人声信号对应的特征参数输入到训练好的歌曲鉴别模型，由所述歌曲鉴别模型根据所述人声信号对应的特征参数，输出所述待鉴别歌曲的第一鉴别信息；将所述待鉴别歌曲中人声信号对应的音色与各个参考音色进行比对，根据比对结果确所述待鉴别歌曲的第二鉴别信息；所述参考音色包括合成歌声对应的音色；根据所述第一鉴别信息和所述第二鉴别信息，确定所述待鉴别歌曲的鉴别结果。
G10L25/87  ,一种提升语音对话系统响应速度的方法 [发明],本发明涉及一种提升语音对话系统响应速度的方法，给VAD组件设定较长和较短两个等待阈值，较短的阈值用于识别用户连续说话中因换气或梳理思路引起的正常停顿信号，较长的阈值用于识别用户说话的休止信号；遇到短停顿时，系统获取承接句语音和应答语音，承接句用于尽快给用户一个简短的反馈信息，用户听到后就会知道机器人已经准备回答了；遇到长停顿时，系统准备播放回应。引入长短两种停顿阈值，用来处理不同类型的静音间隔，并对两种停顿信号的系统行为进行重新设计；引入承接句，以便在用户说完之后立刻给用户快速回应；采用了流水线的思路，利用短停顿到长停顿的间隔以及承接句前台播放的时间在后台处理获取应答语音，缩短用户等待时间。
G10L15/22  ,语音控制方法、装置、介质及车辆 [发明],本发明公开了一种语音控制方法、装置、介质及车辆，所述方法包括：接收用户的语音指令，当判定所述语音指令未预先定义时，执行以下步骤：对所述语音指令进行语义理解处理，得到语义理解结果；至少基于所述语义理解结果，从整车能力数据库所包含的由车辆提供的多个交互功能中确定目标车辆技能；根据所述目标车辆技能对所述车辆进行控制，从而能够在语音指令未预先定义的情况下，精准预测语音指令所代表的含义并调用相应的交互功能。
G10L15/22  ,一种适用于举高作业平台的人机交互系统、方法、车辆及存储介质 [发明],本发明公开了一种适用于举高作业平台的人机交互系统、方法、车辆及存储介质，属于作业车辆技术领域。系统包括供电单元、控制单元及人机交互单元；控制单元包括主控制器和检测反馈模块；主控制器分别与人机交互单元和检测反馈模块通信连接；人机交互单元接收操作指令并传输至控制单元且输出控制单元输出的信息；主控制器执行培训流程，输出指导信息且根据指令控制设备动作，并接收检测反馈模块输出的操作结果信息，将其与操作指导信息对应的预设操作结果信息比较：若两者一致则结束培训流程，否则根据操作结果信息判断故障类型，并输出与故障类型相对应的故障解除指导信息。本发明实现了操作人员对高空产品的快速上手及对突发故障的有效实时解除。
G10L15/26  ,语音处理方法、装置、终端和存储介质 [发明],本公开提供语音处理方法、装置、终端和存储介质。语音处理方法包括：获取目标语音信息；对所述目标语音信息进行语音识别，得到目标文本；确定所述目标文本中的起始词，在所述目标文本中的所述起始词之前添加标点符号；和/或，确定所述目标文本中的结尾词，在所述目标文本中的所述结尾词之后添加标点符号。本公开的方法提高了目标文本的可阅读性。
H04W4/029  ,一种巡逻警车一体化管理系统及方法 [发明],"本发明涉及一种巡逻警车一体化管理系统及方法，包括指挥中心、移动终端和智慧警车；所述指挥中心接到群众报警电话，报警信息录入后派发给移动终端；派出所民警的移动终端接收到警情短信后，启动智慧警车，根据导航路线行驶到案发地点；在车辆行驶过程中，指挥中心会根据智慧警车实时定位和地址信息、报警地点匹配，匹配成功后，后台引擎自动签到，并完成到场确认；同时将智慧警车的实时位置及行驶路线在指挥中心的可视化模块上进行显示。本发明实现将现场情况及时传回指挥中心,便于远程指挥和调度,降低危险性,极大地缩短反应时间。"
G10L15/18  ,意图识别方法、装置、车辆和存储介质 [发明],本申请提供了一种意图识别方法、装置、车辆和存储介质，该方法应用于车辆技术领域。该方法包括：获取车辆内的车载语音；基于预设概率参数库，确定所述车载语音中相邻词之间的候选概率参数；其中，所述预设概率参数库中包括样本车载语料集合中不同词相邻出现的预设概率参数；基于所述候选概率参数，确定所述车载语音的目标意图切分点集合；基于所述目标意图切分点集合对所述车载语音进行意图识别，得到并输出所述车载语音中的目标意图。该方法能够更加准确地切分出车载语音中的每一个意图，即使车载语音中包含多个意图也不会遗漏车载语音中的意图，从而能够提高对车载语音进行意图识别的准确度。
G10L25/27  ,分析方法及分析系统 [发明],一种分析方法及分析系统，分析方法包含下列步骤。根据至少一动件装置的一动作排程，获取该至少一动件装置在一工序下运行的多个音频段。通过声音特征获取，将该些音频段转换为多笔时间序列数据。根据一基准序列数据，对该些笔时间序列数据进行动态时间规整，以获取多笔调整后序列数据。计算该些笔调整后序列数据中的一部分相对于该基准序列数据的多个相似度得分。根据该些相似度得分，将冗余数据自该些调整后序列数据中的该部分中移除，以产生一训练数据集。
G10L17/02  ,声纹处理方法、装置、设备、存储介质和程序产品 [发明],本申请提供一种声纹处理方法、装置、设备、存储介质和程序产品，包括：获取目标歌手的目标歌曲；对目标歌曲进行特征提取，得到第一声学特征；将第一声学特征输入至歌手声纹提取模型，以通过歌手声纹提取模型对第一声学特征进行特征提取，得到多个第一特征向量，对多个第一特征向量进行人声检测，确定多个第一特征向量中目标歌曲中人声部分对应的多个第一人声向量，对多个第一人声向量进行处理，得到目标歌手的第一声纹信息；其中，歌手声纹提取模型是基于歌曲数据训练得到。以提高确定歌手声纹的准确性，降低确定歌手声纹的成本。
G10L15/02  ,基于LAP的语言能力评估系统 [发明],本发明公开了一种基于LAP的语言能力评估系统，包含：采集模块；处理模块；获取模块；标记模块；分类模块，包含分类模型，通过若干标记好的被试者的多个不同种类的声学特征对分类模型进行训练；采集待检测者的待识别语音信号，对待识别语音信号进行信号预处理和降噪处理，获取待识别语音信号的多个不同种类的待识别声学特征，将获取到的多个不同种类的待识别声学特征输入分类模块，分类模块通过训练好的分类模型输出语音能力分类结果。本发明的基于LAP的语言能力评估系统，通过设定多种检测文本任务采集对应的语音信息，并通过对应的语音信息获取不同种类的声学特征，再通过训练好的分类模型对用户的语音能力进行自动识别。
G10L21/0208  ,一种基于噪声联合估计的改进OMLSA语音降噪算法 [发明],本发明公开了一种基于噪声联合估计的改进OMLSA语音降噪算法，属于语音降噪技术领域。通过对噪声估计模块进行改进，引入了残余噪声，结合小波一级分解近似求得残余噪声的估计值；并利用第一次平滑得到的频谱幅值对求得的残余噪声进行第二次平滑噪声估计，联合两次的平滑噪声估计值在每帧信号中迭代处理、合并更新，由于提高了噪声估计的精度，从而提高了语音质量，减少了语音降噪的失真度。本发明提出二次噪声更新，通过联合降噪后的残余噪声，更准确的更新了噪声估计值，通过平滑噪声处理来减少误差，提高语音的信噪比。此外，本发明可显著提高语音信噪比和语音质量，降低语音的失真度。
G06F18/2433  ,一种基于AI智能识别的智能优化节能系统 [发明],本发明公开了一种基于AI智能识别的智能优化节能系统，具体涉及人工智能技术领域，将待监测设备按照位置区域进行划分，并进行编号；采集区域环境信息和设备运行信息，对采集的数据进行转换和关联，对区域环境进行分析，分析区域的音频信号得到每个区域的音频异常参数ypi；分析区域的温湿度得到每个区域的温湿度异常参数wsi，基于区域内设备的基础信息得到每个区域的权重系数ksi，基于区域的音频异常参数、温湿度异常参数、权重系数，得到每个区域的运行安全风险系数YFi；监测每个区域的音频异常参数、温湿度异常参数，运行安全风险系数，根据监测结果采取对应的措施，解决现有技术中设备监测效率低，不够智能的问题。
G10L15/22  ,信息处理方法、装置、设备、介质、产品和车辆 [发明],本申请公开了一种信息处理方法、装置、设备、介质、产品和车辆，该方法包括：获取第一语音指令，其中，所述第一语音指令为用户一次输入的语音指令，所述第一语音指令中包括至少两个子语音指令，每个所述子语音指令用于指示一项指示事项；对所述第一语音指令进行解析，得到各所述子语音指令的目标类型；根据各所述子语音指令的目标类型，确定各所述子语音指令的优先级；根据各所述子语音指令的优先级，输出各所述子语音指令对应的结果。以实现用户与硬件设备之间的高效简洁交互，提升用户与硬件设备的交互体验。
G06Q50/20  ,一种个性化口才训练方法、系统、设备及介质 [发明],本发明提出一种个性化口才训练方法、系统、设备及介质，方法包括：采集口才表达者在口才训练过程中口才表达者和/或观看者对应的感知数据，感知数据为语音数据、脑电波数据、眼动数据或面部数据中至少一种；基于预先建立的深度学习模型对感知数据进行深度学习与分析，得到不同感知数据所对应的表现特征；表现特征包括语音特征、心理特征、注意力特征、视线特征以及情绪特征；调用信息库，筛选不同表现特征所对应的建议信息。本发明能够全面、准确地分析口才表达者的表现，给予学员个性化的反馈，能够提高口才培训的效率。
G06F40/18  ,一种表单质量检测方法、装置、电子设备及存储介质 [发明],本申请提供一种表单质量检测方法、装置、电子设备及存储介质，该方法包括：获取待检测表单中的待检测字段、待检测字段的字段类型、以及字段类型对应的提示参数；提示参数是预先编写的用于反映字段类型的内容；根据字段类型，将待检测字段和提示参数输入预先训练好的表单质量检测模型，生成质量检测结果；表单质量检测模型是将经过标注的训练数据和训练数据对应的提示参数作为训练实例，对训练实例进行训练获得。利用表单质量检测模型对表单中待检测字段进行质量评估，表单质量检测模型是对不同类型的训练实例进行训练获得的，训练好的表单质量检测模型可以对不同类型的待检测字段进行质量检测，提高质量检测的效率和准确性。
G06F16/35  ,基于大模型和动态知识检索的恶意文本内容审核系统和方法 [发明],基于大模型和动态知识检索的恶意文本内容审核系统和方法，系统包括如下模块：语言模型模块、表征模型模块、动态知识库模块、多模态表征模块和内容分类模块；方法包括如下操作步骤：(1)将待分类文本输入到多模态表征模块；(2)多模态表征模块将待分类文本进行多模态表征处理，分别得到待分类文本的语义表征、字形表征和读音表征，然后将上述表征进行加权融合，得到所述待分类文本的融合特征；(3)将所述待分类文本的融合特征输入到所述语言模型模块中的轻量级文本分类语言模型中，得到待分类文本的类别。
G10L15/22  ,用于二轮交通工具或摩托车装备的智能控制方法和系统 [发明],本发明涉及智能控制领域和智能控制硬件设计制造领域，涉及一种用于二轮交通工具或摩托车装备的智能控制方法和系统，其包括：声音采集模块、语音识别模块、控制指令生成模块和蓝牙通信模块，其具体控制方法包括如下步骤1.开启声音采集模块：系统启动后，声音采集模块开始工作，等待用户发出语音指令；步骤2.采集语音指令；步骤3.语音识别；步骤4.指令解析；步骤5.发送控制指令，通过蓝牙连接将控制指令发送给二轮交通工具或摩托车装备；步骤6.装备响应；步骤7.反馈提示。本发明的系统可以根据用户的语音指令自动调节二轮交通工具或摩托车装备的工作状态，满足用户的个性化需求，同时实现对用户语音指令的高精度识别，提高了系统的准确性和可靠性。
G10L25/60  ,基于人工智能的朗读质量测评方法及相关装置 [发明],本申请涉及语音分析技术领域，提供了基于人工智能的朗读质量测评方法及相关装置，该方法包括对待测评语音数据进行发音测评和语音特征测评，采用该方法能够实现对待测评语音数据的全面测评，提高朗读质量测评的精度，进而提高外语学习者的学习体验。
G10L15/20  ,语音对抗样本的防御方法、装置、设备和存储介质 [发明],本发明涉及语音识别技术领域，提供一种语音对抗样本的防御方法、装置、设备和存储介质，该方法包括：获取原始语音指令对应的原始识别结果和降噪后的识别结果；在确定原始识别结果与降噪后的识别结果不相同的情况下，根据白噪声异常度和预设的异常度阈值，确定降噪后的识别结果对应的第一指令是否为语音对抗样本；白噪声异常度用于表征输入原始语音指令至语音识别模型时原始语音指令和所处的环境的环境噪声的相关程度；在第一指令为语音对抗样本的情况下，将第一指令进行作废。本发明提升了语音对抗样本的防御效果。
G10L17/02  ,基于AI技术的电话坐席自适应培训系统和方法 [发明],本发明公开了基于AI技术的电话坐席自适应培训系统和方法，涉及音频分析技术领域，方法包括以下步骤：收集各培训人员的语音信息，预处理后生成第一声纹信息，汇总后建立声纹库；将使用者的第一声纹信息与其培训方案绑定；在使用培训系统进行通话时，获取语音信息进行所述预处理生成对应的第二声纹信息；该基于人工智能的培训系统声纹识别方法及系统，通过对培训人员的语音信息进行情感分析，并对不同情感状态下的相同字词句分别进行特征分析，得到相同字、词在不同情感及不同字、词组合和语句下的声纹特征，使得声纹识别时能更贴合培训人员的发言、发音习惯，提高识别的精确度。
G10L15/22  ,一种基于语音识别的健康素养调查质量控制方法及系统 [发明],本发明提供一种基于语音识别的健康素养调查质量控制方法及系统，涉及音频处理领域；方法包括：预处理录音文件，确定文件中的多个语音对象；根据录音文件的时间进程，划分并确定各语音对象的单人语音片段及片段间的对应关系；根据各语音对象的单人语音片段及片段间的对应关系，自动语音识别受测者答复任一问题的单人语音片段中的答题要点；根据答题要点，判断录音文件中是否存在不合格因素；选择合格的录音文件进行健康素养调查结果的分析。本发明根据语音对象和答题要点的识别结果，以及预先学习的问卷问题及答复点校验录音文件是否合格，实现自动判断识别调查过程中不合格因素，提高录音文件质量控制的效率。
H04M3/22  ,面向呼叫中心的抗弱网语音编码自适应切换方法、系统 [发明],本发明涉及语音通信技术领域，公开了一种面向呼叫中心的抗弱网语音编码自适应切换方法、系统，实施在软交换平台上，上述软交换平台分别至少两个语音终端连接，其中一个语音终端为发送端，另一个语音终端为接收端，包括：S1、设计语音通话质量检测模型；S2、通过所述语音通话质量检测模型实时检测所述软交换平台与所述语音终端的语音通话从而得到语音通话质量指标，当某一语音终端与所述软交换平台之间的语音通话质量指标连续不再阈值范围内，则向该语音终端发送re‑INVITE消息来尝试重新更换语音编码。本发明可以实现语音编码切换完成，通话过程不会中断，可以有效提升智能呼叫中心系统的抗弱网能力。
G10L15/22  ,一种钻机智能语音交互控制系统及控制方法 [发明],本申请提供一种钻机智能语音交互控制系统及控制方法，通过获取多个钻机操作场景对应的模板钻机智能交互语音数据序列和每个模板钻机智能交互语音数据对应的标注交互意图指令数据，将模板钻机智能交互语音数据序列加载到初始化神经网络进行交互意图指令生成，生成所述模板钻机智能交互语音数据序列对应的推定交互意图指令数据，依据推定交互意图指令数据和标注交互意图指令数据，确定目标误差参数，依据目标误差参数，对初始化神经网络进行网络参数更新，生成目标交互意图指令生成网络。由此，能够有效地处理钻机智能交互语音数据，提高语音交互的准确性和效率。
G10L15/26  ,音频和文本的对齐匹配方法、装置、设备及存储介质 [发明],本申请实施例提供了一种音频和文本的对齐匹配方法、装置、设备及存储介质，涉及音频合成和处理技术领域。所述方法包括：获取目标文本和待对齐匹配的人声录音，人声录音是采用人声对目标文本的部分文本内容进行录音得到的音频；将人声录音按照录制的时间顺序进行分帧，得到人声录音的多个音频帧，多个音频帧中的每一个音频帧具有对应的发音时间戳；对多个音频帧和目标文本进行对齐匹配处理，得到人声录音与目标文本的对齐匹配结果，对齐匹配结果用于指示人声录音对齐匹配到的文本内容中各个字词分别对应的发音时间戳，人声录音对齐匹配到的文本内容属于目标文本。采用本申请实施例提供的技术方案，能够提升音频和文本的对齐效率。
G06F3/041  ,一种编程触摸式能源开关面板的处理方法及系统 [发明],本发明提供了一种编程触摸式能源开关面板的处理方法及系统，运用于面板数据处理领域；本发明通过差分测量采集相邻电极之间的电压差异，再映射到屏幕坐标上重新获取用户的指令内容，有助于提高触摸屏的精准度，同时采用动态校准方法，通过施加电流和测量电压信息来实现对触摸屏的校准，能够在运行过程中不断调整和优化触摸屏性能，提高系统的容错性，并且引入去中心化控制和共识机制，通过构建节点组合，提高了系统的安全性和稳定性。
G10L15/02  ,一种动态语音识别交互软件展示系统 [发明],本发明公开了一种动态语音识别交互软件展示系统，涉及语音识别技术领域，包括音频获取模块、语音识别模块、硬件设备和交互模块。该动态语音识别交互软件展示系统，设置有音频获取模块，实时获取包含语音的音频数据，然后利用搭载于识别设备或识别软件的语音识别模块对音频数据进行语音识别处理，基于动态时间规整算法精准识别出语音内容，以便通过交互模块实现与硬件设备之间的数据传递和交流活动，该系统通过动态语音识别，与其他展示形式的硬件设备进行交互，在识别到对应指令的时候，控制对应的展示内容出现在硬件设备上，简化了展示流程，同时通过硬件设备对语音识别模块的交互反馈，保障了展示过程的稳定性。
G10L25/03  ,一种基于语音数据的帕金森诊断系统 [发明],本申请实施例提供一种基于语音数据的帕金森诊断系统。系统从用户的语音数据中截取对应于多个预设音节的有效部分。对于所述多个预设音节中的每一个，系统对所述有效部分进行特征提取，得到各预设音节对应的特征提取结果。系统基于各预设音节对应的特征提取结果表征所述语音数据，得到表征数据。进而，系统使用诊断模型处理所述表征数据，得到用户的帕金森诊断结果。用户只需要进行简单的发音，系统就可以反馈帕金森诊断结果，不仅提高了帕金森诊断的准确性和效率，还为用户带来了更好的诊断体验。
H04N7/18  ,一种基于安全风险管控的现场干预系统 [发明],本发明提供了一种基于安全风险管控的现场干预系统，属于电网作业管理技术领域。本发明通过建立控制终端与施工现场的喊话通道，实现对施工现场的喊话，还通过建立控制终端与人员的沟通通道，实现与具体人员的沟通。本发明通过若干种沟通方式之间的相互配合，不仅可以快速的对施工现场进行通知叫停，同时可对施工现场的所有人进行警示，有效的提高了施工现场内工作人员的人身安全；同时，本发明针对多个施工现场同时进行“喊话”工作，相较于以往通过电话依次通知的方式，本发明的效率更高，叫停速度更快，通过此种远程直接干预的方式，可以帮助检测和预防电力作业现场的安全风险，减少事故的发生。
G10L25/51  ,一种音频实时场景识别系统 [发明],本发明公开了一种音频实时场景识别系统，涉及音频识别技术领域，包括：音频特征信息提取单元，音频特征信息提取单元用于对音频文件中包含的音频特征信息进行提取，并整合获得音频特征信息数据集U；特征信息分析单元，计算获取的音频特征信息数据集U中各音频特征信息X的有效系数Px；特征信息选取单元，基于计算获取的各个音频特征信息的有效系数Px选取预设数量Sy的音频特征信息X。音频场景识别模型，将选取的音频特征信息X导入音频场景识别模型中进行识别以确定音频文件对应的音频场景。本发明基于有效系数评估各音频特征信息的代表性和有效性，消除无效音频特征信息或冗余音频特征信息，降低音频场景识别计算复杂性，提高识别的准确性。
G10L13/033  ,音频处理方法、装置、设备、介质和程序产品 [发明],本申请公开了一种音频处理方法、装置、设备、介质和程序产品，涉及人工智能领域。该方法包括如下步骤：获取目标文本内容对应的第一音频数据和第二音频数据；对所述第一音频内容和所述第二音频内容进行音效同步处理，得到所述第一音频内容对应的第一同步音频和所述第二音频内容对应的第二同步音频；基于所述第一位置标签和所述第二位置标签将所述第一同步音频和所述第二同步音频进行音频拼接，得到音频拼接结果。通过对不同音频内容自动去除混响噪声后得到多个混响效果相同的同步音频，再基于位置标签将多个同步音频进行音频拼接，不仅提高了音频处理效率，还能使得拼接得到的音频拼接结果中的多段音频内容的音效保持一致。
G10L13/02  ,基于特定人物少样本情况下情感可控语音合成方法及系统 [发明],本发明属于语音合成技术领域，公开了基于特定人物少样本情况下情感可控语音合成方法及系统。该方法将选定的特定说话音频输入到数据自动化处理模型，形成特定人的可训练数据；针对特定人的可训练数据，利用声纹提取模块和情感特征提取模块分别提取对应声纹特征和情感特征；将得到的融合情感特征后的音素序列特征，嵌入到不同网络中；进行整个端到端的语音合成训练和推理流程，将所提取的说话人特征嵌入到不同的网络中，得到具有指定情感、指定说话人的情感语音合成。本发明采用端到端的语音合成流程，基于数据自动化处理模块形成实现快速响应的自动化训练流程。
G10L15/22  ,语音唤醒的控制方法、装置、电子设备及车辆 [发明],本申请提供一种语音唤醒的控制方法、装置、电子设备及车辆，能够为不同唤醒场景提供不同的控制方式，具有较高适应性和普及性，还可以避免单一控制方式带来的误判。由于车内唤醒场景属于安全场景，执行语音唤醒指令不会产生安全隐患。如果唤醒场景类型为车外唤醒场景，通过合法性验证可以实现识别出非法车外用户，在验证通过后执行语音唤醒指令可以避免安全隐患。如果唤醒场景类型为综合唤醒场景，对语音唤醒指令进行安全性验证可以识别出非法的语音唤醒指令，在验证通过后执行语音唤醒指令可以避免安全隐患。实现了为车辆提供多场景下的安全唤醒保障。
G10L21/10  ,语音形象显示方法、装置、计算机存储介质以及车辆 [发明],本申请公开了一种语音形象显示方法、装置、计算机存储介质以及车辆，其中，该方法包括：获取用户输入的语音指令；将用户输入的语音指令与已注册的多个声纹进行匹配，确定与语音指令匹配的目标声纹；目标声纹为已注册的多个声纹中的一个；确定与目标声纹对应的语音形象，并显示与目标声纹对应的语音形象。采用该方法可以基于声纹使车辆显示不同用户对应的语音形象，满足了不同用户针对语音形象的个性化需求。
G10L19/18  ,一种语音频信号切换系统 [发明],本发明公开了一种语音频信号切换系统，涉及语音频处理技术领域，本发明借助处理终端的常规模式和习惯模式来对目标对象进行编码处理，根据来源对象的个数是否超过预设数量，从而确定采用常规模式还是习惯模式进行处理，常规模式下能够借助选择算法对目标对象进行编码处理；灵活选择最适合用户的编码方式，切合实际使用场景；习惯模式下能够根据用户过往数据快速确定何种编译方式对语音频信号进行编码，本发明简单有效，且易于实用。
G10L13/08  ,音频处理方法、装置、设备、介质和程序产品 [发明],本申请公开了一种音频处理方法、装置、设备、介质和程序产品，涉及人工智能领域。该方法包括如下步骤：获取第一文本数据，第一文本数据中包括第一文本内容和基于第一文本内容识别得到的第一音效标签，第一音效标签用于指示与第一文本内容关联的音效类型；获取第一音效标签对应的第一音效音频；获取文本音频，文本音频中包括第一文本内容对应的第一音频内容，第一文本数据中还标注有第一音频内容在文本音频中的第一起止时间戳；基于第一起止时间戳将第一音效音频叠加至文本音频中，得到具有音效的文本音频。能够自动将音效音频叠加至文本音频中，得到具有音效的文本音频，提高音频处理的效率和准确率。
G10L15/22  ,语音指令的回复方法、装置和车辆 [发明],本申请公开了一种语音指令的回复方法、装置和车辆，属于计算机技术领域。通过本申请实施例提供的技术方案，响应于目标对象的语音指令，对该语音指令进行亲密度识别和平等度识别，得到该目标对象对该语音助手的亲密度和平等度。基于该目标对象对该语音助手的亲密度和平等度，确定目标对象对该语音助手的身份定位，身份定位用于表示目标对象对该语音助手的身份认定。基于该身份定位和该语音指令，确定并播报针对该语音指令的回复内容，该回复内容的风格与该身份定位匹配，从而以与目标对象期望的风格来回复目标对象，满足目标对象的需求，提高目标对象与语音助手进行交互时的效率。
G10L13/08  ,一种数字机器人语音交流控制方法及系统 [发明],本发明公开了一种数字机器人语音交流控制方法及系统，通过构建人脸识别模型和自然语言生成模型，依据人脸识别模型对人脸图像进行识别，得到人脸特征，并依据自然语言生成模型对人脸特征进行识别，得到相匹配的语言文本，最后再通过文本转语音技术将语言文本转换成语音进行输出，能够有效根据不同情景调整相对应的语言输出，从而使得语音交流适应性和自然感更加强，同时，通过采用计算机视觉技术获取人脸图像，能够提高获取人脸图像的清晰度，从而提高人脸识别的精准度和速度，进一步提高根据不同情景调整相对应语言输出的精准度和速度。
G10L17/02  ,一种通话场景说话人识别方法 [发明],本发明公开了一种通话场景说话人识别方法，涉及语音识别领域，本方法使用音频信号的FBank频谱作为说话人的浅层特征表示，通过声纹编码器增强浅层说话人特征表示中的各种局部模式，生成说话人特征的深度表示；然后使用这些深度表示训练PLDA分类器；最后使用结构重参数机制合并声纹编码器中冗余的网络层，并使用声纹编码器和PLDA分类器预测不同语音信号属于同一说话人的概率，不仅可以进行有效的说话人识别，还可以加快识别速度，满足实时性要求。
G10L21/0208  ,一种音视频系统中多麦克风回声消除方法及系统 [发明],本发明公开了一种音视频系统中多麦克风回声消除方法，其包括以下步骤：S1：对远端语音信号进行采样获得原始语音信号，将所述原始语音信号作为参考信号；S2：对近端语音信号进行采样获得混合语音信号；S3：将混合语音信号和参考信号进行比较，得到参考信号与混合语音信号的差异信号；S4：根据所述差异信号和对应预设补偿系数获得所述参考信号的补偿信号；S5：根据所述补偿信号得到一个负补偿信号，将所述负补偿信号与所述混合语音信号合并以消除回声。本发明还提供了一种音视频系统中多麦克风回声消除系统。本发明可以解决解决多个麦克风设备的情况下发生多个声学耦合导致回声消除效果差的问题。
G10L25/66  ,一种基于深度学习的精神分裂症语音检测方法及系统 [发明],本发明公开了一种基于深度学习的精神分裂症语音检测方法及系统，涉及个人健康风险评估技术领域，所述方法包括：获取受试者人群的认知测试语音样本，集成希尔伯特黄变换和倒谱内插方法提取语音样本的声学特征参数集，声学特征参数集包括音质情感变化特征；构建声学特征参数集的语音向量，根据语音向量训练多尺度多头精神分裂症语音检测模型，其中，语音向量包括音节、音素、音位以及语素单元的隐含状态序列；利用多尺度多头精神分裂症语音检测模型对受检者的语音进行自动分类检测，输出受检者的人群类别。本发明集成希尔伯特黄变换和倒谱内插方法提取声学特征，利用多尺度多头精神分裂症语音检测模型对受检者的语音进行自动分类检测。
G10L25/63  ,一种语音情绪识别方法、装置、设备及存储介质 [发明],本申请公开了一种语音情绪识别方法、装置、设备及存储介质，涉及语音识别技术领域，包括：获取目标语音信号，并基于预设时间长度将目标语音信号分为若干语音片段信号；基于预设信噪比预测模型对若干语音片段信号进行处理得到对应的信噪比；利用预设语音增强模型对信噪比不大于预设阈值的第一语音片段信号进行降噪得到降噪后语音片段信号；分别对降噪后语音片段信号和信噪比大于预设阈值的第二语音片段信号进行梅尔倒谱特征提取处理，得到若干语音特征；根据若干语音特征，并通过多分类器确定若干情绪类别。这样一来，本申请可以划分语音信号，对部分语音降噪处理，然后确定若干个情绪类别，结合了语音情绪的上下文信息，提升情绪识别的准确率。
G10L13/02  ,文本信息的处理方法、装置、设备及存储介质 [发明],本申请公开了一种文本信息的处理方法、装置、设备及存储介质，属于自然语言技术领域。该方法包括：获取文学作品，文学作品是包括多个字符的自然语言信息；在文学作品中确定出对话文本和旁白文本，对话文本是至少一个角色发起交流的文本，旁白文本是文学作品中除去对话文本以外的信息；基于旁白文本以语音合成方式生成第一音频；以及基于对话文本以录制方式生成第二音频；拼接第一音频和第二音频，得到文学作品对应的播报音频。通过在文本信息中确定出对话信息和旁白信息；充分考虑了对话文本具有浓厚的情感表达的特点，以录制方式获取第二音频，保证了对话文本对应的第二音频的情感表达的饱满，兼顾播报音频中情感表达的饱满和生成效率。
G06T5/00  ,视频帧增强方法、装置、计算机设备和存储介质 [发明],本申请涉及一种视频帧增强方法、装置、计算机设备、存储介质和计算机程序产品，可用于视频处理技术领域，也可用于金融科技领域或其他相关领域。该方法包括：获取待处理视频；根据待处理视频的业务场景，确定待处理视频的目标关键内容和目标话术模板；根据目标关键内容和目标话术模板，对待处理视频进行语音识别，确定出待处理视频中的关键视频帧；通过视频帧增强模型，对关键视频帧进行增强处理，得到目标视频帧。采用本方法能够提高视频帧增强处理的效率。
G10L21/0216  ,一种回声消除方法及系统、一种语音通信设备及介质 [发明],本发明提供一种回声消除方法及系统、一种语音通信设备及介质，包括：对第一语音信号和第二语音信号进行短时傅里叶变换，得到第一频域信号和第二频域信号；第一语音信号和第二语音信号分别由处于不同地理位置的语音通信设备生成，且第一语音信号包含目标语音信号和回声信号；将第一频域信号和第二频域信号输入至自适应滤波器中进行信号估计，然后进行线性回声信号消除后作为深度学习模型的输入，通过用于进行非线性回声信号消除的深度学习模型来消除残余的非线性回声信号。本发明通过自适应滤波器与深度学习模型形成级联，不仅可以消除线性回声信号，还可以消除非线性回声信号，从而在语音传输过程中获得更好的听感，提升用户体验。
G10L13/02  ,基于语音自监督学习表征的重读可控语音合成方法及装置 [发明],本发明公开了一种基于语音自监督学习表征的重读可控语音合成方法及装置，其方法实现，包括：获取原始语音信号，通过预设的语音自监督预训练模型从原始音频信号中提取帧级表征；通过预设的微调模块对帧级表征进行加权和处理以及池化处理，以得到字级表征，并对其进行重读分类预测，以得到每个字的字级重读表征；获取待处理文本数据，将文本数据转换为对应的离散音素序列，并编码为连续音素嵌入表征，并输入至预设的编码器中进行处理，以得到文本隐层表征；将文本隐层表征与字级重读表征输入至预设的自监督学习表征编码器中进行处理，以得到解码器输入特征；将解码器输入特征输入至预设的解码器中进行解码处理，以得到音频的梅尔频谱表征，并还原为语音波形。
G10L15/16  ,基于注意力机制的CRNN网络在麦克风唤醒中应用方法 [发明],本发明涉及语音识别技术领域，具体涉及基于注意力机制的CRNN网络在麦克风唤醒中应用方法，该方法包括，建立端到端神经网络模型，网络模型由卷积神经网络、循环神经网络和注意力机制构成，输入特征经过卷积神经网络后得到输出特征，再经过循环神经网络计算各个时间步的隐藏状态，注意力机制选择更可能包含关键词的语音部分。本发明通过建立端到端的神经网络模型，将语音特征表示为更高维度的特征表示，并使用注意力机制选择更可能包含关键词的语音部分，并通过线性变换和softmax函数生成概率分布，实现关键词的识别，实现了小体积、高识别率的多分类KWS系统，并将其应用于麦克风唤醒控制中。
G10L21/007  ,一种基于视听不一致效应的声环境主观感受调控方法 [发明],本发明公开了一种基于视听不一致效应的声环境主观感受调控方法，属于调节声环境主观感受技术领域，包括：采集和识别声环境中能够显著影响人体主观感受的烦恼声音成分；基于专家经验或人工智能方法，根据烦恼声音成分，获取声音成分与烦恼声音成分相近但让人感觉舒适的视觉场景；结合视觉场景和声环境，基于视听不一致效应，形成若干调控方案；征集受试者对各调控方案中的声主观感受进行评价，依据声主观感受的改善程度得到最优调控方案，实施最优调控方案并做后评价以确认调控效果。本发明通过在环境中融入声音成分相似但让人感觉更舒适的视觉场景，利用视听不一致效应，实现声主观感受调控，为调控声环境主观感受提供新的思路。
G10H1/36  ,一种基于AIGC技术将歌曲融入戏曲唱腔方法和系统 [发明],本申请涉及音乐技术领域，公开了一种基于AIGC技术将歌曲融入戏曲唱腔方法和系统，所述方法包括：收集戏曲唱腔歌曲；对戏曲唱腔歌曲进行特征提取，得到戏曲唱腔歌曲的特征标识；将戏曲唱腔歌曲的特征标识和戏曲唱腔歌曲作为输入，基于AIGC技术训练唱腔融合模型；将目标歌曲输入唱腔融合模型，得到目标歌曲的新型唱腔。本申请对戏曲唱腔歌曲进行特征提取，得到戏曲唱腔歌曲的特征标识；将戏曲唱腔歌曲的特征标识和戏曲唱腔歌曲作为输入，基于AIGC技术训练唱腔融合模型，将目标歌曲输入唱腔融合模型，得到目标歌曲的新型唱腔。因此，本申请能够自动将目标歌曲融入戏曲唱腔。
H04N21/439  ,一种基于文字转换的直播视频的方法 [发明],本发明涉及直播视频的文字处理技术领域。一种基于文字转换的直播视频的方法，包括：获取缓存区；在直播视频录像中，分别获取剪切时间段内的第一图像和第一音频，并将第一音频存入缓存区；对存入缓存区内的第一音频进行语音识别，得到第一音频对应的第一文字；将第一文字加载到第一图像的第一区域，得到第二图像，其中，第二图像具有第一图像和第一文字；将第二图像和第一音频同步播放，得到文字转换的直播视频。将直播视频中的直播片段的音频存储在缓存区内，在缓存区内进行文字识别，当文字识别后，再与图像进行结合，从而完成直播片段的文字同步，从而使得不方便打开电子设备声音的用户，可利用直播视频同步的文字观看，提高了用户的体验。
G10L25/51  ,一种基于多中心单分类的自监督语音鉴伪训练方法及系统 [发明],本发明属于语音检测技术领域，公开了一种基于多中心单分类的自监督语音鉴伪训练方法及系统。该方法包括：将处理后的语音数据输入到特征提取模块，使用预训练自监督前端网络提取语音特征；将预训练的自监督前端提取到的语音特征进融合；将融合后的语音特征输入到鉴伪网络中，加入多中心单分类的损失模型，并对多中心单分类的损失模型以及鉴伪网络进行训练优化；利用推理过程使用阈值判断语音的真伪。本发明结合不同特征说话人在嵌入空间上的不同位置，引入多中心的嵌入空间进行训练，解决单中心嵌入空间方法鉴伪导致的错误率高问题，同时添加多种噪音和混响模拟真实环境，有效解决语音鉴伪在真实环境下准确率较低，泛化性差的问题。
G10L13/027  ,一种提升语音合成情感表达的方法及系统 [发明],本发明公开了一种提升语音合成情感表达的方法和系统，属于语音合成技术领域。其方法包括步骤：将文本转换为音素序列和语言特征标签，所述语言特征标签包括说话人标签、语言风格标签以及语言情感标签；将所述音素序列和语言特征标签输入声学模型，获取对应的梅尔频谱；根据所述梅尔频谱还原出音频信号。通过上述方法和相关系统本发明能够更细粒度的对不同情感进行区分，从而提高情感表达的自然度与拟人度。
G10L15/02  ,一种AI设备的语音辅助方法 [发明],本发明公开了一种AI设备的语音辅助方法，包括：步骤1：实时采集用户的面部表情、手势多模态数据，同时采集语音输入，形成语音和图像的多模态数据流；步骤2：将采集到的语音和图像数据进行融合，形成综合的用户输入；步骤3：对用户的面部表情进行情感分析，识别用户的情绪状态，同时结合语音内容，分析用户的语音情感，推断用户的意图和需求；步骤4：结合图像识别结果，根据用户的面部表情或手势进行上下文感知触发；步骤5：在接收到用户请求后，通过语音和图像数据的综合分析，确认用户的意图；步骤6：基于多模态数据的综合分析，动态调整唤醒频率。本发明更好地结合语音与图像识别，实现了更智能、更自然、更人性化的用户体验，有效解决了现有技术中可能存在的一些交互和响应上的不足。
G10L25/63  ,基于时频特征分离式transformer交叉融合架构的语音情感识别方法 [发明],本发明提供一种基于时频特征分离式transformer交叉融合架构的语音情感识别方法，包括以下步骤S1、对原始语音信号进行预处理，将所述原始语音信号转换为相应的特征表示，包括语谱图和音频梅尔频率倒谱系数；S2、从所述特征表示中进行特征提取，使用两条支路提取特征，其中一条支路通过时频分离式transformer交叉融合架构提取特征，另一条支路通过扩张因果卷积网络提取特征；S3、进行特征融合，使用transformer的多头自注意力机制来动态地融合时频分离式transformer交叉融合架构和扩张因果卷积输出特征；S4、输出结果，使用输出层来对时频分离式transformer交叉融合架构的输出进行分类或回归，以使时频分离式transformer交叉融合架构适应训练数据，并对任务进行预测或分类。
G10L21/0208  ,滤波器更新方法、装置、存储介质及电子设备 [发明],本申请公开了一种滤波器更新方法、装置、存储介质及电子设备，其中，该滤波器更新方法包括采集语音信号，并将语音信号转换为频域信号，频域信号包括第一目标信号；将频域信号分别输入至固定波束形成器和阻塞矩阵模块中，生成第二目标信号和第三目标信号；基于第一目标信号、第二目标信号和第三目标信号进行计算，得到滤波器更新因子；将第二目标信号、第三目标信号和滤波器更新因子输入目标滤波器，以对目标滤波器的滤波器系数进行更新。本方案可以减少语音失真度。
G10L25/51  ,送水泵组健康检测的融合声纹处理方法、装置及存储介质 [发明],本发明适用于送水泵健康检测技术领域，提供了一种送水泵组健康检测的融合声纹处理方法、装置及存储介质，所述方法包括获取送水泵组中的多通道声音数据；计算所述多通道声音数据的时频特征，得到时频特征图集；根据所述时频特征图集计算时频特征掩码集；通过所述时频特征掩码集对所述时频特征图集进行处理，得到可视化的融合时频图。本发明将采集到的送水泵组的多通道声音数据的时频特征进行融合去冗余，弱化各通道间共存的声纹特征，强化不同通道间声纹特征差异，降低了声纹特征图可视化所需计算资源，得到一副可视化的声纹特征图，使得用户能够更加直观地实时观察多通道声音数据声纹特征。
H04N21/4788  ,直播间的语音互动方法、装置、直播系统、设备及介质 [发明],本申请涉及一种直播间的语音互动方法、装置、直播系统、电子设备及计算机可读存储介质；所述方法包括：在主播开启AI语音互动模式时，利用AI服务器上预先训练的主播的声音模型生成相应的口播语音模板集合，口播语音模板保存至少一段与直播间的动态变化事件相关联的语音内容；当检测到观众用户触发设定的动态变化事件时，选择与该动态变化相匹配的第一口播语音模板；根据观众用户的用户属性信息调用所述主播的声音模型生成主播声音发音的用户信息语音；将用户信息语音和第一口播语音模板进行合成得到AI互动语音，并在直播间播放所述AI互动语音；该技术方案，提升主播的直播效率，提升了直播间互动的真实性，有助于提升直播间活跃度。
H04N21/475  ,直播场景交互追溯的方法和装置、计算机设备、存储介质 [发明],本申请实施例提供了一种直播场景交互追溯的方法和装置、计算机设备、存储介质，属于计算机技术领域。本申请实施例将每个直播话术分句作为话术树的一个节点。若检测到直播场景存在交互信息，则打断当前的播报，且播报交互信息对应的回复话术，实现直播场景中的交互。在打断当前的播报时，从话术树找出打断节点至根节点之间的目标遍历路径序列，且以打断次数作为索引，将根节点的直播话术分句和目标遍历路径序列存储于第一线性表。在续报时，基于第一线性表中的根节点对应的直播话术分句可以查询出话术树，然后基于目标遍历路径序列能从话术树快速查询出续报节点，实现直播场景中的交互追溯。本申请降低了查询追溯的复杂度，提高了直播交互效率。
G10L21/0272  ,一种支持多通道的改进SEGAN网络语音增强方法及系统 [发明],"本发明涉及一种支持多通道的改进SEGAN网络语音增强方法及系统，包括对多通道语音数据执行语音分离操作生成对应的单通道语音数据集并对增强语音数据集分别执行时域鉴别操作和Mel频率域鉴别操作，获得时域鉴别损失值和Mel频率域鉴别损失值以及反馈获得的生成损失值判断收敛平衡，将多声道语音进行分离，同时增加了Mel频率域鉴别器,优化了生成器和鉴别器的损失函数，使生成器能够同时学习语音的时域波形特征和Mel频域特征，从而更好的学习真实的纯净语音特征，实现优化SEGAN的语音增强效果、提升语音质量、提高语音的信噪比的技术效果。"
G06Q10/0631  ,一种变电站电子操作票作业智能管控系统 [发明],"本发明公开的一种变电站电子操作票作业智能管控系统，属于保健材料技术领域；包括：电子操作票作业智能管控系统、平板终端、智能安全帽，平板终端和智能安全帽之间通过热点连接，智能安全帽设置有摄像装置以及音频采集装置，电子操作票作业智能管控系统包括电子操作票系统服务器端、电子票作业管控客户端、智能设备管控客户端、交换机，电子操作票系统服务器端、电子票作业管控客户端、智能设备管控客户端均与交换机连接，电子操作票系统服务器端连接有五防系统服务器，平板终端与交换机连接，可以解决目前的两票系统仅实现了开票信息化,对于操作票执行过程的监管仍是一片空白，未通过有效技术手段确保现场是否按票执行的问题。"
G10L15/16  ,语音识别的方法及装置、非易失性存储介质 [发明],本申请公开了一种语音识别的方法及装置、非易失性存储介质。其中，该方法包括：获取语音信息，并确定每一帧语音信息所属的语音类型，其中，语音类型包括：方言和普通话；根据每一帧语音信息所属的语音类型确定每一帧语音信息对应的语音识别模型，其中，语音识别模型包括：用于识别属于方言的语音信息的第一语音识别模型、用于识别属于普通话的语音信息的第二语音识别模型；采用每一帧语音信息对应的语音识别模型对每一帧语音信息的内容进行识别，得到识别结果。本申请解决了由于粤语和普通话存在同形异音字造成的使用一个语音识别模型同时识别粤语和普通话的识别效果准确率低的技术问题。
G10L15/16  ,一种基于深度卷积生成对抗网络的环境声音分类方法 [发明],本发明涉及一种基于深度卷积生成对抗网络的环境声音分类方法，与现有技术相比解决了ESC识别率低、鲁棒性差的缺陷。本发明包括以下步骤：ESC音频数据的收集和预处理；ESC分类检测模型的构建和训练；待检测ESC音频数据的收集和预处理；环境声音分类结果的获得。本发明将ESC音频数据转化为语谱图像，通过图像判别网络模型与图像生成网络模型之间的对抗训练，增强了数据，提高了图像判别网络模型的识别能力，提高了ESC识别率。
G06F16/33  ,异常语言检测方法、电子设备、存储介质 [发明],本申请涉及保险金融、人工智能技术领域，尤其是涉及一种异常语言检测方法、电子设备、存储介质。本申请异常语言检测方法需要先获取目标音频与目标文本，目标音频与目标文本用于反映同一目标语言内容；再将目标音频输入预训练的音频编码器进行音频特征提取，得到音频特征信息，将目标文本输入预训练的文本编码器进行文本特征提取，得到文本特征信息；进一步，将音频特征信息与文本特征信息进行整合，得到融合嵌入信息；将融合嵌入信息输入预训练的模态融合解码器进行异常语言检测，得到异常语言检测结果。如此一来，便能够提升异常语言检测的准确性。尤其在金融、保险相关领域，对业务资料中敏感词、不雅词等不良信息的筛查，提供了便利。
G10L13/02  ,一种智能语音识别和语音合成优化方法 [发明],本发明公开了一种智能语音识别和语音合成优化方法包括，采集数据信息，并对采集到的数据进行预处理；将预处理后的数据输入语音识别算法模型，输出语音识别结果；通过自然语音处理和深度学习对语音识别结果进行深度语义分析，并进行语义优化最终输出语音合成结果。本方法能够解决传统技术在适应性方面表现不足，特别是在处理噪声背景、非标准语言或口音时效果较差的问题。其次，本发明还能够解决现有的语音合成系统虽然能够转换文本为语音，但生成的语音往往缺乏自然的语调和流畅性，尤其是在复杂的句子或情感表达的问题。
A61B5/11  ,一种基于用户特征的音频分析方法 [发明],本发明公开了一种基于用户特征的音频分析方法，通过穿戴式健康监测设备实时获取用户的健康监测数据和行为监测数据，提取健康特征数据和行为特征数据。评估用户的健康监测等级，根据用户的健康监测等级，周期性获取音频数据。对存在质量问题的音频数据进行质量修复。随后，进行用户异常事件的识别，确定异常事件的紧急程度。最终，基于异常事件识别结果和其紧急程度，制定相应的异常事件预警方案。本发明将用户特征与音频分析相结合，为健康监测提供了全面而个性化的解决方案，可广泛应用于穿戴式健康监测设备，为用户提供更好的健康管理和紧急事件响应。
G10L15/00  ,一种基于AI的智能语音识别系统及方法 [发明],本发明公开了一种基于AI的智能语音识别系统及方法，包括语音信号接收单元、语音信号识别单元、语音信号转换单元、文字指令解析单元、指令控制单元、反馈单元和存储单元；语音信号识别单元用于语音信号接收单元获取的语音指令的识别，包括多种方言的识别；语音信号转换单元用于将识别语音指令转化为可理解的文字和命令；文字指令解析单元用于识别转换后文字和命令的关键词，并提取关键信息、进行语义分析和命令解释。本发明的语音识别系统对语音信号识别单元进行了设计，通过多语言语音数据集、声学模型、语言模型和多方言识别算法的配合辅助，能够使得本语音识别系统可以对多种方言进行识别，进而能够完成对应的识别控制。
G10L25/51  ,一种基于声音视频AI分析的特种设备智能运输监控方法 [发明],本发明涉及特种设备运输监控技术领域，尤其涉及一种基于声音视频AI分析的特种设备智能运输监控方法，本发明提出以下方案，首先通过声学传感器获取车辆行驶过程中车厢内特种设备异常响动发出的声音信号，对特种设备运输过程中的特种设备状态进行识别，其次，通过摄像设备获取车辆行驶过程中驾驶人员的面部视频信息，进行驾驶人员面部特征提取，根据驾驶人员面部特征对特种设备运输过程中的驾驶人员疲劳状态进行识别，最后根据特种设备状态和驾驶人员疲劳状态对特种设备运输过程进行实时监控，对特种设备运输过程中的状态进行分析，根据分析结果进行预警，保障特种设备的运输安全。
G10L17/02  ,一种应用于电力作业中的声纹识别方法及其系统 [发明],本发明公开了一种应用于电力作业中的声纹识别方法，包括：获取待建档人员的声音信号，并进行预处理；基于Gammatone滤波器组提取预处理后的所述声音信号的时频数据生成第一GFCS参数矩阵，并基于所述Gammatone滤波器组中各通道的输出信号构建频域信号的能量谱，生成第二GFCS参数矩阵；利用FastICA算法，提取所述第一GFCS参数矩阵和所述第二GFCS参数矩阵构成的混合信号中的ICA分离矩阵，并获取所述待建档人员的声纹特征；基于所述声纹特征训练SVM二分类器；在存在待测声音信号时，待测声音信号经过Gammatone滤波器组及FastICA算法处理后输入至训练完成的所述SVM二分类器，所述SVM二分类器输出声纹识别结果。
G10L25/51  ,一种基于D-CNN和KNN技术的环境声音分类识别方法 [发明],本发明涉及一种基于D‑CNN和KNN技术的环境声音分类识别方法，与现有技术相比解决了环境声音分类(ESC)特征提取困难、识别率低、鲁棒性差的缺陷。本发明包括以下步骤：对训练的环境声音进行收集和预处理；构建环境声音分类识别模型；环境声音分类识别模型的训练；对待测的环境声音进行收集和预处理；环境声音分类识别结果的获得。本发明不仅解决了环境声音数据特征提取困难，提高了环境声音识别的准确率，而且增强了环境声音分类识别算法的鲁棒性，达到了实际应用水平。
G10L25/66  ,一种基于语音时序特征的抑郁症诊断系统、设备及介质 [发明],本发明公开一种基于语音时序特征的抑郁症诊断系统、设备及介质，包括：获取历史语音音频数据集及每个样本对应的正/负样本标签；以负样本中居中的设定时序长度的片段为新样本，对正样本根据设定时序长度进行切片划分，以每个片段为一个新样本，由此得到新样本集；对新样本集中每个样本在时序维度上提取语音特征值，对预先构建的分类模型进行训练，并采用训练后的分类模型对待测语音音频数据进行抑郁症诊断。解决数据不平衡问题，保证训练集充足的数据量且不涉及病患隐私。
G01S5/18  ,基于麦克风射频通信网络的定位方法及系统 [发明],本发明公开了一种基于麦克风射频通信网络的定位方法及系统，包括：获取目标区域中分布式麦克风阵列对应的射频通信网络，确定待定位麦克风节点，提取待定位麦克风节点与信标节点的射频信号对应的目标射频指纹；构建麦克风定位模型获取潜在特征，获取待定位麦克风节点所属位置分类的概率；将待定位麦克风节点的定位作为目标声源的初始定位区域，获取区域各点的可控响应功率进行迭代搜索，获取可控响应功率最大时对应的空间位置作为目标声源的位置。本发明利用射频通信网络中不同环境场景的迁移学习提高了定位效率及精度，另外根据待定位麦克风的位置实现目标声源的初定位，弱化噪声对时延估计的同时降低了计算复杂度。
G08B21/10  ,一种基于声音特征的山洪监测与预警方法及设备 [发明],本申请涉及山洪灾害防治技术领域，具体涉及一种基于声音特征的山洪监测与预警方法及设备。方法包括：沿河道铺设监测设备；利用监测设备对河道声音进行实时采集；获取河道声音的最大音量；响应于最大音量大于预设音量，对河道声音进行预处理，得到待识别声音；提取待识别声音的声音特征；将声音特征输入山洪预警模型进行识别；响应于识别结果为山洪暴发，启动山洪应对措施。本申请提供的基于声音特征的山洪监测与预警方法及设备，能够提高监测和预警准确度，能够实现长期自动化监测，降低设备成本和维护成本。
G10L15/01  ,语音会话质量信息生成方法、装置、电子设备和介质 [发明],本公开的实施例公开了语音会话质量信息生成方法、装置、电子设备和介质。该方法的一具体实施方式包括：对跟进用户会话音频信息进行语音识别处理，得到会话文本信息序列组；对各个会话文本信息序列进行分类处理，得到第一会话文本信息序列和第二会话文本信息序列；对第一会话文本信息序列进行关键词提取处理，得到用户需求关键词组；对第二会话文本信息序列进行检测处理，得到跟进人员会话完成信息；确定用户需求会话分值；基于跟进人员会话完成信息、用户需求关键词组和用户需求会话分值，生成语音会话质量信息。该实施方式可以提高语音会话质量信息的准确性，较为全面地对用户开发人员开发新用户的沟通行为进行反馈。
G06F18/25  ,对话意图识别方法和装置、电子设备及存储介质 [发明],本申请提供了一种对话意图识别方法和装置、电子设备及存储介质，属于金融科技领域。方法包括：获取具有至少两个说话对象的对话视频，对对话视频进行音视频分离，得到对话音频和对话图像帧；对对话音频进行音频特征提取，得到对话频谱特征；对对话图像帧进行人物特征提取，得到人物唇部特征；基于对话频谱特征和人物唇部特征从至少两个说话对象筛选出目标对象；根据目标对象对对话音频进行音频识别，得到目标音频片段；根据目标音频片段对目标对象进行意图识别，得到目标意图数据；目标意图数据用于指示所述目标对象的意图类别。本申请能提高对对话音频中的说话对象的判断准确性，进而提高对说话对象的意图识别的准确性。
G10L15/22  ,一种通过语音操控PDC的方法 [发明],本发明公开了一种通过语音操控PDC的方法，涉及汽车技术领域，语音操控PDC系统包括：用户、声音采集系统、声音处理系统和PDC系统，用户根据工况及用户自身需求，发出语音指令，声音采集系统采集用户发出的语音指令，继而发送给声音处理系统，声音处理系统解析用户发出的语音指令背后的含义，并将解析之后的命令发到PDC系统，由PDC系统执行响应指令，执行PDC参数的调整，以开启/关闭/增强/减弱PDC系统的探测能力，PDC系统响应用户的操控要求探测障碍物信息，可根据不同工况实时变化，响应用户的不同需求，提升用户感受和使用满意度。
G10L21/0208  ,一种基于循环神经网络和全子频带特征的实时语音降噪方法 [发明],本发明公开了一种基于循环神经网络和全子频带特征的实时语音降噪方法，包括S1、搜集纯净语音、不同类型的噪声以及不同尺寸的房间冲激响应；S2、合成对应的带噪语音；S3、对其预设参数做短时傅里叶变换，得到其时频域的表示；S4、在每个频点联合其相邻的频点一起构成子频带特征；S5、把常规的全频带特征融合子频带特征作为最终的模型输入特征；S6、分别对全频带特征和子频带特征建立模型并且做合适的融合以充分利用；S7、依据S1‑S6训练出完整的降噪模型，对真实的带噪语音进行测试；S8、进行提升音质。本发明采用循环神经网络架构，融合了子频带特征以捕获更多的频谱信息，做到按帧实时处理，降低实时通信、语音会议场景下的延时。
G06F40/58  ,一种多语交互对话的翻译系统及其翻译方法 [发明],一种多语交互对话的翻译系统，包括通讯设备，每套通讯设备包括电子设备和与电子设备通讯连接的收录播放装置，收录播放装置包括话筒、听筒和按钮，收录播放装置内设置有与话筒、听筒和按钮连接的芯片，所述电子设备上安装有翻译APP。本发明多语交互对话的翻译系统通过收录播放装置上的按钮来控制语言的翻译，当长按按钮时，只有自己讲出的话能翻译，而对方收录播放装置只能听，松开按钮时，翻译完成的语言会实时传送至对方收录播放装置中，从而能够避免双方同时讲话导致翻译APP不能及时翻译识别语言，从而提高了翻译效率。
G06F18/214  ,测试集数据处理方法、服务器及存储介质 [发明],本申请公开了一种测试集数据处理方法、服务器及存储介质，包括：根据历史语音请求，确定归一化语音请求，其中归一化语音请求对应了多个语句结构相同的历史语音请求；根据归一化语音请求以及出现频次满足预设条件的历史语音请求，确定包含于测试集的测试用语音请求。本申请能够根据大量的语音请求的历史记录进行归一化，将句子结构相同的历史语音请求通过归一化的方式保存为一个框架性的归一化语音请求，并根据历史语音请求的出现频次以及归一化语音请求还原出形成测试集、用于车辆功能测试的测试用语音请求，从而避免大量的重复数据、同时通过归一化对高频句式进行统计，便于对历史语音请求的进行语料特征的统计。
G10L25/63  ,一种动态提取语音情感特征的方法及装置 [发明],本发明公开了一种动态提取语音情感特征的方法及装置，该方法及装置将语音数据的正向输入数据和反向输入数据分别导入到N个帧级特征编码器，导入的语音数据先通过帧级动态融合单元动态的提取语音的帧级融合特征，之后通过一维时间序列卷积单元获取帧与帧之间的跨尺度信息，归一化和激活处理后由注意力单元对获得的信息进行注意力权重分配，并作用于导入的语音数据。分别输出N个正向语音情感特征和反向语音情感特征，并导入全局特征编码器进行情感融合，获得最终的高级语音情感特征。该方法及装置可以实现动态的提取语音数据每一个时间步的情感特征，同时还可以提取语音数据的全局特征，改善了语音情感特征提取的准确性、效率和适应性。
B64U20/80  ,无人机巡检化工生产厂区的控制方法、系统及装置 [发明],本公开提供了一种无人机巡检化工生产厂区的控制方法、系统及装置，涉及化纤智能化技术领域。具体方案为：确定目标场景下用于执行预设巡检任务的第一无人机；其中，第一无人机负责化工生产厂区的预设巡检任务；获取目标场景下第一无人机采集的目标对象的数据；基于目标对象的数据确定目标场景下目标对象的状态；在状态表征目标对象处于目标场景的预设状态时，输出目标场景下与预设状态相匹配的提示信息。根据本公开的方案，通过无人机对化工生产厂区进行巡检，能够提高巡检的效率，提高巡检的灵活性，从而保证化工生产厂区的正常运行和化工生产厂区的安全。
H04N21/466  ,基于CNN算法的AI智能电视机顶盒系统 [发明],本发明提供基于CNN算法的AI智能电视机顶盒系统，涉及机顶盒系统技术领域，包括中央处理单元、图形处理单元、存储单元和配套模块，其中配套模块包括：语音识别与控制模块，图像和视频分析模块，推荐系统模块，自然语言处理模块，多模态交互模块，安全性与隐私保护模块，系统能够实时地进行网络负载均衡和数据传输优化。这不仅提高了数据传输的效率，还减少了网络延迟，从而提供了更流畅的用户体验。
G10L21/0208  ,一种基于Transformer的语音降噪方法及系统 [发明],本发明公开了一种基于Transformer的语音降噪方法、系统、平台及存储介质，通过实时获取及预处理与待降噪语音数据相应的原始数据，并卷积处理所述原始数据，生成与待降噪语音数据相应的第一处理数据；根据所述第一处理数据，结合卷积神经网络，提取与待降噪语音数据相应的特征数据；构建Transformer网络层，结合所述Transformer网络层，生成与待降噪语音数据相应的循环神经网络数据；根据所述循环神经网络数据，变换并重构与待降噪语音数据相应的语音信号，生成降噪处理后的语音数据，以及与方法相应的系统、平台及存储介质，可以对噪声能进行实时有效的抑制。
G06Q30/01  ,一种投诉工单的处理方法、装置、设备及存储介质 [发明],本发明实施例提供一种投诉工单的处理方法、装置、设备及存储介质，该方法包括：对采集到的投诉工单音频信息进行预处理，获得处理后的目标文本信息；针对基于层级关联学习的多标签文本分类模型中的每个分类器，将预设标签信息和目标文本信息进行标签嵌入处理，获得嵌入后的文本特征向量；根据文本特征向量和预设的层级向量确定公式，确定各分类器所处层级的层文本特征向量；基于自顶向下为主、自底向上为辅的注意力机制对各层文本特征向量进行层级关联处理，获得处理后的各层级的目标文本特征向量以生成分类预测结果。利用该方法，将投诉工单分类任务抽象为层级多标签文本分类任务，能够更加快速、准确的分类预测，降低人工复核的时间成本和难度。
G06Q10/0635  ,一种卷烟仓库不安全行为自动识别预警系统 [发明],本发明公开了一种卷烟仓库不安全行为自动识别预警系统，涉及行为识别技术技术领域，通过将人员行为因素、声音因素、环境因素作为一级影响因素，将各个不安全特征因素作为二级影响因素构建因素集，根据因素集的各个不安全特征因素对评估集各个元素的隶属度，建立模糊评估矩阵，将各个一级影响因素的一级模糊评估指标B＆lt;subgt;i＆lt;/subgt;作为单元素评估集，建立二级模糊评估指标矩阵，通过层次分析法获取各个一级影响因素的权重集，计算出二级模糊评估指标，通过设置评分集合，计算获得各一级影响因素的综合参数值以及卷烟仓库的综合参数值，不仅可以对明显的不安全行为进行识别，对于一些潜在的不安全行为也可以进行识别和分析。
G10L15/22  ,语音唤醒方法、移动终端及车辆 [发明],本公开涉及一种语音唤醒方法、移动终端及车辆。方法包括：第二设备接收到语音唤醒指令包括的目标唤醒词中的部分内容，发送第二目标广播；第一设备接收到语音唤醒指令，确定第一设备的目标感知状态以及目标感知状态对应的目标唤醒决策时长，目标感知状态包括用于表征感知到第二设备的第一状态和用于表征未感知到第二设备的第二状态；第一设备在目标唤醒决策时长内监听到第二目标广播，第一设备不被所接收到的语音唤醒指令唤醒。如此，根据不同的感知状态，在不同的唤醒决策时长内监听第二目标广播，提高第一设备监听到第二目标广播的灵活性，进而能够有效避免多个设备同时唤醒的问题，提升用户的使用体验。
G10L21/0272  ,语音提取方法、装置、计算机设备和存储介质 [发明],本申请涉及一种语音提取方法、装置、计算机设备和存储介质。所述方法包括：获取待提取混合语音、目标对象的待处理语音特征数据、已训练的目标语音提取模型与目标线索编码模型；获取目标对象在历史时间段的历史语音数据集，将历史语音数据集输入目标线索编码模型进行特征提取得历史语音特征；将待处理语音特征数据输入目标线索编码模型进行特征提取得待处理线索特征；基于目标线索编码模型将待处理线索特征和历史语音特征融合得目标线索特征；将目标线索特征和待提取混合语音输入目标语音提取模型处理输出待提取混合语音中目标对象的目标语音，将目标语音存储至历史语音数据集。采用本方法能提高从混合语音中提取目标对象的语音的准确性。
G10L15/22  ,一种基于自由泛化的自然语义理解交互方法及相关设备 [发明],本发明公开了一种基于自由泛化的自然语义理解交互方法及相关设备。方法包括：接收目标语音指令，当设备指令库不包含所述目标语音指令且符合目标条件时，基于所述目标语音指令推荐目标指令集合，所述目标条件为，在预设时间内接收到大于或等于预设数量个与所述目标语音指令的意图类型相同的语音指令；接收目标信号，基于所述目标信号确定执行所述目标指令集合中的目标指令对应的操作动作，并基于所述目标指令对所述目标语音指令进行泛化匹配，得到目标泛化结果。本发明能够基于用户的说话习惯去匹配指令，不断完善对用户意图的理解，为用户在进行语音交互时带来了更好的体验。
A61M21/00  ,一种可实现降压功能的健康服务机器人 [发明],一种可实现降压功能的健康服务机器人，包括机器人本体，以及搭载在机器人本体上的平板上位机、环境感知模块、语音交互模块、降压设备模块、运动控制模块、下位机主控系统。本发明通过降压设备模块与移动机器人的结合，可以实现用户随时随地的进行降血压治疗；移动便捷，结果准确，功耗极低，便于进行室内家居或者高血压患病者的每日健康治疗，最大程度的对高血压患者进行即时治疗；能够很大程度提高降压装置的移动便携性能，方便用户随时随地进行医疗检测，为用户带来更好的医疗体验。
G10L15/24  ,光纤分布式声学传感信号识别方法、系统、设备及介质 [发明],本发明公开了一种光纤分布式声学传感信号识别方法、系统、设备及介质，其目的在于通过对迁移学习以及半监督学习方法的局限性进行改进，解决DAS跨场景识别的问题。其包括：构建DAS信号识别网络模型，信号识别网络模型采用ResNet‑34网络；利用源域ImageNet图像数据集对信号识别网络模型进行预训练训练，再经过DAS某一典型场景下二维时频图数据集对信号识别网络模型进行训练调整，得到源模型；在源模型基础上，利用DAS其他应用场景所对应的二维时频图数据集对信号识别网络模型进行迁移学习和半监督训练，从而得到最终的识别模型。
G10L13/047  ,一种基于深度学习的语音合成系统及方法 [发明],本发明公开了一种基于深度学习的语音合成系统及方法，包括声学模型，所述声学模型采用深度神经网络或卷积神经网络构建，用于接受语言无关的特征输入，并输出对应的语音波形；参数调整模块，所述参数调整模块针对特定语言的发音特性进行调整，使合成的语音更符合目标语言的发音规则；数据预处理模块，所述数据预处理模块处理语音数据，并将其转化为适合声学模型输入的格式，同时进行标注和分类，为训练声学模型提供充足的数据资源；本发明的有益效果是：将多个关键技术环节整合在一个统一的框架中，实现了从数据预处理到语音波形处理的完整流程；本发明能够自适应多种语言，无需针对每种语言单独训练模型，这在语音合成领域具有创新性。
G10L25/51  ,基于八度偏移的演唱评分校正方法及存储介质 [发明],本发明公开了一种基于八度偏移的演唱评分校正方法及存储介质，方法包括：实时获取演唱者演唱的音的音高值以及所述音对应的曲谱标准音的音高值，得到所述音的演唱音高值和标准音高值，并确定所述音的八度偏移值；当达到预设的校正时间点时，根据已演唱的音的八度偏移值，确定当前演唱八度基准值，并将八度偏移值与当前演唱八度基准值不同的音作为八度唱错音；根据预设的减分比例以及各八度唱错音的单位分值或八度唱错音的数量，计算当前八度减分值，并根据当前八度减分值，对当前演唱评分进行校正。本发明可解决跨不同八度演唱仍给出较高的分数所导致的评分不合理的问题，提高演唱评分的准确性和可靠性。
G10L25/66  ,一种音频数据处理方法及装置 [发明],本申请公开了一种音频数据处理方法及装置，计算机技术领域，用以提高判断待检测的音频数据是否异常的准确性。该方法包括：第一设备可以采用第一数据模型对获取的待检测的音频数据进行处理，获得处理后的音频数据。其中，第一数据模型是对多个正常音频数据的子特征进行训练获得的。正常音频数据的子特征是从时间维度将正常音频数据的特征进行分段处理获得的。第一设备可以根据处理后的音频数据和待检测的音频数据，判断待检测的音频数据是否为异常数据。
G10L15/02  ,语音识别方法、装置、设备及可读存储介质 [发明],本申请公开了一种语音识别方法、装置、设备及可读存储介质。在获取待识别语音数据、确定待识别语音数据的声学特征序列之后，基于声学特征序列进行解码处理，其中，在每个解码时刻，只对该解码时刻的候选解码路径中最后一个词被判定为实体词的候选解码路径进行激励，确定所述解码时刻的各候选解码路径的最终解码得分，最后一个解码时刻解码完毕后，基于最后一个解码时刻的各候选解码路径的最终解码得分，确定语音数据的识别结果。本方案中，在解码过程中，只对可能包含实体词的候选解码路径进行激励，这样可以提升实体词的识别效果，且不影响通用词的识别效果。
F24F11/89  ,一种空调器的控制方法及装置、空调器 [发明],本发明提供了一种空调器的控制方法及装置、空调器，空调器的控制方法包括：获取第一语音指令；分析第一语音指令的第一声源方向角度A＆lt;subgt;声源1＆lt;/subgt;；将第一声源方向角度A＆lt;subgt;声源1＆lt;/subgt;与临界角度A＆lt;subgt;临界＆lt;/subgt;进行比较；根据比较结果和第一声源方向角度A＆lt;subgt;声源1＆lt;/subgt;控制空调器的扫风叶片转动的角度。本发明的控制方法可以使扫风叶片可以直接转向用户所在的位置，不仅提高了风吹向人或避开人所在的位置的准确性，还提高了用户体验。
G16H15/00  ,基于大模型的门诊问诊对话生成电子病历的方法及系统 [发明],本发明公开了基于大模型的门诊问诊对话生成电子病历的方法及系统，其系统包括问诊语音数据收集模块，所述问诊语音数据收集模块电性连接有数据预处理模块，数据预处理模块电性连接有病历数据的模型训练模块，病历数据的模型训练模块电性连接有对话理解与电子病历生成模块，对话理解与电子病历生成模块电性连接有病历审核与编辑模块。本发明通过语音识别和文本生成技术，实现问诊对话的自动转录和电子病历的自动生成，极大减少医生的手动录入工作量，极大的提高了医生的工作效率，从而大大缩短了患者的等待时间，另外统一的格式和结构化的病历内容，使得病历数据更容易被查询和管理。
G10L25/24  ,基于多帧融合的抗噪语音识别方法、系统、设备及介质 [发明],本申请公开了一种基于多帧融合的抗噪语音识别方法、系统、设备及介质，主要涉及抗噪语音识别技术领域，用以解决现有的抗噪技术在面对多噪音源时无法有效的处理，且现有的抗噪声技术需要复杂的传统前端建模步骤，处理过程繁琐的问题。包括：获取进行识别的音频时域信号，进而获得音频特征矩阵；计算音频特征矩阵对应的编码矩阵；将编码矩阵依次输入多头自注意力机制和前馈神经网络模型，以获得融合编码矩阵；将融合编码矩阵，输入预设卷积核通道数的多层卷积模型，以获得输出数据；将输出数据输入decode网络结构的解码器，以获得输出数据对应的文本结果。
G06T11/60  ,稿件生成方法、装置、电子设备和存储介质 [发明],本发明提供一种稿件生成方法、装置、电子设备和存储介质，其中方法包括：确定目标音频；基于目标音频进行要点提取，得到内容要点；基于内容要点进行稿件生成，得到带有图像的目标稿件；图像与内容要点关联，实现了图文并茂的稿件生成，不仅保证了出稿效率，还提升了稿件质量，具有较好的生动性和真实性，克服了传统方案中人工编辑出稿速度慢、智能写作稿件缺乏真实性和生动性，以及后期需要人工处理，十分不便的缺陷，实现了快速有效的稿件生成，极大地缩短了出稿时间，提升了出稿速度和稿件质量。
G10K11/178  ,啸叫抑制方法、装置、电子设备和存储介质 [发明],本发明提供一种啸叫抑制方法、装置、电子设备和存储介质，涉及音频处理技术领域。其中方法包括：获取麦克风采集的第一音频信号，以及所述第一音频信号对应的第二音频信号，所述第二音频信号为所述第一音频信号经过处理后所需输出的参考信号；将所述第一音频信号与所述第二音频信号输入至啸叫抑制模型，得到所述啸叫抑制模型输出的分离权重向量；将所述第一音频信号与所述分离权重向量进行相乘，得到目标音频信号；其中，所述啸叫抑制模型是基于训练样本和所述训练样本对应的目标音频信号标签训练得到的，所述训练样本包括样本第一音频信号和样本第二音频信号。本发明可以减少非线性失真，进而提高啸叫抑制效果，最终提高音质。
H04L67/12  ,一种基于智慧校园的智慧班牌系统 [发明],本发明涉及应用于智慧班牌系统技术领域的一种基于智慧校园的智慧班牌系统，包括班牌系统服务器，班牌系统服务器网络连接有教务系统、管理员端、服务连接端和班牌班级端，服务连接端的连接端连接有信息留言模块，信息留言模块的连接端连接有语音文字转化模块，班牌班级端网络连接有班牌设备、投影设备、音响设备和监控设备，采用上述结构，实现通过将教室中原有的投影设备、音响设备和监控设备与班牌设备进行结合，进而实现对学生进行信息投影和信息播报，有效提高学生接收信息的能力，有效提高信息传递的准确性，有利于智能校园的拓展与完善。
G10L15/32  ,基于机器学习的智能语音交互误唤醒系统及方法 [发明],本发明公开了基于机器学习的智能语音交互误唤醒系统及方法，涉及智能语音交互技术领域，该系统包括特征采集模块、验证比对模块以及执行输出模块，验证比对模块用于对唤醒词准确度评估值Pgz及口型动态数据做综合评估；其技术要点为：在唤醒词准确度评估值Pgz可用的前提下，对口型动态数据与数据库一致语音数据进行执行，利用语音和视频图像结合判断，避免误唤醒的情况发生，若是遇到无法检测到用户口型的场景下，则可通过智能设备之间的联动，利用至少两组语音采集单元获取同一环境下，可用的唤醒词准确度评估值Pgz，分析两组唤醒词准确度评估值Pgz的误差绝对值，在误差范围内即可判断出唤醒口令是否准确，可准确的完成唤醒操作。
G07C9/00  ,一种设置声音密码锁的方法、装置、设备和可读存储介质 [发明],本申请提供一种设置声音密码锁的方法、装置、设备和可读存储介质，该方法包括，通过预设算法识别用户输入的语音信息，确定用户所处情境以及情感状态；通过预设语音识别模型识别语音信息，得到用户的声音特征；根据所处情境、情感状态和声音特征，动态生成声音密码锁。通过该方法可以达到给AR设备设置一个更具有安全性的密码锁的效果。
G10L15/02  ,音频处理方法以及装置 [发明],本发明公开了一种音频处理方法以及装置，该方法包括：确定与待处理音频相对应的至少一个音频片段，并确定至少一个音频片段中每个音频帧所对应的特征向量；将当前音频片段中所有音频帧的特征向量输入至预先训练得到的目标分类器中，以确定当前音频片段的分类结果；基于当前音频片段的分类结果，确定当前音频频段中为人声的位置信息集合；其中，位置信息集合中包括至少一个时序，时序中的第一个元素用于表示起始帧，第二个元素用于表征结束帧；基于各音频片段所对应的位置信息集合，确定至少一个时序的二级标签，以基于二级标签确定待处理音频中的目标内容。本发明实施例所提供的技术方案，实现了有效便捷对音频进行处理的技术效果。
G10L21/0208  ,语音降噪方法、装置、车辆、电子设备和存储介质 [发明],本发明提供一种语音降噪方法、装置、车辆、电子设备和存储介质，所述方法包括：确定目标麦克风采集的待降噪语音信号，以及参考麦克风采集的参考语音信号，目标麦克风与参考麦克风之间的距离大于阈值；基于待降噪语音信号与参考语音信号之间的相关度，确定加权系数；基于加权系数，以及参考语音信号，从待降噪语音信号中提取得到干净语音信号。本发明提供的语音降噪方法、装置、车辆、电子设备和存储介质，由于目标麦克风与参考麦克风之间的距离大于阈值，从而可以保证目标麦克风采集到的待降噪语音信号与参考麦克风采集到的参考语音信号之间存在差异，进而将参考语音信号作为辅助信号，能够更加准确识别和抑制待降噪语音信号中的噪声。
F24F11/89  ,一种空调器的控制方法及装置、空调器 [发明],本发明提供了一种空调器的控制方法及装置、空调器，空调器的控制方法包括：获取语音指令；分析语音指令的声源方向；在多个出风区域中，判断声源方向所处的声源所在区域；根据声源所在区域控制空调器的扫风叶片转向声源所在区域或避开声源所在区域。将空调器的有效使用区域分为多个区域，通过语音指令就可以简单的实现对人的位置的判断并控制扫风叶片转动至人所在的位置或避开人所在的位置且不会形成盲区，在任意空调器的有效使用空间中均可满足用户需求，提高用户的使用体验。
G10L15/06  ,语音批数据生成与混淆方法、语音模型训练方法及装置 [发明],本发明提供一种语音批数据生成与混淆方法、语音模型训练方法及装置，其中语音批数据生成与混淆方法包括：获取各类别语音数据的样本索引序列；对各类别语音数据的样本索引序列进行混淆，并基于预设类别比例，从混淆后各类别样本索引序列中抽取样本索引，生成多个固定比例数据索引块；对多个固定比例数据索引块进行混淆，并基于混淆后固定比例数据索引块，生成索引批数据。本发明提供的方法及装置，可以保证混淆后任意以固定数据索引块大小为粒度的局部范围内批数据的各个类别样本数量比例稳定，从而增强训练模型的稳定性与泛化能力。
H04N21/234  ,云游戏的直播方法、装置、系统、电子设备及介质 [发明],本公开涉及一种云游戏的直播方法、装置、系统、电子设备及介质，方法包括：获取目标云游戏对应的游戏数据；所述游戏数据包括操作指令数据和音视频数据；通过将所述操作指令数据和所述音视频数据输入生成模型进行处理，生成解说文本信息；将所述解说文本信息进行语音转换处理，生成解说音频；将所述解说音频与所述游戏数据中的音视频数据进行合流处理，得到直播数据；将所述直播数据推流至观众端，无需用户进行人工解说，此外，直播数据基于操作指令数据和音视频数据生成的解说文本信息生成，能够提升直播数据的质量，进而提升观看直播数据的用户的体验。
G10L15/00  ,语音识别方法、装置、电子设备及存储介质 [发明],本申请提供一种语音识别方法、装置、电子设备及存储介质，所述方法包括利用目标语音识别模型确定第一帧语音的声学嵌入向量；利用目标语音识别模型确定第一帧语音对应的文本嵌入向量；获取第一帧语音的语种嵌入向量；根据声学嵌入向量、文本嵌入向量和语种嵌入向量，确定第一帧语音对应的第一文本信息。本申请提供的语音识别方法在语音识别时，结合语音对应的语种嵌入向量，在识别过程中考虑到语种的相关信息从而更加准确的识别出对应的文本信息，提高语音识别的精度；同时还可以利用同一个语音识别模型识别不同的语种，增加语音识别模型的适用场景。
G10L21/0216  ,一种基于数据分析的远程音频信息处理方法及系统 [发明],本发明涉及音频信息处理技术领域，特别是一种基于数据分析的远程音频信息处理方法及系统。将音频信号分成不重叠的短时帧信号，并将所述短时帧信号进行降维处理，得到由音频特征数据组成的特征矩阵；基于奇异值分解算法剔除所述特征矩阵的冗余点，得到降冗后的特征矩阵；对所述降冗后的特征矩阵进行逆变换与反标准化处理，得到逆变换和反标准化后的数据矩阵，根据逆变换和反标准化后的数据矩阵生成预设时间段内待分析音频信号的实际波形图；将所述待分析音频信号的实际波形图与相应的标准波形图进行比较分析，得到分析结果；基于所述分析结果，对相应时段的音频信号进行处理，能够有效提高音频处理效率与音频整体质量。
G06F40/226  ,一种NLP质检方法及计算机可读存储介质 [发明],本发明涉及一种NLP质检方法及计算机可读存储介质，将分离或标注出不同讲话人的大篇幅音频会话内容转换为文本，通过模糊查找方式，检查会话内容字符串中是否包含有所述目标字符串中的预期话术内容或/和固定问答内容，如有，则将会话内容字符串中包含的与目标字符串中的预期话术内容或/和固定问答内容相同或相似的文本内容进行剔除，对经步骤3处理后的会话内容字符串进行分句，然后对每个分句进行逐句语义分类，对会话内容字符串中包含的消极情绪分类项进行统计；对处理后的整段会话内容字符串使用大语言模型进行处理，并输出质检结果。本发明在使用少的算力资源同时，将不同讲话人的对话内容进行有效的NLP处理。
G10L15/22  ,货运轨迹生成及查询方法 [发明],本发明公开了货运轨迹生成及查询方法，涉及货运传输领域，包括：大数据建立语音识别反应模式，通过语音识别反应模式控制语音传输器；启动语音识别反应模式，获取操控指令，语音识别反应模式智能识别操控指令，语音传输器切换至对应功能，与语音处理器建立联系机制；在语音传输器所在的对应功能下，语音传输器天线接收语音处理器发射的信号；语音传输器话筒接收音频指令，语音传输器处理音频指令并转化音频指令为信号；通信结束，启动语音识别反应模式，获取操控指令。通过设置大数据处理模块、大数据训练模块、语音识别模块和语音传输器控制模块，可以解放双手执行其他操作，进而提升货运管理的便捷度和智能度。
G06F21/32  ,一种车辆语音交互方法及系统 [发明],本发明提供了一种车辆语音交互方法及系统，该方法包括：当实时监测到用户进入车辆内部时，通过预设拍摄装置实时采集用户的实时人脸图像，并在预设图像数据库中实时判断是否存在与实时人脸图像适配的目标人脸图像；若在预设图像数据库中实时判断到存在与实时人脸图像适配的目标人脸图像，则实时采集用户的声音信息，并对声音信息进行解析处理，以实时判断声音信息是否满足预设要求；若实时判断到声音信息满足预设要求，则判定用户为预绑定人员，并对应启用车辆内部的语音交互权限。本发明能够有效的避免语音控制混淆的现象发生，对应大幅提升了用户的使用体验。
G06N5/025  ,一种数字出版的知识图谱构建方法 [发明],"发明公开了一种数字出版的知识图谱构建方法，包括以下步骤：S1：用SI FT方法提取图片特征，获得128维视觉特征向量，提取语音特征参数MFCC，获得13维声音特征向量；S2:如果两个媒体的低层向量的分布频率较为一致,则认为它们具有相同的语义标签；S3:通过GM‑PLSA主题模型学习潜在的语义主题,构建主题语义空间；S4:获得语义标注后，结合领域知识库与专家经验知识库，实现单模态媒体信息中媒体特征概念与关系抽取。本发明从语义的角度分析提取跨媒体特征，能够将单一模态媒体低层特征映射到多模态媒体高层语义空间，避免了维度灾难，解决了语义鸿沟的问题，进而提升跨媒体多模态信息表达的可靠性。"
G10L25/51  ,干声分类模型训练方法、干声分类及电子设备和存储介质 [发明],本申请公开了一种干声分类模型训练方法、干声分类方法及设备和介质，干声分类模型训练方法包括：标注音频的干声类别，干声类别大于等于2；提取标注后的音频的音频特征，利用音频特征生成音频训练数据集；将音频训练数据集输入多层卷积层后，经过双向LSTM网络，再输入全连接层，最后得到共享音频特征，共享音频特征参与多层卷积层、双向LSTM及全连接层的梯度计算；将共享音频特征输入多个干声类别任务网络，得到音频训练数据集的干声类别的分类结果；基于音频标注的干声类别和音频训练数据集的干声类别的分类结果训练干声分类模型。本申请提高了干声分类模型的训练效率，提高了训练完成的干声分类模型的分类准确率。
G10L15/01  ,基于语音大模型的合成语音检测方法及装置 [发明],本发明涉及一种基于语音大模型的合成语音检测方法及装置，基于语音大模型的合成语音检测方法包括：对每一语音合成算法对应的样本语音进行多鉴别任务的标签标记，构建鉴别任务序列；遍历每一语音合成算法，获取该语音合成算法对应的样本语音的梅尔谱，输入基于前一语音合成算法对应的语音训练模型的编码器，得到隐变量；将隐变量及鉴别任务序列输入基于前一语音合成算法对应的语音训练模型的解码器，获取预测鉴别值；依据预测鉴别值及实际鉴别值，对前一语音合成算法对应的语音训练模型的模型参数值矩阵进行梯度方向优化，在所有合成语音算法遍历完毕后，得到语音大模型。可以提升合成语音检测效率。
G10L21/0216  ,一种基于多通道盲辨识和多通道均衡的语音去混响方法 [发明],本发明公开了一种基于多通道盲辨识和多通道均衡的语音去混响方法，对多通道盲辨识问题，在归一化多通道频域最小均方算法(NMCFLMS)的基础上，设计了一种可变正则化函数，将信噪比、输出信号能量和滤波器长度信息融入其中，使算法对加性噪声、语音的非平稳性具有鲁棒性。此外，为了使所提方法在时变条件下具有更好的跟踪性能，提出了一种根据均方误差对正则化参数刷新的机制。这样，在噪声环境下能获得更快的收敛速度和跟踪速度，能使基于通道均衡的语音去混响获得更好的去混响效果，尤其是在低信噪比环境下自适应滤波器处于暂态期间，去混响性能显著提升。
G10L25/51  ,一种基于音频的电网频率实时跟随与篡改鉴别方法及系统 [发明],本发明公开了一种基于音频的电网频率实时跟随与篡改鉴别方法及系统，本发明方法包括对包含电网频率的音频信号进行降噪、分帧、短时线性调频Z变换，查找指定窗口内最大幅值对应的频率k＆lt;subgt;l＆lt;/subgt;，将所有窗口内获得的频率拼接，得到频率估计值序列F，对其进行平滑滤波得到滤波后的频率估计值序列f＆lt;subgt;z＆lt;/subgt;，然后将其与参考频率序列r进行逐点计算皮尔逊相似度CC和欧式距离D，得到最佳匹配点，最后将最佳匹配点作为参考频率序列r的起点与f＆lt;subgt;z＆lt;/subgt;进行对比，根据是否突变进行篡改判断。本发明旨在实现对电网频率信号的准确提取，尤其是在低信噪比条件下电网频率信号的准确提取，以及实现对包含电网频率的音频信号实现基于电网频率信号的实时跟随与篡改鉴别。
G10L15/06  ,音频特征提取模型的训练方法、设备和存储介质 [发明],本公开提供了一种音频特征提取模型的训练方法、设备和存储介质，属于计算机技术领域。所述方法包括：将多个音频数据分别输入待训练的音频特征提取模型得到每个音频数据的第一特征信息；基于每个音频数据的第一特征信息，确定多个目标训练子集和每个原唱歌曲对应的非同曲歌曲的第一训练排序；按照第一训练排序获取与原唱歌曲之间的相似程度最大的第一预设数目个非同曲歌曲，确定为目标非同曲歌曲；基于目标训练子集和目标训练子集对应的目标非同曲歌曲的音频数据，对待训练的音频特征提取模型进行多次训练，若满足预设训练结束条件，则得到训练完成的音频特征提取模型。采用本公开，提高了训练完成的音频特征提取模型进行特征提取时的准确性。
G10L25/30  ,基于反向知识蒸馏的合成音频检测方法及系统 [发明],本发明提供了一种基于反向知识蒸馏的合成音频检测方法及系统，涉及音频检测技术领域。本发明中，引入反向知识蒸馏模型，学生模型采用与教师模型反向的残差网络结构，教师模型依次提取待检测音频不同层次的音频特征，多尺度融合模块和单层嵌入模块基于该不同层次的音频特征得到瓶颈信息，将教师模型提取到的合成音频特征表示为对真实音频特征的扰动，禁止合成扰动传播到学生模型，学生模型基于该瓶颈信息进行特征重建，从而可以基于学生模型输出的音频重建特征与教师模型输出的音频特征之间的相似度差异来判断待检测音频的真实性。可见，本发明提供的基于反向知识蒸馏的合成音频检测方法不依赖于已知规则或特征，可以更好区分真实音频和合成音频。
G10L25/51  ,一种睡眠声音事件识别方法、装置、存储介质及电子设备 [发明],本发明公开了一种睡眠声音事件识别方法、装置、存储介质及电子设备，获取睡眠环境对应的第一睡眠声音数据集；基于所述第一睡眠声音数据集，经过预设处理方法，确定第二睡眠声音数据集；基于预设特征数据集，经过预设计算方法，计算所述第二睡眠声音数据集中每种睡眠声音对应的所述预设特征数据集中每个特征的特征值；基于所述第二睡眠声音数据集和所述每个特征的特征值，经过预设非线性分类器处理，确定所述每种睡眠声音对应的睡眠声音事件。通过计算每种睡眠声音对应的每个特征的特征值来识别不同睡眠声音；进一步，利用预设非线性分类器描述非线性的数据特征，达到分类效果。因此，通过实施本发明，提高了对睡眠声音事件的识别准确度。
G10L25/51  ,环境噪声源的位置测定方法及系统 [发明],本发明公开了一种环境噪声源的位置测定方法及系统，包括：在设定的时间范围内，采集监测区域中的噪声数据；对所述噪声数据进行预处理，得到处理后的噪声数据；对处理后的噪声数据计算自相关函数，确定自相关函数中表现出周期性的时间尺度，基于时间尺度测定噪声源的位置。本发明能够快速准确地测定噪声源的位置，测定消耗低、易操作，为城市规划和环保策略提供了技术支持。
G10L15/22  ,一种基于语音控制的多种保障设备联合测试方法及系统 [发明],本申请属于飞机测试技术领域，涉及一种基于语音控制的多种保障设备联合测试方法及系统。各保障设备通过手持式终端进行参数设置，所述联合测试方法包括：步骤S1、接收操作人员的语音数据；步骤S2、根据操作人员输入的语音中的关键词，唤醒与该关键词关联的保障设备；步骤S3、提取所述保障设备的待设置参数，并呈现给操作人员，由操作人员对待设置参数进行设置；步骤S4、将设置好的参数发送给所述保障设备。本申请可有效减少手动操作次数，降低人员需求，减轻工作人员的负担，缩短整个测试过程的时长。
G06Q10/0639  ,服务评分方法、装置、电子设备和存储介质 [发明],本发明提供一种服务评分方法、装置、电子设备和存储介质，其中方法包括：获取业务办理场景下的音频数据和视频数据；基于所述音频数据进行情绪识别和意图识别，得到各角色的情绪识别结果和意图识别结果，所述各角色包括客户和客服；基于所述视频数据进行表情识别，得到各角色的表情识别结果；基于所述各角色的情绪识别结果、所述意图识别结果，以及所述表情识别结果，确定客服服务评分，克服了传统方案中视频客服的服务质量不稳定，服务质量改善难度大的缺陷，能够及时了解客户的满意度，从而针对性的进行服务管理，以提升服务质量，优化用户体验，规避服务过程中的风险。
G10L21/0208  ,一种音频数据优化降噪方法及系统 [发明],本发明涉及数据处理技术领域，具体涉及一种音频数据优化降噪方法及系统，包括：采集原始音频信号；获得原始音频信号的所有极值点，根据每个极值点局部范围中数据点的幅值变化获得每个极值点的局部特征值；根据每个极值点与相邻极值点的局部特征差异获得目标极值点；根据目标极值点对原始音频信号进行分解，获得第一组信号；以及获得第二组信号；获得第一组信号与第二组信号中各分量信号的波动程度；根据各分量信号波动程度的差异获得第二组信号中各分量信号的小波阈值；根据获得的小波阈值对第二组信号中各分量信号进行去噪，将第二组信号的去噪分量信号进行重构，获得去噪后的音频信号，从而实现对原始音频信号进行准确的降噪。
G10L21/0208  ,一种实时连麦环境下的动态声音过滤和分类系统、方法及存储介质 [发明],本发明提供了一种实时连麦环境下的动态声音过滤和分类系统、方法及存储介质，其系统包括声音输入捕获模块、多通道缓冲模块、音频预处理模块、动态声音分类模块、环境噪音剔除模块、语音识别与优化模块、多用户语音合成模块、音频输出编码模块、实时传输与播放模块以及用户反馈与自适应调整模块。本发明能够较好地解决现有技术方案在多人实时语音通讯环境中表现出准确性不足、适应性差和计算效率低下等多个方面的缺点，与现有技术相比具有明显优势。
H04M1/72454  ,基于I2S的智能手表通话音频处理单元智能切换方法 [发明],本发明涉及数据处理技术领域，提出了基于I2S的智能手表通话音频处理单元智能切换方法，包括：获取智能手表通话时的监测数据；根据每一秒所取特征观测时间窗内不同时间点的监测数据之间的变化量确定每一秒的行为功耗识别因子；根据每一秒所分各帧音频数据的特征值以及每秒的行为功耗识别因子获取每一秒的通话判别因子；基于每一秒的通话判别因子以及每秒的音频特征矩阵中的元素值确定每一秒的通话决策指数；智能手表的音频处理单元根据每一秒的通话决策指数实现不同模态的切换。本发明通过评估智能手表每一秒的通话状态实现不同模式的切换，避免VAD算法检测手表通话状态时的误差。
G06N5/04  ,一种基于多模态输入和知识图谱的问答方法及装置 [发明],本发明公开了一种基于多模态输入和知识图谱的问答方法及装置，属于人工智能技术领域。所述方法包括：对获取到的多模态数据进行融合，获得融合后的多模态数据；在预先构建的知识图谱中，找到与融合后的多模态数据多个相关的实体与关系，并构成实体集合与关系集合；利用上下文感知技术对实体集合与关系集合中元素的权重进行调整，获得调整权重后的实体集合与关系集合；根据调整权重后的实体集合与关系集合，利用自适应路径探索方法，在预先构建的知识图谱中，找到所有可能导向最终答案的路径并对其进行评估与优化，获得可能导向最终答案的路径；对可能导向最终答案的路径提取信息并生成最终答案。采用本发明，可提高问答系统的准确性和高效性。
G10L15/06  ,语音识别模型的训练方法、语音识别方法、设备和介质 [发明],本公开提供了一种语音识别模型的训练方法、语音识别方法、设备和介质，涉及人工智能技术领域，语音识别模型的训练方法包括：获取至少一个语音指令及每个语音指令对应的词向量；基于多个词向量的加权相乘结果生成与每个语音指令对应的第一语义特征；获取正样本语音对应的第二语义特征和负样本语音对应的第二语义特征；基于第一语义特征与正样本语音对应的第二语义特征的距离和第一语义特征与负样本语音对应的第二语义特征的距离，对语音识别模型进行训练。
G10L15/07  ,一种机载语音交互功能自动分流方法及装置 [发明],本申请属于飞机设计技术领域，特别涉及一种机载语音交互功能自动分流方法及装置。该方法包括步骤S1、基于语音识别请求，开始采集音频；步骤S2、将采集的音频同时发送给设置在指令识别模块及智能问答模块的语音转写单元；步骤S3、通过各语音转写单元进行文字转写；步骤S4、对转写单元转写的文字进行语义理解；步骤S5、基于语义理解结果进行指令匹配；步骤S6、当匹配到预存的指令后，根据指令代码区分采集的音频对应于机载语音控制指令或者是机载实时状态查询指令，并交由控制系统的相应模块执行，当未匹配到预存的指令后，对转写单元转写的文字在问答数据库中进行答案搜索。本申请为飞行员提供便捷，减轻飞行员的操纵负担。
G10L25/51  ,一种用于施工现场环境噪声的监测方法及系统 [发明],本发明涉及施工环境监测的技术领域，特别是涉及一种用于施工现场环境噪声的监测方法及系统，其能够全面、准确地评估施工现场的噪声情况，提高监测的可靠性和管理的效果；方法包括：获取施工现场的声音数据信息；构建噪声信号提取模型，并利用噪声信号提取模型对施工现场的声音数据信息进行噪声提取，获得噪声信号；对噪声信号进行声音识别处理，获得噪声类型特征和噪声强度特征；将噪声类型特征和噪声强度特征输入至一阶施工噪声评估模型中，获得一阶施工噪声评估参数；将一阶施工噪声评估参数与预设的一阶噪声评估阈值进行比对，若一阶施工噪声评估参数超过一阶噪声评估阈值，则将该施工现场标注为“不合格”，若未超过，则标注为“初步合格”。
G10L25/51  ,一种基于DCN的声纹识别方法 [发明],本发明提供了工程施工安全监控技术领域的一种基于DCN的声纹识别方法，包括：步骤S1、获取工程施工过程中大量的历史声纹数据，基于各历史声纹数据构建数据集，将数据集划分为训练集、验证集以及测试集；步骤S2、基于DCN创建一声纹识别模型；步骤S3、通过训练集对声纹识别模型进行训练，通过验证集对训练后的声纹识别模型进行验证；步骤S4、通过测试集对验证后的声纹识别模型进行测试，并不断优化声纹识别模型的损失函数以及超参数；步骤S5、通过声纹传感器阵列从工程施工场地采集施工机械发出的声纹模拟信号，将声纹模拟信号转换为声纹数字信号后输入测试后的声纹识别模型，以进行声纹识别。本发明的优点在于：极大的提升了声纹识别准确性。
G10L15/14  ,一种农机无人驾驶语音识别的控制系统 [发明],本发明公开了一种农机无人驾驶语音识别的控制系统，属于语音识别技术领域。该技术方案由语音识别系统结合无人驾驶农机的启停控制，是一种创新且有潜力的应用。通过语音识别技术实现无人驾驶农机的启停控制，可以提高操作的灵活性和效率，并且在出现人为操作失误、控制线路故障或操控装置断电等情况下依然能够有效地进行启停操作。为了保证系统的安全性，同时加入了保险措施，在控制指令与实际的情况不吻合的情况下还能控制启停电路进行响应操作，这对于保障农机无人驾驶的稳定性和安全性非常重要。这样的创新应用有助于提高农机作业的智能化程度，并减轻人工操作的负担。
G10L21/0216  ,一种定向拾音方法、系统、设备及存储介质 [发明],本发明属于智能语音技术领域，尤其涉及一种定向拾音方法、系统、设备及存储介质，所述方法包括：获取麦克风采集到的原始语音，对所述原始信号进行处理得到第一语音和第二语音；所述第一语音为麦克风阵列采集的目标拾音方向及对侧的语音信号，所述第二语音为定向麦克风采集的语音信号，其中，所述麦克风阵列由若干个全向麦克风组成；对所述第一语音和所述第二语音进行盲源分离处理，得到所述目标拾音方向的目标语音。采用本发明的方法，能够解决现有技术中三维空间的定向拾音中由于某一维度无法布置麦克风阵列而导致无法实现该方向的定向拾音的问题，可以在某维度不设置麦克风阵列，实现该维度上的噪声抑制，提升目标定向拾音性能。
G10L13/08  ,语音合成方法及装置、电子设备和存储介质 [发明],本说明书实施方式提供了一种语音合成方法及装置、电子设备和存储介质。该方法包括：获取第一文本信息，其中，第一文本信息为待合成语音的文本信息；对第一文本信息进行文本转换，得到转换后的第二文本信息，其中，文本转换是指对第一文本信息中的特定文本区间进行标签标注，以对特定文本区间进行文本替换；以及对第二文本信息进行语音合成，获得对应的音频信息，能够提供语音合成的准确率。
G10L15/06  ,热词模型映射的更新方法、语音处理方法及装置 [发明],本公开提供了一种热词模型映射的更新方法、语音处理方法及装置，可以应用于计算机技术、人工智能技术和语音处理技术领域。该热词模型映射的更新方法包括：响应于接收到针对热词模型映射的更新请求，根据更新请求中更新后的远程地址，将更新后的热词模型存储至更新后的本地地址，其中，更新请求还包括热词模型标识和更新后的版本信息；响应于更新后的热词模型存储完成，将热词模型标识、更新后的本地地址和更新后的版本信息关联存储至热词模型映射；响应于定时任务被触发，根据热词模型映射、热词模型标识和更新后的版本信息，确定更新前的热词模型的引用频次；根据引用频次，对热词模型映射进行更新，得到更新后的热词模型映射。
G10L21/16  ,一种音频处理方法、电子设备及介质 [发明],本申请涉及音频技术领域，公开了一种音频处理方法、电子设备及介质。本申请的音频处理方法包括：获取待处理音频数据的第一频率信息；确定振动组件的第二频率信息；根据第一频率信息、第二频率信息确定将待处理音频数据转换为振动组件对应的振动数据的映射参数；根据映射参数对待处理音频数据进行映射处理，获取待处理音频数据对应的振动数据；基于振动数据控制振动组件振动。上述音频处理方法可以将音频数据的高频部分通过映射参数映射转换成马达振动数据对应的低频部分，并且用户可以根据实际需要设计多种映射参数以得到多种振动波形，极大提高了振感的丰富度。
G10L15/16  ,一种语音唤醒方法、装置、设备及介质 [发明],本发明公开一种语音唤醒方法、装置、设备及介质，方法包括：当检测到待识别语音时，对待识别语音进行预处理，并提取其声学特征；将声学特征输入至预设的声学模型，通过声学模型输出声学特征所对应的音素状态后验概率，并确定音素状态序列；基于预设的发音词典和音素状态序列，利用基于令牌的维比特解码方式对待识别语音进行解码，当识别到待识别语音中存在预设唤醒词时，触发待唤醒设备进行唤醒状态；其中，声学模型由基于预设的电力调度场景语料库训练所获得的隐马尔可夫模型和神经网络模型组成；神经网络模型包括正交时延神经网络、深度神经网络和长短期记忆网络。本发明能够降低在电力调度场景下语音唤醒的误唤醒率，提高语音唤醒的识别精度。
G10L17/24  ,一种关于用户语音唤醒灵敏度的自适应调节方法 [发明],本发明公开了一种关于用户语音唤醒灵敏度的自适应调节方法，步骤S1、采集用户有效在线使用时长；步骤S2、采集用户唤醒终端的音频数据，采用训练好的ASR模型识别所述音频数据的识别效果，标注误激活和难激活数据；步骤S3、计算用户设定时间内难激活和误激活分数；步骤S4、根据难激活和误激活分数下发用户语音唤醒灵敏度结果，终端调整用户语音激活阈值。本发明引入ASR语音识别，对用户的语音唤醒情况进行分析和标注，并根据用户的使用时长计算出用户的语音唤醒灵敏度自适应结果并下发给用户，使用户在使用唤醒词拉起语音功能时出现误激活和难激活的频率大大降低，大幅提升了用户体验。
G10L15/22  ,语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种语音交互方法、服务器及计算机可读存储介质，方法包括：接收车辆转发的当前语音请求，根据大语言模型，确定与当前语音请求相对应的目标意图信息和目标交互信息。服务器根据目标意图信息和目标交互信息，生成与当前语音请求对应的车辆控制指令，及将车辆控制指令转发至车辆，由此完成与用户的语音交互。如此，在本申请中，对于接收到的当前语音请求，服务器可调用预先训练的大语言模型，以通过大语言模型确定当前语音请求的目标意图信息和目标交互信息，最终生成车辆控制指令。本申请可根据语音请求和大语言模型，定位车载系统用户界面中目标操作对象，避免用户需进行多轮澄清的情况出现，语音指令的流畅性和便捷性得以提升。
G10L25/51  ,基于音频的设备故障检测方法、装置及相关设备 [发明],本公开提供了基于音频的设备故障检测方法、装置及相关设备。涉及数据处理领域，尤其涉及深度学习、语音技术等技术领域。该方法包括：获取由无人机针对目标设备采集的初始音频数据；对初始音频数据进行预处理，得到待检测音频数据；对待检测音频数据进行特征提取，得到待检测音频数据的音频特征；基于音频特征构建信息图；基于信息图和图神经网络模型，得到针对目标设备的故障检测结果。基于本公开实施例提供的方式，可以借助音频数据的音频特征反映设备的实时情况，因此，可实现自动化对设备进行故障检测，以节约人力资源。
G10L25/51  ,演讲提示与辅助演讲的方法、装置和辅助演讲系统 [发明],本申请提供了一种演讲提示与辅助演讲的方法、装置和辅助演讲系统。该方法包括：获取演讲对象的演讲信息；根据演讲信息确定演讲对象是否卡顿和/或紧张；在演讲对象卡顿和/或紧张的情况下，控制耳机播报提示音频；在演讲对象卡顿和/或紧张的情况下，生成虚拟演讲对象，并控制虚拟演讲对象代替演讲对象继续演讲。本方案解决了现有技术中演讲提示的效果较差的问题。
G10L15/08  ,一种基于AI的降噪扩声方法、系统、电子设备及介质 [发明],本发明公开了一种基于AI的降噪扩声方法、系统、设备及介质，属于降噪扩声领域，包括采用预设方式获取课程信息，将课程信息转化为课程文字信息；使用收音装置采集声音信息，将声音信息转化为声音文字信息；采用AI识别模型，将课程文字信息与声音文字信息进行比对，滤除与课程文字信息不匹配的声音文字信息对应的声音信息，保留课程声音；对课程声音扩声。本发明在使用过程中，只有老师的声音被保留下来，然后针对老师的声音进行扩声，能够消除杂音，保证学生能够听的更加清楚。
G10L21/10  ,一种数字人音视频生成系统 [发明],本申请实施例公开了一种数字人音视频生成系统，所述系统包括数字人形象生成模块、音视频生成模块以及画质优化模块，其中：所述数字人形象生成模块，用于获取初始音视频，所述初始音视频为包括目标用户形象和语音的音视频，以及，根据所述初始音视频创建得到与所述目标用户形象和语音对应的目标数字人形象的音视频；所述音视频生成模块，用于获取录制文本数据，以及，根据所述录制文本数据以及所述目标数字人形象的音视频，生成初始数字人音视频；所述画质优化模块，用于对所述初始数字人音视频进行人脸修复处理，生成目标数字人音视频。用户利用该系统不仅可以自动生成数字人音视频，还提高了音视频质量、画质，从而提高了用户的观看体验。
G10L15/06  ,一种基于语言知识融合的高效低资源语音识别方法 [发明],本发明实施例提供了一种基于语言知识融合的高效低资源语音识别方法，属于低资源语音识别领域，其特征在于：(1)利用权重共享实现适配器轻量化微调；(2)利用两阶段训练策略实现源语言的知识提取与融合；(3)通过细粒度适配器融合模块实现多个适配器的精细化特征联合表达。其中的方法具体包括：创建源语言以及低资源语言数据集；搭建第一阶段训练网络，基于轻量化适配器完成源语言的训练，实现源语言知识提取；搭建第二阶段训练网络，基于轻量化适配器，利用细粒度适配器融合模块进行精细化知识融合。本发明实施例可以提高低资源语言的识别准确率，同时可以保证微调时具备较高的参数效率。
G06Q30/018  ,综合多模态AI分析的欺诈风险评估方法及系统 [发明],本发明涉及数据处理的技术领域，且公开了综合多模态AI分析的欺诈风险评估方法及系统，所述系统包括被调查人员特征数据采集管理模块、被调查人员异常特征分析模块、被调查人员综合欺诈风险分析模块；通过采用人工智能蜻蜓优化算法分别将被调查人员脸部表情图像与异常脸部表情图像、语音数据与异常语音数据、语音文本文字数据与异常文字文本语气词数据进行匹配并高效自动统计出被调查人员的异常脸部表情评分、异常语音评分、异常文本文字评分，从而实现对欺诈风险评估的自动量化及多模态智能处理，提高了欺诈风险评估结果的可靠性和效果。
G10L17/18  ,基于DW-Metaformer轻量级神经网络模型的说话人识别方法 [发明],本发明提供了一种基于DW‑Metaformer轻量级神经网络模型的说话人识别方法，包括如下步骤：原始语音信号预处理；提取短期幅度功率谱的语音特征并进行融合；获取GMM统计特征；构建DW‑Metaformer轻量级神经网络模型，进行训练，并进行奇异值分解处理，得到低秩化DW‑Metaformer训练模型；构建虚拟教师知识蒸馏模型，并利用其对所述低秩化DW‑Metaformer训练模型进行知识迁移；构建NPLDA后端模型并训练；测试。该说话人识别方法，弥补了MFCC特征部分信息的缺失和估计方差大的问题，可以更好的表示说话人的个性信息，使用更低的计算成本，更准确更高性能地实现说话人识别任务。
G10L25/30  ,一种基于少量强标注数据的声音事件检测方法和装置 [发明],本发明提供一种基于少量强标注数据的声音事件检测方法和装置，该方法包括：S1、构建在大量弱标注数据下的音频预训练模型；S2、采用少量强标注数据训练得到初步的声音事件检测网络；S3、通过音频预训练模型获取强标注数据的特征；S4、将强标注数据的特征输入初步的声音事件检测网络中进行训练，得到训练后的声音事件检测模型；S5、将待预测的音频输入到训练后的声音事件检测模型中，检测待预测的音频中的声音事件。解决强标注数据收集和标记困难，尤其针对一些特殊应用领域，难以利用少量数据实现声音事件检测模型训练的问题。
G10L15/06  ,会议纪要的生成方法、装置和会议纪要生成系统 [发明],本申请提供了一种会议纪要的生成方法、装置和会议纪要生成系统。该方法包括：获取训练语音数据和目标语音数据；构建初始识别模型；将训练语音数据输入至初始识别模型，得到训练语音数据对应的识别文本；对识别文本进行多维度评估，在识别文本不满足预定条件的情况下，对初始识别模型进行优化，直到识别文本满足预定条件，得到目标识别模型；将目标语音数据输入至目标识别模型，得到目标语音数据对应的目标识别文本。该方案解决了现有技术中用户对于生成的会议纪要的体验效果较差问题。
G10L25/03  ,一种基于音频分发的音频传输质量评价方法及系统 [发明],本发明公开了一种基于音频分发的音频传输质量评价方法及系统，通过将用户音频数据进行环境声音频分析与人声音频分析，得到环境音频数据与人声音频数据；基于所述环境音频数据与人声音频数据进行用户行为特征的周期性变化分析，得到行为特征数据；基于时间维度，获取实时环境音频数据进行数据序列化并基于LSTM预测模型进行音频特征分析与预测，结果预测音频数据；基于结果预测音频数据与行为特征数据进行基于音频传输方案分析与降噪音频分析，得到音频传输方案。通过本发明，能够基于用户行为特征，在音频数据的处理中，实现动态调整音频处理方案的目的，从而提高音频数据的传输效率与降噪处理的质量，实现音频数据的科学评价分析，提高用户体验。
H04M7/00  ,一种家用智能音箱内置话机系统及实现方法 [发明],本发明公开一种家用智能音箱内置话机系统及实现方法，所述家用智能音箱内置话机系统将传统固定电话内置到智能音箱中，所述系统包括：安卓应用层、安卓HAL层、Linux层、硬件层，仍然通过RJ11电话线实现传统固话语音业务。本发明在传统智能音箱走进千家万户和传统固定话机逐步退出家庭环境的背景下，以及中小学生近视比例逐年攀升和父母经常需要远程和孩子沟通的背景下，可以在家庭没有传统固定电话机的情况下实现传统固定电话机的功能，支持人工智能语音呼叫，操作方便，实用性强，提升用户感知。
G07F19/00  ,无障碍控制方法、装置、自动存取款机和存储介质 [发明],本发明公开了一种无障碍控制方法、装置、自动存取款机和存储介质。该方法应用于自动存取款机，该方法包括：响应于当前用户的插卡操作，获取所述当前用户的无障碍信息，并基于所述无障碍信息确定所述当前用户是否为视障用户；如果所述当前用户为视障用户，则开启无障碍控制功能，所述无障碍控制功能支持所述当前用户进行无障碍存取款。本发明实施例利用上述技术方案，能够丰富自动存取款机的功能，提高视障用户的存取款效率。
G10L15/22  ,音频的处理方法、装置、电子设备及存储介质 [发明],本申请提供了音频的处理方法、装置、电子设备及存储介质，具体实现方案为：在终端设备处于声控模式的情况下，根据第i帧音频的音频特征确定所述第i帧音频中的干净语音；其中，i为正整数；根据所述第i帧音频中的干净语音确定所述第i帧音频的统计特征；利用所述第i帧音频的音频能量以及所述第i帧音频的统计特征，控制所述终端设备的声控触发状态。根据本申请的技术方案，能够减少终端设备出现声音误触发的情况。
A01M29/10  ,一种智能车用低能耗激光驱鸟方法、系统及介质 [发明],本发明提出一种智能车用低能耗激光驱鸟方法、系统及介质，方法包括：获取鸟鸣信号，对鸟鸣信号进行信号预处理，得到目标音频信号；基于预设的声纹库对目标音频信号进行鸟鸣声特征识别，确定目标鸟类及其属性信息，并根据鸟鸣信号确定目标鸟类所在的目标范围；获取红外检测信号，根据红外检测信号定位目标鸟类在目标范围内的位置，得到目标鸟类与当前车辆之间的方位信息；并基于红外检测信号确定目标鸟类与当前车辆之间的距离信息；根据属性信息、方位信息以及距离信息生成用于驱赶目标鸟类的驱鸟激光信号。本发明可提高驱鸟准确性，降低能耗，可适用于车载环境。
G10L25/18  ,一种基于音频特征形状匹配的乐器演奏质量评价方法 [发明],本发明涉及一种基于音频特征形状匹配的乐器演奏质量评价方法，属于计算机技术领域，包括以下步骤：对乐器演奏的音频进行演奏难度评级；声纹提取和计算相似度：收集乐器演奏的数据，通过aukit处理音频并进行降噪和去除静音；对输入的乐器演奏音频进行短时傅里叶变换得到音频的梅尔频谱；提取音频特征时；计算音频特征灰度图的相似度；节奏检测和旋律检测：提取不同乐器的演奏节奏特征和旋律特征；获取试卷评分：根据条件评价和相似性对比融合，同时结合难度系数、整体相似度、乐器演奏的节奏和旋律的评价输出，获取整体分数。本发明通过评估音频的难度系数和音频节奏、旋律相似度获取整体评分，使得节奏和旋律提取更加稳定和鲁棒。
G06F40/30  ,基于大语言模型实现无人机集群的精准指控方法及系统 [发明],本发明公开一种基于大语言模型实现无人机集群的精准指控方法及系统，该方法包括如下步骤：步骤1，语音/文本处理模块通过语音/文本处理模型，将用户输入的语音/文本数据转化成可以输入到指控领域的垂直大语言模型中的文本数据；步骤2，将经语音/文本处理模块转化得到的文本数据输入到指控领域的垂直大语言模型中，指控领域的垂直大语言模型输出集群指控语令；步骤3，指令输出模块通过正则化和数据存储对接收到的集群指控语令进行处理，得到可被指控平台调用的集群指控指令；步骤4，指控平台将接收到的集群指控指令发送到无人机集群中，实现无人机集群指控。
G10L25/51  ,一种智能开关柜的监测方法、系统以及存储介质 [发明],本申请涉及一种智能开关柜的监测方法、系统以及存储介质，涉及开关柜设备的领域，该方法包括获取预设时间段内多个开关柜各自对应的音频信息以及电压数据，基于电压数据确定每个开关柜在预设时间段内的电压平均值以及方差，基于预设音频信息对每个开关柜对应的音频信息进行过滤，得到异常音频信息，预设音频信息表征每个开关柜运行正常时发出音频对应的音频，基于异常音频信息确定每个开关柜在预设时间段内的异常音频数量以及异常音频持续时长，基于电压平均值、方差、异常音频数量以及异常音频持续时长确定每个开关柜的巡检频率，基于巡检频率控制巡检机器人对每个开关柜进行监测巡检。本申请具有提高每个开关柜的监测巡检效果的效果。
G06F16/332  ,一种面向养老服务机器人的情感调节系统 [发明],本发明以深度学习为基础提出了一种关于养老服务机器人的情感调节系统，主要包括：情感语音识别模块、语义理解模块、情感分级模块、决策模块和情感语音合成模块五大模块，判断老人的当前的语音情绪，并将情绪分级，针对老人的不同情绪，做出不同的决策，通过使用不同语气的语音来做出不同的应答，使老人的情绪得到缓和，并将老人一段时间内的不同情绪记录统计。
G10L13/08  ,基于文本的数字人生成方法及装置 [发明],本申请提供了一种基于文本的数字人生成方法及装置，其中，该方法包括：构建嵌入层；利用所述嵌入层对说话文本进行文本到语音的编码，得到训练好的语音模型；将所述训练好的语音模型嵌入到视频的训练结果中，以生成数字人。本申请解决了现有技术中通过TTS进行音频合成导致生成能说话的数字人速度慢、精准度有损失的技术问题。
G10L13/08  ,文本驱动数字人的方法及装置 [发明],本申请提供了一种文本驱动数字人的方法及装置，其中，该方法包括：构建说话文本到说话音频的隐式空间的嵌入层；基于所述嵌入层，通过在音频生成视频的训练结果上再次训练，建立起所述音频和所述视频的映射关系；基于所述映射关系，来驱动数字人。本申请解决了现有技术中通过TTS进行音频合成导致生成能说话的数字人速度慢、精准度有损失的技术问题。
G10L21/007  ,一种音频处理方法、装置、电子设备、芯片及介质 [发明],本公开提供一种音频处理方法、装置、电子设备、芯片及介质，涉及电动汽车技术领域。该方法包括：基于终端的当前工况下的第一音频和固定工况下的第二音频之间的差异，确定第一音频的相位信息；基于当前工况和固定工况，对第二音频的幅度信息进行调整，获得第一音频的幅度信息；基于第一音频的幅度信息和相位信息，获得第一音频的实时声浪。本公开提供的音频处理方法，能够基于不同的工况在对相位声码器算法中改变相位的同时对幅度部分进行修正，从而保障不同工况下人耳的同等感知。
G10L15/183  ,基于知识驱动文本生成的语音识别领域自适应方法及系统 [发明],本发明实施例提供一种基于知识驱动文本生成的语音识别领域自适应方法及系统。该方法包括：将目标领域知识输入至知识描述框架进行填充，引导大语言模型生成符合目标领域知识的目标领域文本；将目标领域文本输入至文本转语音模型，生成第一训练数据；利用第一训练数据对语音识别模型进行领域自适应的第一优化训练，利用训练后的语音识别模型输出第一训练数据的目标音频假设；将目标音频假设输入至大语言模型进行知识驱动的文本生成迭代，得到第二训练数据；利用第二训练数据对语音识别模型进行领域自适应的第二优化训练，得到领域自适应的语音识别模型。本发明实施例显著提高语音识别性能，同时优化训练出领域自适应性能更强的语音识别模型。
G10L13/02  ,一种基于智能客服的处理方法、装置、设备及介质 [发明],本发明实施例公开了一种基于智能客服的处理方法、装置、设备及介质。其中，该方法包括：获取对话内容中客服内容对应的情感信息和语音文件；将所述情感信息和所述语音文件输入目标情感适配模型中，输出重构后的声学特征；将重构后的声学特征转换为目标音频，并以所述目标音频回复目标客户。本技术方案，能够有效缓解在交互场景中存在合成的语音回复语气生硬、自然性和表现力差的问题，提高了智能回复语音的可懂度和表现力。
H04M3/527  ,对话方法及装置、存储介质和电子设备 [发明],本申请公开了一种对话方法及装置、存储介质和电子设备，涉及人工智能领域，该方法包括：获取目标对象的初始语音数据，其中，初始语音数据中至少包括目标对象询问的问题信息；通过目标识别模型对初始语音数据进行意图识别，得到意图识别结果；依据意图识别结果，确定目标对象询问的问题信息对应的目标业务场景；依据目标业务场景，获取目标对象的多个目标语音数据，并依据多个目标语音数据，生成问题信息的回复信息。通过本申请，解决了相关技术中在人机交互对话时通过对用户的语音数据和预定义的规则进行匹配，实现对用户的意图进行识别，导致回复用户问题的准确率比较低的问题。
G06Q50/20  ,一种口才训练方法、装置、设备及存储介质 [发明],本申请提出一种口才训练方法、装置、设备及存储介质，口才训练方法获取训练对象的口才表达音频数据以及视频流，对口才表达音频数据以及视频流进行情感分析，确定训练对象的情感标签，确定口才表达音频数据对应的文本内容，通过跨模态分析模型对口才表达音频数据、视频流以及文本内容进行语义关系、上下文信息以及手势动作的协同分析，生成手势动作指导建议以及语音指导建议，基于跨模态的协同分析，有利于准确反映不同模态数据的关联以及保证训练过程中模态数据的连贯性，提高手势动作指导建议以及语音指导建议的准确性；根据情感合成模型、语音指导建议以及文本内容生成情感标签对应的目标改善语音，进一步提高训练对象的训练效果。
G06T11/60  ,流程图的绘制方法、装置和电子设备 [发明],本申请提供了一种流程图的绘制方法、装置和电子设备，涉及大数据技术领域，该流程图的绘制方法包括：获取对待绘制语音进行语音识别得到的识别文本；对识别文本进行解析，得到识别文本中的多个关键文本；对多个关键文本进行分类，得到多个文本类别，多个文本类别包括：决策性、主体性和动作性；根据多个文本类别，文本类别包括的至少一个关键文本以及识别文本的语义，确定主干文本；根据主干文本中决策性的关键文本，以及识别文本的语义，确定分支文本；根据主干文本和分支文本，绘制待绘制语音对应的目标流程图，实现目标流程图像准确高效的绘制。
G10L15/22  ,一种音视频的生成方法、装置、设备及存储介质 [发明],本申请实施例公开了一种音视频的生成方法、装置、设备及存储介质。该生成方法包括：基于初始二维人脸图像，生成与初始二维人脸图像对应的匹配三维人脸模型。对音频数据进行特征提取，得到语音特征，根据语音特征和匹配三维人脸模型，预测和音频数据对齐的目标三维人脸动作序列，根据目标三维人脸模型中的第二人脸关键点，匹配三维人脸模型中的第二人脸关键点，以及第一人脸关键点和匹配三维人脸模型中的第二人脸关键点的对应关系，对第一人脸关键点调整，得到匹配的目标二维人脸图像，将目标二维人脸图像拼接，得到视频，将视频与音频合成，得到目标音视频。实现了对二维人脸图像的面部五官进行整体驱动，使人脸表情变化自然流畅，更加拟人化。
G10L15/22  ,语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种的语音交互方法，所述方法包括：获取目标字词信息，通过预先训练完成，且能根据字词信息推理出对应的类别信息的大语言模型，确定目标字词信息的目标类别信息，根据目标字词信息和目标类别信息，确定语音交互模型，进而根据语音交互模型完成语音交互。如此，本申请的服务器可根据大语言模型，推理目标字词信息的类别以确定目标字词信息的目标类别信息，使得目标字词信息的理解和分类均可由大语言模型执行，目标字词信息的分类效率得以保障。本申请可根据目标字词信息及目标字词信息的目标类别信息，训练语音交互模型，以使得语音交互模型能学习到目标字词信息的语义或类别，语音交互模型的可信度得到保障。
G06F3/0354  ,一种基于无线语音控制的智能触摸面板 [发明],本发明涉及一种基于无线语音控制的智能触摸面板，包括面板本体、按键、语音输入模块、控制板和盖板；面板本体正面开设有相邻的第一区域和第二区域，第二区域开设有拾音孔，第二区域和面板本体背面通过拾音孔连通；按键安装在第一区域，且按键的一端贯穿第一区域位于面板本体背面；语音输入模块安装在面板本体背面，且与拾音孔相对；控制板安装在面板本体背面，控制板上具有分别与第一区域和第二区域对应的第一控制区域和第二控制区域，并且通过按压按键能够对第一控制区域进行控制，通过语音能够对第二控制区域进行控制；盖板滑动安装在面板本体正面，且盖板能够对第一区域或第二区域进行遮挡。
G10L15/22  ,基于深度学习的智能语音控制系统及方法 [发明],本申请涉及语音控制领域，其具体地公开了一种基于深度学习的智能语音控制系统及方法，其首先获取智慧教室待检测语音信息和从数据库白名单中调取的多个已授权用户的语音信息，然后，将所述待检测语音信息进行降噪后进行语义编码并通过二维排列以得到待检测语音特征矩阵，接着，将所述多个已授权用户的语音信息经过傅里叶变换后进行排列并通过语义编码以得到多个已授权语音特征矩阵，最后，构建所述待检测语音特征矩阵和所述多个已授权语音特征矩阵之间的优化相似度关联特征矩阵并通过分类器，以判断智慧教室门锁语音对比认证结果是否通过，进而为智慧教室提供了一种先进的语音控制解决方案，从而提升了教学环境的智能化和便捷性。
H04N23/66  ,拍照的控制方法、装置、电子设备及存储介质 [发明],本申请提供了拍照的控制方法、装置、电子设备及存储介质，控制方法应用于耳机，包括：获取用户的语音信息；通过已构建的语音语义识别模型识别语音信息，确定唤醒信息；若唤醒信息为预设唤醒词，基于唤醒信息启动与耳机连接的移动终端的语音控制拍照功能；通过已构建的语音语义识别模型识别语音信息，确定控制信息；基于控制信息，控制移动终端的拍照动作，由于通过耳机获取用户的语音信息，并将语音信息转换为控制信息，再采用控制信息控制与耳机连接的移动终端的拍照动作，提高了自拍拍照的控制效率，解放了用户的双手，能自由摆出各种姿势，从而提高了用户进行自拍的体验感。
A61G7/015  ,随床智能用鞋护理系统、智能护理床及其控制方法 [发明],本申请涉及一种随床智能用鞋护理系统、智能护理床及其控制方法，本申请采用机器人技术，利用搬鞋机器人响应病人语音指令，进行搬鞋，语音提示穿鞋，机器人即可将鞋子送到到指定位置，方便病人穿鞋。因此，本申请设计的智能护理床，能够为患者提供随床智能护理功能，方便患方使用，避免患者在找鞋的过程中发生意处，保证患者安全。
G10L15/16  ,基于涌现交流规则的多智能体通信方法及系统 [发明],本发明提出一种基于涌现交流规则的多智能体通信方法，包括：说话者模型根据第一上下文面板推理得到第一规则，并结合第一上下文面板的规则标签构建损失函数，以训练更新说话者模型，得到中间说话模型；中间说话模型将第二上下文面板的第二规则发送至听者模型，听者模型根据第二规则从备选答案面板选择正确答案以回答问题面板；根据第二规则和第二上下文面板的规则标签、正确答案和答案标签构建损失函数联合训练中间说话模型和听者模型，得到最终说话模型和最终听者模型；通过最终说话模型提取目标上下文面板的目标规则，最终听者模型根据目标规则从其候选答案中选择答案以完成指定任务。本发明提高了智能体的认知推理能力和表达抽象概念的能力。
G06F18/214  ,一种多种信息源的多模态大模型构建系统 [发明],本发明公开了一种多种信息源的多模态大模型构建系统，属于人工智能技术领域。所述构建系统包括收集和处理目标人物的多种模态信息，并构建具备该目标人物语言语音特征的自生成式语音大模型。构建系统包括信息采集、处理、模型构建、训练、文本生成、输出和评价模块。通过模型的训练，使模型学习目标人物的语音、语言和情感特征，并生成模拟目标人物语言风格和情感特征的文本。同时，系统中的评价模块在训练过程中评价模型生成的语音和/或语言文本与目标人物特征的差异，并将评价结果反馈到模型训练模块优化模型，并最终获得满足用户要求的多模态大模型。
H04W4/02  ,实时位置共享方法、装置、设备及存储介质 [发明],本公开提供了一种实时位置共享方法、装置、设备及存储介质，涉及通信领域，该方法由第一终端执行，在第一终端和第二终端的通话过程中，接收第二终端发送的位置共享请求，第二终端是向第一终端发起通话的终端；根据定位请求向短信系统下发短信发送通知；接收第一终端发送的第一定位信息，第一定位信息包括卫星定位信息和网络定位信息；根据第一终端和第二终端的通话音频确定音频定位信息；根据第一定位信息和音频定位信息，确定第一共享定位信息；向第二终端发送第一共享定位信息。该方法可以使第一共享定位信息更加准确，精度更高。
G10L17/26  ,一种便携式蝙蝠超声波监测与在线识别终端 [发明],本发明公开了一种便携式蝙蝠超声波检测与在线识别终端，它包括：电源管理单元、声波采集处理单元、嵌入式微处理器单元、存储单元和触控显示单元；电源管理单元采用高效低功耗稳压电源，为整个系统提供电能；声波采集处理单元采用MEMS模拟麦克风采集和处理蝙蝠超声波信号；嵌入式微处理器单元将超声波时域信号转换为频域信号的语谱图，并基于深度学习模型对蝙蝠种类智能分析及处理；存储单元采用大容量SD卡存储超声波文件；触控显示单元通过触摸屏进行功能设置、功能操作和显示识别结果等。本发明能采集宽频声波信号，尤其是采集蝙蝠超声波信号，同时能有效解决卷积神经网络对于信号特征的提取存在时间损失的弊端以及目前尚无便携式蝙蝠种类在线识别设备等问题。具有方便携带、便于操作，识别准确率高、识别速度快等优势，为此提供了一种新的便携式蝙蝠种类在线识别工具。
G07B15/04  ,具有语音互动模块的停车管理系统及方法 [发明],本申请实施例公开一种具有语音互动模块的停车管理系统，可将用于停车费支付的二维码转变为对应的音频信号，使得用于支付的支付终端可通过接受音频信号来获取支付信息，并根据支付信息来进行支付动作，包括：车辆识别模组、闸口模组、支付设备和处理模块，其中，所述车辆识别模组、所述闸口模组和所述支付设备分别与所述处理模块可通讯地连接；其中，所述车辆识别模组包括图像识别模块和声音识别模块，所述图像识别模块和所述声音识别模块分布被可通讯地连接于所述处理模块；其中，所述支付设备包括二维码展示模块和设备发声模块，所述二维码展示模块和所述设备发声模块分别被可通讯地连接于所述处理模块。
G10L17/02  ,语音数据的说话人的识别方法、装置及相关设备 [发明],本申请公开了一种语音数据的说话人的识别方法、装置及相关设备，属于人工智能技术领域。所述方法包括：获取待识别语音数据；将所述待识别语音数据对输入到预先训练得到的声纹特征识别模型中进行特征提取，得到多个特征向量，所述特征向量与说话人对应，所述声纹特征识别模型为用于进行特征提取的模型；将所述多个特征向量进行语音聚类处理，得到声纹聚类信息，所述声纹聚类信息包括所述说话人在至少一个时间段内的语音数据。在本申请实施例中，利用预先训练得到的声纹特征识别模型，识别语音数据的声纹特征再进行分类，根据语音聚类结果，就能将语音数据与对应的说话人进行匹配，与相关技术中通过人工依次匹配的方式相比，提高了匹配效率。
G10L25/51  ,一种基于设备运行声纹采集分析方法及装置 [发明],本申请公开了一种基于设备运行声纹采集分析方法及装置，将声学传感器记录的设备运行的声纹进行保存；通过高通滤波器，采用传递函数增强声纹中的高频部分，获取增强的声纹信号；将增强的声纹信号之间的重叠区域的每一帧声纹信号进行加窗处理；获取每一帧声纹信号的频谱，根据频谱计算功率谱并进行平滑并消除谐波；获取设备运行静态信息和动态信息；进行声纹特征提取，并形成声纹模型；使用声纹数据库中的测试数据对声纹模型进行测试；将声纹模型中的声纹与声纹数据库中的声纹进行分析比对，并输出比对的结果，解决了现有的方法不能较早的发现设备存在的设备隐患和缺陷无法对化工装置设备运行异常状况及时进行处置的问题。
A47G1/02  ,一种智能化妆方法及其智能化妆镜 [发明],本发明公开了一种智能化妆方法及其智能化妆镜，具体涉及妆容大数据收集处理领域，本发明通过语音唤醒智能化妆镜开机，智能化妆镜对用户面容进行摄取并进行检测，通过网络获取妆容数据信息，自动搜索与用户脸型相匹配的妆容供用户选择；用户可多次对妆容进行选择，并将用于所选择的妆容匹配在用户脸部进行显示，进行妆前效果展示，在化妆的过程中进行分屏展示妆容效果图和妆前效果图进行比对，并通过对妆容局部放大的方式提示用户需要精修点，精修完毕后，用户通过语音关闭智能化妆镜。具有能够对用户面容进行自动识别检测，搜索与用户脸型匹配的妆容，方便用户进行选择，并能够提前观察妆容效果，以提高用户化妆的满意度以及妆容的精美度。
G06F16/332  ,一种基于人工智能的英语口语交互训练系统 [发明],本发明公开了一种基于人工智能的英语口语交互训练系统，涉及人工智能技术领域。云服务器包括多个预先训练的对话模型，每一对话模型对应一个场景标签；用户端采集识别音频数据对应的文本数据，进行语法修正得到待回复文本上传至云服务器；云服务器识别待回复文本的语义信息和场景信息，根据场景信息匹配场景标签调用目标对话模型得到回复文本，向用户端返回回复文本；用户端根据回复文本生成回复音频数据，根据回复音频数据播报回复音频。结合语音识别和人工智能进行语音交互提高英语口语训练的自由度，并且云服务器可以预先训练多个对话模型，根据当前对话的场景信息确定目标对话模型，极大减小了对话模型的复杂度和回复的速度和准确度。
G06F40/30  ,一种智能客服的自动测评方法、装置、设备及存储介质 [发明],本说明书涉及人工智能技术领域，尤其涉及一种智能客服的自动测评方法、装置、设备及存储介质。其方法包括，获取至少一个客户与智能客服进行交互的全过程整合为交互信息，然后分析交互信息中的语义以及语义相似度，获得语义分析结果；同时根据交互信息对客户的情绪进行判断，从而获得客户的客户满意度，根据语义分析结果以及客户满意度生成智能客服的测评报告，根据所述测评报告更新所述智能客服的作答模型。通过本说明书实施例，实现了通过获取客户与智能客服的交互过程，更新作答模型的作答逻辑，提高作答模型的合理性，从而提高智能客服的服务质量，提升客户的体验。
G10L25/03  ,一种水下设备特征提取方法、装置、设备及存储介质 [发明],本申请涉及一种水下设备特征提取方法、装置、设备及存储介质，其中，水下设备特征提取方法包括：对水下设备不同状态下的辐射声场进行测量，得到所述水下设备的多种声场物理量；根据所述多种声场物理量对声场进行声源面声场重构，得到所述多种声场物理量的空间分布图像；通过多种特征提取方法对所述空间分布图像进行特征提取，得到所述多种声场物理量的多种空域特征。本申请能够优化对水下设备特征提取的效果。
G10L25/51  ,一种基于音频信号的事件检测反馈处理系统 [发明],本发明公开了一种基于音频信号的事件检测反馈处理方法，包括：步骤一：音频信号检测系统接收到原始音频信号，根据需要检测的故障问题提取对应的音频信号特征和信号参数；步骤二：利用噪声估计对待检测的音频信号进行估计和增强；步骤三：通过端点检测在连续的音频信号流中定位出噪音段和静音段的起始时刻和结束时刻，并削弱或消除检测音频信号中的静音段与噪声段；步骤四：对预处理后的音频信号进行分析，根据音频信号的声学信息对待检测的音频信号事件进行是否存在故障异常的判断；步骤五：基于故障异常的检测判断结果进行音频信号对应的故障检测的故障标签类型预测，本发明，具有提高音频信号处理精度故障检测精度的特点。
E04H1/12  ,一种基于AI全景模拟的5G智能导游亭 [发明],"本发明公开了一种基于AI全景模拟的5G智能导游亭，涉及导游实训设备技术领域，包括置地基板、钢化玻璃板和AI全景模拟系统，钢化玻璃板铰接有防护门板，钢化玻璃板和防护门板的相对侧皆安装有液晶显示屏，AI全景模拟系统包括模拟记录单元、全景展示单元、动作分析单元、语音识别单元和路径核准单元；本发明由工艺精湛的钢化玻璃板为载体，构建一个小型学习空间，将全景数据库内的景区实景展示在液晶显示屏上，多组液晶显示屏同时呈现不同方向上的景区实景实现实地模拟的效果，经过动作分析单元和语音识别单元对实习过程进行分析生成练习成绩单,基于5G传输的高时效性和准确性提高了实习体验感，可方便实习导游在该空间进行模拟导游实训。"
H04M3/51  ,外呼方法、装置、系统、服务器及介质 [发明],本申请提供一种外呼方法、装置、系统、服务器及介质，涉及通信技术领域。该方法应用于外呼系统，该方法包括：在坐席终端与第一客户终端通话过程中，对第一客户终端的音视频数据进行意图识别，得到第一意图识别结果；在第一意图识别结果为指示通话结束的意图时，将第二客户终端预分配至坐席终端；在第一客户终端挂断通话后，建立坐席终端与第二客户终端间的通话。上述方式降低了呼损率。
G10L21/013  ,语音转换方法、装置、设备及计算机可读介质 [发明],本发明的实施方式提供了一种语音转换方法、装置、设备及计算机可读介质。该方法包括：获取原始说话人的第一语音和目标说话人的第二语音；提取所述第一语音的内容特征和韵律特征，并采用随机打乱策略提取所述第二语音的目标音色特征；将所述内容特征、所述韵律特征以及所述目标音色特征输入解码器，获得所述解码器输出的目标梅尔频谱特征；利用声码器将所述目标梅尔频谱特征还原为第三语音，以将所述原始说话人讲述的所述第一语音转换为所述目标说话人讲述的所述第三语音。本申请解决了音色解耦会导致韵律信息严重损失的技术问题。
G10L15/05  ,语音识别方法、系统和存储介质 [发明],本公开提供了一种语音识别方法、系统和存储介质，涉及人机交互领域。该方法包括：对每个用户音频进行端点检测，得到每个用户音频对应的多段有效音频；提取多段有效音频的第一音频特征；将第一音频特征输入至声学模型，得到每一帧每个建模单元的概率；以及根据每一帧每个建模单元的概率，利用WFST搜索网络进行解码搜索，得到每个用户音频对应的文本信息。本公开提高了语音识别的准确性，进而提高了后续语音审核的准确性。另外，将各个步骤在GPU上运行，提高了语音识别系统的吞吐，降低了语音识别延迟，解决了语音审核及时性问题，同时降低了资源消耗。
G10L15/22  ,语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种语音交互方法，所述方法包括：获取初始训练数据，根据第一预设模型确定初始训练数据中样本的多个标签推理结果，根据样本的多个标签推理结果确定初始训练数据中参考样本，在候选训练数据中选取与参考样本语义相近的目标样本，确定目标训练数据，利用目标训练数据训练第二预设模型以得到语音交互模型，根据语音交互模型完成语音交互。如此，本申请选取选训练数据中目标样本以确定目标训练数据，根据目标训练数据训练语音交互模型，训练时长得到保障。本申请根据样本推理结果确定参考样本，选取与参考样本语义相近的目标样本，目标样本的选取考虑到模型推理情况，可信度和有效性得到保障，语音交互模型的预测精度得到保障。
G10L13/08  ,一种文本读音的自动判别方法及系统 [发明],本发明提供的一种文本读音的自动判别方法及系统，所述判别方法包括：步骤S1：采集文本数据；步骤S2：将所述文本数据进行文本序列清洗；步骤S3：文本表征模式特征挖掘及判定；步骤S4：文本浅层句法特征挖掘与判定；步骤S5：文本深层语义特征融合；步骤S6：文本深层语义特征训练；步骤S7：判定文本读音的文本。结合基于规则的方式和深度学习的方式，同时加入依存句法分析特征以考虑不同场景的影响，进行文本上下文语义特征扩充，有效判定出文本的读音。基于规则的方式、加入依存句法分析，解决了基于深度学习有监督模型训练的冷启动问题，节省了人工标注数据的环节。
G01N21/64  ,一种荧光信号计数方法及装置 [发明],本发明涉及数据处理领域，揭露了一种荧光信号计数方法、装置、电子设备及存储介质，其中，所述方法包括：响应目标检测人员的荧光信号计数请求，并在所述荧光信号计数请求响应期间，每当所述目标检测人员发出语音时，采集所述目标检测人员发出语音，将采集到的语音转换为数字信号，得到待识别语音；对待识别语音进行语音识别，得到目标识别文本；并提取目标识别文本中的荧光信号计数信息，得到荧光信号计数结果，并筛选有效的荧光信号计数结果，当所述荧光信号计数请求停止响应，将所有所述有效荧光信号计数结果进行汇总，得到目标荧光信号计数结果。本发明主要目的在于提高了荧光信号计数的效率。
G10L15/16  ,无声语音识别方法及智能耳机系统 [发明],本申请涉及一种无声语音识别方法及智能耳机系统，方法包括获取经人体耳道反射的声波数据；声波数据携带无声语音信息；对声波数据进行耳机自干扰消除，得到自干扰消除后的声波数据；提取干扰消除后的声波数据中的有效数据；基于有效数据提取传递函数特征和连续小波变换特征；将传递函数特征和连续小波变换特征输入到无声语音识别模型中，得到无声语音识别结果。本申请无需额外的设备，利用低廉的具有麦克风的耳机就可以实现用户无声语音识别，降低无声语音识别的成本；通过提取人体耳道结构的关键特征多路径轮廓和形变特征，利用双通道分层神经网络实现用户无声语音识别，提高系统的健壮性。
G06F16/332  ,对话处理、语音摘要提取以及目标对话模型训练方法 [发明],本说明书实施例提供对话处理、语音摘要提取以及目标对话模型训练方法，其中所述对话处理方法包括：获取目标对话数据；从目标对话数据中提取对话关键信息，其中，对话关键信息表征目标对话数据的对话情境；将对话关键信息和目标对话数据输入目标对话模型中，获得初始答复内容，其中，目标对话模型基于对话样本集训练得到，对话样本集基于多个样本文本的样本文本标签、样本生成指令和指令预测结果构建得到；根据目标对话数据和初始答复内容，生成目标对话数据对应的目标答复内容。在目标对话模型处理之前进行要点提炼和场景归纳，缓解初始答复内容的关键信息幻觉问题；利用目标对话数据作为参考，生成目标答复内容，保证目标答复内容的事实准确性。
G10L15/22  ,一种语音唤醒方法、电子设备和计算机可读存储介质 [发明],本发明实施例提供了一种语音唤醒方法、电子设备和计算机可读存储介质。该方法包括：采集用户输入的原始语音信号；根据原始语音信号生成脉冲密度调制数据；对脉冲密度调制数据进行解码，生成解码数据；对解码数据进行预处理和特征提取处理，生成语音特征；根据获取的隐马尔可夫模型对语音特征进行模式匹配，生成识别结果；根据识别结果唤醒电子设备的外部处理器。本发明实施例提供的技术方案中，通过对解码数据进行预处理和特征提取处理，生成语音特征；根据获取的隐马尔可夫模型对语音特征进行模式匹配，生成识别结果并根据识别结果唤醒电子设备的外部处理器，实现了语音唤醒功能，在降低电子设备功耗的同时，提高语音唤醒的准确性。
H04N21/234  ,一种视频流发送方法、系统、电子设备和存储介质 [发明],本发明实施例提供的一种视频流发送方法、系统、电子设备和存储介质，应用于视频播放技术领域，通过获取第一视频流；对所述音频数据中的语音进行识别，得到语音文本；将所述语音文本翻译为至少一种预设语种的字幕文本；根据所述第一视频流创建第二视频流；将所述至少一种预设语种的字幕文本添加至所述第二视频流，得到包含字幕文本的视频流；将所述包含字幕文本的视频流发送至客户端，以使所述客户端获取所述至少一种预设语种的字幕文本中的目标预设语种的字幕文本并渲染显示，可以在获取第一视频流后，对该第一视频流进行语音识别和翻译，得到至少一种预设语种的字幕，然后创建包含至少一种字幕文本的视频流并发送给客户端，从而节约占用的资源。
G10L25/63  ,情绪识别方法、装置、存储介质及电子设备 [发明],本发明公开了一种情绪识别方法、装置、存储介质及电子设备。涉及人工智能技术领域、金融科技领域或其他相关技术领域。该方法包括：获取目标对象的N段目标语音信号的特征向量；将N段目标语音信号的特征向量输入第一识别模型，输出第一数据集合，其中，第一数据集合中包括每段目标语音信号属于M种情绪中每种情绪的概率值；基于第一数据集合，确定每种情绪的第二数据集合；将M种情绪的第二数据集合和N段目标语音信号的特征向量输入第二识别模型，输出目标对象的情绪识别结果，其中，第二识别模型的类型包括极限学习机模型。本发明解决了相关技术中基于神经网络模型的滤波器直接确定用户的情绪识别结果，情绪识别结果的准确率低的技术问题。
G10L15/18  ,异常会话的问题识别方法、装置、电子设备和可读介质 [发明],本公开提供一种异常会话的问题识别方法、装置、电子设备和可读介质，其中，异常会话的问题识别方法包括：获取异常会话的语音样本对应于指定语音处理模型的多个维度的指定特征；将多个维度的指定特征输入至多门混合专家模型进行识别，多门混合专家模型的任一门被配置为输出语音样本中包含指定系统性问题的概率；根据多个门输出的概率对多门混合专家模型中的专家模型的输出结果进行加权；根据加权的结果确定语音样本中导致会话异常的系统性问题。通过本公开实施例，可以提高异常会话的问题识别的可靠性和准确性。
G10L21/0208  ,一种非线性回声消除方法及装置 [发明],本发明公开一种非线性回声消除方法及装置，通过接收近端语音信号以及远端语音信息生成音频信号后，将深度学习语音状态鉴别模型计算音频信号对应的语音概率值与自适应滤波器计算音频信号对应的残余回声能量相结合对非线性回声消除，以及将音频信号划分为不同的子带信号，并分别计算子带信号的能量值得到子带信号能量比，当根据语音概率值以及子带信号能量比遍历判断音频信号中存在非线性回声时，根据残余回声能量估计值修正所述残余回声能量，并根据修正的所述残余回声能量计算得到非线性回声抑制因子，实现对音频信号的滤波，解决拾音设备扬声器导致的非线性回声以及设备自带回声算法性能不佳导致部分非线性回声的残留问题，从而提升通话体验。
G10L25/87  ,一种多模态语音端点检测方法、装置、介质及车辆 [发明],本申请涉及数据处理技术领域，具体提供一种多模态语音端点检测方法、装置、介质及车辆，旨在解决如何提升语音端点检测的准确性和稳定性的问题。为此目的，本申请的多模态语音端点检测方法包括：获取同一预设时间段内同一空间内的视频数据和音频数据，基于视频数据获取视频特征，基于音频数据获取音频特征，根据视频特征和音频特征，获取视频特征的权重和音频特征的权重，基于视频特征的权重和音频特征的权重对视频特征和音频特征进行融合，得到多模态特征，基于多模态特征进行语音端点检测，得到语音端点检测结果。通过上述配置方式，本申请能够提升语音端点检测的准确性和稳定性。
G10H1/00  ,一种音频识别方法、电子设备及存储介质 [发明],本申请公开一种音频识别方法、电子设备及存储介质，包括：对待识别音频进行文本识别，得到待识别文本；计算预设数据库中的文本与待识别文本之间的文本相似度，将满足文本相似度阈值条件的所述数据库中的多个文本确定为目标文本集，并将目标文本集中多个文本对应的多个音频确定为目标音频集；将待识别音频和目标音频集进行旋律检测，得到待识别音频与目标音频集中各音频之间的旋律相似度；分别将对应同一目标文本的文本相似度及旋律相似度进行融合相似度处理，得到多个目标相似度，并召回大于融合相似度阈值的目标相似度对应的目标音频。本申请结合文本相似度识别和旋律相似度识别，有效避免因噪声引起的误召回，提高音频识别召回的精确性。
G10L15/22  ,远距离语音控制方法、系统、计算机设备和可读存储介质 [发明],本申请涉及一种远距离语音控制方法、系统、计算机设备和可读存储介质，涉及语音控制技术领域。所述方法包括：若在预设语音采集范围内接收到针对目标设备的控制语音，则对所述控制语音进行语音识别，得到语音识别结果；通过语音信号发射端，将所述语音识别结果广播至每一语音信号接收端，其中，所述语音信号发射端与每一所述语音信号接收端之间均是基于预设的远距离通信协议进行语音信号传输；通过每一所述语音信号接收端，将所述语音识别结果发送至控制端，得到所述控制端生成的语音控制结果，其中，所述语音控制结果是指所述控制端控制所述目标设备执行与所述语音识别结果对应的操作后得到的结果。采用本方法能够提高远距离语音控制的效率。
F24F11/30  ,语音空调的识别控制方法、装置、空调及存储介质 [发明],本发明公开了一种语音空调的识别控制方法、装置、空调及存储介质，该方法包括：当检测到唤醒语音时，基于获取的当前时间判定所述语音空调的当前模式；基于所述当前模式获取语音空调数量，其中，所述语音空调数量为已检测到用户的空调数量；采用与所述语音空调数量相对应的检测方式从多个所述语音空调中确定目标应答空调，并对所述目标应答空调进行控制。本发明实实现了从多台语音空调中准确识别出需要控制的空调，避免了多台语音空调同时被唤醒控制，有利于提高空调控制精度。
G10L15/22  ,一种语音遥控智能床 [发明],本发明公开了一种语音遥控智能床，包括麦克风，麦克风的输出端将接收到的命令词传递给语音识别模块，语音识别将语音命令识别之后，传送到控制单元中，本发明涉及智能床技术领域。该语音遥控智能床，通过集成语音识别技术，用户可以使用语音命令来控制床的各种功能，无需额外的设备，控制床的各种功能，使床的操作更为简单和便捷，这极大地提高了用户的使用便捷性，对于一些身体不便的用户，特别是老年人或身体不便者，语音控制提供了更好的使用方式，满足特殊需求；多模式语音识别：系统支持多种语音命令，使用户可以自然地与床互动，如调整床的高度、倾斜床头或床尾、开启按摩功能等，用户只需说出相应命令词，系统即可精确执行操作。
G10L25/03  ,语音转换方法、装置、计算机设备及存储介质 [发明],本申请公开了一种语音转换方法、装置、计算机设备及存储介质，涉及语音处理技术领域。该方法包括：对待转换语音进行特征提取处理，得到所述待转换语音的第一梅尔频谱、第一音调数据、第一静音/非静音数据；将所述第一梅尔频谱输入至语音识别模型中，得到第一语义特征数据；将所述第一音调数据、所述第一静音/非静音数据及目标用户的第一音色特征数据输入至训练好的语音转换模型中，得到目标梅尔频谱；将所述目标梅尔频谱输入至声码器中，得到目标语音，所述目标语音音频中的音色为所述目标用户的音色。本申请可以直接将用户说话的语音转换成语音内容不变但具有目标用户的音色的语音。
G08B21/18  ,一种无线远程报警装置及报警方法 [发明],本发明公开了一种无线远程报警装置及报警方法，涉及远程报警技术领域，包括MCU，所述MCU接收控制信号，然后根据处理后的信号对外围的硬件进行控制，电源单元，所述电源单元通过电源为MCU进行供电。本发明为融合多种功能为一体，实现无线、遥控与语音播报一体结合，方便各种场合快速部署应用，本发明具备实时人声语音播报，可以实时更改任意播报内容，系统采用无线连接方式，简化部署安装过程，系统采用加密通信，防止误触发报警，通过人声语音合成播报，任意内容表达，适应性广泛，尤其适合复杂报警提示内容播报，通过网络播报或遥控播报，多种报警方式融合，应用方式更灵活可靠。
G06F40/18  ,一种基于语音识别的业务员单据提报方法 [发明],本发明涉及语音识别技术领域，具体涉及一种基于语音识别的业务员单据提报方法；内置语音识别单据提报模块；明确该模块业务人员需要提报的具体单据类型和内容；采集业务员的包含业务信息的语音数据；进行语音识别；进行数据处理；生成业务单据；提报业务单据；通过采用基于语音识别的技术，实现业务员与客户之间的自动语音交互，提高业务处理效率和准确性；同时，通过自动生成单据和报表，减少人工录入和处理的工作负担，降低错误率。
G06V20/40  ,一种服务人员管理方法、系统、计算机设备及存储介质 [发明],本申请提供了一种服务人员管理方法、系统、计算机设备及存储介质，其中，响应于流媒体服务器对至少一张视频图像的识别请求，云服务器对该视频图像进行人脸识别，得到该视频图像中所包含的每个在场人员的人脸特征；对于该视频图像中的每个在场人员，流媒体服务器根据该在场人员的五官特征和每个服务人员的五官特征，判断该视频图像中的该在场人员是否属于服务人员；若该视频图像中的该在场人员属于服务人员，流媒体服务器则确定该在场人员的表情特征结果；流媒体服务器根据确定的该在场人员的表情特征结果，对该在场人员的服务合规标准进行评价得到评价结果。采用上述方法，以提高进行服务人员管理时的有效性和准确性，同时避免人力成本的浪费。
G06T17/00  ,一种Unity下基于音频生成闪电效果的方法、系统及存储介质 [发明],一种Unity下基于音频生成闪电效果的方法、系统及存储介质，包括获取一段闪电效果的音频数据；根据预设采样频率与采样阈值，对音频数据进行采样并转换为闪电效果的曲线信息；将曲线信息对应的初始的配置数据进行调整，以得到至少一种不同闪电效果的新曲线信息以及对应的配置数据并进行存储；在脚本的帧更新中监听当前场景下的天气是否为雨天，若是，则随机调用至少任一新曲线信息的配置数据，生成新的闪电效果。本发明通过将曲线信息对应的初始的配置数据进行调整，以得到至少一种不同闪电效果的新曲线信息以及对应的配置数据并进行存储，后续直接调用对应的配置数据就能实现不同的闪电效果，不仅操作简便，而且后续的维护成本和开发成本低。
G06V20/40  ,一种针对2D数字人的视频生成算法及系统 [发明],本发明公开了一种针对2D数字人的视频生成算法及系统，算法包括使用计算机图像深度学习技术输入的模特身材图像进行检测，获取模特的上半身区域图像；使用声音编码器进行原始音频进行音频特征提取；使用图像分割算法对模特的上半身区域图像进行分割，获取人脸区域与躯干区域；将获取的人脸区域，使用人脸关键点检测算法检测人脸区域，获取人脸关键点信息和人脸眨眼信息；将获取的人脸关键点信息、人脸眨眼信息和提取到的音频特征信息对神经辐射场模型进行训练；将实时采集的模特身材图像输入到训练好的神经辐射场模型中生成视频。优点是：解决了现有技术中嘴型生成不清晰的问题，能达到更为真实的2d数字人效果。
G10L15/02  ,一种基于虚拟人进行人机交互的方法 [发明],本发明公开了一种基于虚拟人进行人机交互的方法，包括控制系统、数据库、选取调用模块、语音处理模块、播音模块以及与控制系统通讯连接的下位设备；所述数据库内设有语音包数据集合；预先往语音包数据集合内传送多种不同性格的语音从而形成多个性格语音子集，用户选取喜好性格并通过录音模块与虚拟人物进行对话，从而丰富虚拟人物的性格属性表现能力，进而提高用户的满意度，每种虚拟人物形象包集合对应一个性格语音子集，通过选取调用模块调取出对应的虚拟人物形象包集合在显示面板上进行展示，从而提高虚拟人物的个性化展示能力。
G10L15/22  ,一种融合端侧ASR与TTS深度模型的通航自动气象观测合成通播方法及装置 [发明],本发明公开了一种融合端侧ASR与TTS深度模型的通航自动气象观测合成通播方法及装置。装置包括传感器模块、与传感器模块通信的气象采集模块、存储气象采集模块的数据信号的存储模块、甚高频收发信模块、与甚高频收发信模块及主处理模块相连接的ASR处理模块、与甚高频收发信模块及主处理模块相连接的TTS处理模块、实现各个模块之间信息传递的主处理模块。方法为飞机将请求机场气象情报信息的指令发送至甚高频收发信模块，经ASR处理模块、TTS处理模块、甚高频收发信模块再将机场气象情报信息通播给相应频段内的全部飞机。本发明融合深度语音模型，相比传统语音识别率及语音合成效果有极大提升；改善了飞行员获取气象情报的应答率及地面管控中心的管控效率。
G10L15/26  ,音频处理方法、装置、计算机设备和存储介质 [发明],本申请涉及一种音频处理方法、装置、计算机设备、存储介质和计算机程序产品，涉及计算机技术领域。可用于金融科技领域或其他相关领域。方法包括：获取待处理音频，将待处理音频划分为多个音频片段，提取各音频片段的声学特征；基于各音频片段的声学特征，为各音频片段标记说话人标签；基于为各音频片段所标记的说话人标签，针对每个说话人标签确定与当前说话人标签对应的音频片段；基于与当前说话人标签对应的音频片段，确定与当前说话人标签对应的音频划分时间戳；基于音频划分时间戳，从待处理音频中确定与当前说话人标签对应的待转换音频片段；对待转换音频片段进行文本转换。采用本方法能够清楚的知道音频所表达的内容。
G10L25/51  ,基于通道注意力机制与AH-Softmax的变压器声纹识别方法 [发明],本发明涉及一种基于通道注意力机制与AH‑Softmax的变压器声纹识别方法，包括：实时采集任意一台电力变压器的音频数据，获取音频数据的二进制格式的声纹数据以及采样频率；对二进制格式的声纹数据进行预处理；对训练集中的声纹数据进行特征提取；对VGG19模型进行改进，得到改进后的VGG19模型；利用声纹特征训练集对改进后的VGG19模型进行训练，将待识别的电力变压器的音频数据输入训练后的VGG19模型，识别出电力变压器声纹类型。改进后的VGG19模型对各个通道的特征更有辨别能力，加强对变压器声纹的辨别能力；强调变压器声纹样本的信息量，可以动态区分信息量不同的变压器声纹样本，可以提高改进后的VGG19模型对于变压器声纹信号的识别的度和准确度。
G11B27/10  ,调整播放进度的方法、相关装置及计算机程序产品 [发明],本公开提供了调整播放进度的方法、相关装置及计算机程序产品，涉及音频处理、多媒体播放、自然语言处理等人工智能技术领域。该方法的一具体实施方式包括：响应于用户针对目标音频发送播放指令，生成目标音频的内容文本；基于内容语义完整度，将内容文本拆分为一组段落文本，一组段落文本中的每个段落文本的语义完整度均满足预先确定的完整度阈值的要求；基于每个段落文本的语义内容生成相应的梗概信息；为用户呈现至少部分的段落文本的梗概信息；响应于用户针对目标段落文本的目标梗概信息做出跳转指示，基于目标段落文本对应的目标音频播放位置，跳转目标音频的播放进度。由此，能够辅助用户以“段落”为单位进行进度调整，提升用户的操作效率。
G16H50/30  ,一种用于老人日常记录与智能监护的方法及装置 [发明],本发明涉及一种用于老人日常记录与智能监护的方法及装置，属于智能监控技术领域，该方法包括：分别获取老人周围预设范围内采集到的音频数据和图像数据；对音频数据依次执行语音信号预处理、低级声学特征提取、高级情感特征提取得到用以评估老人心理健康程度的健康数据；当健康数据满足预设条件时，发出预警信息；对图像数据依次执行图像预处理、提取图像情感特征和图像情感决策后得到积极图像和消极图像；将积极图像存储，用以后续对老人进行怀旧治疗；将消极图像删除；降低了语音心理测评和怀旧疗法的成本，同时简化了操作。
G10L15/26  ,多事件音频-文本对生成方法及装置 [发明],本发明公开一种多事件音频‑文本对生成方法，包括：获取多个单事件音频片段；确定将所述多个单事件音频片段合成多事件音频所需的配置数据；根据所述配置数据将所述多个单事件音频片段合成目标多事件音频；至少根据所述配置数据生成对应于所述目标多事件音频的合成文本。通过配置数据的设置使得生成的多事件音频－文本对不仅仅关注于声音事件本身，还能够通过配置实现各单声音事件在将要合成的多事件音频中的诸多细节，从而得到具有丰富细节的多事件音频－文本对。
G02C9/00  ,智能眼镜、智能眼镜控制方法及存储介质 [发明],本发明提供一种智能眼镜、智能眼镜控制方法及存储介质，涉及智能控制技术领域，该智能眼镜包括眼镜本体、遮光镜片、视力镜片、驱动模块、语音采集模块和控制模块；语音采集模块用于采集用户输入的模式切换指令，并将模式切换指令发送至控制模块；控制模块用于在模式切换指令指示切换为遮光模式的情况下，控制驱动模块向第一方向转动，以将遮光镜片覆盖在视力镜片上；控制模块还用于在模式切换指令指示切换为非遮光模式的情况下，控制驱动模块向第二方向转动，以使遮光镜片与视力镜片之间的夹角大于90度；第二方向与第一方向相反。该智能眼镜基于模式切换指令，无需手动即可调整遮光镜片的位置，提高了智能化程度，降低了模式切换的难度。
G10L15/22  ,车辆语音控制方法、装置、设备及存储介质 [发明],本发明涉及车载语音技术领域，公开了一种车辆语音控制方法、装置、设备及存储介质，该方法包括：按预设分割方式将当前语音信息切分为语义词组，并获取各语义词组的连接顺序；根据连接顺序在车辆指令库中进行匹配，确定当前指令类型，当前指令类型包括：问句型指令、命令型指令以及条件型指令；获取当前指令类型的标准格式，并通过标准格式对当前语音信息进行改写；根据改写后的当前语音信息获得当前执行脚本，并通过当前执行脚本完成交互控制。本发明能够由切分得到的语义词组进行当前指令类型匹配，并根据标准格式实现对当前语音信息的改写，使得改写后的语音信息具有车辆更易识别的完整语义，有利于车辆对用户指令的准确反馈。
G10L25/63  ,一种情绪监测分析方法及系统 [发明],本发明适用于计算机领域，提供了一种情绪监测分析方法，所述方法包括：采集异常声音信息，生成复检指令；分时采集并比对多个目标声音信息，获取第一复检结果信息；识别并采集第一复检结果信息获取后设定时段内的目标语音流；计算目标语音流，得到目标语音语速；对比目标语音流语速，获取第二复检结果信息；若第一复检结果信息和第二复检结果信息均存在，则生成终检信息；根据终检信息，生成提示信息；向管理者终端设备发送提示信息，定时监控被监测环境中的异常声音信息，通过获取分贝信息和语速信息，计算、分析声音发出者的情绪状况，及时向监测者发出提示信息，便于监测者及时了解被监测者的情绪状态，提高了对被监测者的安全保护能力。
A63F13/424  ,音视频数据处理方法、装置、可读存储介质与电子设备 [发明],本公开属于数据处理技术领域，涉及一种音视频数据处理方法及装置、存储介质、电子设备。该方法包括：接收从云服务器发送的音视频编码数据，根据音视频编码数据构建出待解码音视频数据；待解码音视频数据中包括与多个音视频帧对应的音视频编码数据以及在相邻的两个音视频帧之间插入的宏块；对待解码音视频数据进行解码处理得到待渲染音视频数据，对待渲染音视频数据进行渲染处理，以渲染出与待渲染音视频数据对应的声音以及画面。在本公开中，构建出的待解码音视频数据中包括在相邻的两个音视频帧之间插入的宏块，避免了后续对待解码音视频数据解码处理的过程中出现的屯帧现象，进而避免了对待渲染音视频数据进行渲染时出现的卡顿现象。
G10L15/06  ,语音翻译模型的训练方法、语音翻译方法和装置 [发明],本公开提出了一种语音翻译模型的训练方法、语音翻译方法和装置，涉及自然语言处理和深度学习等人工智能领域，包括：获取训练好的第一文本翻译模型以及语音识别模型，并基于第一文本翻译模型和语音识别模型构建待训练的候选语音翻译模型；获取第一样本源语言语音和/或第一样本源语言文本，以得到候选语音翻译模型的训练样本；基于训练样本对候选语音翻译模型进行训练，直至训练结束，得到训练好的目标语音翻译模型。降低了候选语音翻译模型的构建难度以及模型的复杂程度，提高了语音翻译模型的可实现性，降低了语音翻译模型的训练难度，提高了语音翻译的效率和准确率，优化了语音翻译的方法。
H04N21/43  ,一种无听障障碍的文字讲述内容的生成方法及相关设备 [发明],本发明公开了一种无听障障碍的文字讲述内容的生成方法及相关设备，所述方法包括：获取目标视频的音频，多模态大型语言模型进行识别生成带时间轴的音频内容文本；获取目标视频的图像，识别获得图像内容文本；获取目标视频的字幕，根据字幕和图像内容文本比对出音频内容文本的独有内容并标注；获取目标视频的剧本和演员信息，将图像内容文本、剧本和演员信息进行对比得到角色识别结果，对每条音频内容文本标注出对应角色；根据标注后的音频内容文本生成提示词，根据提示词引入已有内容生成文字讲述内容；将文字讲述内容添加到所述字幕中。本发明生成对听障人士无障碍的讲解文本内容，充分解析音频中的信息，便于听障人士获取更丰富的视频信息。
G06F3/0483  ,可视化大屏智能解说方法、装置、设备及存储介质 [发明],本申请提供的可视化大屏智能解说方法、装置、设备及存储介质，涉及人工智能技术领域。通过获取针对可视化大屏所显示的目标对象的智能解说指令，智能解说指令是可视化大屏在检测到作用于目标对象的智能解说操作时生成的；响应智能解说指令，识别获得目标对象的相关内容；对相关内容进行数据分析，以获得相关内容的关键信息；基于关键信息，生成智能解说内容；输出智能解说内容。相较于传统的可视化大屏，本申请由于通过基于关键信息生成智能解说内容，并输出智能解说内容，能够帮助用户深入理解和快速消化信息，从而缓解用户获取的信息有限的技术问题。
G10L25/03  ,零样本音频分类模型训练方法、零样本音频分类方法 [发明],本申请公开一种零样本音频分类模型训练方法，包括：获取样本音频所属声音类别对应的声音属性描述；根据所述声音属性描述确定对应于所述样本音频的属性描述文本；根据所述样本音频和所述属性描述文本之间的相似度进行零样本音频分类模型训练。本申请根据声音属性描述确定对应于所述样本音频的属性描述文本，使得本申请中的描述文本侧重多样化的声音属性，声音属性更能代表声音的内在特征，从而提升了训练得到的零样本音频分类模型的识别准确率。
G10L25/18  ,一种EMD风噪抑制下的Mel谱多维特征空间的声音识别方法 [发明],本发明属于信号处理领域，具体公开了一种EMD风噪抑制下的Mel谱多维特征空间的声音识别方法，包括如下步骤：采用经验模态分解方法，结合非负矩阵分解方法，实现对目标声信号的风噪声抑制；然后，建立声目标的高斯混合模型，提取声目标的希尔伯特‑黄变换的边际谱系数、Mel谱系数以及各谱系数的一阶差分谱等特征参数，将这些特征参数作为声目标的识别参数，根据高斯混合模型准则，训练出多维特征空间的特征向量；将未知声目标与已建立的多维特征向量做对比，得到未知声目标的最大输出概率类型，从而识别出声目标类型。本发明能精确识别出声目标特征，提高了目标识别率，降低了虚警率。
G10L15/24  ,无声语音识别方法、装置、电子设备和计算机可读介质 [发明],本公开的实施例公开了无声语音识别方法、装置、电子设备和计算机可读介质。该方法的一具体实施方式包括：获取无声振动信号；对无声振动信号进行特征提取处理，得到无声振动特征系数；将无声振动特征系数输入至预先训练的信号增强模型，得到无声振动增强信号；将无声振动增强信号输入至预先训练的无声语音识别模型，得到语音指令识别结果；基于语音指令识别结果，控制多媒体系统。该实施方式提高了对多媒体系统控制的准确度。
G06F16/9032  ,话术推荐方法、装置、计算机设备及存储介质 [发明],本发明涉及人工智能技术领域，公开了一种话术推荐方法，该方法包括对获取的音频数据进行语音识别，得到文本数据；通过GPT模型中的文本特征提取层对文本数据进行特征提取，得到文本特征；通过GPT模型中的语音特征提取层对音频数据进行特征提取，得到音频特征；通过GPT模型中的情绪识别层对文本特征和音频特征进行情绪识别，得到情绪识别结果；基于情绪识别结果对音频数据进行话术推荐，得到目标话术。本发明应用于保险或金融业务中的话术推荐。本发明通过GPT模型对文本特征和音频特征进行情绪识别，实现了精准识别音频数据中的情绪，提高了情绪识别结果的准确率，进而提高了话术推荐的准确率。
H04L67/141  ,会话的实现方法及装置、会话的实现系统 [发明],本申请公开了一种会话的实现方法及装置、会话的实现系统。其中，该方法包括：接收会话请求，其中，会话请求用于请求与语音识别服务器建立会话；响应于会话请求，分别创建第一线程和第二线程，其中，第一线程与第二线程并行执行，第一线程用于进行语音捕获，第二线程用于连接目标接口，目标接口为语音识别服务器的语音识别服务接口；基于第一线程和第二线程实现与语音识别服务器的会话。本申请解决了由于相关技术采用单一线程执行语音识别接口的连接和语音数据捕获转写的工作造成的存在内存越界的问题，导致系统运行不稳定，以及导致客户端感知的等待时间长的技术问题。
G06T13/40  ,一种基于驾培行业的AI数智人构建方法和系统 [发明],本发明提供了一种基于驾培行业的AI数智人构建方法和系统，包括以下步骤：步骤一、计算机系统从数据中学习和改进，获取自主学习和决策的能力；步骤二、根据自然语言处理技术训练大规模的文本数据，学习语言的概率分布和语义结构；步骤三、使用三维建模技术建立三维模型来模拟驾培教练的形象和动作。本发明的AI数智人可以实现与学员实时交互，根据学员的学习需求、能力水平和学习进展，提供个性化的学习方案和指导，通过智能化的学习推荐和反馈，可以帮助学员更好地理解和掌握驾驶技能，提高学习效果和通过率，还可以辅助教练员的培训工作，提供教学辅助工具和反馈机制，帮助教练员更好地指导学员，提升教学效果和质量。
G10L25/03  ,一种音频重采样方法、装置、电子设备及存储介质 [发明],本申请公开了一种音频重采样方法、装置、电子设备及存储介质。该方法包括：确定待进行重采样的原始音频的内容分布，建立原始音频的内容分布到预设的标准音频的内容分布的映射关系；根据标准音频的采样方式以及映射关系设置重采样的采样点；根据原始音频的内容分布将原始音频划分为不同的音频段，对不同的音频段进行不同尺度的抗混叠预处理；根据重采样的采样点对抗混叠预处理后的原始音频进行重采样。通过建立原始音频的内容分布到标准音频的内容分布的映射关系，为原始音频的重采样的采样点设置提供有效指导，可以过滤掉无效的音频内容，提高采样效率，同时，最大限度的保留了原始音频中的有效信息，便于后期进行文字转换工作。
G06F11/07  ,故障处理方法及电子设备 [发明],本申请提供了一种故障处理方法及电子设备，该方法包括：确定第一信息，第一信息为用户输入的针对目标设备所存在故障的第一故障描述信息；根据第一信息和故障处理模型，确定第一故障处理信息以及第一故障处理信息对应的第一置信度；在第一置信度大于第一置信度阈值的情况下，将第一故障处理信息反馈给用户，以用于用户根据第一故障处理信息进行故障处理；在第一置信度小于等于第一置信度阈值的情况下，确定第二信息，根据第二信息进行故障处理，第二信息为目标设备中与故障相关的设备信息。由此增加了目标设备的故障处理信息的准确性，使得目标设备的故障可以及时得到更准确地处理，提升用户体验感。
H04N7/15  ,发言者的位置确定方法、装置、计算机设备和存储介质 [发明],本申请涉及一种发言者的位置确定方法、装置、计算机设备和存储介质。所述方法包括：根据待检测视频帧对应的音频信息，确定待检测视频帧对应的目标音频定位角度；基于目标音频定位角度和目标映射关系，确定待检测视频帧中第一发言者的目标位置；目标映射关系为根据各采样视频帧中第二发言者的预测位置，对初始映射关系中音频定位角度对应的初始位置进行更新得到的；预测位置为基于采样视频帧和发言检测模型确定的。采用本方法能够提高确定的发言者的目标位置的准确性。
G06F18/2415  ,多视角人脸特征与音频特征融合的情绪识别方法及系统 [发明],本发明公开了一种多视角人脸特征与音频特征融合的情绪识别方法及系统，所述方法包括：获取用于捕获目标对象在不同视角的人脸图像的所有相机之间的位置关系，根据所述位置关系对所有所述相机进行校准；接收所有所述相机发送的所述目标对象在不同视角的人脸图像，并对所有所述人脸图像进行特征提取和融合，得到最终视觉特征；接收所述目标对象发出的音频信号，并根据所述音频信号得到音频特征，将所述最终视觉特征和所述音频特征进行融合得到最终融合特征，根据所述最终融合特征识别得到所述目标对象的情绪识别结果。本发明通过对相机进行标定，提供更加真实和全面的人脸图像，更全面地理解和分析用户的面部表情，提高情绪识别的准确性和可靠性。
G10L19/02  ,音频处理方法、装置设备及存储介质 [发明],本发明属于音频技术领域，公开了一种音频处理方法、装置设备及存储介质。本发明通过基于预设窗函数、短时傅里叶变换方式以及房间冲击混响确定传递函数矩阵；根据音频信号对应的多个音频帧数据对与音频信号对应的初始音频矩阵进行更新，得到更新后的音频矩阵；基于预设卷积方式对传递函数矩阵和更新后的音频矩阵进行卷积处理，得到卷积时域向量；根据音频信号对应的初始音频向量和卷积时域向量得到目标输出向量。通过预设窗函数和短时傅里叶处理房间冲击混响得到传递函数矩阵，根据预设卷积方式处理传递函数矩阵和更新后的音频矩阵得到卷积时域向量，根据初始音频向量和卷积时域向量得到目标输出向量，实现了在保证混响效果的同时降低了计算量。
G10L15/02  ,文本声音事件检测模型训练方法及检测方法 [发明],本申请公开一种文本声音事件检测模型训练方法，包括：对样本音频进行音频编码获得多个音频帧嵌入；将对应于所述样本音频的样本文本分解为多个正短语；至少对所述多个正短语进行文本编码获得多个短语嵌入；根据所述多个音频帧嵌入和所述多个短语嵌入确定音频‑文本相似度；至少根据所述音频‑文本相似度与真实音频‑文本相似度之间的损失进行模型训练。本申请通过使用短语级别的匹配而非句子级别的匹配进行模型训练，大大提升了准确率。
G10L15/02  ,说话人识别后端打分训练方法及相关设备 [发明],本发明公开了一种说话人识别后端打分训练方法及相关设备，涉及说话人识别领域，主要为解决在注册或测试音频出现平凡发音时，后端打分结果与语音注册和测试差异大的问题。该方法包括：确定训练数据集，其中，所述训练数据集包括说话人嵌入层、语音与平凡发音存在向量和说话人标签；构建后端打分系统，其中，所述后端打分系统是基于LDA模型、PLDA模型和分数校准模型确定的；基于训练对进行前向传播，以计算所述后端打分系统的后端损失，其中，所述训练对是基于所述训练数据集确定的；基于所述后端损失进行反向传播，以更新所述后端打分系统。本发明用于说话人识别后端打分训练过程。
G10L15/22  ,一种基于语音识别的转码控制设备 [发明],本发明公开了一种基于语音识别的转码控制设备，包括转码控制设备保护罩，在使用时，首先可在墙体的合适的高度上安装若干墙体连接件，然后将转码控制设备保护罩后侧的转码控制设备保护罩固定底座与墙体连接件相对应，然后将墙体连接件的部分完全插入转码控制设备保护罩固定底座的内部，然后转动第一螺纹杆，第一螺纹杆会带动后抵板沿着后抵板滑槽向墙体连接件的一侧移动，直至后抵板完全抵住墙体连接件，此时就完成了该装置在墙壁上的固定，然后按压中心按钮，中心按钮会向左侧挤压挤压块，挤压块会向左侧挤压第二卡扣转动轴，第二卡扣转动轴会向左侧挤压挤压横杆，挤压横杆会向左侧挤压挤压竖杆，挤压竖杆会向左侧挤压第二伸缩弹簧。
G10L15/06  ,模型训练方法、装置、电子设备和介质 [发明],本申请公开了一种模型训练方法、装置、电子设备和介质，属于声音事件检测领域。模型训练方法包括获取音频训练样本，对音频训练样本进行特征提取，得到特征信息；基于特征信息和第一卷积核生成自适应卷积核，第一网络模型包括第一卷积核；将第一网络模型中的第一卷积核替换为自适应卷积核，得到第二网络模型；将特征信息输入第二网络模型，第二网络模型输出与音频训练样本对应的预测事件类别；根据预测事件类别对第一网络模型进行训练。
G10L21/0224  ,一种音频处理方法、装置、存储介质及电子设备 [发明],本公开实施例提供了一种音频处理方法、装置、存储介质及电子设备。其中方法包括：获取待处理音频，基于第一处理模型对所述待处理音频进行第一类型失真的修复，得到第一修复音频；基于第二处理模型对所述第一修复音频进行第二类型失真的修复，得到第二修复音频。通过两个阶段的修复过程，对待处理音频进行全面性的失真修复，提高音频质量。同时，在两个阶段分别用不同的处理模型分别进行第一类型失真的修复和第二类型失真的修复，降低一次性修复难度，在提高音频质量的基础上，降低模型开发成本。
G06F3/01  ,一种提升机动车驾驶人员空间感知能力的方法及系统 [发明],本发明公开了一种提升机动车驾驶人员空间感知能力的方法及系统，包括以下步骤：步骤一、通过声纹识别系统，抓取驾驶员的声纹信息与声纹库中报名时录入的学员的声纹进行1：1对比验证和1：N的检索；步骤二、验证成功后，声纹识别系统自动从报名录入收集的学员信息库中检索出对应的学员身高数据，通过车辆上加装的声纹识别系统：一、自动为学员选择教学语言语种，减少学员的语言认知负荷；二、自动识别学员身份，获取学员的身高和视角参数信息，输出适合学员的参照点。同时通过车辆上安装的机件传感器对车辆自身的位置和实时状态进行测量感知，让学员在圆环或8字环内进行重复练习，并且实时为学员播报语音教学和错误评判。
G10L15/25  ,基于舌部超声和唇部视频视觉融合的语音识别方法及系统 [发明],本发明公布了一种基于舌部超声和唇部视频视觉融合的语音识别方法及系统，将说话人唇部运动视频和舌部运动视频之间的视觉特征进行关联，采用视觉特征融合的方式融合唇部运动视频和舌部运动视频两种视觉特征信息以提高语音识别的准确性；系统包括：说话人舌唇数据获取模块、舌唇特征正样本计算模块、舌唇视觉特征融合模块、语音识别计算模块。采用本发明的技术方案，可提高语音识别的准确性。
G06V40/20  ,开集场景下防深度伪造的讲话人认证方法及系统 [发明],本发明提供了一种开集场景下防深度伪造的讲话人认证系统及方法，包括：特征提取模块：将讲话人说某个单词的唇部视频进行预处理得到滑动窗口视频组，基于滑动窗口视频组分别进行静态特征提取和动态特征提取，得到每个滑窗的静态特征和动态特征；再将静态特征和动态特征与时序融合得到视频的最终特征；其中，训练时利用静态特征提取模块中的重构损失、动态特征提取模块中的滑窗顺序预测损失和最终特征的认证损失进行监督，得到优化后的网络参数；推理时利用静态特征提取器、动态特征提取器和特征融合模块得到视频的最终特征；特征认证模块：利用用户的原型特征对视频的最终特征进行认证。
G10L15/06  ,语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种语音交互方法，所述方法包括：获取第一数据集，利用预设模型和第一数据集中的样本数据，确定第一数据集中样本数据的样本标签置信度，根据样本数据的样本标签置信度，采样第一数据集以确定第二数据集，根据第二数据集确定语音交互模型，以可根据语音交互模型完成语音交互。如此，本申请的服务器可在获取到数据量较大的第一数据集后，对第一数据集进行采样以得到数据量较小的第二数据集，及根据第二数据集进行预设模型或语音交互模型的训练，模型训练时间得以降低。同时，本申请的服务器可根据样本标签置信度采样，使得采样能考虑到模型实际推理情况，第二数据集的有效性得以保障，语音交互模型的精度可得到保障。
G10L15/22  ,音频转写方法、装置、电子设备和存储介质 [发明],本发明提供一种音频转写方法、装置、电子设备和存储介质，其中方法包括：确定当前场景下的音频数据和视频数据；对所述音频数据进行文本转写，得到音频转写结果；对所述视频数据进行文字识别，得到视频识别结果；基于所述视频识别结果，对所述音频转写结果进行校正，得到校正转写结果，提升了转写结果的准确率，同时基于同源视频数据的校正还保证了校正转写结果的可靠性，避免了传统方案中因转写结果不准确导致的理解出错，用户体验不佳的问题，实现了转写结果准确率的提升，以及用户体验的优化。
G10L15/16  ,一种语音识别方法和相关装置 [发明],本申请提供了一种语音识别、编码方法和相关装置，通过预训练的语音识别模型中的编码器对待识别语音特征向量进行编码，得到编码特征向量，通过语音识别模型中的解码器对编码特征向量进行解码，得到待识别语音特征向量对应的语音识别结果。由此可见，本申请会在对待识别语音特征向量进行编码的过程中对编码层中的多个注意力头的权重进行修正，以使得具有正向激励作用的注意力头的修正后权重大于具有负向激励作用的注意力头的修正后权重，由此可以削弱具有负向激励作用的注意力头在编码过程中的负向激励作用，因此基于各个注意力头的修正后权重进行编码，使得到的编码特征向量更准确，提高了语音识别的准确度。
G10L25/60  ,一种英语教学管理系统 [发明],本发明公开了一种英语教学管理系统，属于语音信号处理技术领域，在本发明中采集声音信号后，从声音信号提取出属于教师的声音信号，一方面能剔除噪声，另一方面能剔除学生的声音，再从教师声音信号中提取出声音特征，先通过中英文声音分类单元进行分类，识别出该声音特征是否属于英文声音，若是，则再进一步地对声音特征进行处理，得到音准评估值，提供一种能规避英语教学课堂中其他干扰声音，又能精准提取出属于英文声音的声音特征，从而对其进行音准评估。
G10L15/02  ,一种远场语音识别方法、系统、装置及存储介质 [发明],本申请公开了一种远场语音识别方法、系统、装置及存储介质，通过近场语音频域特征集预训练编码器和解码器，再使用近场语音频域特征集和远场语音频域特征集对域判别器、预训练后的编码器和解码器进行训练，再根据训练后得到的编码器和解码器构建得到声学模型，使得在预训练和训练的过程中结合了近场语音数据和远场语音数据，使得声学模型能够消除近场语音数据和远场语音数据之间的特征分布差异，将具备不同特征分布的近场语音数据和远场语音数据映射到同一个特征空间，能够实现声学模型的域适应，使得由声学模型、词典和语言模型构建的远场语音识别模型具备远场语音识别的能力，从而能够有效地提高远场语音识别模型对远场语音识别的准确率。
G10L15/06  ,基于语音的意图识别方法和装置、设备、存储介质 [发明],本申请实施例提供了一种基于语音的意图识别方法和装置、设备、存储介质，属于人工智能和金融科技技术领域。该方法包括：获取目标对象在第一轮对话的初步语音数据，对预设的原始语音样本进行样本扩充，得到目标语音样本，根据目标语音样本对预设语音识别模型进行训练，得到目标语音识别模型，基于目标语音识别模型对初步语音数据语音识别，得到初步语音内容，根据初步语音内容启动第二轮对话，并生成第二轮对话的初步问答数据，在第二轮对话中将初步问答数据发送给目标对象，获取目标对象对初步问答数据进行答复得到的当前语音数据，基于目标语音识别模型对初步语音内容和当前语音数据进行意图识别，以得到当前意图，从而提高意图识别的准确性。
G01H17/00  ,噪音测试方法、装置、设备及存储介质 [发明],本发明涉及产品测试技术领域，尤其涉及一种噪音测试方法、装置、设备及存储介质，本发明通过获取产品样件设备在运行过程中产生的多组噪音数据，并对这多组噪音数据进行叠加去噪，得到产品运行噪声数据，并对产品运行噪声数据进行分帧处理，得到多帧标产品运行噪声数据，进而综合计算出产品样件设备运行过程中的产品噪声大小，避免了现有技术中产品噪音较小时，难以对产品噪音进行噪音测试的技术问题，减少了环境噪音的影响。
G06F16/9038  ,一种基于驾驶场景的检索结果确定方法及装置 [发明],本申请提供了一种基于驾驶场景的检索结果确定方法及装置。该方法包括：当目标用户在驾驶过程中，利用车载交互系统进行查询时，获取目标用户的查询语句；当查询语句基于最优语义相关度检索生成的第一检索结果不满足预设的匹配条件时，利用退化搜索算法修改查询语句的语义相关度，以确定查询语句对应的扩展语句；检索扩展语句以确定第二检索结果；当第二检索结果满足匹配条件时，根据预设的用户个性模型对第二检索结果进行排序，以确定第二检索结果的个性化顺序；根据第二检索结果的个性化顺序，确定查询语句对应的目标检索结果。本申请结合了退化搜索算法和个性化模型，在车载交互系统中实现了高度精准和个性化的检索服务，提升了用户体验。
G06Q30/01  ,投诉工单的处理方法、装置、终端设备及存储介质 [发明],本申请公开了一种投诉工单的处理方法、装置、终端设备及存储介质，涉及互联网技术领域，该方法包括：根据投诉工单的工单内容确定候选处理人，并基于预设的情绪识别模型得到候选处理人的匹配投诉内容，其中，匹配投诉内容为得到客户正向反馈的历史工单内容；将匹配投诉内容与投诉工单的投诉内容进行相似度比对，根据比对结果确定是否将候选处理人作为目标处理人；若确定将候选处理人作为目标处理人，则根据投诉工单的投诉客户的偏好语音风格，对目标处理人处理投诉工单时的会话内容进行风格转换。采用本方案能够使投诉工单处理人发出的会话从内容和语音风格这两个维度上最大程度的符合客户的偏好，从而提升客户的满意度，提高投诉工单的处理效率。
G10L15/22  ,一种虚拟数字人的交互方法及装置 [发明],本发明公开了一种虚拟数字人的交互方法及装置，包括初始化语义不完整标志位和声音采集和图像采集，使用语音活动检测算法，检测降噪后的有效用户声音是否为人声，将客户端中用户的声音转换成文字，并根据语义不完整标志位进行预处理，并判断保存的文本语义是否完整，进行流式回复生成或生成针对语义完整的问句，并调整语义不完整标志位；进行语音生成并加入虚拟数字人的待生成列表和连续帧图片生成，生成正在说话的虚拟人头部身体连续帧图片或是沉默的虚拟人头部身体连续帧图片；将生成的图像和语音传输到客户端进行展示并从采集阶段重新循环。本发明能够降低噪音的误识别率，保证用户语句的语义完整并提高语音的生成速度。
G10L15/08  ,车载语音交互方法、装置、车辆及存储介质 [发明],本申请公开了一种车载语音交互方法、装置、设备及存储介质，属于车辆技术领域。所述方法包括：确定驾驶员的语音交互数据库；在所述目标车辆的行驶场景满足目标语音触发场景的情况下，从所述语音交互数据库中获取所述目标语音触发场景对应的语音生成规则集；确定车内人员对应的目标语音交互权限，从所述目标语音触发场景对应的语音生成规则集中获取所述目标语音交互权限对应的目标语音生成规则，基于所述目标语音生成规则以及所述行驶场景的场景信息生成并播放语音。本申请通过在行驶场景满足目标语音触发场景的情况下，基于不同的语音交互权限，生成不同的语音并进行播放，提高语音交互的灵活性和私密性。
G10L15/26  ,一种基于人工智能的视频内容处理方法及系统 [发明],本发明公开了一种基于人工智能的视频内容处理方法及系统。通过获取用户媒体的原始视频数据与原始文案数据并进行音频数据识别，得到视频场景信息与人物语音文字信息；将视频场景信息与人物语音文字信息进行文本格式转化并导入基于人工智能的大语言模型进行语义分析，并实现视频分割与优化，根据视频运营数据进行投放反馈分析与预测，基于预测数据，生成优化投放视频数据。通过本发明能够解决创作者同时运营多个内容平台效率低下的问题，同时，能够周期性分析出用户反馈波动，允许系统根据不同平台自动化进行内容修正与完成作品投放，有效提升用户媒体的视频运营效率与投放效果。
G10L15/22  ,语音交互方法、装置、设备及存储介质 [发明],本申请公开了一种语音交互方法、装置、设备及存储介质，属于智能交互领域。所述方法包括：接收目标用户发出的语音指令；识别该语音指令中的关键词，得到关键词组；若通过该关键词组无法确定该目标用户的语音意图，则基于该关键词组对该目标用户进行语音引导，以使该目标用户进行语音意图补充；若通过该目标用户的语音补充结果能够确定该目标用户的语音意图，则开启该语音意图对应的目标功能。本申请通过在单个语音指令无法确定目标用户的语音意图的情况下，基于语音引导交互的方式引导目标用户进行语音补充，以确定目标用户的语音意图，并开启语音意图对应的目标功能，能够提升语音交互的效率，提升用户的使用体验。
G06V20/17  ,一种目标人员识别方法和装置 [发明],本发明涉及一种目标人员识别方法和装置，属于图像处理与识别技术领域，解决体型识别的不确定性、目标人脸丢失以及微小型无人机无法承载现有计算平台等问题。该方法包括：采用无人机上的视觉传感器获取实时图像；将实时图像输入目标识别模型识别出待识别人员和装备特征；利用人员分类决策函数基于装备特征将待识别人员划分为警戒人员和非警戒人员；当待识别人员为非警戒人员时，利用声纹识别在多个待识别人员范围内初步筛选出敌方头目的搜索范围，利用体型识别缩小敌方头目的搜索范围以及利用人脸识别锁定敌方头目。结合人员分类决策函数实现基于装备特征的警戒人员精准识别，利用体型识别缩小敌方头目的搜索范围及利用人脸识别锁定敌方头目。
G10L19/16  ,音频编码方法、音频解码方法、装置、可读存储介质 [发明],本申请提供了一种音频编码方法、音频解码方法、装置、电子设备、计算机可读存储介质及计算机程序产品；音频解码方法包括：响应于针对音频码流封装的解码请求，从音频码流封装包括的帧头中获取目标编码模式以及目标码率模式；其中，音频码流封装包括的音频码流是通过目标编码模式以及目标码率模式，对音频信号进行音频编码得到的，目标编码模式是从多个编码模式中获取的，目标码率模式是从多个码率模式中获取的；通过目标编码模式以及目标码率模式，对音频码流进行信号解码处理，得到音频码流对应的编码特征估计值；通过目标编码模式，对音频码流对应的编码特征估计值进行重建处理，得到音频码流对应的合成音频信号。
G10L25/30  ,口语评测方法、装置、设备及存储介质 [发明],本申请公开了一种口语评测方法、装置、设备及存储介质，本申请配置了文本语音对齐模型，该模型的输入为目标音频的音频表征及参考文本，模型被配置为提取参考文本的嵌入表征，并将嵌入表征与音频表征进行拼接，基于拼接表征解码得到对齐结果，对齐结果包括了目标音频的识别文本及识别文本与参考文本的对齐信息，由此可见，本申请文本语音对齐模型可端到端的直接预测得到对齐结果，避免了传统方案识别结果中产生的级联误差。在得到对齐结果后可以进一步基于对齐结果和参考文本来计算目标音频的完整度测评结果，提高了口语完整度测评结果的准确度。
G16H15/00  ,基于语音识别的消化内镜诊断报告验证方法、装置和设备 [发明],本发明涉及医疗信息技术领域，提供一种基于语音识别的消化内镜诊断报告验证方法、装置和设备，该方法包括：获取内镜检查过程中生成的记录有实时内镜画面的影像表现的语音文件；通过对语音文件对应的语音文本进行诊断分类并生成固定格式的标准诊断结果，当生成消化内镜诊断报告时，对消化内镜诊断报告中记载的内镜诊断文本进行诊断分类并生成相同格式的内镜诊断文本，通过由语音文件得到的标准诊断结果对由诊断报告得到的内镜诊断文本进行验证，并在报告诊断结果与标准诊断结果不一致时，根据生成语音文件时采集的内镜影像对消化内镜诊断报告进行修改优化，避免内镜诊断报告书写过程中病情遗漏的异常情况发生，保证消化内镜诊断报告的准确性。
G10L25/45  ,电机信号处理方法、装置、设备及介质 [发明],本申请公开了一种电机信号处理方法、装置、设备及介质，涉及信号处理技术领域。其中，电机信号处理方法包括：获取电机的原始数字信号；将所述原始数字信号转换至巴克域，获得多个临界频带信号；确定各所述临界频带信号对应的窗函数；基于所述窗函数，对各所述临界频带信号进行短时傅里叶变换，得到各所述临界频带信号对应的目标频域信号。本申请通过对电机噪声信号进行处理，得到的不同频带的电机噪声信号对应的目标频域信号有着贴近于人耳感受的分辨率，以便于分析不同频带的电机噪声信号对人耳产生的实际影响，从而便于进行声学设计和优化，以降低电机噪声对人体的负面影响，提高电机的声音品质。
H04M1/72433  ,语音消息录入的方法及装置、电子设备和存储介质 [发明],本公开提供了一种语音消息录入的方法及装置、电子设备和存储介质，响应于语音录入指令进行语音录入，并对用户触摸屏幕产生的触摸点进行监测，并生成所述触摸点的轨迹信息；根据所述轨迹信息确定用户触摸的录入热区，所述录入热区包括手动录入热区及自动录入热区；基于用户触摸的所述录入热区，确定语音录入模式并按照对应的语音录入模式录入语音消息。与相关技术相比，本公开实施例通过设置不同的录入模式，在监测到用户触摸自动录入热区或用户触摸手动录入热区的时长超过时间阈值后，将语音录入模式切换为自动录入；如此能够在语音消息录入时，提高录入操作的鲁棒性、以及录入的成功率。
G10L13/02  ,语音合成方法、装置、可读介质及电子设备 [发明],本公开涉及一种语音合成方法、装置、可读介质及电子设备。所述方法包括：获取目标文本和用于表征至少一种音色属性的目标属性信息；根据预先生成的目标模型，生成与所述目标属性信息和目标隐向量对应的目标说话人表征向量，其中，所述目标模型基于流模型生成，所述目标隐向量从高斯分布中采样得到；根据所述目标说话人表征向量和所述目标文本，生成与所述目标文本对应的合成音频。由此，可以根据不同虚拟角色的特点为其设置音色属性进而合成符合该音色属性的音频。基于此，在为虚拟角色生成声音时，无需再花费成本寻找特定的发音人，也无需花费较长周期学习发音人的声音特性用以合成虚拟角色对应的合成音频，有利于节省成本。
H04M11/02  ,一种紧急呼叫唤醒方法及装置 [发明],本发明公开了一种紧急呼叫唤醒方法及装置，其中紧急呼叫唤醒方法包括利用T‑BOX系统获取用户的唤醒语音，识别所述唤醒语音获取所述唤醒语音对应的唤醒阈值及语音内容；利用T‑BOX系统判断所述唤醒阈值是否达到目标声音阈值，以及判断所述语音内容是否存在唤醒词；若所述唤醒阈值达到目标声音阈值，且所述语音内容存在唤醒词，使用T‑BOX系统唤醒紧急呼叫系统。本发明利用T‑BOX系统执行进行唤醒的触发及呼叫，识别唤醒语音获取唤醒语音对应的唤醒阈值及语音内容，并判断唤醒阈值是否达到目标声音阈值，以及判断语音内容是否存在唤醒词，实现紧急呼叫的唤醒；为车主提供一个更安全、更便捷的驾驶环境，也为车辆增加了一种新的唤醒方式。
G10L15/22  ,车辆控制方法、服务器及存储介质 [发明],本申请公开了一种车辆控制方法，包括：接收用户位于车辆座舱外发出的语音请求；基于预先训练完成的大语言模型，构建与语音请求相对应的远程智慧场景；下发远程智慧场景至车辆，以使车辆执行与远程智慧场景相对应的车辆控制指令。本申请中，在用户离车后，仍支持通过用语音实现对车辆的远程控制。具体而言，可基于预训练完成的大语言模型，可根据用户的自由表达的语音请求构建远程智慧场景，来满足用户的远程用车需求。相较于通过遥控设备进行简单的控制，能够提供更为丰富智能的车控指令，使得在用户离车后，相较于仅能执行预先设置的远程场景，能够为用户提供更高的灵活性和自由度，充分满足用户需求，改善用户体验。
H04H60/29  ,一种应用于市域监测的基于深度学习的调频广播信号频谱监测方法及系统 [发明],本发明涉及一种应用于市域监测的基于深度学习的调频广播信号频谱监测方法及系统，包括：对广播信号频谱图预处理后输入CNN与LSTM的融合深度学习网络，得到调频广播信号的图像表征信息，并判断其是否为非法调频广播信号；更进一步，对其非法类型进行判断，对中频分析后的语音信号的文本信息进行处理，输入TextCNN模型进行文本特征提取，获取文本的词向量特征表示；图像表征信息和词向量特征表示进行拼接，形成一个综合的多模态特征表示；对拼接后得到的综合的多模态特征表示进行最终的分类，实现非法调频广播信号监测，尤其是“黑广播”的判断。
G10L13/08  ,一种定制化语音生成方法、装置、设备及可读介质 [发明],本申请公开了一种定制化语音生成方法、装置、设备及可读介质，属于语音合成技术领域。该方案包括：获取待合成文本的语言学特征，以及目标发声者的第一语谱图；所述第一语谱图是对所述目标发声者的目标音频数据进行离散傅里叶变换得到的；利用声学模型对所述语言学特征进行转换，得到所述待合成文本对应的第二语谱图；对所述第一语谱图和所述第二语谱图进行融合处理，得到第三语谱图；利用声码器对所述第三语谱图进行转化，得到所述待合成文本的语音波形。该方案能够根据目标发声者的少量语音文件，实现语音的定制化。
G10L25/51  ,基于声纹识别的输电铁塔金属物体检测方法和装置 [发明],本申请涉及一种基于声纹识别的输电铁塔金属物体检测方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取待识别声波数据；对待识别声波数据进行特征提取，得到待识别声波数据对应的共振峰频率范围信息和听觉特征信息；将共振峰频率范围信息输入至预训练的第一声波分类模型，得到待识别声波数据对应的第一声波分类结果；在第一声波分类结果表征输电铁塔中存在金属物体的情况下，将听觉特征信息输入至预训练的第二声波分类模型，得到待识别声波数据对应的第二声波分类结果；第二声波分类结果表征输电铁塔内是否存在金属物体。采用本方法能够提高对输电铁塔内的金属异物检测的准确性。
G10L13/047  ,一种音频数据采集和个性化语音训练及推理方法 [发明],本发明提供的一种音频数据采集和个性化语音训练及推理方法，所述推理方法包括：个性化语音合成环境部署；构建使用人员组织架构；部署数据采集和算法服务；音频数据采集和音频文本对齐；文本预处理和音频预处理；模型训练和评估；模型推理和管理。避免数据泄露，提高用户录音效率，进一步提高数据质量。
H04N21/2187  ,一种直播环境下的低延迟语音识别与翻译方法、设备及存储介质 [发明],本发明提供一种直播环境下的低延迟语音识别与翻译方法、设备及存储介质，包括以下步骤：接收音频数据并进行预处理、对解包的音频数据进行初步处理、音频分割、语音文本转换、文本翻译、文本显示，用来解决目前直播环境下的语音识别和翻译延迟较高，特别是在高并发和大规模直播场景中，对硬件资源的依赖较高，导致成本较大的技术问题。
G10L25/60  ,一种音频处理测试方法 [发明],一种音频处理测试方法，属于音频信号技术领域。其通过算法处理系统将处理后的音频数据打包发送给播放系统，播放系统负责接收音频数据馈入播放系统的扬声器进行播放；并通过扬声器输出口，使用音频短接线，由line in口接入到第三方系统，在第三方系统演播、传输该音频音效；其包括单声道语音降噪处理及声学回声消除处理。本发明提供一种将算法处理结果实时接入第三方系统，在第三方系统里进行音频播放或展示，从而获得算法处理效果评估主观评价的音频处理测试方法。
G10L15/06  ,一种语音识别方法及系统 [发明],本发明公开了一种语音识别方法，该方法包括：采集多个目标场景的训练语音数据，基于每个目标场景的环境特征对所述训练语音数据进行预处理生成至少一个离线指令训练集；通过扩展Baum‑Welch算法对离线指令训练集进行训练构建多个场景的离线语音识别模型；基于预置的精度评价体系对多个场景的离线语音识别模型进行评价确定最优离线语音识别模型；响应于多个场景的语音识别指令，匹配关联的最优离线语音识别模型输出场景语音识别结果。通过本发明公开的方法和系统能够在多个不同的语音场景中进行高精度的语音识别，克服了现有的语音识别模型的识别精度差、鲁棒性低、用户体验感差的问题。
G10L15/18  ,语音识别方法、装置、设备及可读存储介质 [发明],本申请公开了一种语音识别方法、装置、设备及可读存储介质。该方案中，在确定候选语音识别结果之后，针对每个候选语音识别结果，基于候选语音识别结果的实体相关性，以及，与预设实体库中实体的匹配结果，确定候选语音识别结果的最终得分，最后从各个候选语音识别结果中选取最终得分最高的，作为最终的语音识别结果。考虑到与实体相关，以及，与预设实体库中实体匹配的候选语音识别结果，实体识别正确的概率更高，将该种候选语音识别结果的最终得分设置的高一些，使得这种候选语音识别结果具有更高的概率被选作为最终的语音识别结果，从而提升了语音识别结果的实体识别正确率。
H04B1/711  ,一种多径信道下的仿鲸目click通信信号识别方法 [发明],本发明公开了一种多径信道下的仿鲸目click通信信号识别方法，用于移除待识别信号中由多径信道产生的多径干扰信号，并准确识别真实鲸目click叫声信号和基于时延差编码的仿鲸目click通信信号，包括以下步骤：对未知属性click信号进行谱减法去噪；提取未知属性click信号内的叫声脉冲的起点和终点；基于信号自相关运算检测当前是否为多径信号，如果为多径信号则进行多径干扰信号移除操作，如果不是多径信号，则不做处理；基于高斯核概率密度估计计算叫声脉冲间隔概率密度曲线；观测叫声脉冲间隔概率密度曲线分布特征，如果呈现单峰分布则为真实鲸目click叫声信号，如果呈现多峰分布则为基于时延差编码的仿鲸目click通信信号。
G10L15/22  ,一种基于语音的场景自动生成方法 [发明],本发明公开了一种基于语音的场景自动生成方法，包括以下步骤：S1：通过语音识别设备、数据分析模块、场景生成模块、存储模块和通知模块共同组成场景自动生成系统，语音识别设备与数据分析模块进行电性连接，数据分析模块与场景生成模块进行电性连接，场景生成模块同时与存储模块、通知模块进行电性连接。本发明无需用户事先配置就可以达到场景的智能控制和生成，使用起来更加方便快捷，简化用户操作步骤，增强用户使用体验。
G10L15/02  ,基于云平台的语音数据处理方法及其系统 [发明],本申请涉及智能分析领域，其具体地公开了一种基于云平台的语音数据处理方法及其系统，其通过对发声人的声音信号进行特征提取以识别发声人的身份，进而决定是否执行语音指令。这样，智能家居系统可以根据个人设置和权限执行相应的操作，以给用户提供更加个性化的智能体验。
G10L21/007  ,语音修正方法、装置、设备及计算机可读存储介质 [发明],本发明公开了一种语音修正方法、装置、设备及计算机可读存储介质，其中，方法包括：获取麦克风采集的目标语音信号，将目标语音信号转换得到第一语音频谱，以及将目标语音信号转换得到第一频响曲线；获取第二语音频谱；将第一语音频谱与第二语音频谱进行比较，确定第一语音频谱中与第二语音频谱的差异大于预设阈值的目标频段；获取参考频响曲线，根据第一频响曲线和参考频响曲线计算得到将第一频响曲线在目标频段内各个频点的曲线值补偿至参考频响曲线水平的增益值，采用增益值对目标语音信号进行修正后输出。本发明提供一种语音修正方案，对用户语音信号进行修正，以提高语音的清晰度。
G10L15/22  ,一种用于电网调控业务的智能语音调度系统 [发明],本发明公开了一种用于电网调控业务的智能语音调度系统，属于电网调控技术领域，该用于电网调控业务的智能语音调度系统，包括前端模块、后端模块、数据库模块和系统测试模块，所述前端模块包括语音输入单元和语音识别单元，所述后端模块包括任务调度单元、资源管理单元和语音合成单元，所述数据库模块包括数据存储单元和数据管理单元；所述系统测试模块包括系统实施单元、测试单元和上线运营单元。本发明通过设计前端模块、后端模块、数据库模块和系统测试模块，实现对电网调控业务能够通过智能语音调度，提高了调控业务处理效率，同时智能语音调度系统提供了更便捷、灵活的交互方式，提升了用户的工作体验和满意度。
G10L25/51  ,一种车辆泊车碰撞监控方法、系统、装置及控制器 [发明],本发明提出一种车辆泊车碰撞监控方法、系统、装置及控制器，监控方法包括：采集车辆振动信号和车辆现场的音频信号；当振动信号超过预设振动阈值时，对音频信号进行特征提取以获取特征数据；将特征数据输入至训练好的场景分类模型中进行场景识别；当场景为异常场景时，控制车辆发出告警信号和/或录制音频、视频。本发明通过振动监测模块被触发后通过对音频监测模块监测到的音频信号进行处理分析，以判定当前场景是否为异常场景，再依据判定结果控制报警和/或录制音频、视频，其通过调低振动监测模块的阈值，以提高其灵敏度，从而降低漏报率，并且在振动监测模块被触发后再次对音频信号进行分析处理，以避免产生误报并准确识别具体场景。
G06F16/332  ,对话状态的追踪方法及装置、电子设备和存储介质 [发明],本公开公开了对话状态的追踪方法及装置、电子设备和存储介质，涉及人工智能技术领域，通过使用预设词频算法提取文本向量的全局特征，使用神经网络模型提取文本向量的局部特征，以及使用长短期记忆网络模型提取文本向量的时序特征的方法，能获得文本向量在时序、空间、全局和局部的多维特征集合，在提取更多的特征向量的同时兼顾了对会话中的上下文信息的提取，更好的实现对用户对话状态的跟踪。
G10H1/36  ,一种合唱音频数据处理方法、装置、电子设备及介质 [发明],本发明公开了一种合唱音频数据处理方法、装置、电子设备及介质，方法包括：从音乐授权方获取当前歌曲的伴奏版本；根据当前歌曲的歌曲名称，获取对方用户的声纹文件和用户使用授权；根据用户使用授权，对声纹文件与伴奏版本进行id匹配，得到匹配结果；根据匹配结果，将声纹文件发送到对方用户和所有听众的终端设备；实时检测对方用户声音流，当一定时间段内没有收到对方用户声音流时，根据歌曲进度自动播放声纹文件，直至再次收到对方用户声音流。本发明实施例能够利用声纹文件为合唱掉线问题提供优化方案，使得即使有一方网络故障或者掉线，也能够及时反应，有利于提高合唱体验和听众用户的收听体验，可以广泛应用于计算机技术领域。
H04M3/22  ,音频通话过程中的异常音频数据处理方法、介质及设备 [发明],本发明涉及一种音频通话过程中的异常音频数据处理方法、介质及设备，在音频通话过程中实时获取音频数据，并对音频数据中的每一音频帧信息进行异常检测，以判断音频数据是否存在异常，若存在异常则生成第一触发指令，第一触发指令用于对当前音频通话自检测出异常的音频帧开始执行录音操作，直至音频通话结束，并将这一录音数据上传至服务器。本技术方案能够在音频通话过程中实时对音频帧进行异常监测，并在存在异常音频时即时对这一音频通话进行录音，以采集异常音频数据，在通话结束后能够及时将这一异常音频数据上传至服务器，以供开发人员对这一异常数据进行分析、调试，提升音频通话的运维效率。
G10L25/51  ,一种输电线路隐患故障声音识别系统及方法 [发明],本发明提出的一种输电线路隐患故障声音识别系统及方法，所述系统包括：声音识别装置和监拍装置，监拍装置固定安装在输电线路上，用于获取输电线路周边的故障隐患图像，并利用图像识别算法进行故障隐患识别和预警；声音识别装置固定安装在输电线路上，用于对输电线路周围环境声音进行监听监测，当监听到异常声音后，进行录音采集，生成相应的音频文件并上传至监拍装置，由监拍装置调用内置的声音识别模型识别出声音的类型，若识别出声音为隐患故障类声音，则获取声音的定位信息，并进行预警。本发明通过在图像识别基础上增加音频检测识别功能，对输电线路隐患故障进行多模态监测、识别和预警，扩大了隐患故障监测的范围，同时提高了识别准确率。
H04N5/76  ,一种智能可视化噪声监测及溯源装置 [发明],本发明公开了一种智能可视化噪声监测及溯源装置，属于环境监管技术领域，包括感知单元和数控主体；感知单元包括摄像装置和相控阵声波检测器；摄像装置可以旋转，拍摄周围环境的图像；相控阵声波检测器检测周围环境中的噪声；数控主体包括数据处理模块和控制模块；相控阵声波检测器将检测得到的噪声信息传输至数据处理模块；数据处理模块根据噪声信息解析出噪声的种类、声压大小和方位信息；再根据噪声的种类和声压大小判断噪声是否为问题噪声，若属于问题噪声，则将噪声的方位信息传递给控制模块，控制模块根据噪声的方位信息控制旋转摄像装置进行记录。本装置能够时刻记录周边噪声的情况并分析，结合旋转摄像装置记录噪声污染源的情况。
G10L15/06  ,基于深度学习音频分类的电影高光自动剪辑方法 [发明],本发明公开了一种基于深度学习音频分类的电影高光自动剪辑方法，包括以下步骤：S1，基于AudioSet公开数据集，训练音频识别深度学习模型；S2，对待处理的电影以16000的采样率提取音频信号；S3，对提取的音频信号以64000长度作为采样窗口，以32000长度作为采样间隔进行采样；S4，对每个采样间隔用音频识别深度学习模型进行推理，将得到的结果按照分类进行保存；S5，按类别将结果整合，映射到电影帧数上，重叠部分取平均值；S6，按照阈值对S5结果做0‑1赋值；S7，将响应为1的部分作为高光片段计算对应的起始时间与结束时间，同时将每个片段内对应S5的分数取平均作为高光评分；S8，基于高光片段时间信息进行片段剪辑并输出。
G06T13/40  ,人工智能屏的交互方法、人工智能屏及存储介质 [发明],本发明涉及人工智能领域，公开了一种人工智能屏的交互方法、人工智能屏及存储介质。该方法包括：检测到交互请求时，对交互请求进行逻辑处理，得到响应结果；基于响应结果，生成响应结果对应的语音信息，并生成响应结果对应的数字人动作；基于语音信息以及预设的音唇同步算法，生成语音信息对应的口唇驱动动画；根据数字人动作、口唇驱动动画以及语音数据，执行回复操作，以响应交互请求。在本发明实施例中，人工智能屏可实现更高水平的对话和功能。
G10L21/0216  ,风噪处理方法、可穿戴设备、电子设备、音频处理系统及存储介质 [发明],"本申请提供风噪处理方法，包括：由可穿戴设备的语音拾取装置采集噪声样本；应于所述可穿戴设备被唤醒，由所述噪声样本确定风噪强度,并从预设降噪策略中选择与所确定的风噪强度相应的降噪策略；以及根据所选择的降噪策略处理所述语音拾取装置采集的音频。还提供可穿戴设备、电子设备、风噪处理系统和存储介质。"
G06V40/16  ,一种人脸特征的生成方法、系统以及电子设备 [发明],本申请提供了一种人脸特征的生成方法、系统以及电子设备，涉及人脸识别技术领域。本申请在预先训练目标人脸特征生成模型时，对模型的训练数据增加一套损失函数，该函数通过梯度反转的底层方法，致力于故意让模型分不清楚谁是谁，也即消弭不同发音人的个人特色，同时，对训练数据进行随机增强，通过对训练数据中的音频做频谱的随机缩放，改变音频的发音人音色，促使模型在输入音色变化的情况下还能照旧输出原人脸特征参数，从而提高模型对输入变化的稳定性。通过本申请预先训练得到的目标识别模型，具有更好的泛化性和稳定性。
G10L15/22  ,语音交互方法、服务器和存储介质 [发明],本申请公开了一种语音交互方法、服务器和存储介质。该语音交互方法包括：接收车辆转发的用户语音请求；根据大语言模型对语音请求进行槽位识别、应用程序接口预测以及应用程序接口参数填充以得到应用程序接口参数填充的执行结果，其中，大语言模型预先训练完成，且能够根据语音请求生成应用程序接口参数填充的执行结果；输出执行结果下发至车辆完成语音交互。本申请实施方式精简语音交互系统的架构，并利用预训练的大语言模型，减少了对于不同垂域的相关模型的调用，有效降低延时，提升对于用户语音请求的响应速度，精简架构也有利于后续的维护，节省成本。
G01S5/18  ,一种面向多通道音频定位的特征预处理和提取方法 [发明],本发明是一种面向多通道音频定位的特征预处理和提取方法。本发明涉及音频预处理技术领域，本发明进行DSB特征提取LogMel特征和IV特征，提取后的特征进行全局归一化，归一化的数据在深度学习上进行训练和测试；通过DSB边缘端加速方法进行加速处理，将提取的特征用于训练一个CRNN模型，用于声源方向的估计。本发明对经过DSB处理的音频进行LogMel特征和IV特征的提取。在特征提取过程中，本发明利用边缘端GPU在Nano上加速处理。最后使用提取的特征训练一个CRNN。与使用不进行DSB的特征相比，使用DSB方法训练的CRNN可以有效的降低DoA误差，并且依然可以在边缘端实时的运行。
G10L15/32  ,处理数据的方法、装置、电子设备 [发明],本公开涉及一种处理交互数据的方法、装置、电子设备及计算机可读存储介质。本公开的各项实施例将对话管理系统与通用大语言模型进行融合，使得对话管理系统中的其他神经网络与通用大语言模型能够并行地工作。本公开实施例基于超时机制和/或判断条件，确定是否继续等待通用大语言模型的响应，在减少延迟的前提下，提高针对交互数据的推理结果的合理性。
G06T13/40  ,基于多模态数据的数字人驱动方法及系统 [发明],本申请公开了一种基于多模态数据的数字人驱动方法及系统，其通过采集用户语音数据和面部表情图像，并在后端引入语义理解和图像处理算法来进行用于语音和面部表情的分析和识别，以此利用多模态数据来进行用户面部表情的识别判断，并实现数字人的驱动。这样，能够基于用户语音和面部表情图像来优化面部表情的识别精准度，使得数字人能够更加准确地模仿和响应用户的语音和面部表情，提高数字人驱动的精准度，从而实现更加自然和真实的交互体验。
G10L15/06  ,数据标注方法、装置和语音识别方法、装置 [发明],本公开涉及一种数据标注方法、装置和语音识别方法、装置，涉及计算机技术领域。该数据标注方法，包括：利用语音识别模型，对视频的音频流数据进行语音识别，以获取语音识别结果和语音识别结果的置信度；利用文本识别模型，对视频的字幕区域进行文本识别，以获取文本识别结果；根据置信度，对语音识别结果与文本识别结果进行融合处理，以确定最终识别结果；根据最终识别结果，对音频流数据进行标注。本公开的技术方案能够降低数据标注的人工成本，提高数据标注的效率。
G10L25/51  ,一种经典底质分类与高频环境声学底质分类的转换方法 [发明],本发明涉及一种经典底质分类与高频环境声学底质分类的转换方法，通过将经典Wentworth底质分类转换为高频环境声学底质分类(HFEVA)，并根据海图底质分类与高频环境声学底质分类之间的粒级范围对应关系，实现海图底质分类向HFEVA底质分类的转换。本发明设计合理，实现了从国际广泛应用的Wentworth底质分类以及标准海图底质分类向高频声学底质分类的转换，有利于将传统底质分类数据资源，转换为可应用于声学参数模型计算的底质产品，拓展了传统底质分类产品在声学领域的应用，同时大大丰富了可用于声学参数计算的底质数据来源。
G10L15/00  ,语音识别方法、装置、电子设备及存储介质 [发明],本申请实施例提供一种语音识别方法、装置、电子设备及存储介质，本申请提供的语音识别方法，利用包括第一初始语音识别模型和第二初始语音识别模型的初始多任务语音识别模型进行模型训练，同时在训练过程中利用多个不同的损失函数计算模型损失，利用多个模型损失同时更新初始多任务语音识别模型中的模型参数，得到训练后多任务语音识别模型。本申请实施例提供包括多个语音识别模型多的多任务语音识别模型，同时整合多个损失函数共同增强多任务语音识别模型的语音识别精度。
G06Q30/08  ,一种评标违规行为检测方法及系统 [发明],本申请涉及一种评标违规行为检测方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取音频信息并将所述音频信息转换为频域特征信息；通过循环神经网络建立声学模型将频域特征信息映射到文本序列；基于所述声学模型和预设的语言模型计算文本序列的最佳排列；若最佳排列的文本序列与预设的违规关键词相匹配，则在预设的告警库中发送与违规关键词对应的警报信息，所述告警库中储存有不同的违规关键词以及与违规关键词相对应警报信息。采用本方法通过结合自然语言处理和视觉识别技术，实现了对评标专家在封闭评标场所内违规行为的监测和判断，提高了评标的公正性和公平性。
G10L25/30  ,基频生成方法、计算机设备和计算机可读存储介质 [发明],本申请涉及一种基频生成方法、计算机设备和存储介质，能够提升了基频提取结果的准确性。所述方法包括：获取歌曲的各歌词对应的音素，以及多个音素之间的顺序信息；根据每个音素在歌曲的曲谱中的音高、音高时长和连音方式信息，生成每个音素的编码信息；按照顺序信息将多个音素的编码信息输入到训练好的生成模型，由生成模型基于每个音素的编码信息以及每个音素的上下文音素的编码信息，确定多个帧的预测基频特征；每个音素的上下文音素基于多个音素之间的顺序信息确定；获取多个帧中每个帧的音高，根据每个帧的音高和预测基频特征，确定每个帧的基频，并根据多个帧的基频，得到歌曲的基频。
G06F18/241  ,角色行为的检测方法、装置及电子设备 [发明],本发明实施例提供了一种角色行为的检测方法、装置及电子设备，涉及数据处理技术领域，该方法包括：获取包含角色的待检测视频片段；基于待检测视频片段中的视频帧的图像特征和辅助信息，利用预先训练的行为检测模型进行处理，得到待检测视频片段的角色行为检测结果；其中，辅助信息表示：对待检测视频片段中的音频帧进行特征提取得到的音频特征，和/或，待检测视频片段包含的对象。通过本方案，能够利用多个维度的信息来确定待检测视频片段中的角色行为的检测结果，从而能够提高确定视频片段中的角色行为的检测结果的准确性。
H04M3/51  ,坐席服务方法、坐席服务系统以及存储介质 [发明],本申请公开了一种坐席服务方法、坐席服务系统以及存储介质。该方法包括：获取与目标对象的呼叫操作对应的目标语音流，其中，目标语音流中包括：与目标对象的呼出操作对应的主叫语音流、与目标对象的呼入操作对应的被叫语音流；基于目标识别算法对目标语音流进行识别，得到与目标语音流对应的目标意图结果；将目标意图结果和预设的坐席服务进行匹配，确定目标坐席服务，并将目标坐席服务反馈至目标对象，其中，目标坐席服务包括以下至少之一：话术调用服务、咨询流程导航服务、订单填写服务、用户画像服务、质检服务。本申请解决了相关坐席服务技术需要坐席人员自主判断服务流程，并通过手动处理，导致坐席服务质量较差、效率较低的技术问题。
G10L15/22  ,一种交互方法、装置、控制设备及存储介质 [发明],本发明提供了一种交互方法、装置、控制设备及存储介质，交互方法包括：获取目标用户的手部图像序列和语音序列；识别语音序列中的指令词，并获取指令词对应的时间；根据手部图像序列以及指令词对应的时间，确定目标用户发出指令词时的手部指向区域；根据目标用户发出指令词时的手部指向区域，确定交互设备；控制交互设备执行指令词对应的操作。本发明提供的交互方法为结合语音的指向交互方法，该交互方法有效利用了不同模态信息的互补性，其不但能够实现丰富的交互功能，而且具有较好的交互稳定性，用户体验较好。
G06F40/174  ,一种表单填报方法、装置、设备及介质 [发明],本申请公开了一种表单填报方法、装置、设备及介质。其中，该方法通过将目标语音输入至预先训练的多语言识别模型中，得到与目标语音对应的语音文本；对语音文本进行自然语言处理，提取语音文本中至少一个关键数据；将各关键数据与目标表单中各字段进行匹配确定匹配结果，并根据匹配结果进行表单填报。本技术方案，以实现语音填报表单，提高表单填报准确率和效率，改善用户体验。
G01M7/02  ,伺服驱动器振动试验方法、装置、设备及介质 [发明],本申请涉及一种伺服驱动器振动试验方法、装置、设备及介质，应用于振动试验技术领域，其方法包括：获取音频数据；基于所述音频数据判断试验是否存在异常；若试验存在异常，则获取视频数据以及监测数据；基于所述视频数据以及所述监测数据确定异常情况；基于所述异常情况确定修正策略；基于所述修正策略进行修正。本申请具有提高振动试验的效率的效果。
G10L21/028  ,基于高阶MUSIC正交联合约束的多通道声源分离方法 [发明],本发明基于高阶MUSIC正交联合约束的多通道声源分离方法，与现有技术相比解决了传统声压传感器在高斯噪声背景下分离效果急剧下降以及阵列孔径的相关问题上存在限制的缺陷。本发明包括以下步骤：多通道声源的获取；利用高阶MUSIC正交联合约束MNMF方法进行多通道声源分离处理；多通道声源分离信号的获得。本发明提出了高阶多重信号分类(MUSIC)正交联合约束的多通道非负矩阵分解算法，针对复杂环境中高斯噪声的干扰，通过高阶累计量的MUSIC算法，获得声音信号精确地方位信息，将声源信号方位信息引入到多通道非负矩阵模型中，为空间协方差矩阵提供了先验信息，提高了声音的分离效果。
G09B5/06  ,一种便携式英语翻译教学终端 [发明],本发明公开了一种便携式英语翻译教学终端，涉及英语翻译领域，包括翻译终端主机，所述翻译终端主机的下端外表面设有防护胶垫，所述翻译终端主机的上端外表面设有显示屏、扬声器、控制按钮与智能收音器，所述翻译终端主机的两侧外表面均设有魔术贴绑带，所述翻译终端主机的一端外表面设有弹性提拉带，所述翻译终端主机的另一端外表面设有智能扫描器与充电插孔，所述智能扫描器位于充电插孔的一侧。本发明所述的一种便携式英语翻译教学终端，在使用时可便于讲师随身携带翻译，其次在使用时可对文字英语进行识别翻译，也可将文字翻译成音频进行播放，并且该翻译教学终端语音收入效果较好，可避免在语音翻译过程中受外界干扰影响翻译结果。
G10L25/27  ,歌曲识别模型训练方法、歌曲识别方法、设备和存储介质 [发明],本申请涉及一种歌曲识别模型训练方法、歌曲识别方法、计算机设备和存储介质。歌曲识别模型训练方法包括：获取第一样本音乐对应的原唱歌曲以及翻唱歌曲，以及与第一样本音乐不相同的第二样本音乐的样本音乐歌曲；将原唱歌曲以及翻唱歌曲进行切片处理，并将切片处理得到的第一样本音乐的多个音乐切片输入预先训练的音乐切片特征提取模型，得到第一样本音乐的多个音乐切片特征；根据原唱歌曲、翻唱歌曲以及样本音乐歌曲的旋律特征，得到第一损失值，并根据多个音乐切片特征的旋律特征，得到第二损失值；根据第一损失值以及第二损失值，对待训练的歌曲识别模型进行训练，以得到训练完成的歌曲识别模型。采用本方法能提高歌曲识别模型的识别准确率。
G10L15/183  ,基于急救报警信息的定位方法、装置和电子设备 [发明],本申请实施例提供一种基于急救报警信息的定位方法和电子设备，定位方法包括：获取语音急救报警信息，语音急救报警信息为通过急救报警终端输出；获取急救报警终端的定位信息；在语音急救报警信息未包含地名描述信息时，利用预训练的语音识别模型对语音报警信息进行识别，得到位置关联信息，位置关联信息至少包括现场环境对象和/或现场环境对象与报警人的位置关系信息，预训练的语音识别模型基于预设语言逻辑的语音样本进行训练得到；将位置关联信息和定位信息进行匹配，得到报警位置信息。可以实现基于报警信息少量的位置特征进行精确定位，实现在一些特殊场景下的异常语音报警无法识别的情况下准确的定位报警位置。
G10L25/51  ,一种摩斯信号活动区域检测与截取方法 [发明],本发明公开了一种摩斯信号活动区域检测与截取方法，用以在音频信号中完整的截取出存在摩斯信号的部分。所述方法包括信号能量提取，获取由信号能量构成的一维序列；局部最大值处理，获取能量序列包络的同时保留上升沿的突变特性；上升沿搜索，寻找信号的上升沿所在的位置，基于此判定摩斯信号的起点；信号能量估计，估计摩斯信号的能量；噪声估计，估计噪声能量；获取摩斯信号结束阈值，结束阈值依据摩斯信号能量估计值和噪声能量估计值来确定；摩斯信号结束点搜索，基于结束阈值来寻找摩斯信号的结束位置。本发明能够高效、准确的实现摩斯信号活动区域的检测与截取，有较广泛的实用价值。
G10L15/02  ,语音识别方法、装置、电子设备和存储介质 [发明],本发明提供一种语音识别方法、装置、电子设备和存储介质，其中方法包括：获取待识别语音；基于语音识别模型，对所述待识别语音进行语音识别；所述语音识别模型是联合基于语音的音素识别任务和/或基于音素的文本生成任务，以及语音识别任务训练得到的。本发明提供的方法、装置、电子设备和存储介质，联合基于语音的音素识别任务和/或基于音素的文本生成任务，以及语音识别任务训练语音识别模型，以增强语音识别模型对于语音信息的提取能力，使得基于由此训练得到的语音识别模型，能够获取到在语义层面上表现更优的语音识别文本，从而提高语音识别的可靠性和准确性。
G10L15/22  ,一种语音识别控制便携式储能电源装置及方法 [发明],本发明公开了一种语音识别控制便携式储能电源装置及方法，包括便携式储能电源本体，所述在便携式储能电源本体中的控制电路和语音芯片，所述语音芯片用于接收用户发出的语音指令，所述语音芯片传输给所述控制电路进行处理。包括如下步骤：第一步，便携式储能电源本体中的语音芯片接收到语音指令；第二步，所述便携式储能电源本体通过所述语音芯片接收到语音指令与所述便携式储能电源本体的控制电路本身预存的语音指令库中的指令源相匹配，如当相一致时则会通知便所述便携式储能电源本体执行相应的操作，如当不相一致则所述便携式储能电源本体不会执行相应的操作。本发明旨在解决现有技术中操作复杂，用户使用不便捷的问题。
G10L21/013  ,歌曲音色转换方法、计算机设备和存储介质 [发明],本申请涉及一种歌曲音色转换方法、计算机设备和存储介质，涉及歌声合成技术领域和人工智能技术领域，能够提高歌曲音色转换效率。所述方法包括：对待转换歌曲进行切片处理，得到所述待转换歌曲的多个切片；对所述多个切片进行处理，得到所述待转换歌曲的音高和音素后验概率；将所述待转换歌曲的音高，音素后验概率输入目标音色对应的音色转换网络，得到所述目标音色对应的歌曲。
G10L15/06  ,模型训练方法、语义通信传输方法及模型训练装置 [发明],本发明公开了模型训练方法、语义通信传输方法及模型训练装置，本发明实施例通过对各个批次训练数据的分块操作，进而基于语义分块重要性的语义分块筛选法，优先传输重要性较高的语义分块，在实际应用中，可根据传输任务的精度要求动态调节，通过对语义数据进行分块、重要性筛选和量化操作，实现了对数据的高效传输。本发明实施例能够精确高效进行语音通信传输，可广泛应用于数据处理技术领域。
G06F9/451  ,一种应用程序界面跳转方法及系统 [发明],本发明提供了一种应用程序界面跳转方法及系统，该方法包括：当获取到用户输入的语音信息时，对语音信息进行解析处理，以识别出语音信息中包含的应用描述以及功能描述，并将应用描述转换成对应的请求指令；基于请求指令在预设映射数据库中匹配出与应用描述对应的应用编码，并根据应用编码在预设应用数据库中匹配出对应的目标应用程序；根据功能描述在目标应用程序中调取出对应的目标应用程序界面，并将目标应用程序界面实时显示在用户终端。本发明能够省去人工手动的操作，对应提升了用户的使用体验。
G10L19/16  ,音频数据处理方法、装置、设备及计算机可读存储介质 [发明],本申请涉及一种音频数据处理方法、装置、设备及计算机可读存储介质，属于音频处理技术领域，方法包括：对待处理音频流数据进行音频格式检测，并将待处理音频流数据存储至第一缓冲区，待处理音频流数据包括对应至少一种音频格式的多个待处理音频数据；对于任一待处理音频数据，获取待处理音频数据的音频格式对应的音频解码器，利用音频解码器对待处理音频数据进行解码，将生成的PCM数据存储至第二缓冲区；对从第二缓冲区中读取的多个PCM数据进行后处理，将生成的多个多声道数据存储至第三缓冲区；对从第三缓冲区读取的多个多声道数据进行通道排序，并将生成的多个音频通道数据存储至第四缓冲区。本申请能够减少音频数据处理卡顿、失真、失败的情况。
G06Q10/0639  ,一种客服服务质量评估方法、装置、设备及存储介质 [发明],本发明公开了一种客服服务质量评估方法、装置、设备及存储介质。方法包括：获取用户与客服沟通过程中的文本信息和语音信息，从文本信息中提取文本特征，以及从语音信息中提取语音特征，融合文本特征和语音特征，得到融合特征，采用多头注意力机制对融合特征进行处理，从融合特征中提取反应用户情绪的特征向量，基于特征向量预测用户情绪，基于用户情绪确定客服的服务质量。本发明基于用户与客服沟通过程中的情绪来进行客服服务质量的评估，无需依赖用户的反馈，提高了服务质量评估的真实性和数据的覆盖范围，此外，本发明融合了用户与客服沟通过程中的文本特征和语音特征，从多维度判断用户的情绪，提高客服服务评估准确性。
G10L25/51  ,一种语音音高的识别方法、系统、电子设备及存储介质 [发明],本申请提供了一种语音音高的识别方法、系统、电子设备及存储介质，涉及语音识别技术领域。本申请通过在训练音高识别模型时引入了自监督模型，通过自监督模型提供额外的训练数据，从而能够预测出更加可靠的辅助置信度向量，并通过将原始置信度向量和辅助置信度向量相加，得到目标置信度向量，最终通过计算目标置信度向量能够得到更加准确的音高。
G10L15/22  ,交互提示文本确定方法、装置、电子设备和存储介质 [发明],本发明提供一种交互提示文本确定方法、装置、电子设备和存储介质，涉及人工智能技术领域，所述方法包括：获取用户输入的提问语音数据，以及所述提问语音数据对应的提问文本数据；基于所述提问语音数据对应的目标声纹特征，确定所述用户对应的目标身份数据；基于所述目标声纹特征和所述提问文本数据，确定所述用户对应的身心状态数据；基于所述目标身份数据和所述身心状态数据，确定所述提问语音数据对应的提示文本，所述提示文本用于控制回复文本的类型。本发明可通过控制回复文本的类型，提高回复文本的针对性和准确性。
G10L25/84  ,语音检测方法、装置、设备及存储介质 [发明],本发明涉及语音检测技术领域，公开了一种语音检测方法、装置、设备及存储介质。该语音检测方法包括：获取音频序列；对所述音频序列进行第一音频特征提取，并根据第一音频特征提取结果对所述音频序列进行语音人声检测，得到第一语音检测结果；对所述音频序列进行第二音频特征提取，并根据第二音频特征提取结果对所述音频序列进行语音人声检测，得到第二语音检测结果；根据所述第一语音检测结果和所述第二语音检测结果确定所述音频序列的语音检测结果。通过上述方式，本发明能够通过非训练的方式进行语音检测，算力低且检测精度高。
G10L21/0264  ,一种动漫数据智能编码存储方法及系统 [发明],本发明涉及音频噪声过滤技术领域，具体涉及一种动漫数据智能编码存储方法及系统。首先获取动漫的原始音频数据，基于扩展卡尔曼滤波获得预测音频数据，对音频采样点在原始音频数据和预测音频数据中幅值差异的变化情况进行分析，筛选待定采样点；然后分析每个待定采样点的局部范围内音频采样点的幅值差异的波动情况从而确定待定采样点的平滑必要性，进而根据局部范围内各待定采样点的平滑必要性的分布情况获得待定采样点的平滑参数；从而根据平滑参数对原始音频数据幅值和预测音频数据幅值进行加权分配，实现去噪的同时极大程度上保留音频细节信息；对音频数据进行重构，获得音频输出数据，保证了音频输出数据编码存储后的质量。
G07C5/08  ,一种汽车仪表语音播报自动化检测系统 [发明],本发明涉及汽车仪表声音测试技术领域，公开一种汽车仪表语音播报自动化检测系统，包括：信号触发模块，用于对汽车仪表发送信号，在预设时间段触发汽车仪表产生语音播报声音；音频录制模块，用于录制语音播报声音；信号处理模块，用于对语音播报声音进行处理，基于预设时间段从语音播报声音中提取当前声音频率特征；数据分析模块，用于将当前声音频率特征和预设声音频率特征对比，分析语音播报声音的分析结果。本发明通过信号触发模块、音频录制模块、信号处理模块、数据分析模块可实现对汽车仪表产生语音播报声音进行录制、处理、分析，得到语音播报声音的分析结果，减少了大量的人力检测成本和时间成本，可以降低在测试过程中的测试误差。
G06F18/214  ,数据标注方法、存储介质和电子设备 [发明],本发明公开了一种数据标注方法、存储介质和电子设备，数据标注方法包括：获取人脸视频数据及其对应的音频数据；对人脸视频数据和音频数据进行唇音一致性检测，得到人脸视频数据相对音频数据的偏帧量和人脸视频数据的置信度：若偏帧量和所述置信度满足预设条件，则确定音频数据与人脸视频数据匹配，并将音频数据对应的文本标签作为人脸视频数据、音频数据的标注信息。通过上述方法，可以快速且低成本的获得高质量的音频、带唇形人脸视频、文本标签的多模态数据，便于后续多模态语音识别模型的训练。
G01R31/52  ,一种干式空心电抗器匝间短路监测装置及其监测方法 [发明],本发明公开了一种干式空心电抗器匝间短路监测装置及其监测方法，包括表贴麦克风，表贴麦克风设置在干式空心电抗器上，依次连接多通道采集卡、FPGA模块和处理平台，多通道采集卡与FPGA模块分别连接高压取电及储能模块；FPGA模块利用快速傅里叶变换以及梅尔倒谱系数对空心电抗器固体绝缘材料破损声音、匝间短路电流声音进行特征分解与识别，分别获取其频谱特征与语音特征，处理平台用于与数据库进行比对完成干式空心电抗器匝间短路的识别。本发明为干式空心电抗器匝间短路识别提供了经济、安全、高效的解决方案。
G06F40/289  ,一种基于大数据的语义分析方法、系统和存储介质 [发明],本申请实施例提供了一种基于大数据的语义分析方法、系统和存储介质。该方法包括：对用户场景的语音片段解析获得词义集，并对语音数据信息处理获得补偿系数和辨识度指数，根据模型对词义集解析并与实际语义对比获得差异度指数，再将指数以及补偿系数和干扰因子处理获得语义辨识成效数据，再与历史样本均指数进行阈值对比，若不满足则获取优化样本对模型进行优化训练，并获得训练模型处理后的优化结果；从而基于大数据对用户场景化语音进行词义解析以及语义解析并获取语义辨识成效数据，并与历史样本的优化数据进行效果检验，并根据历史优化样本进行模型优化训练，实现对语义的优化分析和辨识效果的检验，提高用户场景化下的语义分析的准确率。
G16H50/20  ,在线问诊辅助方法、装置、电子设备和存储介质 [发明],本发明公开了一种在线问诊辅助方法、装置、电子设备和存储介质，包括：获取就诊患者的就诊目标科室ID，加载与就诊目标科室ID匹配的微表情识别模型，获取就诊患者的视频数据，将视频数据输入微表情识别模型中得到就诊患者的表情标签，根据表情标签和就诊目标科室ID确定辅助文本，并在医生终端显示辅助文本，通过辅助文本辅助医生对就诊患者进行问诊，使得医生在有限的问诊时间内可以通过就诊患者的语音描述和就诊患者的表情进行问诊，能够获取到就诊患者准确有效的信息，在一定程度上辅助提高医生对就诊患者问诊的准确度，以及提高在线问诊的效率。
G06F9/445  ,可穿戴设备的应用运行方法、电子设备和存储介质 [发明],本申请提供了可穿戴设备的应用运行方法、电子设备和存储介质。所述方法包括：获取运行目标应用的指示，在可穿戴设备的本地内存中为目标应用分配内存空间；从与可穿戴设备连接的移动终端获取目标应用运行时所需的应用资源，并将应用资源保存至所分配的内存空间中；加载应用资源，以使得可穿戴设备运行所述目标应用。在启动目标应用的运行之前，应用运行所需的应用资源并不会占用可穿戴设备的内存空间，相当于可穿戴设备和移动终端共享了手机的部分存储资源，降低了可穿戴设备的存储需求和存储成本，在可穿戴设备存储资源有限的情况下，使得可穿戴设备也可以加载较为复杂的应用并且获得较好的应用性能，优化了可穿戴设备的运行性能。
G10L15/26  ,语音校验方法及装置、计算设备、计算机可读存储介质 [发明],本说明书实施例提供一种语音校验方法及装置、计算设备、计算机可读存储介质；所述方法包括：获取待校验的语音数据，并将所述语音数据转换为文本数据；基于多个提示文本组，调用目标文本处理模型对所述文本数据进行处理，得到针对各提示文本组的回复结果，其中，所述提示文本组基于参考文本中的校验规则信息分析得到，所述提示文本组用于指示所述目标文本处理模型输出是否符合所述校验规则信息的回复结果；基于所述各提示文本组的校验权重和回复结果，确定针对所述语音数据的校验结果；该方法可以降低对语音数据的分析复杂度。
G10L15/22  ,车辆语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种车辆语音交互方法，所述方法包括：根据大语言模型对原始训练数据进行更新以得到目标训练数据。根据目标训练数据更新预设模型，得到语音交互模型。部署语音交互模型至车辆，以使车辆根据语音交互模型和获取到的当前语音请求完成语音交互。如此，本申请的服务器通过目标训练数据得到可部署至车辆的语音交互模型，车辆通过语音交互模型完成语音交互，车辆语音交互功能的使用场景拓宽。本申请通过大语言模型生成训练数据并更新，消除因偶发致幻而导致的噪声，语音交互模型的可靠性得以保障。本申请通过大语言模型生成训练数据，使得样本生成和样本标注由人工完成的情况改善，训练数据获取难度降低，模型训练难度降低。
G07C1/20  ,煤矿回风巷道的巡检方法及装置、巡检系统 [发明],本发明公开了一种煤矿回风巷道的巡检方法及装置、巡检系统。其中，该方法包括：通过图像采集设备采集回风巷道中顶板立柱的立柱图像和回风巷道内顶板支架对应底板的底板图像，同时通过音频采集设备采集顶板支架上方的音频信号；对音频信号进行分析，得到顶板支架上方的异响次数和异响持续时长；根据矸石密度、异响次数和异响持续时长确定顶板支架对应的顶板的异常指数；在确定变形指数小于顶板立柱的变形指数阈值时生成顶板立柱异常信号，同时在确定异常指数大于异常指数阈值时生成顶板异常信号，以对回风巷道进行巡检。本发明解决了相关技术中依赖于人工对煤矿回风巷道进行巡检，对巡检人员存在安全隐患的技术问题。
G10L15/16  ,语音唤醒方法、装置、电子设备及存储介质 [发明],本申请提供了一种语音唤醒方法、装置、电子设备及存储介质，方法包括：对接收的语音信息进行预处理以提取得到音频特征；将音频特征输入语音唤醒模型中进行计算；基于语音唤醒模型得到的每一帧音频特征的得分进行整句唤醒词检测并获得唤醒分数；基于语音唤醒模型得到的残差连接输出进行唤醒词中单个音节的识别，并获得语音信息的状态机跳转状态；根据唤醒分数和状态机跳转状态判断语音信息是否满足唤醒条件。本申请基于单神经网络模型进行二段式的唤醒词检测，满足唤醒率的同时抑制了明显的误唤醒。
H03G5/16  ,一种信号动态范围控制方法和装置 [发明],本发明实施例公开了一种信号动态范围控制方法和装置。信号动态范围控制方法包括：获取目标信号的静态变化信息；根据静态变化信息，确定目标信号的在不同分段的幅值信息和分段点的阈值信息；根据信号幅值信息和阈值信息，确定目标信号的运行参数；根据运行参数和目标信号的输入量，确定输入量的增益并对增益进行平滑处理，以确定目标信号的输出量。本发明实施例提供的信号动态范围控制方法和装置，能够提升信号动态范围控制效率并实现对信号的多段DRC。
G10L17/02  ,一种声纹识别方法、系统以及电子设备 [发明],本申请实施例提供了一种声纹识别方法、系统以及电子设备，涉及声纹识别技术领域。本申请通过增量数据训练原始声纹模型得到增量模型，通过目标匹配数据训练声纹模型得到全量模型，并将增量模型的神经网络层和全量模型的嵌入层进行合并得到组合模型，通过目标匹配数据对组合模型进行训练得到优化后的目标声纹模型，通过目标声纹模型来识别获取的待识别的目标声纹数据，使得模型对声纹的识别的准确度大大提高。
G10L15/00  ,基于英语多级语义交叉拟合的语义识别方法及系统 [发明],本发明公开了基于英语多级语义交叉拟合的语义识别方法及系统，涉及语音识别技术领域，包括：训练多级语义拟合模型；获取待识别英文语音数据；生成至少一个待匹配英文文本；获取与每一个待匹配英文文本一一对应的单词特征集合；通过多级语义拟合模型，分别计算待匹配英文文本对应的单词特征集合的语义拟合总指标；筛选出语义拟合总指标最大的单词特征集合，以该单词特征集合对应的待匹配英文文本作为待识别英文语音数据对应的语义识别文本。本发明的优点在于：采用语音和英文文本多重单词之间的语义交叉拟合的方式进行识别英文语音，极大的提高了其英文语音的识别精准度，进而可有效的满足多种应用环境下的英文语义识别需求。
G10L15/22  ,车辆语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种车辆语音交互方法，所述方法包括：根据第一大语言模型，更新第二大语言模型生成的原始训练数据，得到目标训练数据。根据目标训练数据训练预设模型得到语音交互模型。部署语音交互模型至车辆，使得车辆能根据语音交互模型，及获取到的当前语音请求完成语音交互。如此，在本申请中，可通过第二大语言模型更新原始训练数据，消除原始训练数据中的噪声数据，语音交互模型的可靠性得以保障。车辆可根据部署的语音交互模型，在离线状态下完成语音交互，车辆语音交互功能的使用场景拓宽。本申请通过大语言模型生成训练数据，在一定程度上改善训练数据由人工得到的情况出现，训练数据的获取难度降低，语音交互模型的训练难度降低。
G10L15/26  ,一种基于时序的会议音频分析处理方法及系统 [发明],本发明公开了一种基于时序的会议音频分析处理方法及系统，涉及会议管理技术领域，包括：获取会议音频；对语音信号进行降噪处理；对语音信号进行预处理；获取人声在频域上的第一特征范围，剔除至少一个基本正弦信号在第一特征范围外的部分；对至少一个修正正弦信号进行傅里叶逆变换，得到分离出的人声；对人声进行语音识别，产生文字，文字为多人产生的交错乱文；使用深度学习建立文字重排模型，文字重排模型将不同人产生的文字进行分类，得到至少一个文字时序集合。通过设置语音信号分离模块、语音信号识别模块和文字处理模块，将不同人产生的文字进行区分，并按照时间顺序进行汇总，得到至少一个文字时序集合。
G10L15/22  ,车辆语音交互方法、服务器及计算机可读存储介质 [发明],本申请公开一种车辆语音交互方法，所述方法包括：根据预先训练完成的大语言模型，生成目标训练数据，根据目标训练数据对预设模型进行训练，得到语音交互模块，部署语音交互模型至车辆，以使得车辆根据部署的语音交互模型和获取到的当前语音请求，完成语音交互。如此，在本申请中，服务器可通过大语言模型生成目标训练数据及语音交互模型，以使车辆可通过语音交互模型，结合当前语音请求以完成与用户的语音交互，从而能完成离线状态下的语音交互，车辆语音交互功能的使用场景拓宽。本申请通过大语言模型生成目标训练，使得样本生成和样本标注均需由人工完成的情况得以改善，语音交互模型的训练难度和训练成本在一定程度上得以降低。
G10L15/22  ,基于多头注意力机制和时延神经网络的语音识别方法 [发明],本发明涉及一种基于多头注意力机制和时延神经网络的语音识别方法，属于语音识别技术领域。本发明针对已有低资源语音识别模型单一，长序列上下文依赖捕获能力差、局部特征提取能力不足的问题。本发明将通过对比学习、时延神经网络等方法提高自监督低资源语音识别模型特征提取能力。针对目标域标注数据稀缺的情景，传统的低资源语音识别模型由于训练数据和测试数据的不匹配的影响，通常难以在高维潜在空间中找到更加理想的片段语音到字元的维特比对齐，最终导致了模型的健壮性不理想。本研究拟定通过数据增强的方法对未标注数据进行理想分布拓展，降低了未标注数据的概念偏移量，加强了未标注数据的可靠性。
G10L21/0332  ,基于固定延迟值和可调幅度的波束形成装置及听力装置 [发明],本申请实施例提供的一种基于固定延迟值和可调幅度的波束形成装置及听力装置，通过设置最大平坦滤波器基于固定延迟值对所述第一声音信号进行处理得到第一延迟信号，并基于固定延迟值对所述第二声音信号进行处理得到第二延迟信号，并通过第一减法器和第二减法器来进行差分处理，然后通过幅度调节器基于幅度调节系数对所述第二差分信号进行幅度调节得到调节信号，最后通过第三减法器将第一差分信号减去所述调节信号，得到输出信号，能够实现以较小的计算量完成声音信号的降噪处理。
H05K5/02  ,一种基于鸣声监测技术的两栖动物物种种群分布信息采集装置 [发明],本发明公开了一种基于鸣声监测技术的两栖动物物种种群分布信息采集装置，包括：鸣声采集模块，用于采集鸣声数据；其中，所述鸣声采集模块包括：采集组件，包括外壁设有散热孔的外壳；以及，防潮组件一，包括设于外壳内且与散热孔对应的内盒，所述内盒内填充有活性炭颗粒，所述内盒的外壁均匀开设有直径大于活性炭颗粒粒径的通孔。本发明通过鸣声采集模块采集鸣声数据时，鸣声采集模块中外壳内的电器件通过防潮组件一提供防潮保护，在外界的潮湿空气进入外壳内时，通过防潮组件一可进行吸收，以防止外壳内的电器件受潮损坏，以保证鸣声采集模块稳定的进行工作。
A63F13/54  ,游戏中虚拟车辆的音效处理方法、装置、设备及介质 [发明],本发明实施例提供了游戏中虚拟车辆的音效处理方法、装置、设备及介质，所述方法包括：包括：获取对车辆的声音进行采集得到的第一音频数据；对所述第一音频数据进行粒子切分处理，得到多个循环音频片段，并将所述多个循环音频片段重新组合合成，得到第二音频数据；建立所述第二音频数据与游戏中虚拟车辆的转速区间的映射关系，以在游戏中虚拟车辆处于所述转速区间的情况下，调用所述第二音频数据进行播放。通过本发明实施例，结合粒子合成技术，将实体车辆的声音转换为游戏中虚拟车辆的音效，能够体现不同车辆的特点，车辆音效具有更高的辨识度，提升了游戏中虚拟车辆音效的多样性和真实性。
G06F16/35  ,一种基于多渠道聚合的意图分类方法、装置、设备及介质 [发明],本发明涉及人工智能技术领域，尤其涉及一种基于多渠道聚合的意图分类方法、装置、设备及介质。获取待推荐对象所在的N个推荐渠道，确定推荐渠道记录的待推荐对象的内容信息，对内容信息进行关键词提取，得到推荐渠道的关键词，从预设的意图类别中选取与关键词匹配的匹配意图类别集，将N个匹配意图类别集中的匹配意图类别进行聚合处理，得到意图聚合结果，对意图聚合结果中的匹配意图类别进行评分处理，得到每个匹配意图类别中的评分结果，根据评分结果，确定待推荐对象的目标意图类别。先提取待推荐用户在单推荐渠道中的意图类别，再将多推荐渠道中的意图类别进行聚合处理，根据聚合后的结果再次进行意图挖掘分类，提高了意图分类的精度。
G10L21/0208  ,一种模型训练、鸟声降噪方法、装置、电子设备及介质 [发明],本发明公开了一种模型训练、鸟声降噪方法、装置、电子设备及介质，方法包括：获取干净鸟声数据集；对干净鸟声数据集进行加噪处理，得到带噪鸟声数据集；配置鸟声降噪网络和音频分类损失网络；将第一训练样本输入鸟声降噪网络得到降噪鸟声；依次将降噪鸟声和第二训练样本输入不同的音频分类损失网络，获得两个激活特征；根据激活特征得到损失值，根据损失值对鸟声降噪网络的参数进行调整；更新第一训练样本和第二训练样本，然后返回将第一训练样本输入鸟声降噪网络得到降噪鸟声这一步骤，直至满足预设训练条件，得到训练完成的鸟声降噪网络。本发明的鸟声降噪网络在带噪鸟类声音数据集上显示出优异的降噪性能，可广泛应用于数据处理技术领域。
G10L15/22  ,基于语音的智能座舱与移动终端互联的社交软件交互方法与系统 [发明],本发明涉及一种基于语音的智能座舱与移动终端互联的社交软件交互方法与系统，属于车载语音交互技术领域。该系统包括：座舱中控端包括语音与文本转换模块、语音接收模块、语音播报模块、手机互联协议模块和人机交互模块；移动终端包括社交软件交互管理模块、车机互联协议模块和语音识别模块；社交软件交互管理模块负责执行座舱端的语音命令，监听社交软件的消息，获得接收消息文本或语音；移动终端将接收消息文本或语音从移动终端发送至座舱端，在座舱端通过语音交互软件将文本与语音分别处理后通过扬声器播报，或者通过人机交互模块实现对车机的功能操作。本发明降低了应用的不断增加对座舱端硬件与软件的要求，降低了安全事故发生的可能性。
G10L15/16  ,用于泊位视频采集的语音互动系统 [发明],本申请涉及语音互动领域，其具体地公开了一种用于泊位视频采集的语音互动系统，其首先采集驾驶员的语音输入以及汽车在停泊位的行为状态监控视频，接着提取出驾驶员的语音控制指令特征以及汽车的相关停车行为特征，然后将所述驾驶员的语音控制指令特征以及所述汽车的相关停车行为特征进行融合以得到汽车调整指令相关特征，最后将所述汽车调整指令相关特征进行优化后输入到生成器中以生成语音信号，所述语音信号用来指导驾驶员该如何操作以使停车的位置更加合适。这样，给停车提供了更多的信息辅助，使得停车过程更加方便和准确。
G10L15/06  ,基于数据集难度的说话人嵌入层模型训练方法、介质和设备 [发明],本发明公开基于数据集难度的说话人嵌入层模型训练方法、介质和设备，利用基于数据集难度的损失函数进行训练，获得对语音和平凡发音识别准确率高的训练后说话人嵌入层模型，也就是完成训练的说话人嵌入层模型；采集说话人的注册音频并进行频谱特征提取，所述注册音频的频谱通过所述训练后说话人嵌入层模型，获得注册说话人嵌入层；获得实时音频数据，确认其是否为注册说话人的音频。本说话人嵌入层模型训练方法是利用基于数据集难度的损失函数进行训练的，每次训练后均能够更新语音和平凡发音数据集参与训练的权重，有利于提升说话人嵌入层模型在语音和平凡发音数据集上的准确率。
G10L15/22  ,一种电子设备的语音唤醒方法、电子设备及存储介质 [发明],本公开提供了一种语音唤醒方法、电子设备及存储介质，该方法包括：对接收到的语音数据中的第一语音帧依次进行语音唤醒识别，直至识别到置信度满足唤醒条件的第一语音帧后，唤醒所述电子设备；其中，相邻的两个第一语音帧之间相差的第二语音帧的帧数是根据所述相邻的两个第一语音帧中前语音帧的置信度确定的，且，所述相差的第二语音帧的帧数随所述前语音帧的置信度的增大而减小或不变。
G10L13/08  ,一种支持智能处理的语音合成方法及系统 [发明],本发明公开了一种支持智能处理的语音合成方法及系统，涉及智能语音处理技术领域，包括对输入文本集中管理配置属性并转化为语音资源；进行文本预处理与分词，构建文本向量模型；进行信息过滤与权重调整，调整后输入复合模型生成数值型向量进行语音合成。本发明提供的支持智能处理的语音合成方法本发明在通过信息过滤函数和权重分配机制，确保每个词语在语音合成中的重要性得到合理体现，充分考虑词语在特定上下文中的重要性和适用性。根据文本内容的特性，灵活选择不同的语音合成引擎，以适应不同类型的文本。采用jieba分词工具对文本进行预处理，构建文本向量模型，更有效地理解和处理文本数据。
G10L17/26  ,一种基于云边协同控制的鸟鸣声智能监测系统 [发明],本发明公开了一种基于云边协同控制的鸟鸣声智能监测系统，涉及语音识别技术领域。本发明与之前的鸟鸣声处理系统相比，改进了缺少对鸟鸣声信息的有效利用；边缘侧识别结果并不充分可靠；鸟鸣声采集缺乏针对性；未能构建可持续优化的智能识别系统的问题，通过以融合增量学习的云端训练+边缘推理的智能边缘数据分析技术为核心，以智能移动设备为边缘设备基础，以移动通信技术为信息通道，连接高性能的云端智能服务器，形成具有持续学习能力的云边协同鸟鸣声监测模式。实现野外鸟鸣声采集的远程上传和自动识别，构建开放、精准识别和持续进化的云边协同鸟类鸣声监测系统。
G08B13/16  ,分布式光纤声波信号识别方法、装置、电子设备及存储介质 [发明],本发明涉及一种分布式光纤声波信号识别方法、装置、电子设备及存储介质，其方法包括：获取原始光纤振动信号，对所述原始光纤振动信号在空间上进行分离，得到每一激励源对应的光纤振动信号；获取每一激励源产生的第一光纤声波信号，并基于每一激励源对应的光纤振动信号对同一激励源产生的第一光纤声波信号进行增强处理，得到第二光纤声波信号；将所述第二光纤声波信号输入到训练完备的声音识别模型中，输出监测模式识别结果。本发明能够根据实际场景需求，有效区分具有破坏性和无破坏性的外界激励源，优化光纤传感振动探测系统的预警效果。
A61B5/021  ,一种利用耳内麦克风采集骨传导心音的血压监测方法 [发明],一种利用耳内麦克风采集骨传导心音的血压监测方法，属于移动计算应用技术领域。采用对数梅尔频谱图及谱反演算法，进行噪声消除，提高抗环境的干扰能力；基于香农能量峰值检测算法和能量熵比端点检测算法，分别提取心音的时域和频域特征，提高特征提取的准确性；使用主成分分析降低特征的维度，以获得与血压相关的主要特征，降低网络训练的负担；基于DNR建立血压与心音特征之间的映射关系，实现血压检测。本发明适用于医疗、健康检测及移动计算应用技术领域，使用耳机在耳道内采集的骨传导心音进行血压测量，能够降低血压测量的成本、提高检测的舒适性和便捷性，并支持长期监测，适合广泛采用。
H04N21/2368  ,基于音视频通话的远程调试方法、终端设备及存储介质 [发明],本发明公开了一种基于音视频通话的远程调试方法、终端设备及存储介质，所述方法包括：建立音视频通话，根据所述音视频通话获取音视频通路，并将所述音视频通路复用为系统通路，所述系统通路包括系统音频通路和系统摄像头通路；根据所述系统音频通路获取音频数据，并分析所述音频数据中的调试话术，根据所述调试话术确定目标调试模式，所述目标调试模式包括进入调试模式和退出调试模式；当所述目标调试模式为所述进入调试模式时，获取目标调试意图，根据所述目标调试意图执行远程调试。本发明可基于安装的音视频通话应用来建立通信链路，通过复用音视频通路，能在音视频应用时以语音视频通话的方式进行实时调试，优化了远程调试方法的操作步骤。
G10L15/26  ,音频识别方法、装置、电子设备和存储介质 [发明],本申请提供了应用于智能可穿戴设备的音频识别方法、装置、电子设备、存储介质和计算机程序产品，依据本申请实施例，先执行语音端点检测，获取包括完整语句的待识别的音频数据，再使用语音模型识别待识别的音频数据对应的文本内容，最后使用命令词库匹配文本内容，确定对应的目标命令词，在匹配到命令词库中多个命令词的情况下，目标命令词为匹配到的多个命令词中最长的命令词。上述音频识别的方法实现了对包括完整语句的音频数据的一次识别、精准匹配，提高了音频识别结果的准确性，节省了算力。
G10L17/02  ,语音信息的处理方法及装置、非易失性存储介质 [发明],本申请公开了一种语音信息的处理方法及装置、非易失性存储介质。其中，该方法包括：接收语音流，其中，语音流包括：目标对象发送的语音信息、非目标对象发送的语音信息，非目标对象与目标对象在同一通话场景；确定语音流中每个语音帧的评价指标，并在语音流中选择评价指标高于预设分值的语音帧，得到语音帧集合，评价指标用于确定每个语音帧所属的语音信息的类型，预设分值为目标对象的输入值，不同类型的语音帧对应不同的预设分值；在语音帧集合中截取有效信息，并根据有效信息确定有效识别结果，其中，有效识别结果为语义连续的文本信息。本申请解决了由于通话环境中存在噪声和非有效人声造成的语音识别准确率低的技术问题。
G06F18/25  ,一种基于智能手表的多模态交互系统及方法 [发明],本申请实施例中提供了一种基于智能手表的多模态交互方法，包括：智能手表获取的图像信息和/或语音信息输入多模态模型；基于所述多模态模型，对所述语音信息和所述图像信息进行分析识别处理，确定用户需求；依据所述用户需求，基于所述多模态模型的输出，使用麦克风和摄像头分别获取用于语音交互的语音信息和用于视频交互的图像信息，以及通过显示屏和扬声器分别输出图像和音频。通过将智能手表与多模态模型算法相结合，通过多模态模型算法将图像和声音数据相结合，提供相关信息和答案，用户可以通过简单的语音命令获取复杂的信息，这提供了更便捷的使用体验。
G06T17/00  ,元宇宙场景的构建方法、系统、服务器及存储介质 [发明],本发明提供一种元宇宙场景的构建方法、系统、服务器及存储介质，该方法包括：根据用户上传的多张多角度实景场景图片，构建实景场景对应的元宇宙场景的三维空间模型；接收用户上传的原声文件和录制文件，所述录制文件为用户在所述实景场景播放所述原声文件时录制得到的文件；将所述原声文件在所述三维空间模型内进行声音渲染处理；对所述录制文件和渲染后的音频文件进行频谱分析并比对，根据比对结果判断构建的所述三维空间模型是否准确。本发明中，在还原现实的前提下大幅降低对UI设计师的依赖，并且创建元宇宙场景的三维空间模型之后，根据音频文件进行三维空间模型的声音空间校验，保证了构建的三维空间模型的准确性。
G10L17/26  ,融入自注意力机制的CRNN珍稀动物识别与定位方法 [发明],本发明涉及动物识别技术领域，尤其涉及一种融入自注意力机制的CRNN珍稀动物识别与定位方法，通过将功率归一化倒谱系数和线性预测倒谱系数融合，得到混合特征，与传统的音频特征梅尔倒谱系数、伽马通频率倒谱系数相比，具有更好的鲁棒性、抗噪性，大大提高了在噪声及混响环境中的识别准确度，且不需要过多的计算，本发明通过残差网络来作为系统的识别和定位网络，可以避免梯度爆炸和梯度消失，同时可以训练更深的网络，通过融入自注意力机制层，弥补了卷积不能处理序列数据时捕捉长程依赖关系的缺点，提高网络的识别和定位精度。
G10L13/027  ,一种基于矫正流模型的高质量语音合成方法 [发明],本申请提供了一种基于矫正流模型的高质量语音合成方法，基于RK45 ODE Solver进行采样时能够得到较好的音频生成质量，和大多数现存的基于扩散的语音合成模型相比，在使用Euler ODE Solver进行一步采样时也能够得到很好的音频生成质量，而且整个训练过程是简单有效的，也不需要预先训练一个教师模型得到更好的音频质量，显著提高了真实场景中的高质量语音合成的可用性。
G10L25/60  ,音频质量确定模型的训练方法、装置、设备以及存储介质 [发明],本申请关于一种音频质量确定模型的训练方法、装置、设备以及存储介质，属于音频技术领域。该方法中，以样本音频的平均质量分、质量分分布和类型分布作为样本音频的标签，进而基于该标签对音频质量确定模型进行有监督的多任务训练，由于质量分分布为样本音频为不同分档的概率，将质量分分布作为标签的一部分能够使得模型学习到不同的对象对音频的评价尺度，进而基于训练好的模型预测出的质量分能够更加精准地反映人对音频的主观听感，并且由于类型分布为样本音频为不同音频类型的概率，将类型分布作为标签的一部分能够使得模型同时学习到音频分类知识，从而使得训练后的模型能够满足多种场景下不同类型的音频的质量评价，并且无需参考音频。
G10L25/51  ,异音识别方法、装置、电子设备和存储介质 [发明],本发明涉及故障识别技术领域，提供一种异音识别方法、装置、电子设备和存储介质。该方法包括：将采集的声音样本划分为训练集和测试集；其中，训练集为正样本的集合，测试集为正样本和负样本的集合，正样本为声音样本中的正常音样本，负样本为声音样本中的异常音样本；根据声音信号的强度和声音信号的频率中的至少一个，识别出测试集中的第一负样本；从测试集中剔除第一负样本，得到目标测试集；将目标测试集输入至异音识别模型，识别出目标测试集中的第二负样本。本发明能够在仅依赖正样本对模型训练的同时保证模型的识别准确性，从而提高压缩机、电机异音识别的准确性，进而提高通过异音识别压缩机、电机故障的准确性。
G10L15/02  ,基于方言的业务辅助处理方法、装置及电子设备 [发明],本申请公开了一种基于方言的业务辅助处理方法、装置及电子设备。涉及人工智能领域，该方法包括：获取目标客户的方言语音，从方言语音中提取目标语音特征；确定方言语音中出现预设用语的次数，得到目标次数，判断目标次数是否小于次数阈值，其中，预设用语为表征目标客户的负面情绪的用语；在目标次数小于次数阈值的情况下，将目标语音特征输入目标模型，得到语义信息，其中，目标模型由多组第一训练样本训练得到，每组第一训练样本包括历史语音特征和历史语义信息；通过语义信息确定目标客户需要办理的业务类型，调用业务类型对应的应用程序对目标客户提供服务。通过本申请，解决了相关技术中由于方言难以理解导致业务处理效率低的问题。
G06M1/272  ,一种井下钻杆计数方法、监测设备及存储介质 [发明],一种井下钻杆计数方法、监测设备及存储介质，涉及智慧煤矿建设领域，该方法包括：采集钻机作业时的声音音频；提取声音音频中的作业声音，并设置对应的声音模板；将视觉识别的动作模板与声音模板进行匹配，确定多个声音模板对应的多个作业阶段；基于多个作业阶段的声音数据进行训练，得到声音钻杆计数模型；在视觉计数模式出现故障时，确定当前钻机作业阶段；基于当前钻机作业阶段，使用声音钻杆计数模型进行钻杆计数。实施该方法，通过用声音辅助计数，对有规律的声音进行采集和分析，直接进行当前钻杆计数，在使用视觉计数的监测设备视野丢失时，能提供重要的备份计数方式，确保瓦斯抽放工作的正常进行。
H04L45/12  ,一种低延时网络音频传输方法及系统 [发明],本发明提供了一种低延时网络音频传输方法及系统，涉及数据传输技术领域，包括：通过对获取的传输音频进行频率分析，获得传输音频的音频频率，基于音频频率获得传输音频的最佳采样频率；基于最佳采样频率获得所有采样信息，基于所有采样信息获得传输音频的振幅集合；基于振幅集合获得传输音频在所有传输链路上的传输值；基于传输音频在所有传输链路的传输值与传输音频的振幅集合构建传输矩阵，基于传输矩阵确定传输音频的最优传输链路；基于传输音频的最优传输链路对传输音频进行网络音频传输。本发明实现了在音频传输过程中通过分析传输矩阵来对多条传输链路进行分析，并在多条传输链路选出传输通道拥塞最少、时延最小的传输链路。
G16H50/20  ,一种智能语音医疗系统 [发明],本发明公开了一种智能语音医疗系统，涉及医疗系统领域，包括交互设备、执行设备和存储设备；交互设备，与执行设备和存储设备连接，用于非接触式语音信号获取，并将语音信号发送至执行设备，接收存储设备的最终结果并显示，执行设备，用于接收语音信号，并将语音信号转成编码信号，将编码信号发送至存储设备，存储设备，用于存储数据并构建医疗语音模型，将最终结果发送至交互设备，本发明的有益效果是：交互设备中的信息识别模块登录至病患个人信息，使得后续录入的内容能够和对应患者的信息连通，进入语音录入模块，选择合适的单元，将不同场景下的语音信息录入在适当的位置，便于后续的翻阅查找，减轻了医生的工作强度，提高工作效率与质量。
G06F18/25  ,一种针对生猪的健康状况评估系统 [发明],本发明提供了一种针对生猪的健康状况评估系统。包括数据接收模块，用于接收需要判断健康状况的生猪行为、声音和生理数据；异常判断模块，用于对接收的生猪行为、声音和生理数据进行处理，输出相应异常模糊度，包括对前一天饮食情况的判断、日常行为的异常隶属度判断、异常声音的隶属度判断以及体温异常隶属度判断；融合判定模块，利用Choquet模糊积分将多源多时段的异常隶属度进行融合，评估出生猪的异常情况。本模型通过行为、声音、生理三个方面对生猪进行评估，能较为准确并且全面地评估出生猪的健康状况，完成生猪自然条件下的健康评估。
H04M1/72433  ,可盲用人工智能手机 [发明],可盲用人工智能手机，手机具有切换到盲用的语音模式；其中语音识别是由网络的人工智能完成语音识别，手机根据语音识别的内容，能进入相应的功能及APP菜单，产生等效于触摸点击的效果，能发出相应的消息及拨打相应的电话或语音。
G10L21/0216  ,一种对于电力二次电缆寻径的降噪方法及系统 [发明],本发明提供一种对于电力二次电缆寻径的降噪方法及系统，包括，采集电力二次电缆寻径对应的信号并识别对应的小波系数；将各路小波系数串联组成一维小波系数矢量，将一维小波系数矢量作为两路输入信号进行数据分解为多个独立信号；将多个独立信号中峰度大于预设峰度阈值的信号作为主声音信号；对所述主声音信号进行小波重构和残留噪声抑制得到最终的主声音信号。本发明采用自适应综合算法进行信号判别与阀值消噪抑噪的技术应用，实现了电力二次电缆寻径自适应降噪算法与存储介质，完成满足电力二次电缆寻径的技术实现和实现准确性的方法。
G10L21/0216  ,一种基于房间冲激响应估计模型的回声消除方法 [发明],本发明公开了一种基于房间冲激响应估计模型的回声消除方法，属于声学信号处理技术领域，包括以下步骤：步骤S1.搭建房间冲激响应估计模型；步骤S2.训练、评估、验证房间冲激响应估计模型；步骤S3.双讲检测；步骤S4.根据检测结果可以得出无语音、单讲回声语音、双讲回声语音，根据不同的路径对其进行回声消除。本发明主要针对网络音频通话、视频会议环境下的回声问题进行处理，能够对回声问题进行削弱和消除，提高语音视频通话质量，适用范围广。
G10L17/02  ,一种基于自动声纹鉴定的声纹识别方法和系统 [发明],本发明公开了一种基于自动声纹鉴定的声纹识别方法，包括以下步骤：S1，获取大量不同背景、不同人声的语音分割为特定长度的语音段，并将大量的语音段组成数据集，且数据集中每一个样本包括语音段、元音声纹、清辅音声纹、浊辅音声纹四个指标数据；S2，构建元辅音声纹识别模型；S3，用户需要识别的用户声纹的目标语音，将语音标准化后输入所述元辅音声纹识别模中，得到元音声纹、清辅音声纹、浊辅音声纹的结果。本发明可通过元辅音声纹识别模型自动鉴定出所有元音声纹、清辅音声纹、浊辅音声纹，然后再根据元音声纹、清辅音声纹、浊辅音声纹识别出用户可发出所有字词的发音声纹，提高了声纹识别结果的准确性。
H04L12/28  ,一种电子设备之间信息交换方法及其系统 [发明],本发明涉及信息交换技术领域，具体涉及一种电子设备之间信息交换方法及其系统，本发明的信息交换系统在使用时，首先可以通过任一个电子设备完成对指令信息的输入操作，代表系统内的每个电子设备均可以作为系统的主机使用，有效的解决了现有技术必须指定主机交换信息输入的操作，提高信息交换系统使用的便捷性；并且本发明通过采用以任一电子设备为中心的、范围内信息发送和接收的信息传输方法，实现对信息的小范围不断扩大的传输形式实现信息的传递，可以有效的避免在大范围内因为无线传输强度原因导致的信息交换限制的弊端，提高信息交换的稳定性。
G10L15/22  ,语音唤醒模型的训练方法、装置、设备及存储介质 [发明],本申请公开了一种语音唤醒模型的训练方法、装置、电子设备及存储介质，该方法包括：接收上传的唤醒词文本和场景提示；利用生成式大模型对唤醒词文本和场景提示进行处理，得到场景提示对应的训练数据，其中，训练数据包括训练样本和测试样本；根据训练样本对通用唤醒模型进行训练，得到语音唤醒模型，并根据测试样本对语音唤醒模型进行测试；在根据测试样本确定语音唤醒模型测试通过的情况下，将语音唤醒模型下发至目标终端进行配置。实现了在训练过程中，以通用唤醒模型为基础进行训练，可以有效的提高训练效率，并且将场景信息作为训练基础，提高语音唤醒模型对场景的适应性，进而提高了唤醒效果。
G10L15/06  ,音频信号处理模型的训练方法、装置、电子设备及介质 [发明],本公开提供了一种音频信号处理模型的训练方法、装置、电子设备及介质，属于计算机技术领域。该方法包括：获取样本语音信号、样本噪声信号以及样本回声信号；基于样本语音信号、样本噪声信号、样本回声信号以及掩蔽矩阵，确定音频信号处理模型的训练目标值；基于训练目标值和音频信号处理模型的输出信号，更新音频信号处理模型的参数。上述技术方案通过根据样本信号确定是否处在双讲场景下，从而确定在训练目标值中是否保留部分回声。通过根据上述训练目标值对音频信号处理模型进行训练，从而使得在双讲场景下使用上述音频信号处理模型时，可以在尽量抑制回声的前提下，减少了对人声的剪切量，从而提高了人声的音质。
A47B17/02  ,一种智能学习桌 [发明],本发明提出了一种智能学习桌，包括框体、与框体连接的立柱、连接立柱的升降电机以及桌面装置，框体包括底板以及围绕该底板向上延伸的边框，桌面装置包括固定桌面、旋转桌面以及推杆电机，旋转桌面前端与边框前端通过枢转轴连接，旋转桌面下端与框体的底板之间设有用于驱动旋转桌面绕枢转轴转动的推杆电机，固定桌面设于旋转桌面一侧且与边框的上端固定连接；还包括控制终端APP，输入所需要的旋转桌面高度和旋转角度指令信息；及智能控制模块，设置在框体的空腔内，包括微处理器单元和连接微处理器单元的通讯单元，通讯单元接收控制终端APP发送的指令信息，微处理器单元将通讯单元接收的指令信息进行数据处理，并向升降电机和推杆电机输出控制信息。
G06V20/40  ,一种自动可视化智慧大数据会议管理方法及系统 [发明],本发明公开了一种自动可视化智慧大数据会议管理方法及系统，属于智能会议管理技术领域，方法包括：S1：获取会议信息；S2：启用视频模组，识别会场的参会人员，在所述参会人员为预设参会人员的情况下，开启会议；S3：所述视频模组获取目标参会人员的瞳孔图像和目标词汇，在所述瞳孔图像和所述目标词汇满足预设条件的情况下，接收目标参会人员的语音，通过语音识别，形成会议记录。本方案可以解决当前会议管理工作繁重且处于无系统流程的状态，经常会有参会者忘记会议、因为会议流程的复杂，导致难以正常进行会议、难以完整的记录会议笔记的技术问题。
G10L25/51  ,一种音频处理方法、系统和电子设备 [发明],本申请公开了一种音频处理方法、系统和电子设备，其中，音频处理方法通过获取待检测音频信号；对待检测音频信号进行特征提取，得到特征音频值；当特征音频值大于特征阈值时，则将待检测音频信号进行滤波处理，以减少待检测音频信号中的异常信号，进而有效缓解电子设备播放的音频信号发生异常的问题。
G06Q10/10  ,用于数据中心的任务处理方法及装置 [发明],本公开涉及一种用于数据中心的任务处理方法及装置。其中，任务处理方法包括：获取用于指示目标任务的语音命令；根据所述语音命令确定所述目标任务的任务类别；根据所述任务类别，基于所述语音命令提取一个或多个物理属性参数，其中，所述一个或多个物理属性参数用于确定所述数据中心中的目标设备；以及根据所述一个或多个物理属性参数生成用于指示所述目标任务的执行情况的反馈信息。
G10K11/26  ,一种预警声波驱散器 [发明],本发明属于声波装置应用领域，具体是涉及一种预警声波驱散器，包含有数据采集与处理模块、声音识别与分类模块、预警声波生成模块、声波驱散模块、处理器模块以及供电模块，上述模块通过所述处理器模块控制并通过供电模块电性相连；利用数据处理技术对声波数据进行去噪、滤波和放大，然后利用使用MFCC对声波数据特征提取并且使用长短记忆网络（LSTM）深度学习模型模式识别和分类，从而实现对不同预警信号的准确分类，并使用带有功率放大器作为换能器驱动电路的声波发射器发出信号，从而实现预警功能，本发明能够进行声音识别和分类，应对复杂多变的预警信号。
G10L15/22  ,语音唤醒方法、语音唤醒装置、可穿戴设备及存储介质 [发明],本公开提供了一种语音唤醒方法、语音唤醒装置、可穿戴设备和存储介质。该语音唤醒方法包括：响应于检测到唤醒词，对接收到的音频数据进行语音活动检测；在音频数据包括检测结果为存在语音的第一音频数据的情况下，继续对第一音频数据之后的第二音频数据进行语音活动检测；在第二音频数据的检测结果为存在语音的情况下，执行连说唤醒的操作。通过对音频数据进行多次语音活动检测，来提高确定语音是否存在的准确性，从而解决现有技术中连说唤醒过程中语音指令识别不准确的问题。
G10L17/06  ,一种基于主成分分析的声纹检测方法及系统 [发明],本发明提出了一种基于主成分分析的声纹检测方法及系统，通过将声纹时域信号进行傅里叶变换，得到频域信号，根据频域信号的均方差值确定局部相似块，作为分析样本，对分析样本进行主成分分析提取主成分特征，根据所提取的主成分特征得到声纹检测的结果。本发明通过确定局部相似块的方式，针对性利用声纹信号中的特征数据，提高声纹检测的准确性。
G10L15/22  ,语音交互方法、装置、芯片、电子设备及介质 [发明],本申请提供一种语音交互方法、装置、芯片、电子设备及介质，该方法包括：响应于对电子设备的语音助手的激活请求，初始化语音助手；在初始化语音助手之后，显示语音助手处于第一状态时的第一页面，第一页面包括对应第一状态的第一动画；其中，第一状态为语音聆听状态、语音识别结果显示状态、语音交互结果显示状态、或者介于语音识别结果显示状态和语音交互结果显示状态之间的目标状态。本申请能够支持用户与电子设备间的语音交互，且通过显示页面动画可提升用户的语音交互体验。
G10L15/18  ,演示文档页面的控制方法及装置、存储介质和电子设备 [发明],本申请公开了一种演示文档页面的控制方法及装置、存储介质和电子设备，涉及人工智能领域、金融科技领域及其他相关技术领域，该方法包括：在目标空间内展示目标演示文档，并获取目标空间内的初始语音数据和图像数据，其中，目标空间内存在N个第一对象；对初始语音数据进行语义分析，得到N个第一对象中的M个第二对象对应的第一语义信息，其中，第二对象为目标空间内产生初始语音数据的对象；依据图像数据，计算N个第一对象视线的焦点信息，并依据第一语义信息和焦点信息，对目标演示文档的页面进行控制。通过本申请，解决了相关技术中采用人工的方式对演示文档进行换页操作，导致对演示文档进行页面切换的准确性比较低的问题。
G10L17/26  ,一种利用声波传感器的智能安防系统及其事件识别方法 [发明],"本发明公开了一种利用声波传感器的智能安防系统及其事件识别方法,包括以下步骤：在不同危险监控位置的汇合节点处接入声波传感器，监测危险监控点物体声波反馈信号，并接入声波算法与处理平台；声波算法与处理平台采集物体原始声波；声波算法与处理平台将信息汇集后通过统一数据加密后上传至边缘计算网关；上传的信息汇总至声波算法与处理平台进行危险物大小以及危险物危害评估；声波算法与处理平台进行危险物大小以及危险物危害评估包括危险物停留时间分析评估、危险物危害性等级评估以及给出维护与控制方案，本发明实现危险监控点危险物的种类性能监测，能有效的拓展声波算法与处理在危险监控点识别方面的应用。"
G06F30/27  ,一种基于近场高精度模拟的远场噪声预测方法 [发明],一种基于近场高精度模拟的远场噪声预测方法，包括以下步骤：获取数据集；将物理域声场数据以及传播方程转换至计算域；训练和测试机器学习模型；给定近场高精度模拟数据预测远场噪声。本发明解决了现有的利用卷积机器学习模型学习声传播方程时，因对网格的均匀性有着强制要求，无法处理非均匀网格的数据输入，而真实的网格通常是非均匀的，其模型不能处理非均匀网格数据，导致只能利用均匀网格来作为网络的输入，难以实用的问题。
G10L25/06  ,管道气体泄漏声音诊断方法、系统、设备和介质 [发明],本发明公开了一种管道气体泄漏声音诊断方法、系统、设备和介质，涉及石化安全监测技术领域，包括：获取待诊断管道的检测声音信号；对检测声音信号进行低频滤波处理和小波包分析，得到多个分层声信号；对每个分层声信号进行自相关分析，得到每个分层声信号对应的自相关序列；分别计算每个自相关序列在原点附近的能量比值；确定除去第一个分层声信号之外的分层声信号对应的自相关序列的原点附近的能量比值的最大值与最大偏差；基于最大值和最大偏差，判断待诊断管道是否存在气体泄露。本发明缓解了现有技术中存在的检测效率低、检测精度低和检测成本高的技术问题。
G06Q40/02  ,风险账户识别方法、装置、电子设备和存储介质 [发明],本申请提供了一种风险账户识别方法、装置、电子设备和存储介质，其中方法包括：获取待识别账户的账户名称在当前语种下的字符表示结果；基于所述当前语种对应的单变音位编码规则，对所述字符表示结果进行编码，得到所述账户名称对应的语音代码；将所述账户名称对应的语音代码与各个风险账户名称对应的语音代码进行匹配；基于语音代码匹配结果，确定所述待识别账户的风险识别结果；所述当前语种对应的单变音位编码规则是基于所述当前语种中各个字母在不同字符表示结果中对应的音位变体确定的。本申请提供的方法和装置，提高了风险账户的识别准确率。
G01M99/00  ,一种工业设备在线监测系统 [发明],本发明涉及工业设备监测领域，公开了一种工业设备在线监测系统，包括：传感器，用于实时采集工业设备的运行参数以及采集工业设备的运行声音，本发明中，通过采用多种传感器实时采集工业设备的运行参数和声音，系统能够全面掌握设备的运行状态，并通过对采集的音频数据进行频谱、功率谱密度、倒频谱和时频分析，系统可以得到一系列特征参数，如频率、幅度、相位、频谱熵等，这些特征参数可以用于故障诊断和分类，同时为预测设备未来的运行状况提供数据支持，结合数据通信模块支持的多种通信协议和数据分析单元的高效处理能力，系统能够准确识别不同类型的故障声音，有助于及时发现设备的潜在问题，避免严重故障发生，降低设备维修成本。
G10L15/22  ,一种基于智能语音鼠标的控制方法及智能语音鼠标 [发明],本公开提供了一种基于智能语音鼠标的控制方法及智能语音鼠标，涉及语音识别技术领域，方法包括：执行语音数据采集结果的场景降噪，根据降噪结果生成第一语音识别结果；对降噪结果进行语义识别，通过语义识别结果对第一语音识别结果校正，生成第二语音识别结果；进行新增更改数据接收；将带有稳定标识的语音数据对新增更改数据匹配，基于匹配结果完成非稳定标识部分的第二语音识别结果修正，生成第三语音识别结果；将第三语音识别结果和关联搜索结果可视化显示。能够解决现有智能语音鼠标存在语音识别准确率较低导致鼠标控制准确性较低的技术问题，可以提高鼠标语音控制数据识别的准确率，从而提高智能语音鼠标的控制精准性和工作效率。
G10L25/51  ,基于声纹与红外特征融合的变压器故障诊断方法与系统 [发明],本发明公开了一种基于声纹与红外特征融合的变压器故障诊断方法与系统，属于变压器多传感器融合故障感知与诊断技术领域，方法包括：采集变压器运行过程中的声纹信号和红外图像；提取声纹信号的声纹特征以及三种不同尺度的红外图像特征；基于级联通道注意力和空间注意力机制将声纹特征分别与三种尺度的红外特征进行融合，获得三个尺度的融合特征；建立特征融合故障诊断模型，利用所述特征融合故障诊断模型对三种尺度的融合特征进行聚合，利用两个多层感知机构建检测和分割多任务网络，进行预测故障类型和位置。本发明将红外图像信息和声纹信息进行有机结合，提供了更加综合、准确的故障诊断结果，有效提高了复杂故障的诊断准确率。
G10L25/51  ,一种施工机械作业声纹信号的监测方法及系统 [发明],本发明提出了一种施工机械作业声纹信号的监测方法及系统，根据时域特征中声纹信号幅度/频率特征中声纹频率组成与声纹时域周期/声纹频率周期的关系，确定施工是否开始或结束；根据时域特征中声纹时域周期与频率特征中声纹频率周期的相似性，结合注意力机制，确定是否为异常噪声信号。充分利用了声纹信号中对机械施工影响大的特征信号进行机械施工的判断，提高对机械施工的监测的有效性。
G01S5/18  ,一种声源定位方法和装置 [发明],本发明公开了一种声源定位方法和装置，涉及信号处理技术领域。该方法的一具体实施方式包括：基于麦克风阵列获取声音信号；对声音信号进行预处理；基于经过预处理的声音信号，识别声音信号所属的目标声源类型；在多个与声源类型对应的定位算法中，确定目标声源类型对应的目标定位算法；对经过预处理的声音信号进行波束形成处理；基于经过波束形成处理的声音信号，采用目标定位算法得到声源的定位结果；确定是否满足循环终止条件，如果是，终止当前流程，否则，基于声源的定位结果计算导向矢量，基于导向矢量对声音信号进行波束形成处理，得到增强后的声音信号，基于增强后的声音信号执行对声音信号进行预处理。该实施方式能够提高声源定位精度。
G07C9/00  ,锁的身份认证识别系统及锁的身份认证识别方法 [发明],本发明公开锁的身份认证识别系统及锁的身份认证识别方法，所述系统包括：拾音模块用于采集第一预设范围内的声纹信息；图像采集模块用于采集第二预设范围内的图像信息；身份认证模块包括声纹识别单元和有形生理特征识别单元；当监测到声纹信息时常供电控制模块唤醒常断电控制模块，以常断电控制模块控制声纹识别单元开启声纹识别并在识别成功后控制锁控模块开锁；当未监测到声纹信息或者仅检测到图像信息且图像信息中存在人物图像时，常供电控制模块唤醒常断电控制模块；常断电控制模块控制有形生理特征识别单元开启有形生理特征识别，并在识别成功后控制锁控模块开锁。通过优先使用声纹识别后有形生理特征识别，提升锁的身份识别的速度和准确性。
G10L21/0224  ,音频信号处理方法、装置、电子设备及存储介质 [发明],本发明公开一种音频信号处理方法、装置、电子设备及计算机可读存储介质，所述音频信号处理方法包括以下步骤：获取第N帧的输入音频数据X(T＆lt;subgt;n＆lt;/subgt;)及第N+1帧的输入音频数据X(T＆lt;subgt;n+1＆lt;/subgt;)；使用第一淡入淡出函数对所述第N帧的输入音频数据X(T＆lt;subgt;n＆lt;/subgt;)进行处理获得第N帧的处理音频数据Y(T＆lt;subgt;n＆lt;/subgt;)；使用第二淡入淡出函数对所述第N帧的输入音频数据X(T＆lt;subgt;n+1＆lt;/subgt;)进行处理获得第N+1帧的处理音频数据Y(T＆lt;subgt;n+1＆lt;/subgt;)；在第N帧的音频播放时段，对所述第N帧的处理音频数据Y(T＆lt;subgt;n＆lt;/subgt;)进行淡出以及对所述第N帧的输入音频数据X(T＆lt;subgt;n＆lt;/subgt;)进行淡入；在第N+1帧的音频播放时段，对所述第N+1帧的处理音频数据Y(T＆lt;subgt;n+1＆lt;/subgt;)进行淡入以及对所述第N+1帧的输入音频数据X(T＆lt;subgt;n+1＆lt;/subgt;)进行淡出。
G06F16/332  ,信息处理方法及装置、存储介质和电子设备 [发明],本申请公开了一种信息处理方法及装置、存储介质和电子设备，涉及人工智能技术领域、金融科技领域或其他相关领域。该方法包括：获取N个文本信息；依据N个文本信息和目标分类模型确定N个文本信息对应的类别信息；依据N个文本信息对应的类别信息确定目标指令，并将N个文本信息和目标指令输入信息提取模型进行处理，得到N个文本信息中的目标信息；基于N个文本信息中的目标信息和数据库中的信息确定问题信息对应的答案信息，并将答案信息返回至第一对象。通过本申请，解决了相关技术中通过客服手动查询相关文件的方式回答客户提出的与金融相关的问题，导致回答该问题的效率较低的问题。
G10L15/22  ,音频信号处理方法、装置、设备、车辆以及存储介质 [发明],本公开提供了一种音频信号处理方法、装置、设备、车辆以及介质，所述方法包括：通过多个车载拾音装置对多个目标环境音区的声音信号进行采集，得到包括近端语音信号和回声信号的多路音频信号；获取回声参考信号，将多路音频信号和回声参考信号输入至训练好的音频信号处理模型中，得到与各个目标环境音区对应的多路目标语音信号；音频信号处理模型基于多路音频样本信号经有监督训练得到；音频样本信号为人声样本信号与回声参考样本信号混合得到的；每路音频样本信号对应的样本标签为纯净人声信号。本公开实施例利用预先训练好的音频信号处理模型对多路音频信号进行回声消除处理以及音区分离处理，进而可以提升各个音区输出语音信号的的准确性。
G10L17/04  ,一种语音转换主动防御方法、装置、系统及存储介质 [发明],本发明公开了一种语音转换主动防御方法、装置、系统及存储介质，属于音频主动防御技术领域，方法包括：基于预构建的GAN网络，设置损失函数和训练参数，并对所述GAN网络中的生成器网络和判别器网络进行训练；将读取到的干净样本输入至训练好的生成器网络生成对抗扰动，并将所述对抗扰动加至所述干净样本，获取对抗样本；将所述对抗样本输入至预训练的各语音转换模型进行测试，利用测试好的对抗样本进行语音转换主动防御；其中，所述判别器网络能够判别所述对抗样本和干净样本的差异。该方法能够快速生成对抗扰动，对语音转换模型进行主动防御，保护说话人的隐私。
G10L15/00  ,一种多语种语音识别系统及方法 [发明],一种多语种语音识别系统及方法，属于语音识别技术领域。首先构建多语种的独立声学模型和语言模型，然后将各声学模型的建模单元线性投影至一个通用的混合建模单元输出，独立构建的各语种语言模型与该统一的建模单元进行结合，构建各语种的语音识别系统解码所需要的网络(如WFST网络)，然后对语种网络进行并行解码。所述系统及方法通过构建统一建模声学单元与语种独立语言模型进行结合的方式，完成多语种语音识别系统。
G10L15/08  ,基于前后鼻音的智能问答方法、装置、设备及存储介质 [发明],本发明涉及人工智能技术，揭露了一种基于前后鼻音的智能问答方法、装置、设备及存储介质。所述方法包括：对用户输入的语音音频数据进行拆分得到音素序列；根据前后鼻音声韵母转换规则对音素序列进行声韵母转化得到音素排列矩阵，并量化得到音素向量矩阵；对音素向量矩阵中的各个音素向量进行全连接得到组合音素序列集合；对组合音素序列集合中的各个组合音素序列进行特征提取及分词识别操作，得到每个组合音素序列对应的分词排列矩阵；对各个分词排列矩阵进行分词排列，识别分词排列结果的意图完整性，得到完整意图语句；根据当前业务场景信息对完整意图语句进行筛选，得到语音意图文本。本发明可以增加语音识别准确率，实现提高智能问答效率。
H04N23/61  ,多媒体数据采集方法及装置、存储介质、计算机设备 [发明],本申请公开了一种多媒体数据采集方法及装置、存储介质、计算机设备，该方法包括：通过声音采集设备进行音频数据采集，以及通过视频采集设备进行视频数据采集；将音频数据转换为文本数据，以及对视频数据进行动作识别和物体检测，确定视频数据对应的目标动作信息和目标物体信息；基于文本数据、目标动作信息和目标物体信息，通过大语言模型生成指令理解语句，通过大语言模型生成指令理解语句对应的目标多媒体数据采集指令并与控制指令库作对比；若控制指令库中不包含目标多媒体数据采集指令，则将目标多媒体数据采集指令添加至控制指令库中，并基于控制指令库中的目标多媒体数据采集指令对多媒体数据采集设备进行控制。
G10L21/028  ,变电设备声源定位方法、装置、电子设备及存储介质 [发明],本申请提供了一种变电设备声源定位方法、装置、电子设备及存储介质，涉及变电设备技术领域，包括：获取变电设备的声源数据，声源数据包括设备声源数据和环境声源数据；对设备声源数据和环境声源数据进行分析，得到设备声源特性参数和环境声源特性参数；对设备声源特性参数和环境声源特性参数分别进行去噪处理，得到声源信号；采用波束形成算法对声源信号进行声源定位，得到声源位置数据。本申请能够实现变电设备噪声声源的准确定位。
G10L21/10  ,基于离散编码的语音驱动嘴型生成方法及装置 [发明],本申请提供了一种基于离散编码的语音驱动嘴型生成方法及装置，其中，该方法包括：采用向量量化的方式对面部图片进行离散编码，得到多个第一离散向量，并将所述离散向量转化为中间特征；对所述中间特征进行解码，得到与所述第一离散向量的维度对应的第二离散向量，并基于所述第二离散向量生成嘴型。本申请解决了现有技术中生成嘴型的自然度不高的技术问题。
G10L19/008  ,语音处理方法、装置、电子设备及存储介质 [发明],本公开提供了一种语音处理方法、装置、电子设备及存储介质，涉及语音处理技术领域。该方法包括：对接收的语音数据进行分割，得到多个第一语音数据片段；在多个第一语音数据片段中每个第一语音数据片段中添加元数据时间戳，得到多个第二语音数据片段；根据多个第二语音数据片段进行语音来源对象识别，得到至少一个语音来源对象对应的语音数据序列；其中，语音数据序列中包含至少一个第二语音数据片段，至少一个第二语音数据片段的识别结果为同一语音来源对象；对每个所述语音数据序列分别进行压缩，得到压缩语音数据，本公开能够取得更高的压缩率，大大节省压缩、存储和传输的成本；使得冗余信息大大减少，能够缩短压缩处理的时间。
H04M3/527  ,一种基于智能语音机器人的催收方法与系统 [发明],本发明提供一种基于智能语音机器人的催收方法与系统，属于语音识别技术领域，具体包括：获取催收案件的历史催收数据和历史接通数据的确定，并基于历史催收数据和历史接通数据进行催收案件的催收优先值的确定，根据被催收人员在不同的历史催收次数下的历史语音特征进行催收案件的不同的历史催收次数下的接通人员相似性的确定，并结合催收优先值进行催收顺序的确定，按照所述催收顺序，采用智能语音机器人进行所述催收案件的催收，通过催收案件的被催收人员的语音数据进行被催收人员的语音关键词的确定，并结合被催收人员的相似度评估结果以及沟通时长确定是否需要进行挂断处理，从而进一步提升了催收处理的效率。
G10L25/45  ,一种基于FFT分析的单音信号功率准确度提升方法 [发明],本发明公开了一种基于FFT分析的单音信号功率准确度提升方法，包括如下过程：对单音信号分别进行加窗和频率检测，通过对单音信号进行加窗，得到单音信号加窗后的窗函数的频谱；通过对单音信号进行频率检测得到单音信号的频率；利用单音信号加窗后的窗函数的频谱得到单音信号在最邻近子载波上的泄露量，根据单音信号在最邻近子载波上的泄露量得到补偿量；对FFT谱分析的最邻近子载波进行幅度或者功率补偿，使单音信号的FFT谱功率可以正确显示。通过本发明，可以实现既不用缩小fs，也不用增大N，也就是说在不改变RBW的情况下，提高单音信号FFT谱分析的功率准确度。
G10L13/02  ,人机交互方法及装置 [发明],本发明实施例公开了一种人机交互方法及装置。本发明实施例的人机交互方法会采集交互对象的语音数据，并根据所述语音数据确定出交互对象的当前情绪状态，再至少基于所述当前情绪状态和虚拟助手当前人物设定的语言风格确定交互文本和交互语气，进而根据所述交互文本和交互语气向所述交互对象提供语音交互。由此，通过至少基于交互对象的当前情绪状态和虚拟助手当前人物设定的语言风格来确定交互文本和交互语气，本发明实施例可以使虚拟助手向交互对象提供与交互对象的当前情绪状态和虚拟助手当前人物设定的语言风格相匹配的语音交互内容，从而改善人机交互体验。
G10L25/51  ,基于全局-局部特征再校准的多声源定位与检测方法 [发明],本发明公开了一种基于全局‑局部特征再校准的多声源定位与检测方法，包括计算一阶立体声格式的多通道空间音频信号的短时傅里叶变换，获得log线性频谱和归一化的声强向量作为输入特征后，对训练集的特征做数据增广；将增广后的频谱和声强向量拼接作为神经网络模型的输入，对神经网络模型进行训练，获得最优的网络模型参数并保存；对待测试样本进行预处理后送入训练好的模型中，输出获得预测的声音事件类别和位置信息，根据预测结果绘制声音事件检测图、方向角和方位角轨迹曲线图，并与测试样本真实标签的可视化图像进行对比，分析模型的性能。本发明可以达到较高的声源定位与检测性能，模型在真实和合成数据集上都表现出较好的泛化性。
G10L25/63  ,一种基于叠加模型融合宽度学习系统的语音情感识别方法 [发明],本发明提出一种基于叠加模型融合宽度学习系统的语音情感识别方法，该方法通过构建包含支持向量机、卷积神经网络、长短期记忆的多模型集成框架并采用宽度学习系统二次融合，实现对语音情感的识别，与依靠单一模型的识别方法相比具有很大的技术进步，经语音情感数据集选择、语音数据预处理、声学特征工程、基模型训练、多模型集成、宽度学习二次融合，最终构建出端到端的语音情感识别系统，该系统可以实现对语音情感的自动分析和判断，具有较好的识别效果。
G10L25/78  ,一种单音信号检测方法 [发明],本发明涉及信号检测，具体涉及一种单音信号检测方法，将待测信号转换为数字信号，并对数字信号进行端点检测；对输出的数字信号进行预处理，并对预处理后的数字信号进行特征提取；对提取特征进行陷波滤波检测，根据检测结果判断待测信号中是否存在单音信号；获取m个采样点的单音信号，并对m个采样点的单音信号进行频率估计，得到m个频率估计值；对m个频率估计值进行累加平均计算，得到单音信号的频率值；本发明提供的技术方案能够有效克服现有技术所存在的无法有效检测是否存在单音信号并对单音信号进行精确频率估计的缺陷。
G10L15/22  ,交互优化组件、方法和计算机可读存储介质 [发明],本发明涉及语音交互技术领域，公开了一种交互优化组件、方法和计算机可读存储介质，通过将多模语义识别结果进行功能过滤和交互场景过滤，并对过滤结果进行确认整合，将匹配结果下发到语音助手，从而实现语义功能过滤、需要静默交互的单次交互的场景过滤，从而提高了多模交互的便利性和用户体验。
G10L15/22  ,一种基于多音区交互的可见即可说系统 [发明],本发明公开了一种基于多音区交互的可见即可说系统，所述系统包括语音助手模块以及多音区可见即可说SDK模块；所述语音助手模块响应用户的语音输入，识别出所述语音输入中的控制功能和控制音区，作为识别结果，将识别结果发送至所述多音区可见即可说SDK模块；所述多音区可见即可说SDK模块根据识别出控制功能和控制音区在预先根据应用端控制界面建立的匹配关系表匹配对应的控件信息，并将匹配的控件信息反馈到所述语音助手模块；所述语音助手模块响应接收的控件信息，在所述应用端的控制界面执行对应控制。能够通过语音交互实现对车机应用端的控制界面中所有操控组件的控制，实现可见即可说的多音区语音交互功能。
G10L21/0208  ,对讲终端的语音处理方法、装置、终端设备及存储介质 [发明],本发明公开了一种对讲终端的语音处理方法、装置、终端设备及存储介质。所述方法包括：获取对讲终端的输入语音；对所述输入语音进行检测，在检测到所述输入语音包含噪声时，将所述输入语音输入降噪模型中，以使所述降噪模型提取输入语音中的活动语音，并对所述活动语音进行增益，输出消除噪声的第一语音；根据所述第一语音确定输出语音，以使对讲终端输出所述输出语音。通过实施本发明能提高对讲终端输出语音质量。
G06F3/01  ,虚拟数字人面部表情管理方法、装置、电子设备及介质 [发明],本发明公开了虚拟数字人面部表情管理方法、装置、电子设备及介质，包括：获取实验对象的多媒体资源，多媒体资源至少包括实验对象在对话过程中的语音信息和面部图像信息；对语音信息和面部图像信息进行处理，得到多组文本以及每组文本对应的面部特征信息；面部特征信息包括面部器官的位置信息和形态信息；按照情绪维度对多组文本进行聚类，并生成每类文本对应的目标属性标签，以及表述目标属性标签的关键信息；针对每类文本对应的面部特征信息，根据所有面部器官的位置信息和形态信息生成面部器官的目标位置信息和目标形态信息，并建立目标属性标签、关键信息、面部器官的目标位置信息和目标形态信息的关联关系。
G06F18/24  ,基于迁移学习的音频和文本的宽时间范畴情感识别方法 [发明],本发明公开涉及基于迁移学习的音频和文本的宽时间范畴情感识别方法，通过使用预训练模型VGGish和BERTbase提取音频和文本两个模态的情感特征，从不同的角度对目标人物的情感进行分析；通过事实描述和文本描述进行情感特征的提取，在宽时间范畴内对目标人物目前的情感状态进行更准确的推理，通过在SVCEmotion数据集的音频和文本描述数据上的实验证明，VGGish和BERTbase预训练模型均能在本文使用的数据集上实现良好的效果，模型在预训练过程中学习到的参数能够有效的提升其在目标任务上的表现；对比实验证明，SVCEmotion数据集中针对宽时间范畴下的情感识别任务引入的情境描述可以为情感识别提供线索，且与事实描述结合能大幅提升情感识别效果。
G01R31/00  ,一种变压器运行状态在线监测系统 [发明],本申请涉及一种变压器运行状态在线监测系统，所述系统包括智慧声纹终端和服务器端；所述智慧声纹终端包括麦克风阵列、信号处理单元以及数据传输单元：所述麦克风阵列实时采集变压器的多通道声音信号；所述信号处理单元对所述麦克风阵列实时采集的多通道声音信号进行处理，生成声音图像数据；所述数据传输单元将声音图像数据传输至服务器端；所述服务器端包括状态监测单元、可视化单元：所述状态监测单元基于声音图像数据以及内置的状态监测模型，对变压器的运行状态进行实时监测，输出变压器的实时运行状态信息；所述可视化单元，用于显示声音图像数据以及变压器的实时运行状态信息。本申请能够实现对变压器实时运行状态的监测。
G10L25/63  ,语音情绪识别方法、装置、电子设备及存储介质 [发明],本申请涉及数据处理技术领域，提供一种语音情绪识别方法、装置、电子设备及存储介质，该方法包括：将原始语音数据输入至语音情绪识别模型；通过数据预处理模块对原始语音数据进行预加重处理、分帧与加窗处理以及端点检测处理，输出语谱图样本；通过语谱图像增强模块以生成式对抗网络对语谱图进行图像增强，输出语谱图组合集；通过双层特征提取融合模块对原始语音数据和语谱图组合集进行特征提取并特征融合，输出语音情绪识别结果。本申请实施例通过数据处理模块、语谱图像增强模块和双层特征提取融合模块的语音情绪识别模型进行语音情绪识别，解决了语音情绪识别中数据稀疏性和类间失衡的问题，提高了语音情绪识别准确性。
G10L25/18  ,一种暖通机房异常音频识别方法及装置 [发明],本申请公开了一种暖通机房异常音频识别方法及装置，涉及暖通技术领域，通过将待识别音频的MFCC特征和正常音频数据的MFCC特征进行合并得到待分类数据集，然后采用预先训练好的KMeans算法和孤立森林算法分别对待分类数据集进行分类，并根据分类结果判断待识别音频是否异常，从而得到第一预测结果和第二预测结果；对第一预测结果和第二预测结果进行投票，根据投票结果最终确定待识别音频是否异常。本申请能够在暖通场景下对特定设备有针对性的进行声音信号分析，并得到预测结果，避免了单个算法单独判断时出现错误的情况，能够准确的判断设备异常声音，减少错判率，提高计算效率。
G10L15/22  ,设备唤醒方法、装置、存储介质及电子设备 [发明],本申请公开了一种设备唤醒方法、装置、存储介质及电子设备，涉及物联网技术领域，该方法包括：获取目标用户的多个用户语音对应的唤醒评定信息；从所述多个用户语音对应的唤醒评定信息中，提取至少包括各所述用户语音的唤醒置信度的语音特征信息，所述唤醒置信度为语音唤醒模型对用户语音分析得到的；对所述语音特征信息进行分析处理，得到所述目标用户对应的用户语音唤醒阈值，所述用户语音唤醒阈值用于判断是否根据所述目标用户的唤醒语音进行设备唤醒。本申请可以提升设备的语音唤醒效果，提升用户的体验。
G10L25/51  ,电抗器故障检测方法、装置、电子设备和存储介质 [发明],本公开提供了一种电抗器故障检测方法、装置、电子设备和存储介质。具体实现方案为：计算饱和电抗器的声音采集信号对应的声音频域信号中任一频点的时频分辨率的取值范围；在该取值范围内，计算频点在各个时频分辨率下的S变换矩阵以及S变换矩阵的能量聚集值；在频点在各个时频分辨率下的S变换矩阵中，基于最小的能量聚集值所对应的S变换矩阵，确定目标S变换矩阵；基于声音频域信号中各个频点的目标S变换矩阵，构建声音频域信号对应的声音时频矩阵；从声音时频矩阵中，提取饱和电抗器的声纹特征；采用故障识别模型，对声纹特征进行识别，得到饱和电抗器的故障信息。采用本公开的技术方案，可以提高电抗器故障检测的准确率。
G09B5/06  ,一种多线程应用程序在线学习方法、学习系统和测试方法 [发明],本发明提出了一种多线程应用程序在线学习方法、学习系统和测试方法，学习方法包括：对学习视频进行解析，利用Whisper模型获取所述学习视频中老师讲课的语音信息，并从所述语音信息中截取专业词汇；将所述专业词汇切分成单个字符，分别获取每个字符的拼音信息，将相邻两所述字符的拼音信息进行合并，生成拼音数据；将专业词汇生成文本数据，利用所述文本数据和拼音数据在数据库中进行匹配，获取所述数据库中对专业词汇的解释信息；并将所述专业词汇的解释信息显示在专业词汇解释栏中。通过上述方法解决了用户在学习过程中用户对老师讲课的专业词汇不懂而影响学习效果的问题，并提高了用户的学习效率和兴趣，同时使得用户学习变得轻松。
H04N21/234  ,歌词文件生成方法、计算机设备和计算机可读存储介质 [发明],本申请涉及歌词文件生成方法、计算机设备和存储介质。所述方法包括：从音乐视频中提取得到视频帧集合和音频数据；提取视频帧集合中各视频帧的歌词数据，得到第一歌词集合，以及提取出音频数据的歌词数据，得到第二歌词集合；从第二歌词集合中，确定与第一歌词集合中任一歌词数据的时间戳对应的歌词数据，作为目标歌词数据；获取任一歌词数据与目标歌词数据，得到第一相似度，基于第一相似度确定目标歌词集合；采用基于目标歌词集合确定的参照曲目歌词集合，计算目标歌词集合与参照曲目歌词集合的第二相似度，调整目标歌词集合中歌词的内容，得到音乐视频对应的歌词文件。采用本方法能够避免歌词漏检和误检，有效提升了歌词文件生成的准确度。
G10L15/02  ,语音识别方法、装置、设备及存储介质 [发明],本申请提供了一种语音识别方法、装置、设备及存储介质，具体实现方案为：基于第i帧音频的标签状态确定跳帧数；其中，i为正整数；利用所述跳帧数对所述第i帧音频进行跳帧解码处理，得到目标音频帧对应的非空白标签特征；其中，所述目标音频帧表示第i+1帧音频之前的标签状态为非空白标签的音频帧；基于所述第i+1帧音频和所述目标音频帧对应的非空白标签特征，预测所述第i+1帧音频的标签状态；根据所述第i+1帧音频的标签状态确定所述第i+1帧音频的语音识别结果。根据本申请的技术方案，能够显著提升推理速度，从而提高语音识别的效率。
G10K11/178  ,头戴设备语音处理方法和头戴设备 [发明],公开了一种头戴设备语音处理方法和头戴设备。该语音处理方法包括：获取麦克风采集的原始时域信号；对原始时域信号进行基于方向的增强抑制处理，以获取经处理时域信号，其中，根据头戴设备的当前使用场景选择增强抑制处理中需要增强和/或抑制的方向；根据原始时域信号与经处理时域信号的能量判定是否进行基于原始时域信号的语音处理。本公开基于经处理信号相比于原始信号的能量衰减程度来判定采集信号是否包含目标说话人的语音信息，尤其能够准确分辨非目标说话人大声说话的情况，避免头戴设备的误操作。
G10L25/51  ,一种语音识别故障噪音的检测方法、系统和装置及介质 [发明],本发明公开了一种语音识别故障噪音的检测方法、系统和装置及介质，涉及电风扇或电机的故障诊断技术领域，所述检测方法包括如下步骤：获取发生预设噪音之间的有效时长；判断相邻两个有效时长CT＆lt;subgt;n＆lt;/subgt;和CT＆lt;subgt;n+1＆lt;/subgt;的大小：若相差在预设阈值内，则累加计数CNT＆lt;subgt;0＆lt;/subgt;；若相差超过预设阈值，则抛出时长CT＆lt;subgt;n＆lt;/subgt;，并计数抛出的数量DCT＆lt;subgt;x＆lt;/subgt;；在累加计数CNT＆lt;subgt;0＆lt;/subgt;过程中，抛出的数量DCT＆lt;subgt;x＆lt;/subgt;达到设定数量时，将计数CNT＆lt;subgt;0＆lt;/subgt;清零，当计数CNT＆lt;subgt;0＆lt;/subgt;累加达到设定上限时，进行故障上报。本发明采用语音识别故障噪音，根据风扇或电机运行的转速识别预设的摩擦噪声，并进行故障报警，及时检测电机或扇叶出现故障噪音异常的情况。
G10L15/02  ,多任务音频处理方法、系统、存储介质及电子设备 [发明],本发明提供一种多任务音频处理方法、系统、存储介质及电子设备，所述方法包括以下步骤：获取用于训练的音频；获取所述音频的标签信息；所述标签信息包括音频的语种信息、语音转文本方式、语音起止时间和音频对应文本信息，所述语音转文本方式包括语音翻译和语音转写；基于所述音频和所述标签信息训练多任务音频处理模型，以基于训练好的多任务音频处理模型获取待处理音频的标签信息。本发明的多任务音频处理方法、系统、存储介质及电子设备能够兼容完成多个音频处理任务，有效地减少了硬件资源和处理耗时。
H04W72/044  ,环境音分类方法、电子设备及存储介质 [发明],本发明实施例公开了一种环境音分类方法、电子设备及存储介质，其中方法包括：将环境音经过预处理后变换到频域，计算出所述环境音的初始频谱周期图；计算后验环境音存在概率，基于所述环境音的初始频谱周期图和所述后验环境音存在概率采用最小均方误差方法估计环境声功率谱；计算所述环境声功率谱在预设的伽马通滤波器中的伽马通能量，对所述伽马通能量进行非线性压缩和离散余弦变换提取APNCC系数；基于所述APNCC系数对所述环境音进行分类。采用本发明的方法，能快速跟踪一般非平稳噪声的功率谱，减少了对环境声功率谱的估计误差，提高了环境音分类的准确度。
G10L15/22  ,基于AI语音助手的语音呼入处理方法、装置及设备 [发明],本发明涉及语音识别领域，公开了一种基于AI语音助手的语音呼入处理方法、装置及设备。该方法包括：当监测到用户呼入的语音呼叫时，将所述语音呼叫转入人工智能语音助手，并基于所述人工智能语音助手获取所述用户的语音信息；对所述语音信息进行识别，得到所述用户的目标需求，根据所述目标需求得出处理方案，并根据所述处理方案处理所述目标需求。本发明提供的是一种基于AI语音助手的语音呼入处理方法，可以快速获取用户的响应结果，提高了呼叫的处理效率；根据用户的响应结果及时对所存在的问题进行处理，可以提升用户体验；还基于目标用户的不同交互意图采取对应的处理方式，进一步提高物流运营效率。
G02B27/01  ,AR眼镜及AR眼镜控制方法 [发明],本申请涉及增强现实显示设备技术，公开了一种AR眼镜及AR眼镜控制方法，AR眼镜包括：镜框模组，用于提供佩戴支撑；显示模组，包括设置于镜框模组的光波导组件及对应光波导组件设置的光机，光波导组件用于接收光机发出的光信号并形成出射光；第一语音采集组件，连接于镜框模组内侧，第一语音采集组件用于在目标对象佩戴AR眼镜时，与目标对象接触以采集目标对象发出的语音；第二语音采集组件，设置于镜框模组，用于语音采集；控制装置，用于获取第一与第二语音采集组件的语音采集结果以控制光机光信号输出。通过第一与第二语音采集组件配合采集语音信息，提升采集针对性识别不同来源的语音信息，便于将识别的外部语音转为文字并显示在佩戴者视野中。
G10L17/22  ,航空器材的智能货柜的控制方法、系统、设备及存储介质 [发明],本发明公开了一种航空器材的智能货柜的控制方法、系统、设备及存储介质，本发明采用语音识别技术来进行智能货柜的人员身份验证以及自动取货控制，如此，只需要用户在取货时提供简单的语音信息，就能在数量庞大，分类复杂的智能货柜中简单明了的打开所需要的货柜，因此，相比于传统技术，本发明无需用户事先查阅货物所在货柜的编号以及无需输入密码，操作简单便捷，不仅节约了操作者的时间，提高了取货效率，且在取货时验证了人员身份的合法性，保证了取货安全；基于此，本发明非常适用于在智能货柜控制领域的大规模应用与推广。
A61B5/087  ,一种基于声音衍射原理的肺通气功能测量装置和方法 [发明],本发明适用于医疗器械技术领域，提供了一种基于声音衍射原理的肺通气功能测量装置和方法，该装置包括气流管道和孔板；所述气流管道的管壁开设有音频输入孔和音频输出孔，所述音频输入孔与手机的音频输入口耦合，所述音频输出孔与手机的音频输出口耦合；所述孔板设置在所述气流管道内，并位于所述音频输入孔和音频输出孔之间，所述孔板包括多个扇形薄膜片，多个所述扇形薄膜片可枢转的呈圆周排列设置；所述气流管道靠近所述音频输出孔的一段为通气管路一，所述气流管道靠近所述音频输入孔的一段为通气管路二；本发明可低成本的实现肺通气功能测试，配合智能手机使用，非常方便，并且无需设置流量传感器，不存在现有采用涡轮流量传感器的缺点。
G10L15/06  ,一种使用检索增强技术强化CTC解码的语音识别方法 [发明],本发明属于语音识别技术领域，更具体地，涉及一种使用检索增强技术强化CTC解码的语音识别方法。该方法给定一个预训练后的CTC解码模型，首先利用数据经过特征编码器得到帧级别向量，然后以帧级别的向量与CTC伪标签形成键值对，构造细粒度键值数据存储。最后，在解码阶段通过检索帧级向量和对应的CTC伪标签对CTC解码解决进行线性插值，提升语音识别系统的性能。
G08B21/18  ,一种高压电力电缆防外破在线监测系统及方法 [发明],本发明涉及一种高压电力电缆防外破在线监测系统及方法，通过在电缆管道、外护套等处加装带通信功能的报警装置，当有大型机械在电缆上方施工作业时，一定会产生较大的震动，震动传感器采集到震动后，将自身所在位置远程传到系统中，电缆运维人员接到报警，根据位置确定为哪段电缆，可前往现场查看，对破路施工方进行路径交底，避免电缆外破事件。本发明通过将现场采集的震动信号传到运维人员，一是避免了人工巡视施工动土场地，大大节省了人力物力等成本；二是方便运维人员第一时间掌控施工动土路段，大比例降低高压电缆外破发生率。此外，本发明还对周围的声音信息进行采集，通过现场声音信息进一步辅助确认是否为施工作业。
G06F16/25  ,智慧城市系统、方法、设备及存储介质 [发明],本申请关于一种智慧城市系统、方法、设备及存储介质，涉及计算机技术领域。智慧城市系统包括业务与应用模块、数据融合模块、数据预处理模块、大数据中心模块和基础设施模块；业务与应用模块用于采集智慧城市数据，并向数据融合模块发送智慧城市数据；数据融合模块用于将业务与应用模块发送的智慧城市数据转换为预设数据格式，并向数据预处理模块发送数据格式转换后的智慧城市数据；数据预处理模块用于将数据融合模块发送的数据格式转换后的智慧城市数据进行预处理，以得到预处理结果；大数据中心模块用于响应于智慧城市服务处理请求，从预处理结果中，确定并展示智慧城市服务处理请求对应的智慧城市数据。
G01R31/00  ,基于混合神经网络的电力变压器故障检测方法 [发明],基于混合神经网络的电力变压器故障检测方法，解决了利用电力变压器频域特征和神经网络进行电力变压器故障诊断的易受噪声影响的问题，属于电力设备检测领域。本发明包括：采集待诊断电力变压器的声音信号，构建训练集：声音信号的频域特征作为输入，电力变压器的状态作为输出；基于混合神经网络构建电力变压器故障检测网络，电力变压器故障检测网络采用LCNN模型实现，其残差模块包括一个输入层、一个卷积层、一定数量的深度残差收缩模块、一个批标准化、一个ReLU激活函数、一个全局均值池化和一个全连接输出层；利用训练集对电力变压器故障检测网络进行训练，利用训练好的电力变压器故障检测网络对待诊断电力变压器进行故障检测。
G10L25/66  ,一种基于第二心音分裂系数的房间隔缺损检测方法 [发明],本发明公开了一种基于第二心音分裂系数的房间隔缺损检测方法，包括第二心音S＆lt;subgt;2＆lt;/subgt;自动分割提取；第二心音分裂系数定义及第二心音分裂时间隔计算；房间隔缺损检测方法及评价指标。本发明采用上述一种基于第二心音分裂系数的房间隔缺损检测方法，通过对标准数据库与临床数据进行性能评估及验证，可实现房间隔缺损型心音高精度(＆gt;95％)自动检测。
H04N21/234  ,视频生成方法、装置、电子设备及存储介质 [发明],本公开提供了一种视频生成方法、装置、电子设备及存储介质，涉及计算机技术领域，尤其涉及自然语言处理、深度学习等人工智能技术领域。具体实现方案为：获取待生成视频的初始文本对应的镜头文本、及所述镜头文本对应的候选视频；将每个所述候选视频对应的视频特征与所述镜头文本对应的文本特征进行对齐，以获取每个所述候选视频对应的目标特征；根据每个所述目标特征，确定每个所述候选视频对应的视频描述文本；根据每个所述视频描述文本与所述初始文本之间的相似度，从所述候选视频中确定所述镜头文本对应的目标视频；基于所述镜头文本对应的目标视频，生成与所述初始文本对应的视频。
G10L17/02  ,一种语音活动检测方法、装置、设备及存储介质 [发明],本申请公开一种语音活动检测方法、装置、设备及存储介质，该方法包括：获取混合语音和第一说话人的注册语音；利用第一个性化语音活动检测PVAD模型对混合语音和注册语音进行特征提取，并基于提取到的混合语音的帧级别声学特征和注册语音的帧级别声学特征，得到第一说话人在每帧子混合语音上的概率分布。如此，通过利用注册语音的帧级别声学特征作为第一说话人的说话人信息，这样在使用短语音(如唤醒词语音)进行注册时，能够提取到短语音的更精细的语音信号特性，进一步保证PVAD模型的输出结果的准确性，从而提升PVAD模型的召回率。